\documentclass[12pt]{article}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{color}
\usepackage{mathrsfs}
\usepackage{fullpage}
\usepackage{commath}
\usepackage{graphicx}
\usepackage{pdfcomment}
%\usepackage{coffee4}
\usepackage{lipsum}
%\usepackage{showkeys}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{verbatim}
\usepackage{longtable}

%General Shorthand Macros
\newcommand{\skipLine}{\vspace{12pt}}
\newcommand{\mb}{\mathbb}
\newcommand{\mc}{\mathcal}
\newcommand{\ms}{\mathscr}
\newcommand{\ra}{\rightarrow}
\newcommand{\ov}{\overline}
\newcommand{\os}{\overset}
\newcommand{\un}{\underline}
\newcommand{\te}{\text}
\newcommand{\ep}{\epsilon}
\newcommand{\tr}{\textcolor{red}}
\newcommand{\tb}{\textcolor{blue}}
\newcommand{\tg}{\textcolor{green}}
\newcommand{\labe}[1]{\tr{\texttt{Label: #1}}}
\newcommand{\tbs}{\textbackslash}
\newcommand{\purpose}{\textbf{Purpose: }}
\newcommand{\pfsum}{\textbf{Proof Summary: }}
\newcommand{\usein}{\textbf{Used in: }}
\newcommand{\app}{\textbf{Applies: }}
\newcommand{\ind}{\hspace{24pt}}
\newcommand{\lin}{\rule{\linewidth}{0.4 pt}}
\newcommand{\pr}{\mb{P}}							%probability
\newcommand{\ex}[1]{\mb{E}\left[#1\right]}			%expectation
\newcommand{\exmu}[2]{\mb{E}^{#1}\left[#2\right]}	%exp wrt a measure
\newcommand{\deq}{\overset{\text{(d)}}{=}}			%equal in dist
\newcommand{\defeq}{:=}								%definition equal
\newcommand{\msr}{\mc{M}}							%space of measures
\newcommand{\pmsr}{\mc{P}}							%space of pmsrs
\newcommand{\neigh}{\mc{N}}					%neighbor
\newcommand{\dneigh}{\mc{N}^2}				%double neighbor
\newcommand{\cad}{\mb{D}}							%Cadlag space


%Paper macros
%Section 2.1
%base commands
\renewcommand{\root}{\mathbf{0}}				%root
\renewcommand{\v}{v}							%typical vertex
\newcommand{\vv}{u}								%typical 2nd vertex
\newcommand{\vvv}{w}							%typical 3rd vertex
\renewcommand{\U}{U}							%typical vertex set
\newcommand{\UU}{W}								%typical 2nd vert set
\newcommand{\UUU}{R}							%typical 3rd vert
\renewcommand{\S}{S}							%State space
\newcommand{\s}{\sigma}							%elt of \S	
\newcommand{\sv}{\vec{\s}}						%typ elt of \XState
\renewcommand{\b}{b}							%inf dim norm coeffs
\newcommand{\ev}[1]{\ep^{#1}}					%standard basis
\newcommand{\T}{T}								%time bound
\newcommand{\x}{x}								%typical elt of Omega
\renewcommand{\t}{t}							%typical time
\newcommand{\sset}{\Omega}						%sample set
\newcommand{\proj}{\pi}							%projection operator
\newcommand{\svnorm}[1]{\|#1\|_{\b}}			%norm of S^V
\newcommand{\omenorm}[1]{\|#1\|_{\b,\t}}		%norm on Omega
\renewcommand{\tt}{s}							%typical time 2
\newcommand{\ttt}{s'}							%typical time 3
\newcommand{\F}{\mc{F}}							%Filtrations
\newcommand{\FG}[2]{\mc{G}}						%Filtrations
\newcommand{\FH}[2]{\mc{H}}						%Filtrations
\newcommand{\X}{X}								%typ random process

%Modifiers
\newcommand{\cl}{\ov}							%closure
\newcommand{\ve}[1]{_{#1}}						%Append vertex
\renewcommand{\ss}[1]{^{#1}}					%vertex set identifier
\newcommand{\tp}[1]{(#1)}						%Time of process
\newcommand{\ts}[1]{_{#1}}						%time bound of set



\newcommand{\degr}{D}								%max degree
\newcommand{\poiss}[1]{N_{#1}}						%Poisson process
\newcommand{\poisses}{\mathbf{N}}				%all Poisson processes
\newcommand{\IG}{\mc{A}}						%Infinitesimal gens
\newcommand{\law}{\te{Law}}							%Law of a process
\newcommand{\leb}{\te{Leb}}							%Lebesgue measure
\newcommand{\pup}[1]{^{#1}}							%Scaling prelimit
\newcommand{\tree}{\mc{T}}							%Tree Subgraph
\newcommand{\core}{\mc{D}}							%Core

\renewcommand{\SS}{\tilde{\S}}						%sub state space

\renewcommand{\ss}{\tilde{\s}}					%2nd elt of \S
\renewcommand{\G}{G}								%Graph
\newcommand{\V}{V}									%Vertex set
\newcommand{\E}{E}									%Edge set




\renewcommand{\r}{r}								%space var for poiss
\newcommand{\rt}[1]{\tau^{#1}}						%typical rand time
\newcommand{\rtt}[1]{\theta^{#1}}					%typical rand time 2
\renewcommand{\it}{k}								%iterator
\newcommand{\itt}{i}								%iterator 2
\newcommand{\ittt}{j}								%iterator 3
\newcommand{\numb}{n}								%# of prelim vars
\newcommand{\XState}[1]{\S^{#1}}				%multidim state space




\newcommand{\piV}[2]{\pi_{#1}^{#2}}					%projection
\newcommand{\xvtt}[2]{y_{#1}{(#2)}}					%typ path val2
\newcommand{\xvttt}[2]{z_{#1}{(#2)}}				%typ path val3
\newcommand{\rxvtt}[2]{Y_{#1}{(#2)}}				%typ rand path val2
\newcommand{\rxvttn}[3]{Y_{#1}^{#3}(#2)}			%typ rp sublim val2
\newcommand{\rxvttt}[2]{Z_{#1}{(#2)}}				%typ rand path val3

\newcommand{\xvtts}[2]{y_{#1}{#2}}					%typ path 2
\newcommand{\xvttts}[2]{z_{#1}{#2}}					%typ path 3
\newcommand{\rxvtts}[2]{Y_{#1}{#2}}					%typ rand path 2
\newcommand{\rxvttsn}[3]{Y_{#1}^{#3}{#2}}			%typ rpath sublim 2
\newcommand{\rxvttts}[2]{Z_{#1}{#2}}				%typ rand path 3
\newcommand{\rxvtttsn}[3]{Z_{#1}^{#3}{#2}}			%typ rpath sublim 3
\newcommand{\rp}[1]{P^{#1}}							%typ point process
\newcommand{\m}[3]{\mu_{#2#1}^{#3}}						%typ measure
\newcommand{\mm}[3]{\nu_{#2#1}^{#3}}						%typ measure 2
\newcommand{\mmm}[3]{\eta_{#2#1}^{#3}}						%typ measure 3
\newcommand{\cm}{\gamma}							%conditional msr funct
\newcommand{\IGr}[1]{c_{#1}}						%IG rate
\newcommand{\rate}[1]{\lambda_{#1}}					%rate
\newcommand{\ratee}[1]{\Lambda_{#1}}				%general rate
\newcommand{\crate}[2]{\alt{\lambda}_{#1}^{#2}}		%conditional rate
\newcommand{\cratee}[2]{\alt{\Lambda}_{#1}^{#2}} 	%general conditional rate

\newcommand{\dist}{d}								%general metric
\newcommand{\gdist}{d_G}							%graph distance
\newcommand{\cont}{\mc{C}}							%space of cont. fs
\newcommand{\const}[1]{C_{#1}}						%Constant
\newcommand{\Sm}{\ell}								%std msr on \S
\newcommand{\alt}{\widetilde}						%alternate val

\newcommand{\mutex}{\|}								%Mutually exclusive
\newcommand{\apath}{\Gamma}						%Given path for CI proof
\newcommand{\pathset}[2]{\Lambda_{#1,#2}}			%A space of paths
\newcommand{\pathsete}[2]{C_{#1,#2}}			%union over pathset
\newcommand{\pathseted}[2]{H_{#1,#2}}			%pathsete with \t
\newcommand{\rv}{A}								%Typical random element
\newcommand{\evnt}{\mc{E}}						%Typical event
\newcommand{\typset}{A}							%Typical set
\renewcommand{\mark}[1]{\kappa^{#1}}				%Typical mark
\newcommand{\dense}[2]{L_{#1}^{#2}}				%Typ density
\newcommand{\cdense}[2]{M_{#1}^{#2}}			%Cond density
\newcommand{\ds}[2]{\Upsilon_{#1}^{#2}}			%mapping in density
\newcommand{\mtop}{\Lambda}						%Markov to point
\newcommand{\spce}{\mc{X}}						%arbitrary space
\renewcommand{\c}[1]{c(#1)}						%child function
\newcommand{\p}[1]{p(#1)}						%parent function
\newcommand{\pmap}[1]{\Gamma_{#1}}				%Markov to MPP	
\newcommand{\inte}{I}							%Interval

\newtheorem{thms}{Theorem: }[section]
\newtheorem{conj}[thms]{Conjecture: }
\newtheorem{prop}[thms]{Proposition: }
\newtheorem{coro}[thms]{Corollary: }
\newtheorem{lem}[thms]{Lemma: }
%\newtheorem{sublem}{Sublemma: }[lem]
\newtheorem{defn}[thms]{Definition: }
\newtheorem{assu}[thms]{Assumption: }

\setlength{\parindent}{0pt}

\begin{document}

\title{A Local Approximation of Finite State Interacting Particle Systems on a Tree (Working Title)}
\author{Ankan Ganguly}

\maketitle

\begin{abstract}
\tg{There will be an abstract here soon enough!}

Title possibilities: Transient dynamics of a typical neighborhood of particles on a regular tree. \tr{Too long and still lacks relevant info!}
\end{abstract}

\newpage
\tableofcontents

\newpage

\section*{For The Author's Use Only (FTAUO)}
\subsection*{Notation}

\begin{longtable}{c|c|c|c}
Macro Command & Arguments & Symbol & Meaning\\\hline
\tbs pr&0&\(\pr\)	& probability\\
\tbs ex&1&\(\ex{X}\)	&expectation\\
\tbs exmu&2&\(\exmu{\m{}{}{}}{\X{\v}{\t}}\)	&exp wrt a measure\\
\tbs deq&0&\(\deq\)		&equal in dist\\
\tbs defeq&0&\(\defeq\)							&definition equal\\
\tbs msr&0&\(\msr\)							&space of measures\\
\tbs pmsr&0&\(\pmsr\)						&space of pmsrs\\
\tbs neigh&1&\(\neigh{\v}\)				&neighbor\\
\tbs dneigh&1&\(\dneigh{\v}\)				&double neighbor\\
\tbs degr&0&\(\degr\)								&max degree\\
\tbs poiss&1&\(\poiss{\v}\)						&Poisson process\\
\tbs poisses&0&\(\poisses\)					&all Poisson processes\\
\tbs IG&0&\(\IG\)					&Infinitesimal gens\\
\tbs law&0&\(\law\)							&Law of a process\\
\tbs leb&0&\(\leb\)							&Lebesgue measure\\
\tbs pup&1&\(\cdot\pup{n}\)						&Prelimit numbering\\
\tbs tree&0&\(\tree\)							&Tree Subgraph\\
\tbs core&0&\(\core\)							&Core\\
\tbs S&0&\(\S\)							&State space\\
\tbs SS&0&\(\SS\)						&sub state space\\
\tbs s&0&\(\s\)								&elt of \tbs State\\
\tbs ss&0&\(\ss\)						&2nd elt of \tbs State\\
\tbs G&0&\(\G\)								&Graph\\
\tbs V&0&\(\V\)									&Vertex set\\
\tbs E&0&\(\E\)									&Edge set\\
\tbs v&0&\(\v\)								&typical vertex\\
\tbs vv&0&\(\vv\)									&typical 2nd vertex\\
\tbs vvv&0&\(\vvv\)								&typical 3rd vertex\\
\tbs U&0&\(\U\)									&typical vertex set\\
\tbs UU&0&\(\UU\)								&typical 2nd vert set\\
\tbs UUU&0&\(\UUU\)								&typical 3rd vert set\\
\tbs T&0&\(\T\)									&time bound\\
\tbs t&0&\(\t\)								&typical time\\
\tbs tt&0&\(\tt\)								&typical time 2\\
\tbs ttt&0&\(\ttt\)							&typical time 3\\
\tbs r&0&\(\r\)								&space var for poiss\\
\tbs rt&1&\(\rt{\numb}\)					&typical rand time\\
\tbs rtt&1&\(\rtt{\numb}\)					&typical rand time 2\\
\tbs it&0& \(\it\)							&iterator\\
\tbs itt&0&\(\itt\)							&iterator 2\\
\tbs ittt&0&\(\ittt\)						&iterator 3\\
\tbs numb&0&\(\numb\)						&numbering of prelimit vars\\
\tbs XState&1&\(\XState{\U}\)				&multidim state space\\
\tbs sv&2&\(\sv{\v}{\U}\)					&typ elt of \tbs XState\\
\tbs ev&1&\(\ev{\v}\)						&standard basis\\
\tbs cad&0&\(\cad\)							&Cadlag space\\
\tbs OmegaV&2&\(\Omega{\v}{\t}\)			&Path space\\
\tbs piV&2&\(\piV{\U}{t}\)					&projection\\
\tbs xvtt&2&\(\xvtt{\v}{\t}\)					&typ path val2\\
\tbs xvttt&2&\(\xvttt{\v}{\t}\)				&typ path val3\\
\tbs rxvt&2&\(\X{\v}{\t}\)					&typ rand path val\\
\tbs rxvtn&3&\(\X{\v}{\t}{\numb}\)		&typ rp val sublim\\
\tbs rxvtt&2&\(\rxvtt{\v}{\t}\)				&typ rand path val2\\
\tbs rxvttn&3&\(\rxvttn{\v}{\t}{\numb}\)		&typ rp val sublim 2\\
\tbs rxvttt&2&\(\rxvttt{\v}{\t}\)				&typ rand path val3\\
\tbs xvtts&2&\(\xvtts{\v}{[0,\t]}\)					&typ path 2\\
\tbs xvttts&2&\(\xvttts{\v}{[0,\t]}\)					&typ path 3\\
\tbs rxvts&2&\(\X{\v}{[0,\t]}\)					&typ rand path\\
\tbs rxvtsn&3&\(\X{\v}{[0,\t]}{\numb}\)	&typ rpath sublim\\
\tbs rxvtts&2&\(\rxvtts{\v}{[0,\t]}\)					&typ rand path 2\\
\tbs rxvttsn&3&\(\rxvttsn{\v}{[0,\t]}{\numb}\)	&typ rpath sublim 2\\
\tbs rxvttts&2&\(\rxvttts{\v}{[0,\t]}\)				&typ rand path 3\\\\tbs rxvtttsn&3&\(\rxvtttsn{\v}{[0,\t]}{\numb}\)	&typ rpath sublim 3\\
\tbs rp&1& \(\rp{\t}\)						&typ point process\\
\tbs m&3&\(\m{\U}{\t}{\numb}\)						&typ measure\\
\tbs mm&3&\(\mm{\U}{\t}{\numb}\)						&typ measure 2\\
\tbs mmm&3&\(\mmm{\U}{\t}{\numb}\)						&typ measure 3\\
\tbs cm&0&\(\cm\)							&conditional msr funct\\
\tbs IGr&1&\(\IGr{\v}\)						&IG rate\\
\tbs rate&1&\(\rate{\v}\)					&rate\\
\tbs ratee&1&\(\ratee{\v}\)					&general rate\\
\tbs crate&2&\(\crate{\v}{\t}\)		&conditional rate\\
\tbs cratee&2&\(\cratee{\v}{\t}\)		&general conditional rate\\
\tbs cl&0&\(\cl{\cdot}\)			&closure (in the graph)\\
\tbs root&0&\(\root\)				&root\\
\tbs F&2&\(\F{\U}{\t}\)&Filtrations\\
\tbs FF&2&\(\FG{\U}{\t}\)&Filtrations\\
\tbs FFF&2&\(\FH{\U}{\t}\)&Filtrations\\
\tbs dist&0& \(\dist\)				&general metric\\
\tbs gdist &0& \(\gdist\)			&graph distance\\
\tbs cont &0& \(\cont\)				&space of cont. \\
\tbs const &1& \(\const{\numb}\)	&Constant\\
\tbs Sm&0&\(\Sm\)							&std msr on \(\S\)\\
\tbs alt&0&\(\widetilde{\cdot}\)			&alternate val\\
\tbs b&1& \(\b{\v}\)						&inf dim norm coeffs\\
\tbs mutex&0&\(\mutex\)						&mutually exclusive\\
\tbs apath&0&\(\apath\)						&Given path for CI proof\\
\tbs pathset&2&\(\pathset{\itt}{\ittt}\)	&set of paths\\
\tbs pathsete&2&\(\pathsete{\itt}{\ittt}\)	&union over pathset\\
\tbs pathseted&2&\(\pathseted{\itt}{\ittt}\)&pathsete with \(\t\)\\
\tbs rv&0& \(\rv\)							&Typical random element\\
\tbs evnt&0&\(\evnt\)						&Typical event\\
\tbs typset&0&\(\typset\)					&Typical set\\
\tbs mark&1&\(\mark{\numb}\)				&Typical mark\\
\tbs dense&2& \(\dense{\numb}{\T}\)			&Typ density\\
\tbs cdense&2&\(\cdense{\numb}{\T}\)		&cond density\\
\tbs ds&2& \(\ds{\v}{\t}\)					&mapping in density\\
\tbs mtop &0& \(\mtop\)						&markov to point\\
\tbs spce &0&\(\spce\)						&arbitrary space\\
\tbs c &1& \(\c{\v}\)						&child function\\
\tbs p &1& \(\p{\v}\)						&parent function \\
\tbs pmap &1& \(\pmap{\v}\)					&Markov to MPP\\
\tbs inte &0& \(\inte\)						&interval
\end{longtable}

\subsection*{TODO}

Resolve notation problems:

\begin{itemize}
\item Complete notation macros

\item Try removing references to measure space \(\pmsr(\cdot)\) in section 2.

\item Finish all proofs.
\end{itemize}

\section{Introduction}
\label{sec::Intro}\labe{sec::Intro}

Partial Lit Review: \tr{A lot of these results are specifically for diffusions. Consider whether they are still relevant.}

Convergence of the Empirical Measure (relevant if I prove equivalence of limiting empirical distribution and limiting typical particle dynamics.):

\begin{itemize}
\item \cite{Yin15} uses Stein's method to proof convergence and estimate rate of convergence.

\item \cite{DupRamWu16} study convergence in finite state space case and analyze Large deviations.

\item \cite{VveDobKar96} and \cite{Mit01} apply analysis to power of two load balancing on a complete network. 
\end{itemize}

McKean-Vlasov Equations:

\begin{itemize}
\item \cite{Mck66} introduces the notation of non-linear Markov processes.

\item \cite{Oel84} uses standard Martingale convergence arguments to prove the McKean-Vlasov weak limit for diffusions and jump processes.

\item \cite{Szn91} uses a fixed point algorithm to prove the McKean-Vlasov limit for diffusions. Explicitly provided a coupling in which the path of a typical particle converges.

\item \cite{Lac15} provides a brief summary of methods by which the McKean-Vlasov limit has been proved. He also addresses cases in which the limiting equation does not have a unique solution and the case of shared noise. Most of the thesis considers a control process derived from these processes.

\item \cite{SzpTanTse17} develop multilevel Monti Carlo estimation of McKean-Vlasov SDEs using Sznitman's fixed point argument.
\end{itemize}

Dense Graph Approximation:

\begin{itemize}
\item \cite{BhaBudWu17} show convergence to McKean-Vlasov of diffusions over asymptotically dense random networks.

\item \cite{MukBorLee17} analyze join-the-shortest-neighboring-queue load balancing over asymptotically dense random networks. \cite{BudMukWu17} also address heterogeneous deterministic networks.

\item \cite{MieBov15},\cite{GreKisKao06} study mean-field numerically for various epidemic models. They demonstrate that it works well for dense graphs and that it's inaccurate for sparse graphs.
\end{itemize}

Alternatives:

\begin{itemize}
\item \cite{Gas15} demonstrates the pairwise approximation. It's better than mean-field, but tail probabilities are still inaccurate.

\item Cavity method may provide an alternative approach. It is currently known as a discrete time algorithm \cite{Lac15}\cite{KanMon11}. There is current work extending it to continuous time \tr{(Citation needed)}.
\end{itemize}

\tg{Outline will be here someday somehow!}


\section{Preliminaries}
\label{sec::Preli}\labe{sec::Preli}

\subsection{Notation}
\label{subsec::Notat:sec::Preli}\labe{subsec::Notat:sec::Preli}

Let \(\G = (\V,\E)\) be a graph with bounded degree with rooted node \(\root \in \V\). For any \(\v \in \V\), let \(\neigh{\v}\) be the set of nodes adjacent to \(\v\). Similarly, for any \(\U \subseteq \V\), let \(\neigh{\U}\) be the set of nodes adjacent to \(\U\) but not in \(\U\). Let \(\cl{\v} = \{\v\}\cup\neigh{\v}\) and \(\cl{\U} = \U\cup \neigh{\U}\). 

\ind Let \(\S\) be a finite set. Without loss of generality, let \(S\) be a finite abelian group with group operation \(+\) and equipped with the norm \(|\cdot|\). 

\ind Let \(\S^\V\) be the set of vectors, \(\sv{}{\V}\) with components \(\sv{\v}{\V} \in \S\) indexed by \(\v\in \V\). Let \(\{\ev{\v}: \v\in \V\}\) be the standard basis vectors of \(\S^\V\). Let \(\{\b{\v}:\v\in \V\}\) be a sequence of positive numbers such that \(\sum_{\v\in\V} \b{\v} < \infty\). Then let \(\|\cdot\|_{\b{}}\) be a norm on \(\S^\V\) defined by \(\|\sv{}{\V}\|_{\b{}} = \sum_{\v\in\V} \b{\v}|\sv{\v}{\V}|\). For any \(\U\subseteq \V\), we will generally assume \(\S^\U\) is embedded in \(\S^\V\). That is, for \(\sv{}{\U}\in \S^\U\), \(\sv{\v}{\U} = 0\) for all \(\v\notin\U\). Thus, we can also define the norm \(\|\sv{}{\U}\|_{\b{}} = \sum_{\v\in\U} \b{\v}|\sv{\v}{\U}|\). \(\S^\V\) acts as the state space of an interacting particle system on \(\G\) whose nodes have state space \(\S\).

\ind Fix some \(\T < \infty\). For any \(\U\subseteq \V\) and \(\t\in [0,\T]\), let \(\Omega{\U}{\t} = \cad([0,\t],\S^{\U})\) and \(\Omega{\U}{\t-} = \cad([0,\t),\S^\U)\). For any \(\x{}{} \in \Omega{\V}{\T}\), \(\v\in \V\) and  \(\t \in [0,\T]\), let \(\x{\v}{\t}\) be the value of the \(\v\)-node of \(\x{}{}\) at time \(\t\). For any \(\U\subseteq \V\), let \(\piV{\U}{\t}\) be the standard projection/embedding into the space \(\Omega{\U}{\t}\). In a slight misuse of notation, we will make the domain clear from context. Let \(\piV{\U}{} \defeq \piV{\U}{0}\) be the projection to \(\S^\U\). For any \(\U\subseteq \V\), define the norm on \(\Omega{\t}{\U}\) by \(\|\x{\U}{}\|_{\b{},\t} \defeq \sup_{\tt \leq \t} \|\x{\U}{\tt}\|_{\b{}}\). Let \(\F{\U}{\t}\) be the Borel \(\sigma\)-algebra of \(\Omega{\U}{\t}\) with respect to the Skorokhod topology. Let \(\X{}{}\) be an \(\Omega{\V}{\t}\)-valued random variable. We say that \(\X{\v}{\t}\) is the state of the \(\v\)-component of \(\X{}{}\) at time \(\t\). Assume \(\X{}{}\) is a Feller process with infinitesimal generator \(\IG\) given by,

\begin{equation}
\IG f(\sv{}{\V}) = \sum_{\v \in \V}\sum_{\s \in \S} \IGr{\v}(\sv{}{\V},\s)[f(\sv{}{\V} + \s \ev{\v}) - f(\sv{}{\V})],
\label{subsec::Notat:Eqn::IG}
\end{equation}
\labe{subsec::Notat:Eqn::IG}

where \(\{\IGr{\v}:\v\in \V\}\) are chosen such that \(\X{}{}\) is well-defined (See Appendix \ref{sec::Infin} for more information. See sections \ref{subsec::Assum:sec::Preli} and \ref{subsec::Well-:sec::Preli} for examples of such \(\IGr{\v}\) relevant to this paper). 

\tr{I have not mentioned any probability measure stuff yet.}

\subsection{Assumptions}
\label{subsec::Assum:sec::Preli}\labe{subsec::Assum:sec::Preli}

Throughout this paper, we will assume that \(\X{}{0}\) is a vector of i.i.d. \(\S\)-valued random variables with respect to \(\pr\).

\lin

\begin{assu}
The following three conditions hold:
\begin{enumerate}
\item \(\IGr{\v}\) as defined in equation \eqref{subsec::Notat:Eqn::IG} is uniformly bounded. That is, there exists a constant \(\const{}\) such that,

\begin{equation}
\sup_{\v\in \V,\s \in \S,\sv{}{\V}\in \S^\V} \IGr{\v}(\sv{}{\V},\s) = \const{} < \infty.
\label{subsec::Assum:Eqn::bddcv}
\end{equation}
\labe{subsec::Assum:Eqn::bddcv}

\item \(\IGr{\v}\) only depends on \(\sv{\cl{\v}}{\V}\). That is, for any \(\v\in \V\), \(\s\in \S\) and \(\sv{}{\V},\ov{\sv{}{\V}} \in \S^\V\) such that \(\sv{\cl{\v}}{\V} = \ov{\sv{\cl{\v}}{\V}}\), \(\IGr{\v}(\sv{}{\V},\s) = \IGr{\v}(\ov{\sv{}{\V}},\s)\).

\item \(\G\) has bounded degree. That is, \(\degr \defeq \sup_\v |\neigh{\v}| < \infty\).
\end{enumerate}
\label{subsec::Assum:Assu::CI}\labe{subsec::Assum:Assu::CI}
\end{assu}

\purpose Intuitively, we are assuming that each node of the process changes state at a bounded rate and that the number of nodes that any one node interacts with is bounded. This assumption (along with independent initial conditions) yields sufficient conditions for well-posedness of the infinitesimal generator and SDE. It is also all that is required to prove the conditional independence property (Theorem \ref{sec::Main:Thm::CI}). 

\usein All of section \ref{subsec::Well-:sec::Preli}. Theorem \ref{sec::Main:Thm::CI}. All of section \ref{sec::Proof1}.

\lin

\begin{assu}
There exists a fixed \(\degr\in \mb{N}\) such that:

\begin{enumerate}
\item There exists a mapping \(\IGr{}: \S^{d+1} \times \S \ra [0,\infty)\) such that:

\begin{equation}
\IGr{\v}(\sv{}{\V},\s) = \IGr{}(\sv{\cl{\v}}{\V},\s) \te{ for all } \v\in \V, \s\in \S\te{ and } \sv{}{\V} \in \S^\V
\label{subsec::Assum:Eqn::Symmetry}
\end{equation}
\labe{subsec::Assum:Eqn::Symmetry}

\item \(\G\) is a regular \(\degr\)-tree. In this case we call an arbitrary node \(\root\in \V\) the root. Let \(\gdist\) be the graph distance. Define \(\tree^\numb = \{\v \in \V: \gdist(\v,\root) \leq \numb\}\) for all \(\numb\in \mb{N}\).
\end{enumerate}
\label{subsec::Assum:Assu::Local}\labe{subsec::Assum:Assu::Local}
\end{assu}

\purpose Assumption \ref{subsec::Assum:Assu::Local} implies Assumption \ref{subsec::Assum:Assu::CI}, so all results for Assumption \ref{subsec::Assum:Assu::CI} hold for Assumption \ref{subsec::Assum:Assu::Local}. This assumption adds an additional symmetry assumption. We also work on trees so we do not have to deal with cycles (which add extra dependencies making the problem harder to analyze). Furthermore, this assumption is sufficient for Theorem \ref{sec::Main:Thm::Local SDE} (existence and uniqueness of a local representation of \(\m{}{}{} \defeq \law(\X{}{})\)).

\usein Theorem \ref{sec::Main:Thm::Local SDE}, all of section \ref{sec::Proof2}.

\ind \(\tree^\numb\) is the tree rooted at \(\root\) with \(\numb\) generations such that \(\root\) has \(\degr\) children and all other non-leaf nodes have \(\degr-1\) children.

\lin

\subsection{Well-Posedness Results}
\label{subsec::Well-:sec::Preli}\labe{subsec::Well-:sec::Preli}

\rule{\linewidth}{0.4 pt}

\begin{prop}
Suppose \(\X{}{}\) is the Feller process defined by equation \eqref{subsec::Notat:Eqn::IG}. If \(\X{}{}\) satisfies Assumption \ref{subsec::Assum:Assu::CI}, then there exists a domain \(\core(\IG)\) such that operator \(\IG\) defined in equation \eqref{subsec::Notat:Eqn::IG} on \(\mc{D}(\IG)\) is an infinitesimal generator with core \(\core\) defined by,

\begin{equation}
\core \defeq \left\{f \in \cont(\S^\V): \sum_{\v\in\V} \triangle_f(\v) < \infty\right\},
\label{subsec::Well-:Eqn::core}
\end{equation}
\labe{subsec::Well-:Eqn::core}

where we define,

\begin{equation}
\triangle_f(\v) \defeq \sup\left\{|f(\sv{}{\V}) - f(\sv{}{\V}+\s\ev{\v})|: \sv{}{\V} \in \S^\V,\s \in \S\right\}.
\label{subsec::Well-:Eqn::fvar}
\end{equation}
\labe{subsec::Well-:Eqn::fvar}

\label{subsec::Well-:Prop::Welldef}
\end{prop}
\labe{subsec::Well-:Prop::Welldef}

\purpose This is necessary for obvious reasons. If \(\X{}{}\) is not well-defined, then there is no longer any point in deriving any results about its properties. The infinitesimal generator representation of \(\X{}{}\) is used to prove convergence of the finite-dimensional approximations of \(\X{}{}\) to \(\X{}{}\).

\usein This is important for Propositions \ref{subsec::Well-:Prop::SDE=IG} and \ref{subsec::Well-:Prop::IGApprox}. It is only implicitly used in \ref{subsec::Well-:Prop::SDE=IG}.

\app \cite[Theorem 3.9]{Lig85} and Assumption \ref{subsec::Assum:Assu::CI}.

\begin{proof}
By \cite[Theorem 3.9 (a) and (b)]{Lig85}, it suffices to show that:

\begin{enumerate}[i)]
\item 

\[\sup_{\v \in \V,\sv{}{\V} \in \S^\V} \sum_{\s \in \S} \IGr{\v}(\sv{}{\V},\s) < \infty.\]

\item 

\[\sup_{\v\in \V}\sum_{\vv\neq \v} \sup_{\substack{\sv{}{\V} \in \S^\V\\ \s\in \S\\ \SS \subseteq \S}} \left|\sum_{\ss \in \SS} (\IGr{\v}(\sv{}{\V},\ss) - \IGr{\v}(\sv{}{\V}+\s \ev{\vv},\ss))\right| < \infty.\]
\end{enumerate}

We have,

\begin{enumerate}[i)]
\item This is just statement 1 of Assumption \ref{subsec::Assum:Assu::CI}.

\item By statement 2 of Assumption \ref{subsec::Assum:Assu::CI}, 

\[\sup_{\substack{\sv{}{\V} \in \S^\V\\ \s\in \S\\ \SS\subseteq \S}} \left|\sum_{\ss \in \SS} (\IGr{\v}(\sv{}{\V},\ss) - \IGr{\v}(\sv{}{\V}+\s \ev{\vv},\ss))\right| = 0 \te{ for all } \vv \notin \cl{\v}\]

Furthermore, \(\IGr{\v}\) is non-negative and bounded from above by some \(\const{} < \infty\) (statement 1 of Assumption \ref{subsec::Assum:Assu::CI}). Therefore, 

\[\left|\sum_{\ss \in \SS} (\IGr{\v}(\sv{}{\V},\ss) - \IGr{\v}(\sv{}{\V}+\s\ev{\vv},\ss))\right| \leq \const{}|\S| \te{ for all } \sv{}{\V} \in \S^\V,\v \in \V, \vv \in \cl{\v}, \s \in \S \te{ and } \SS\subseteq \S\]

Finally, by statement 3 of Assumption \ref{subsec::Assum:Assu::CI}, \(|\neigh{\v}| \leq \degr\) for all \(\v \in \V\). Thus,

\begin{align*}
\sup_{\v\in \V}\sum_{\vv \neq \v} \sup_{\substack{\sv{}{\V} \in \S^\V\\ \s\in \S\\ \SS\subseteq \S}}& \left|\sum_{\ss \in \SS} (\IGr{\v}(\sv{}{\V},\ss) - \IGr{\v}(\sv{}{\V}+\s\ev{\vv},\ss))\right|\\
&  = \sup_{\v\in \V}\sum_{\vv\in \neigh{\v}} \sup_{\substack{\sv{}{\V} \in \S^\V\\ \s\in \S\\ \SS\subseteq \S}} \left|\sum_{\ss \in \SS} (\IGr{\v}(\sv{}{\V},\ss) - \IGr{\v}(\sv{}{\V}+\s\ev{\vv},\ss))\right|\\
&\leq \sup_{\v\in \V} \sum_{\vv \in \neigh{\v}} \const{}|\S|\\
&\leq \degr \const{}|\S| < \infty.
\end{align*}


\end{enumerate}
\end{proof}

\lin

\begin{prop}
Let \(\poisses \defeq \{\poiss{\v}:\v\in \V\}\) be a sequence of i.i.d. Poisson processes on \(\mb{R}^2\times \S\) with intensity measure \(\leb\otimes \Sm\) where \(\leb\) is the Lebesgue measure on \(\mb{R}^2\) and \(\Sm\) is a probability measure on \(\S\) having 0 weight on 0 and nonzero weight on \(\S\setminus \{0\}\). Suppose \(\IGr{\v}\) and \(\G\) satisfy Assumption \ref{subsec::Assum:Assu::CI} and suppose \(\rate{\v}(\sv{}{\V},\s) = \frac{\IGr{\v}(\sv{}{\V},\s)}{\Sm(\{\s\})}\) for \(\sv{}{\V} \in \S^\V\) and \(\s \in \S\). Then the coupled equation,

\begin{equation}
\X{\v}{\t} = \X{\v}{0} + \int_\S\int_0^\t \s\poiss{\v}\left(d\tt,\left(0,\rate{\v}(\X{}{\tt-},\s)\right],d\s\right) \te{ for all }\v \in \V
\label{subsec::Well-:Eqn::SDE}
\end{equation}
\labe{subsec::Well-:Eqn::SDE}

has a unique strong solution.
\label{subsec::Well-:Prop::SDEWP}
\end{prop}
\labe{subsec::Well-:Prop::SDEWP}

\purpose The SDE representation of \(\X{}{}\) is used to prove the conditional independence property. I also make heavy use of this representation in proving uniqueness of the local characterization.

\pfsum Prove uniqueness using Gronwall's inequality. Prove existence using Picard iterations. Proof is provided after Lemma \ref{subsec::Well-:Lem::GronwallPrep}.

\usein Proposition \ref{subsec::Well-:Prop::SDE=IG}, Lemma \ref{sec::Proof1:Lem::Decomposition} and section \ref{subsec::ProofU:sec::Proof2}.

\app Lemma \ref{subsec::Well-:Lem::GronwallPrep} and Assumption \ref{subsec::Assum:Assu::CI}. Lemma \ref{subsec::Well-:Lem::SDEWP} is an intermediate result used to prove Lemma \ref{subsec::Well-:Lem::GronwallPrep}.

\lin

\begin{lem}
Suppose Assumption \ref{subsec::Assum:Assu::CI} holds. Consider the mapping \(F_\poisses: \Omega{\V}{\T} \ra \Omega{\V}{\T}\) parameterized by a sequence of Poisson processes and defined by,

\[\left(F_\poisses(\x{}{})\right)_\v(\t) := \x{\v}{0} + \int_\S\int_0^\t \s \,\poiss{\v}(d\tt,(0,\rate{\v}(\x{}{\tt-},\s)],d\s) \te{ for all }\x{}{} \in \Omega{\V}{\T}, \v \in \V\te{ and }\t \in [0,\T].\]

Then for any pair of random processes \(\X{}{},\alt{\X{}{}}:\Omega{\V}{\T} \ra \Omega{\V}{\T}\), \(\v\in \V\) and \(\t \in [0,\T]\),

\[\ex{\|F_\poisses(\X{}{})_\v - F_\poisses(\alt{\X{}{}})_\v\|_\t} \leq \ex{|\X{\v}{0} - \alt{\X{\v}{0}}|} +  \const{1}\int_0^\t \sum_{\vv\in \cl{\v}} \ex{\|\X{\vv}{} - \alt{\X{\vv}{}}\|_\tt}\,d\tt\]

for some constant \(\const{1} < \infty\).

\label{subsec::Well-:Lem::SDEWP}
\end{lem}
\labe{subsec::Well-:Lem::SDEWP}

\purpose Proposition \ref{subsec::Well-:Prop::SDEWP} is proved using Picard iterations to prove existence and a similar inequality to prove uniqueness. This lemma is also applied in the proof of Proposition \ref{subsec::Well-:Prop::SDE=IG}. Furthermore, the proof that any strong solution, \(\X{}{}\), to equation \eqref{subsec::Well-:Eqn::SDE} also involves a similar computation. This Lemma allows us to do the computation a single time to avoid repetition or citing results found within proofs.

\usein Lemma \ref{subsec::Well-:Lem::GronwallPrep} and Proposition \ref{subsec::Well-:Prop::SDE=IG}. Proof is referenced in Lemma \ref{sec::Proof1:Lem::Decomposition}.

\app Assumption \ref{subsec::Assum:Assu::CI}.

\begin{proof}
Recall that \(\{\IGr{\v}:\v\in\V\}\) is necessarily bounded from above by some \(\const{} < \infty\) (Statement 1 of Assumption \ref{subsec::Assum:Assu::CI}). By assumption, \(\Sm(\{\s\}) > 0\) for all \(\s \in \S\setminus \{0\}\). Since \(\S\) is finite, that means that \(\min_{\s \neq 0} \Sm(\{\s\}) > 0\), so \(\rate{\v}(\sv{}{\V},\s)\) is also bounded from above. Without loss of generality, suppose \(\rate{\v}(\sv{}{\V},\s) < \const{}\) for all \(\v\in \V,\sv{}{\V} \in \S^\V\te{ and } \s \in \S\).

\ind By statement 2 of Assumption \ref{subsec::Assum:Assu::CI}, 

\[\inf_{\substack{\sv{}{\V},\alt{\sv{}{\V}} \in \S^\V, \s\in \S\\ \rate{\v}(\sv{}{\V},\s) \neq \rate{\v}(\alt{\sv{}{\V}},\s)}} \sum_{\vv \in \cl{\v}} |\sv{\vv}{\V} - \alt{\sv{\vv}{\V}}| \geq 1.\]

Then,

\[\sup_{\v\in \V} \sup_{\substack{\sv{}{\V},\alt{\sv{}{\V}} \in \S^\V, \s\in \S\\ \rate{\v}(\sv{}{\V},\s) \neq \rate{\v}(\alt{\sv{}{\V}},\s)}} \frac{|\rate{\v}(\sv{}{\V},\s) - \rate{\v}(\alt{\sv{}{\V}},\s)|}{\sum_{\vv \in \cl{\v}} |\sv{\vv}{\V} - \alt{\sv{\vv}{\V}}|} \leq \const{}\]

So,

\[|\rate{\v}(\sv{}{\V},\s) - \rate{\v}(\alt{\sv{}{\V}},\s)|\leq \const{}\sum_{\vv \in \cl{\v}} |\sv{\vv}{\V} - \alt{\sv{\vv}{\V}}| \te{ for all } \sv{}{\V},\alt{\sv{}{\V}}\in \S^\V,\s\in \S\te{ and }\v\in \V.\]

That is, \(\rate{\v}\) satisfies a Lipschitz-like condition with coefficient bounded from above by \(\const{}\). For any \(\v\in \V\),

\begin{align*}
\mb{E}\bigg[&\|F_\poisses(\X{}{})_\v - F_\poisses(\alt{\X{}{}})_\v\|_\t\bigg] - \ex{|\X{\v}{0} - \alt{\X{\v}{0}}|}\\
&= \ex{\sup_{\ttt \leq \t}\left|\int_\S\int_0^{\ttt} \s\poiss{\v}\left(d\tt,\left(0,\rate{\v}(\X{}{\tt-},\s)\right],d\s\right) -  \int_\S\int_0^{\ttt} \s\poiss{\v}\left(d\tt,\left(0,\rate{\v}(\alt{\X{}{\tt-}},\s)\right],d\s\right)\right|}\\
&=\ex{\sup_{\ttt\leq \t} \left|\int_\S \int_0^{\const{}} \int_0^{\ttt} \s\left(\mb{I}_{\r < \rate{\v}(\X{}{\tt-},\s)} - \mb{I}_{\r < \rate{\v}(\alt{\X{}{\tt-}},\s)}\right)\,\poiss{\v}(d\tt\,d\r\,d\s)\right|}\\
&\leq \ex{\int_\S\int_0^{\const{}}\int_0^\t \left|\s\left(\mb{I}_{\r < \rate{\v}(\X{}{\tt-},\s)} - \mb{I}_{\r < \rate{\v}(\alt{\X{}{\tt-}},\s)}\right)\right|\,\poiss{\v}(d\tt\,d\r\,d\s)}\\
&=\int_\S\int_0^\t\int_0^{\const{}} |\s|\ex{\mb{I}_{\rate{\v}(\X{}{\tt-},\s) \leq \r < \rate{\v}(\alt{\X{}{\tt-}},\s)} + \mb{I}_{\rate{\v}(\alt{\X{}{\tt-}},\s) \leq \r < \rate{\v}(\X{}{\tt-},\s)}}\,d\r\,d\tt\,\Sm(d\s)\\
&= \int_\S\int_0^\t|\s|\ex{\left|\rate{\v}(\X{}{\tt-},\s) - \rate{\v}(\alt{\X{}{\tt-}},\s)\right|}\,d\tt\,\Sm(d\s)\\
&\leq \const{}\int_\S\int_0^\t |\s| \ex{\sum_{\vv \in \cl{\v}}|\X{\vv}{\tt-} - \alt{\X{\vv}{\tt-}}|}\,d\tt\,\Sm(d\s)\\
&\leq \const{}|\S|\int_0^\t \sum_{\vv \in \cl{\v}}\ex{\|\X{\vv}{} - \alt{\X{\vv}{}}\|_\tt}\,d\tt\\
\end{align*}

Then,

\[\ex{\|F_\poisses(\X{}{})_\v - F_\poisses(\alt{\X{}{}})_\v\|_\t} \leq \ex{|\X{\v}{0} - \alt{\X{\v}{0}}|} +  \const{1}\int_0^\t \sum_{\vv\in \cl{\v}} \ex{\|\X{\vv}{} - \alt{\X{\vv}{}}\|_\tt}\,d\tt.\]

\end{proof}

\lin

\begin{lem}
Given the conditions and notation of Lemma \ref{subsec::Well-:Lem::SDEWP}, assume that \(\X{}{0} = \alt{\X{}{0}}\) almost surely. Then,

\[\sup_{\v \in \V} \ex{\left\|F_\poisses(\X{}{})_\v - F_\poisses(\alt{\X{}{}})_\v\right\|_\t} \leq (\degr+1)\const{1}\int_0^\t \sup_{\v \in \V} \ex{\|\X{\v}{} - \alt{\X{\v}{}}\|_\tt}\,d\tt.\]
\label{subsec::Well-:Lem::GronwallPrep}
\end{lem}
\labe{subsec::Well-:Lem::GronwallPrep}

\purpose Provides a nice Gronwall-like inequality for use in proving Proposition \ref{subsec::Well-:Prop::SDEWP}.

\usein Proposition \ref{subsec::Well-:Prop::SDEWP}.

\app Lemma \ref{subsec::Well-:Lem::SDEWP} and Assumption \ref{subsec::Assum:Assu::CI}.

\begin{proof}
By statement 3 of Assumption \ref{subsec::Assum:Assu::CI}, every node \(v \in V\) has degree less than or equal to \(\degr\). By Lemma \ref{subsec::Well-:Lem::SDEWP},

\begin{align*}
\sup_{\v \in \V} \ex{\left\|F_\poisses(\X{}{})_\v - F_\poisses(\alt{\X{}{}})_\v\right\|_\t} &\leq \sup_{\v\in \V}\left(\ex{|\X{\v}{0} - \alt{\X{\v}{0}}|} +  \const{1}\int_0^\t \sum_{\vv\in \cl{\v}} \ex{\|\X{\vv} - \alt{\X{\vv}{}}\|_\tt}\,d\tt\right)\\
&=\sup_{\v \in \V} \const{1}\int_0^\t \sum_{\vv \in \cl{\v}} \ex{\|\X{\vv} - \alt{\X{\vv}{}}\|_\tt}\,d\tt\\
&\leq \const{1}\int_0^\t \sup_{\v \in \V}\sum_{\vv \in \cl{\v}} \ex{\|\X{\vv} - \alt{\X{\vv}{}}\|_\tt}\,d\tt\\
&\leq \const{1}\int_0^\t \sup_{\v \in \V}\sum_{\vv \in \cl{\v}}\sup_{\vvv\in\V} \ex{\|\X{\vvv} - \alt{\X{\vvv}{}}\|_\tt}\,d\tt\\
&= \const{1}\int_0^\t \sup_{\v \in \V}(\degr+1)\sup_{\vvv\in\V} \ex{\|\X{\vvv} - \alt{\X{\vvv}{}}\|_\tt}\,d\tt\\
&= (\degr+1)\const{1}\int_0^\t \sup_{\v\in\V} \ex{\|\X{\v} - \alt{\X{\v}{}}\|_\tt}\,d\tt\\
\end{align*}
\end{proof}
\lin

\begin{proof}[Proof of Proposition \ref{subsec::Well-:Prop::SDEWP}]

This proof is fairly standard. We begin by proving uniqueness. Suppose \(\X{}{}\) and \(\alt{\X{}{}}\) are both strong solutions to equation \ref{subsec::Well-:Eqn::SDE}. Let \(F_\poisses\) be the mapping introduced in Lemmas \ref{subsec::Well-:Lem::SDEWP} and \ref{subsec::Well-:Lem::GronwallPrep}. Then,

\[\X{}{} = F_\poisses(\X{}{})\te{ and } \alt{\X{}{}} = F_\poisses(\alt{\X{}{}}),\]

and \(\X{}{0} = \alt{\X{}{0}}\) almost surely. By Lemma \ref{subsec::Well-:Lem::GronwallPrep}, for any \(\t\in [0,\T]\),

\begin{align*}
\sup_{\v\in \V}\ex{\|\X{\v}{} - \alt{\X{\v}{}}\|_\t} \leq (\degr+1)\const{1}\int_0^\t\sup_{\v\in \V} \ex{\|\X{\v}{} - \alt{\X{\v}{}}\|_\tt}\,d\tt.
\end{align*}

By Gronwall's inequality, \(\sup_{\v \in \V} \ex{\|\X{\v}{} - \alt{\X{\v}{}}\|_\T} = 0\), so \(\X{}{} = \alt{\X{}{}}\) almost surely.

\skipLine

To prove existence, we use Picard iterations. Define \(\X{}{\t}{0} \defeq \X{}{0}\) for all \(\t \in [0,\T]\). Define,

\[\X{}{}{\numb+1} = F_\poisses(\X{}{}{\numb}).\]

Once again, by Lemma \ref{subsec::Well-:Lem::GronwallPrep},

\[\sup_{\v \in \V} \ex{\|\X{\v}{}{\numb+1} - \X{\v}{}{\numb}\|_\t} \leq (\degr+1)\const{1} \int_0^\t \sup_{\v \in \V} \ex{\|\X{\v}{}{\numb} - \X{\v}{}{\numb-1}\|_\tt}\,d\tt\] 

Furthermore, 

\begin{align*}
\ex{\|\X{\v}{}{1} - \X{\v}{}{0}\|_\t} &\leq \ex{\int_\S\int_0^\t |\s|\,\poiss{\v}\left(d\tt,\left(0,\rate{\v}(\X{}{0},\s)\right],d\s\right)}\\
&\leq \ex{\int_\S\int_0^\t |\s|\,\poiss{\v}\left(d\tt,\left(0,\const{}\right],d\s\right)}\\
&= \const{}\int_\S\int_0^\t |\s|\,d\tt\,\Sm(d\s)\\
&=\const{}\t\int_\S |\s|\,\Sm(\s)\\
&\leq \const{}\t|\S|
\end{align*}

here we use the fact that \(\rate{\cdot}(\cdot,\cdot)\) is bounded by some \(\const{} < \infty\) which does not depend on \(\v\), and the fact that \(\S\) is finite and \(\Sm\) is a probability measure. This gives us,

\[\sup_{\v \in \V}\ex{\|\X{\v}{}{1} - \X{\v}{}{0}\|_\t} \leq \t\const{2} \defeq \t\const{}|\S|\]

Iterating yields

\[\sup_{\v \in \V} \ex{\|\X{\v}{}{\numb+1} - \X{\v}{}{\numb}\|_\t} \leq \t\const{2}\frac{(\t(\degr+1)\const{1})^\numb}{(\numb+1)!}\]

Then,

\begin{align*}
\sum_{\numb=0}^\infty \sup_{\v \in \V} \ex{\|\X{\v}{}{\numb+1} - \X{\v}{}{\numb}\|_\T} &= \sum_{\numb=1}^\infty \frac{\const{2}}{(\degr+1)\const{1}}\frac{(\T(\degr+1)\const{1})^{\numb}}{\numb !}\\
& = \frac{\const{2}}{(\degr+1)\const{1}}(e^{\T(\degr+1)\const{1}} - 1) < \infty
\end{align*}


So \(\X{}{}{\numb} \ra \X{}{}\) for some \(\X{}{}\) componentwise almost surely (fast convergence in expectation implies almost sure convergence). Let 

\[\alt{\X{}{}} = F_\poisses(\X{}{}).\]

By Lemma \ref{subsec::Well-:Lem::GronwallPrep}, for any \(\numb\in\mb{N}\),

\begin{align*}
\sup_{\v \in \V} \ex{\|\alt{\X{\v}{}} - \X{\v}{}{\numb+1}\|_\T} &\leq (\degr+1)\const{1}\int_0^\T \sup_{\v \in \V}\ex{\|\X{\v}{} - \X{\v}{}{\numb}\|_\tt}\,d\tt \\
&\leq \T\const{1}(\degr+1)\sup_{\v\in \V} \ex{\|\X{\v}{} - \X{\v}{}{\numb}\|_\T}.
\end{align*}

Taking a limit as \(\numb\) goes to infinity on both sides yields

\[\lim_{\numb\ra\infty} \sup_{\v \in \V} \ex{\|\alt{\X{\v}{}} - \X{\v}{}{\numb}\|_\T} = 0.\]

So \(\X{}{}= F_\poisses(\X{}{})\) almost surely.
\end{proof}

\lin

\begin{prop}
Let \(\X{}{}\) be defined as in Proposition \ref{subsec::Well-:Prop::SDEWP}. Suppose Assumption \ref{subsec::Assum:Assu::CI} holds. Then \(\X{}{}\) is the unique Feller process with initial condition \(\X{}{0}\) and infinitesimal generator given by \eqref{subsec::Notat:Eqn::IG}:

\[\IG f(\sv{}{\V}) = \sum_{\v\in \V}\sum_{\s \in \S} \IGr{\v}(\sv{}{\V},\s)[f(\sv{}{\V} + \ev{\v}\s) - f(\sv{}{\V})].\]
\label{subsec::Well-:Prop::SDE=IG}
\end{prop}
\labe{subsec::Well-:Prop::SDE=IG}

\purpose This proves the two representations of \(\X{}{}\) are equivalent.

\pfsum We prove \(\X{}{}\) is Feller, then directly apply the bijection between Feller processes and infinitesimal generators given in the appendix. (Proposition \ref{sec::Infin:Thm::Bij}).

\usein Theorem \ref{sec::Main:Thm::Local SDE} (both existence and uniqueness). Lemma \ref{sec::TL:Lem::TightSupport}.

\app Assumption \ref{subsec::Assum:Assu::CI}, Proposition \ref{subsec::Well-:Prop::SDEWP}, Definition \ref{sec::Infin:Def::Feller}, Lemma \ref{subsec::Well-:Lem::SDEWP}, Lemma \ref{sec::TL:Lem::concbd} and Theorem \ref{sec::Infin:Thm::Bij}.

\begin{proof}
First, we show that \(\X{}{}\) is a Feller process. Notice that \(\X{}{}\) conditioned on the event \(\X{}{0} = \sv{}{\V}\) is given by the law of the unique solution (Proposition \ref{subsec::Well-:Prop::SDEWP}) to the equation

\begin{equation}
\X{\v}{\t} = \sv{\v}{\V} + \int_\S\int_0^\t \s\,\poiss{\v}(d\tt,(0,\rate{\v}(\X{}{\tt-},\s)],d\s).
\label{subsec::Well-:Eqn::condSDE}
\end{equation}
\labe{subsec::Well-:Eqn::condSDE}

For all \(\sv{}{\V}\in\S^\V\), suppose \(\X{}{0}{\sv{}{\V}}\) is the unique strong solution to equation \eqref{subsec::Well-:Eqn::condSDE}. By Definition \ref{sec::Infin:Def::Feller}, we need to prove that for all \(\sv{}{\V}\in \S^\V\),

\begin{enumerate}[(a)]
\item \(\X{}{0}{\sv{}{\V}} = \sv{}{\V}\) almost surely.

\item The mapping \(\sv{}{\V}\mapsto \pr\left(\X{}{0}{\sv{}{\V}}\in A\right)\) is measurable for all \(A\in \F{\U}{\T}\).

\item \(\pr\left(\X{}{\t+\cdot}{\sv{}{\V}}\in A\middle|\X{}{\tt}{\sv{}{\V}}:\tt \in [0,\t]\right) = \pr\left(\X{}{\cdot}{\X{}{\t}{\sv{}{\V}}} \in A\middle| \X{}{\t}{\sv{}{\V}} \right)\) for all \(A \in \F{\U}{\T}\).

\item For all \(f \in \cont(\S^\V)\) (that is, for all continuous \(f\)), the mapping \(\sv{}{\V}\mapsto \ex{f(\X{}{\t}{\sv{}{\V}})}\) is also continuous for all \(t\geq 0\).
\end{enumerate}

The proof that \(\X{}{}{\sv{}{\V}}\) satisfies these properties is as follows:

\begin{enumerate}[(a)]
\item This is trivially true.

\item Since \(\S\) is finite, \(\S^\V\) is countably infinite. Thus \(\ms{B}(\S^\V)\) is the set of subsets of \(\S^\V\). But then for any \(A \in \F{\U}{\T}\) and \(E \in \ms{B}([0,1])\), we have \(\S^\V \supseteq \left\{\sv{}{\V}: \pr\left(\X{}{}{\sv{}{\V}} \in A\right) \in E\right\}\), so the mapping is measurable.

\item Notice that we can write,

\[\X{\v}{\t+\cdot}{\sv{}{\V}} = \X{\v}{\t}{\sv{}{\V}} + \int_\S\int_\t^{\t+\cdot} \s\,\poiss{\v}(d\tt,(0,\rate{\v}(\X{}{\tt-}{\sv{}{\V}},\s)],d\s).\]

Let \(\alt{\X{}{}}\) be given by the unique solution to the following equation (Proposition \ref{subsec::Well-:Prop::SDEWP}),

\[\alt{\X{\v}{\cdot}} = \X{\v}{\t}{\sv{}{\V}} + \int_\S \int_0^\cdot \s\,\poiss{\v}(d\tt,(0,\rate{\v}(\alt{\X{}{\tt-}},\s)],d\s).\]

Then \(\X{}{\t+\cdot}{\sv{}{\V}} \deq \alt{\X{}{\cdot}}\). By the definition of \(\X{}{}{\sv{}{\V}}\), \(\alt{\X{}{}} \deq \X{}{}{\X{}{\t}{\sv{}{\V}}}\) as desired.

\item Let \(\root \in \V\). Define the sequence of sets \(\V\pup{0}\subset \V\pup{1}\subset \cdots \subseteq \V\) as follows: let \(\V\pup{0} = \{\root\}\). For \(\numb \geq 1\), let \(\V\pup{\numb+1} = \cl{\V\pup{\numb}}\).

\ind Now suppose for \(\sv{}{\V},\alt{\sv{}{\V}}\in \S^\V\),

\begin{align*}
\X{\v}{\t} &= \sv{\v}{\V} + \int_\S\int_0^\t \s\,\poiss{\v}(d\tt\,(0,\rate{\v}(\X{}{\tt-},\s)],d\s)&\te{ for all } \v \in \V\\
\alt{\X{\v}{\t}} &= \alt{\sv{\v}{\V}} + \int_\S\int_0^\t \s\,\poiss{\v}(d\tt\,(0,\rate{\v}(\alt{\X{}{\tt-}},\s)],d\s)&\te{ for all } \v \in \V\\
\end{align*}

Then by Lemma \ref{subsec::Well-:Lem::SDEWP},

\[\ex{\|\X{\v}{} - \alt{\X{\v}{}}\|_\t} \leq |\sv{\v}{\V} - \alt{\sv{\v}{\V}}| + \const{1}\int_0^\t \sum_{\vv\in \cl{\v}} \ex{\|\X{\vv}{} - \alt{\X{\vv}{}}\|_\tt}\,d\tt\]

for all \(\t \in [0,\T]\).

\ind Unfortunately, we cannot just directly apply Gronwall's inequality to the supremum of the above expression. This is because we are trying to prove continuity with respect to the topology of pointwise convergence. Instead, let \(\b{} > \degr\) and let \(\{\b{\v}\}_{\v \in \V}\) be a sequence of positive real numbers defined by \(\b{\v} = \b{}^{-\numb}\) if \(\v \in \V\pup{\numb}\setminus \V\pup{\numb-1}\) and \(\b{\root} = 1\). Because the degree of each node in \(\G\) is bounded by \(\degr\), we know that \(|\V\pup{\numb}\setminus \V\pup{\numb-1}| \leq \degr^{\numb}\) for all \(\numb\in \mb{N}\). Then \(\sum_{\v \in \V} \b{\v} \leq \sum_{\numb=0}^\infty \left(\frac{\degr}{\b{}}\right)^{-\numb} < \infty\). Since \(\S\) is finite, the norm \(\|\sv{}{\V}\|_{\b{}} := \sum_{\v \in \V} \b{\v}|\sv{\v}{\V}|\) generates the topology of componentwise convergence on \(\S^\V\). We can now apply Gronwall's inequality:

\begin{align*}
\ex{\|\X{}{} - \alt{\X{}{}}\|_{\b{},\t}} &= \sum_{\v \in \V} \b{\v}\ex{\|\X{\v}{} - \alt{\X{\v}{}}\|_\t}\\
&\leq \|\sv{}{\V} - \alt{\sv{}{\V}}\|_{\b{}} + \sum_{\v \in \V}\const{1}\int_0^\t \sum_{\vv \in \cl{\v}} \ex{\b{\v}\|\X{\vv}{} - \alt{\X{\vv}{}}\|_\tt}\,d\tt\\
&\os{\b{\v}\leq \b{}\b{\vv}}{\leq} \|\sv{}{\V} - \alt{\sv{}{\V}}\|_{\b{}} + \sum_{\v \in \V}\const{1}\int_0^\t \sum_{\vv \in \cl{\v}} \b{}\ex{\b{\vv}\|\X{\vv}{} - \alt{\X{\vv}{}}\|_\tt}\,d\tt\\
&= \|\sv{}{\V} - \alt{\sv{}{\V}}\|_{\b{}} + \b{}\const{1}\int_0^\t \sum_{\v \in \V}\sum_{\vv \in \cl{\v}} \ex{\b{\vv}\|\X{\vv}{} - \alt{\X{\vv}{}}\|_\tt}\,d\tt\\
&=\|\sv{}{\V} - \alt{\sv{}{\V}}\|_{\b{}} + \b{}(\degr+1)\const{1}\int_0^\t \ex{\|\X{}{} - \alt{\X{}{}}\|_{\b{},\tt}}\,d\tt\\
\end{align*}

Applying Gronwall's inequality:

\[\ex{\|\X{}{} - \alt{\X{}{}}\|_{\b{},\T}} \leq \|\sv{}{\V} - \alt{\sv{}{\V}}\|_{\b{}}e^{\T\b{}(\degr+1)\const{1}}\]

Now, let \(f: \S^\V \ra \mb{R}\) be a continuous function. Since \(\S^\V\) is compact, \(f\) must be uniformly continuous. Then there exists a continuous monotonic function \(\phi: \mb{R}_+ \ra \mb{R}_+\) such that \(\phi(0) = 0\) and \(|f(\sv{}{\V}) - f(\alt{\sv{}{\V}})| \leq \phi(|\sv{}{\V} - \alt{\sv{}{\V}}|)\) for all \(\sv{}{\V},\alt{\sv{}{\V}}\in \S^\V\). Furthermore, since \(f\) is necessarily bounded, we can assume that \(\phi\) is bounded.

\ind Fix any \(\ep > 0\). Let \(\psi_\ep\) be a convex, monotonic, upper-bound of \(\phi\) such that \(\psi_\ep(0) = \ep\) (see Lemma \ref{sec::TL:Lem::concbd}). By Jensen's inequality,

\begin{align*}
\ex{\|f(\X{}{}) - f(\alt{\X{}{}})\|_\T} &\leq \ex{\psi_\ep\left(\|\X{}{} - \alt{\X{}{}}\|_{\T,\b{}}\right)}\\
&\leq \psi_\ep\left(\ex{\|\X{}{} - \alt{\X{}{}}\|_{\T,\b{}}}\right)\\
&\leq \psi_\ep\left(\|\sv{}{\V} - \alt{\sv{}{\V}}\|_{\b{}}e^{\T\b{}(\degr+1)\const{1}}\right) \os{\sv{}{\V} \ra\alt{\sv{}{\V}}}{\ra} \ep.
\end{align*}

Since \(\ep > 0\) is arbitrary, we can conclude that 

\[\ex{\|f(\X{}{}) - f(\alt{\X{}{}})\|_\T} \os{\sv{}{\V} \ra\alt{\sv{}{\V}}}{\ra} 0.\]

This concludes the proof that \(\X{}{}\) is Feller.
\end{enumerate}

Let \(f \in \core\). Recall that \(\core\) is the core of \(\IG\). Then \(f\) can be represented by the SDE

\[f(\X{}{\t}) = f(\X{}{0}) + \sum_{\v \in \V} \int_\S\int_0^\t [f(\X{}{\tt-} + \s\ev{\v}) - f(\X{}{\tt-})]\,\poiss{\v}\left(d\tt,(0,\rate{\v}(\X{}{\tt-},\s)],d\s\right)\]


By Theorem \ref{sec::Infin:Thm::Bij}, the infinitesimal generator of \(\X{}{}\) applied to \(f\) is given by 

\begin{align*}
\IG f(\sv{}{\V}) &= \lim_{\t \searrow 0} \frac{1}{\t} \ex{f(\X{}{\t}) - f(\sv{}{\V})|\X{}{0} = \sv{}{\V}}\\
&= \lim_{\t \searrow 0} \ex{\sum_{\v \in \V} \frac{1}{\t}\int_\S\int_0^\t \left[f(\X{}{\tt-} + \s\ev{\v}) - f(\X{}{\tt-})\right]\,\poiss{\v}\left(d\tt,(0,\rate{\v}(\X{}{\tt-},\s)],d\s\right)\middle|\X{}{0} = \sv{}{\V}}\\
&\os{f \in \mc{D}}{=} \lim_{\t \searrow 0}\sum_{\v \in \V} \frac{1}{\t}\int_\S\int_0^\t \ex{\left[f(\X{}{\tt-} + \s\ev{\v}) - f(\X{}{\tt-})\right]\rate{\v}(\X{}{\tt-},\s)\middle|\X{}{0} = \sv{}{\V}}d\tt\,\Sm(d\s)\\
&\os{\te{Lebesgue Differentiation}}{=} \sum_{\v \in \V} \int_\S \rate{\v}(\sv{}{\V},\s)[f(\sv{}{\V} + \s\ev{\v}) - f(\sv{}{\V})]\,\Sm(d\s)\\
&= \sum_{\v \in \V} \sum_{\s \in \S} \IGr{\v}(\sv{}{\V},\s)[f(\sv{}{\V} + \s\ev{\v}) - f(\sv{}{\V})]
\end{align*}
\end{proof}

\lin

\begin{prop}
Suppose Assumption \ref{subsec::Assum:Assu::CI} holds. Let \(\root \in \V\) be some node. Let \(\V\pup{0} = \{\root\}\) and \(\V\pup{\numb+1} = \cl{\V\pup{\numb}}\) for all \(\numb \in \mb{N}\). For all \(\U \subseteq \V\) and \(\t \in [0,\T]\), let \(\Omega{\U}{\t}\) be embedded in \(\Omega{\V}{\t}\) in the standard way. Let \(\X{}{0}{\numb} = \piV{\V\pup{\numb}}{0}(\X{}{0})\). For each \(\numb\in\mb{N}\), let the \(\Omega{\V\pup{\numb}}{\T}\)-valued random element \(\X{}{}{\numb}\) be the unique Feller process with initial condition \(\X{}{0}{\numb}\) and infinitesimal generator,

\begin{equation}
\IG\pup{\numb}f(\sv{}{\V\pup{\numb}}) = \sum_{\v\in \V\pup{\numb}}\sum_{\s\in \S} \IGr{\v}(\sv{}{\V\pup{\numb}}, \s)[f(\sv{}{\V\pup{\numb}} + \s\ev{\v}) - f(\sv{}{\V\pup{\numb}})]\te{ for all } \sv{}{\V\pup{\numb}} \in \S^{\V\pup{\numb}}.
\label{subsec::Well-:eqn::FinIG}
\end{equation}
\labe{subsec::Well-:eqn::FinIG}

(Here we use the embedding \(\sv{\v}{\V\pup{\numb}} = \mb{I}_{\v\in\V\pup{\numb}} \sv{\v}{\V\pup{\numb}}\) for all \(\v \in \V\)) Then \(\X{}{}{\numb} \Rightarrow \X{}{}\).
\label{subsec::Well-:Prop::IGApprox}
\end{prop}
\labe{subsec::Well-:Prop::IGApprox}

\purpose Our goal is to apply the local representation to finite networks. In order for that to work, we must first know that the marginals converge so that representations of the marginals on the infinite network are asymptotically valid for finite networks.

\pfsum Use Theorem \ref{sec::TL:Thm::Tight} to prove that the sequence is tight. Then show that the infinitesimal generators converge using properties of the core. Finally apply Corollary \ref{sec::Infin:Cor::Convergence} from the appendix to obtain weak convergence.

\usein Nowhere (I should write a corollary to Theorem \ref{sec::Main:Thm::Local SDE} making use of this proposition).

\app Assumption \ref{subsec::Assum:Assu::CI}, Proposition \ref{subsec::Well-:Prop::Welldef}, Definition \ref{sec::TL:Def::modulus}, Lemma \ref{sec::TL:Lem::TightSupport}, Theorem \ref{sec::TL:Thm::Tight} and Corollary \ref{sec::Infin:Cor::Convergence}.

\begin{proof}
First, for each \(\numb\in\mb{N}\), \(\X{}{}{\numb}\) satisfies Assumption \ref{subsec::Assum:Assu::CI}, so by Proposition \ref{subsec::Well-:Prop::Welldef}, \(\X{}{}{\numb}\) is uniquely defined by its initial condition \(\X{}{0}{\numb}\) and its infinitesimal generator \(\IG\pup{\numb}\).

\ind To prove weak convergence, we first begin by showing that \(\{\X{}{}{\numb}:\numb\in \mb{N}\}\) is tight. Note that \(\S^\V\) is compact, so \(\sup_{\sv{}{\V} \in \S^\V} \|\sv{}{\V}\|_{\b{}} < \infty\) (recall that \(\|\sv{}{\V}\|_{\b{}} = \sum_{\v \in \V} \b{\v} |\sv{\v}{\V}|\) where \(\b{\v} = \b{}^{-\numb}\) for some \(\b{} > \degr\) if \(\v \in \V\pup{\numb}\setminus \V\pup{\numb-1}\)).

\ind Now fix \(\ep > 0\). Let \(M\) be large enough that

\[\sup_{\sv{}{\left(\V\pup{M}\right)^c} \in \S^{\left(\V\pup{M}\right)^c}} \left\|\sv{}{\left(\V\pup{M}\right)^c}\right\|_{\b{}} \leq |\S|\sum_{\v \notin \V\pup{M}} \b{\v} < \ep/4.\]

Recall from Definition \ref{sec::TL:Def::modulus}, the c\`adl\`ag version of the modulus of continuity is given by,

\[\omega'_{\X{}{}}(\delta) = \inf_{\{\t\pup{\it}\}} \sup_\it \sup_{\tt,\ttt \in [\t\pup{\it-1},\t\pup{\it})} \|\X{}{\tt} - \X{}{\ttt}\|_{\b{}},\]

where \(\{\t\pup{\it}\} := 0 \leq \t\pup{1} < \t\pup{2} < \cdots < \t\pup{\cdot} = \T\) and \(\min_\it|\t\pup{\it} - \t\pup{\it-1}| > \delta\). Note that \(\X{}{}{\numb}\) is \(\Omega{\V\pup{\numb}}{\T}\)-valued and can be embedded in \(\Omega{\V}{\T}\) the same way we embed \(\S^{\V\pup{\numb}}\) in \(\S^\V\): let \(\X{\v}{}{\numb} \equiv 0\) for \(\v \notin \V\pup{\numb}\). Recall also that \(\piV{\U}{\T}\) is the projection to \(\Omega{\U}{\T}\) for all \(\U\subseteq \V\). Then for any \(\numb\in \mb{N}\),

\begin{align*}
\pr\left(\sup_\numb \omega'_{\X{}{}{\numb}}(\delta) > \epsilon\right) &= \pr\left(\sup_\numb\inf_{\{\t\pup{\it}\}}\sup_\it\sup_{\tt,\ttt \in [\t\pup{\it-1},\t\pup{\it})} \sum_{\v \in \V} \b{\v}|(\X{\v}{\tt}{\numb} - \X{\v}{\ttt}{\numb}| > \epsilon \right)\\
&\leq \pr\left(\sup_\numb \left(\omega'_{\piV{\V\pup{M}}{\T}(\X{}{}{\numb})}(\delta) + \omega'_{\piV{\left(\V\pup{M}\right)^c}{\T}(\X{}{}{\numb})}(\delta)\right) > \ep\right)\\
&\leq \pr\left(\sup_\numb \omega'_{\piV{\V\pup{M}}{\T}(\X{}{}{\numb})}(\delta) > \ep/2\right) \os{\delta\searrow 0}{\ra} 0.
\end{align*}

The last inequality arises because

\[\omega'_{\piV{\left(\V\pup{M}\right)^c}{\T}(\X{}{}{\numb})}(\delta) \leq 2 \sup_{\t\in [0,\T]} \left\|\piV{\left(\V\pup{M}\right)^c}{\T}(\X{}{}{\numb})\right\|_{\b{}} \leq 2 \sup_{\sv{}{\left(\V\pup{M}\right)^c} \in \S^{\left(\V\pup{M}\right)^c}} \left\|\sv{}{\left(\V\pup{M}\right)^c}\right\|_{\b{}} < \ep/2\]

Finally, the convergence to 0 at the end is the result of a direct application of Lemma \ref{sec::TL:Lem::TightSupport}. Thus, \(\{\X{}{}{\numb}:\numb\in \mb{N}\}\) is tight, and therefore relatively compact with respect to the topology of weak convergence (Theorem \ref{sec::TL:Thm::Tight}).

Now, suppose \(f\in \core\). Then for all \(\sv{}{\V} \in \S^\V\),

\begin{align*}
\big|\IG&\pup{\numb}f(\sv{}{\V}) - \IG f(\sv{}{\V})\big|\\
&= \left|\sum_{\v \in \V\pup{\numb}} \sum_{\s \in \S} \IGr{\v}(\piV{\V\pup{\numb}}{}(\sv{}{\V}),\s)[f(\sv{}{\V}+\s\ev{\v}) - f(\sv{}{\V})] - \sum_{\v \in \V}\sum_{\s \in \S} \IGr{\v}(\sv{}{\V},\s)[f(\sv{}{\V}+\s\ev{\v}) - f(\sv{}{\V})]\right|\\
&\leq  \left|\sum_{\v \in \V\pup{\numb}} \sum_{\s \in \S} \IGr{\v}(\piV{\V\pup{\numb}}{}(\sv{}{\V}),\s)[f(\sv{}{\V}+\s\ev{\v}) - f(\sv{}{\V})] - \sum_{\v \in \V\pup{\numb}}\sum_{\s \in \S} \IGr{\v}(\sv{}{\V},\s)[f(\sv{}{\V}+\s\ev{\v}) - f(\sv{}{\V})]\right|\\
&\ind  +\left|\sum_{\v \notin \V\pup{\numb}} \sum_{\s\in \S} \IGr{\v}(\sv{}{\V},\s)[f(\sv{}{\V}+\s\ev{\v}) - f(\sv{}{\V})]\right|\\
&\leq \sum_{\v \in \V\pup{\numb}}\sum_{\s \in \S} \left|\IGr{\v}(\piV{\V\pup{\numb}}{}(\sv{}{\V}),\s) - \IGr{\v}(\sv{}{\V},\s)\right|\triangle_f(\v) + \sum_{\v \in \V\setminus \V\pup{\numb}} \const{}\triangle_f(\v)\\
&\os{Assump. \ref{subsec::Assum:Assu::CI}.2}{=} \sum_{\v \in \V\pup{\numb}\setminus\V\pup{\numb-1}} |\S|\const{} \triangle_f(\v) + \sum_{\v \in \V\setminus \V\pup{\numb}} \const{}\triangle_f(\v)\\
&\leq |\S|C\sum_{\v \in \V\setminus \V\pup{\numb-1}} \triangle_f(\v) \os{n\ra\infty}{\ra} 0.
\end{align*}

Here \(\triangle_f(\v) = \sup\left\{|f(\sv{}{\V}) - f(\sv{}{\V} + \s\ev{\v}): \sv{}{\V}\in \S^\V,\s \in \S\right\}\) as defined in equation \eqref{subsec::Well-:Eqn::fvar}. By Corollary \ref{sec::Infin:Cor::Convergence}, \(\X{}{}{\numb}\Rightarrow \X{}{}\).
\end{proof}


\lin
\section{Main Results}
\label{sec::Main}\labe{sec::Main}

Some further notation. Let \(\X{}{[0,\t]}\) denote the trajectory of \(\X{}{}\) on the time interval \([0,\t]\). Similarly, \(\X{}{[0,\t)}\) is \(\X{}{}\) on the interval \([0,\t)\) and so on.

\ind For \(\U \subseteq \V\), let \(\dneigh{\U} = \neigh{\U} \cup \neigh{\ov{\U}}\). 

\ind For random elements \(\X{}{},\rxvtts{}{}\) and \(\rxvttts{}{}\), we say that \(\X{}{}\) is conditionally independent of \(\rxvtts{}{}\) given \(\rxvttts{}{}\) if \(\X{}{}\perp\rxvtts{}{}|\rxvttts{}{}\).

\lin

\begin{thms}
Suppose Assumption \ref{subsec::Assum:Assu::CI} holds. Suppose \(\U \subset \V\). Let \(\UU = \V\setminus \ov{\ov{\U}}\). Let \(\UUU= \dneigh{U}\) and suppose that \(|\UUU| < \infty\). Then for all \(\t < \infty\),

\[\X{\U}{[0,\t)}\perp \X{\UU}{[0,\t)}|\X{\UUU}{[0,\t)}\]
\label{sec::Main:Thm::CI}
\end{thms}
\labe{sec::Main:Thm::CI}

\purpose This property may be of independent interest elsewhere. However, in this paper it is vital because it allows us to use a crucial recursion in the local representation of \(\X{}{}\).

\pfsum See Section \ref{sec::Proof1}.

\lin

\begin{thms}
Let \(\X{}{}\) be a Feller process satisfying Assumption \ref{subsec::Assum:Assu::Local} with infinitesimal generator \(\IG\). Let \(\m{}{}{} = \law(\X{}{})\). Let the sequence \(\{\rate{\v},\poiss{\v}:\v\in \V\}\) be defined as in Proposition \ref{subsec::Well-:Prop::SDEWP}. Let \(\root\) be the root of \(\G\) and let \(\{1,\dots,\degr\}\) be the children of \(\root\) in \(\G\). For any \(\Omega \supseteq\Omega{\tree\pup{1}}{\T}\), \(\t\in (0,\T]\) and \(\mmm{}{}{} \in \pmsr(\Omega)\), define \(\cm_\t:\Omega{\{\root,1\}}{\t-}\times \pmsr(\Omega) \ra \pmsr(\Omega{\{2,\dots,\degr\}}{\t-})\) by,

\begin{equation}
\cm_\t(\x{\{\root,1\}}{[0,\t)},\mmm{}{}{})(\cdot) = \pr^{\mmm{}{}{}}\left(\X{\{2,\dots,\degr\}}{[0,\t)} \in \cdot|\X{\{\root,1\}}{[0,\t)} = \x{\{\root,1\}}{[0,\t)}\right).
\label{sec::Main:eqn::gamma}
\end{equation}
\labe{sec::Main:eqn::gamma}

Then there exists a unique solution, \(\alt{\m{}{}{}} \in \pmsr(\Omega{\tree\pup{1}}{\T})\), to the following equation:

\begin{align}
\X{\v}{\t} &= \X{\v}{0} + \int_0^\t\int_\S \s\,\poiss{\v}(d\s,(0,\alt{\rate{}}(\X{\{\v,\root\}}{[0,\tt)},\s)],d\tt) \te{ for } \v \in \{1,\dots,\degr\}\nonumber\\
\X{\root}{\t} &= \X{\root}{0} + \int_0^\t\int_\S \s\,\poiss{\root}(d\s,(0,\rate{\root}(\X{}{\tt-},\s)],d\tt)\nonumber\\
\alt{\m{}{}{}} &= \law(\X{}{})
\label{sec::Main:eqn::Local SDE}
\end{align}
\labe{sec::Main:eqn::Local SDE}

where

\[\alt{\rate{}}(\X{\{\v,\root\}}{[0,\t)},\s) = \exmu{\cm_t(\X{\{\v,\root\}}{[0,\t)},\alt{\m{}{}{}})}{\rate{\root}(\X{}{\t-},\s)}\]

for all \(\s\in \S\). Furthermore, \(\alt{\m{}{}{}} = \piV{\tree\pup{1}}{\T}(\m{}{}{})\).
\label{sec::Main:Thm::Local SDE}
\end{thms}
\labe{sec::Main:Thm::Local SDE}

\purpose This is the main result of the paper. 

\pfsum See section \ref{sec::Proof2}.

\lin

\section{Proof of Theorem \ref{sec::Main:Thm::CI}}
\label{sec::Proof1}\labe{sec::Proof1}

\pfsum We consider two sets of stopping times. The events driving \(\X{}{}^{\neigh{\U}}\) and the events driving \(\X{}{}^{\neigh{\UU}}\). Because \(|\UUU| < \infty\), these are well behaved. We apply induction by iterating over one of the stopping times along a path in \(\mb{N}^2\). At each inductive step, we combine various properties of conditional independence with a breakdown of each path into its component random elements to prove the result. By combining all possible paths, we change from stopping times to deterministic times. There is a minor adaptation we have to make at the end to change from closed intervals to half-open intervals.

\skipLine

\textbf{Remark:} In this section we will distinguish between the events \(\{\X{}{[0,\t]} = 0\}\) and \(\{\X{}{[0,\t]}\equiv 0\}\). The first event is an event of probability 0 when \(\X{}{}\) is a \(\Omega{\U}{\t}\) or \(\Omega{\U}{\t-}\)-valued random variable for some \(\U\subseteq \V\) and \(\t \in [0,\T]\) (because 0 is not a path) while the second event is the event that \(\X{}{\tt} = 0\) for all \(\tt \in [0,\t]\).

\ind Given three random elements \(\X{}{},\rxvtts{}{} \te{ and } \rxvttts{}{}\), we say \(\X{}{}\perp \rxvtts{}{}\) if \(\X{}{}\) and \(\rxvtts{}{}\) are independent. We say \(\X{}{}\mutex \rxvtts{}{}\) if the events \(\{\X{}{}\neq 0\}\) and \(\{\rxvtts{}{} \neq 0\}\) are mutually exclusive. We say \(\X{}{}\perp \rxvtts{}{}|\rxvttts{}{}\) if \(\X{}{}\) and \(\rxvtts{}{}\) are conditionally independent given \(\rxvttts{}{}\).

\lin

\begin{defn}
We define the pair of sequences of stopping times:

\begin{align*}
\rt{\itt} &= \inf \left\{\t > 0: \poiss{\neigh{\U}}\left([0,\t],(0,\const{}],\S\right) = \itt\right\}\\
\rtt{\ittt} &= \inf \left\{\t > 0: \poiss{\neigh{\UU}}\left([0,\t],(0,\const{}],\S\right) = \ittt\right\}.
\end{align*}

Here \(\const{}\) is as defined in Assumption \ref{subsec::Assum:Assu::CI}. We also define the set of paths along \(\mb{N}^2\) by,

\begin{align}
\pathset{\itt}{\ittt} = \{\apath \in (\mb{N}^2)^{\itt+\ittt-1}: &\apath(1) = (1,1)\te{, } \apath(\itt+\ittt-1) = (\itt,\ittt)\te{, and } \nonumber\\
&\Gamma(\it+1) - \Gamma(\it)\in \{\ev{1},\ev{2}\}\te{ for }\it\in \{1,\dots, \itt+\ittt-2\}\}.
\label{sec::Proof1:eqn::Lambda}
\end{align}
\labe{sec::Proof1:eqn::Lambda}

\(\ev{1},\ev{2}\) are assumed to be the standard basis vectors on \(\mb{N}^2\). We can equivalently define a path \(\apath \in \pathset{\itt}{\ittt}\) as an event:

\begin{align}
\apath(\it) &= \begin{cases}
\left\{\rt{\apath_1(\it)} \leq \rtt{\apath_2(\it)}\right\} &\te{ if } \apath(\it+1) - \apath(\it) = \ev{1}\\
\left\{\rt{\apath_1(\it)} > \rtt{\apath_2(\it)}\right\} &\te{ if } \apath(\it+1) - \apath(\it) = \ev{2}
\end{cases}\\
\apath &= \bigcap_{\it=1}^{\itt+\ittt-2} \apath(\it)
\label{sec::Proof1:eqn::Gamma}
\end{align}
\labe{sec::Proof1:eqn::Gamma}
\label{sec::Proof1:Def::GammaLambda}
\end{defn}
\labe{sec::Proof1:Def::GammaLambda}

\purpose The core of the proof of Theorem \ref{sec::Main:Thm::CI} comes from iterating over these stopping times in such a way that no stopping time gets too large with respect to the other. \(\apath\) tracks the route taken while \(\pathset{\itt}{\ittt}\) is the set of all possible values of \(\apath\) given the current state of induction.

\lin

\begin{lem}
For all \((\itt,\ittt)\in \mb{N}_0^2\) and \(\apath \in \pathset{\itt}{\ittt}\),

\[\X{\U}{[0,\rt{\itt})}\mb{I}_{\apath}\perp \X{\UU}{[0,\rtt{\ittt})}\mb{I}_{\apath}|\left(\X{\neigh{\U}}{[0,\rt{\it})},\X{\neigh{\UU}}{[0,\rtt{\ittt})}\right)\mb{I}_{\apath}\]
\label{sec::Proof1:Lem::Induction}
\end{lem}
\labe{sec::Proof1:Lem::Induction}

\purpose This is the inductive step on the stopping times given a certain path of induction.

\pfsum Using Lemma \ref{sec::Proof1:Lem::Decomposition}, we break \(\X{}{}\) into its component random elements and manipulate it using the properties of conditional independence proven in Appendix \ref{sec::TL}.

\lin

\begin{lem}
For all \((\itt,\ittt)\in \mb{N}^2\), there exist measurable mappings \(\phi\) and \(\psi\) such that 

\begin{equation}
\X{\U}{[0,\rt{\itt+1})} = \phi\left(\X{\cl{\U}}{[0,\rt{\itt}]}, \poiss{\U}\left((\rt{\itt}, \rt{\itt+1}]\times \mb{R}\times \S\right)\right)
\label{sec::Proof1:eqn::XU forward map}
\end{equation}
\labe{sec::Proof1:eqn::XU forward map}

and

\begin{equation}
\X{\UU}{[0,\rtt{\ittt+1})} = \phi\left(\X{\cl{\UU}}{[0,\rtt{\ittt}]}, \poiss{\UU}\left((\rtt{\ittt}, \rtt{\ittt+1}]\times \mb{R}\times \S\right)\right)
\label{sec::Proof1:eqn::XW forward map}
\end{equation}
\labe{sec::Proof1:eqn::XW forward map}

\label{sec::Proof1:Lem::Decomposition}
\end{lem}
\labe{sec::Proof1:Lem::Decomposition}

\purpose This is an intermediate step required to prove Lemma \ref{sec::Proof1:Lem::Induction}.

\pfsum Take the SDE definition of \(\X{}{}\). Use the existence of a unique solution to break down exactly which random elements need to be known to derive \(\X{\U}{[0,\rt{\itt+1})}\). The same idea holds for \(\X{\UU}{[0,\rtt{\ittt+1})}\).


\begin{proof}
By symmetry, it suffices to prove that equation \ref{sec::Proof1:eqn::XU forward map} holds (if we proof equation \eqref{sec::Proof1:eqn::XU forward map} holds for all \(\U \subseteq \V\), then we can proof equation \eqref{sec::Proof1:eqn::XW forward map} holds by swapping the definitions of \(\U\) and \(\UU\)). By Proposition \ref{subsec::Well-:Prop::SDEWP}, for any sequence of i.i.d. Poisson processes, \(\poisses\), on \(\mb{R}^2\times \S\) with intensity measure \(\leb\times\Sm\) we can write,

\[\X{\v}{\t} = \X{\v}{0} + \int_\S\int_0^\t \s\,\poiss{\v}\left(d\tt,\left(0,\rate{\v}(\X{}{\tt-},\s)\right],d\s\right)\te{ for all } \v\in \V.\]

Consider the following coupled equations:

\begin{align}
\rxvtt{\vv}{\t} &= \X{\vv}{\rt{\itt}} + \int_\S\int_0^\t \s\alt{\poiss{\vv}}\left(d\tt,\left(0,\rate{\vv}(\rxvtt{}{\tt-},\s)\right],d\s\right)\te{ for } \vv \in \cl{\U} \te{ on } \rt{\itt} < \infty \label{sec::Proof1:eqn::alternate SDE}\\
\rxvtts{\vv}{} &\equiv 0\te{ for } \vv\notin \cl{\U}\nonumber\\
\alt{\poiss{\vv}}(d\tt,d\r,d\s) &= \poiss{\vv}(\rt{\itt} + d\tt,d\r,d\s) \te{ for all }\vv\in \cl{\U}\nonumber\\
\alt{\X{\vv}{\t}} &= \begin{cases}
\X{\vv}{\t} &\te{ on } \t \leq \rt{\itt}\\
\rxvtt{\vv}{\t - \rt{\itt}} &\te{ on } \t > \rt{\itt}
\end{cases} \te{ for all } \vv\in \cl{\U} \nonumber
\end{align}
\labe{sec::Proof1:eqn::alternate SDE}

It's easy to see that \(\rt{\itt}\) is almost surely finite for every finite \(\itt\) \(\left(\ex{\rt{\itt}} = \frac{\itt}{\const{}|\neigh{\U}|} < \infty\right)\). 

\ind \tr{Originally I used the strong Markov property to reduce to the case of \(\itt = 0\). However, since \(\rt{\itt}\) is not an \(\X{}{}\)-stopping time, I need to show that \(\X{}{}\) is strong-Markov or Feller with respect to the larger filtration containing the driving Poisson processes. While this is not that difficult, the argument is tedious and long, so I chose not to use this reduction.}

\ind By Proposition \ref{subsec::Well-:Prop::SDEWP}, equation \eqref{sec::Proof1:eqn::alternate SDE} has a unique solution, so \(\alt{\X{}{}}\) is well-defined. To prove this lemma, we first show that \(\X{\U}{[0,\rt{\itt+1})} = \alt{\X{\U}{}}{[0,\rt{\itt+1})}\) almost surely. 

\ind Fix any \(\t > 0\). Let \(\evnt_\t = \{\t < \rt{\itt+1}\}\) and \(\alt{\evnt}_\t = \{\t\in [\rt{\itt},\rt{\itt+1})\}\). Notice that \(\evnt_\tt \supseteq \evnt_\t\) for all \(\tt\in [0,\t]\) when \(\t > 0\). 

\ind Notice that \(\rt{\itt} \perp \poiss{\v}\) for all \(\v \in \U\). Thus, \(\poiss{\v}(d\tt+\rt{\itt},dr,d\s) \deq \poiss{\v}(d\tt,dr,d\s)\). Now, \(\alt{\X{\neigh{\U}}{}}[0,\rt{\itt}] = \X{\neigh{\U}}{[0,\rt{\itt}]}\) almost surely by definition. Furthermore,

\[\alt{\X{\neigh{\U}}{\t}}\mb{I}_{\rt{\itt}\leq \t < \rt{\itt+1}} = \alt{\X{\neigh{\U}}{\rt{\itt}}}\mb{I}_{\rt{\itt}\leq \t < \rt{\itt+1}} = \X{\neigh{\U}}{\rt{\itt}}\mb{I}_{\rt{\itt}\leq \t < \rt{\itt+1}} = \X{\neigh{\U}}{\t}\mb{I}_{\rt{\itt}\leq \t < \rt{\itt+1}}\]

so

\[\alt{\X{\neigh{\U}}{}}[0,\rt{\itt+1}) = \X{\neigh{\U}}{[0,\rt{\itt+1})} \te{ a.s.}\]

Furthermore, by the same argument presented in the beginning of the proof of Lemma \ref{subsec::Well-:Lem::SDEWP}, we can assume without loss of generality that 

\[|\rate{\v}(\sv{\V}{},\s) - \rate{\v}(\alt{\sv{\V}{}},\s)| \leq \const{}\sum_{\vv\in \cl{\v}} |\sv{\V}{\vv} - \alt{\sv{\V}{\vv}}|\te{ for all } \sv{\V}{},\alt{\sv{\V}{}}\in \S^\V,\s \in \S \te{ and } \v \in \V.\]

\tr{For any \(a,b\in \mb{R}\), I use the shorthand \((a,b]\) to denote the interval \((a\wedge b,a\vee b]\)}. Then for all \(v\in \U\) and \(\t > 0\),

\begin{align*}
&\ex{\left\|\alt{\X{\v}{}} - \X{\v}{}\right\|_{\t}\mb{I}_{\t < \rt{\itt+1}}} = \ex{\left\|\alt{\X{\v}{}} - \X{\v}{}\right\|_{\t}\mb{I}_{\evnt_\t}}\os{\alt{\X{\cl{\U}}{}}[0,\rt{\itt}] = \X{\cl{\U}}{[0,\rt{\itt}]}}{=} \ex{\left\|\alt{\X{\v}{}} - \X{\v}{}\right\|_{\t}\mb{I}_{\alt{\evnt}_\t}}\\
&\ind\leq \ex{\mb{I}_{\alt{\evnt}_\t}\left|\int_\S\int_{(\rt{\itt},t]} \s\,\poiss{\v}\left(d\tt,\left(0,\rate{\v}(\X{}{\tt-},\s)\right]\,d\s\right) - \int_\S\int_{(\rt{\itt},\t]} \s\,\alt{\poiss{\v}}\left(d\tt,\left(0,\rate{\v}(\alt{\X{}{\tt-}},\s)\right]\,d\s\right)\right|}\\
&\ind \leq \ex{\int_\S\int_{\mb{R}}\int_{(\rt{\itt},\t]}|\s|\mb{I}_{\alt{\evnt}_\t}\mb{I}_{\r\in \left(\rate{\v}(\X{}{\tt-},\s), \rate{\v}(\alt{\X{}{\tt-}},\s)\right]}\,\poiss{\v}\left(d\tt,d\r,d\s\right)}\\
&\ind \os{\alt{\X{\cl{\U}}{}}[0,\rt{\itt}] = \X{\cl{\U}}{[0,\rt{\itt}]}}{=} \ex{\int_\S\int_{\mb{R}}\int_{(0,\t]}|\s|\mb{I}_{\evnt_\t}\mb{I}_{\r\in \left(\rate{\v}(\X{}{\tt-},\s), \rate{\v}(\alt{\X{}{\tt-}},\s)\right]}\,\poiss{\v}\left(d\tt,d\r,d\s\right)}\\
&\ind = \int_\S\int_\mb{R}\int_0^\t |\s|\ex{\mb{I}_{\evnt_\t}\mb{I}_{\r\in\left(\rate{\v}(\X{}{\tt-},\s),\rate{\v}(\alt{\X{}{\tt-}},\s)\right]}}\,d\tt\,d\r\,\Sm(d\s)\\
&\ind = \int_\S |\s|\int_0^\t \ex{\mb{I}_{\evnt_t}\left|\rate{\v}(\alt{\X{}{\tt-}},\s) - \rate{\v}(\X{}{\tt-},\s)\right|}\,d\tt\,\Sm(d\s)\\
&\ind \leq \const{}\int_\S|\s|\int_0^\t\ex{\mb{I}_{\evnt_t}\sum_{\vv\in \cl{\v}}\left|\alt{\X{\vv}{\tt-}} - \X{\vv}{\tt-}\right|}\,d\tt\\
&\ind \os{\mb{I}_{\evnt_\t}\|\alt{\X{\neigh{\U}}{}} - \X{\neigh{\U}}{}\|_t = 0}{\leq} \left(\int_\S|\s|\,\Sm(d\s)\right)\const{} \int_0^\t \sum_{\vv\in \cl{\v}\cap\U}\ex{\mb{I}_{\evnt_t}\|\alt{\X{\vv}{}} - \X{\vv}{}\|_\tt}\,d\tt\\
&\ind \os{\evnt_\tt \supseteq \evnt_\t}{\leq} |S|\const{}(\degr+1) \int_0^\t \sup_{\v\in \U}\ex{\mb{I}_{\evnt_\tt}\|\alt{\X{\v}{}} - \X{\v}{}\|_\tt}\,d\tt.
\end{align*}

We can conclude that

\[\sup_{\v\in \U}\ex{\left\|\alt{\X{\v}{}} - \X{\v}{}\right\|_{\t}\mb{I}_{t <\rt{\itt+1}}} \leq |\S|\const{}(\degr+1)\int_0^\t\sup_{v\in\U}\ex{\left\|\alt{\X{\v}{}} - \X{\v}{}\right\|_\tt\mb{I}_{\tt < \rt{\itt+1}}}\,d\tt.\]

By Gronwall's inequality,

\[\sup_{v\in \U}\ex{\left\|\alt{\X{\v}{}} - \X{\v}{}\right\|_\t\mb{I}_{\t < \rt{\itt+1}}} = 0 \te{ for all } \t > 0,\]

so \(\alt{\X{\U}{}}[0,\rt{\itt+1}) = \X{\U}{[0,\rt{\itt+1})}\) almost surely. However, \(\alt{\X{\U}{}}[0,\rt{\itt+1})\) is uniquely defined by \(\X{\cl{\U}}{[0,\rt{\itt}]}\) and \(\poiss{\cl{\U}}\left((\rt{\itt},\rt{\itt+1}]\times \mb{R}\times \S\right)\).
\end{proof}

\lin

\begin{proof}[Proof of Lemma \ref{sec::Proof1:Lem::Induction}:]
Begin the proof with the base case of \(\itt=\ittt =1\). \(\pathset{1}{1}\) contains a single element \(\apath = ((1,1))\). In addition, \(\mb{I}_{\apath} = 1\).

By independence of initial conditions,

\[\X{\U}{0}\perp \X{\UU}{0}|\X{\dneigh{\U}}{0}.\]

\(\rt{1}\) is \(\sigma\left(\poiss{\vv}:\vv\in \neigh{\U}\right)\) measurable and \(\rtt{1}\) is \(\sigma\left(\poiss{\vv}:\vv\in \neigh{\UU}\right)\) measurable. Therefore, both stopping times are independent of each other and of the initial conditions. By Lemma \ref{sec::TL:Lem::Props}(b), 

\[\X{\U}{0}\perp \X{\UU}{0}|\left(\X{\neigh{\U}}{0},\X{\neigh{\UU}}{0},\rt{1},\rtt{1}\right).\]

Since \(\X{\neigh{\U}}{}\) is constant on \([0,\rt{1})\) and \(\X{\neigh{\UU}}{}\) is constant on \([0,\rtt{1})\), the mapping \((\X{\dneigh{\U}}{0},\rt{1},\rtt{1}) \mapsto (\X{\neigh{\U}}{[0,\rt{1})},\X{\neigh{\UU}}{[0,\rtt{1})})\) is 1-to-1. By Lemma \ref{sec::TL:Lem::Props}(a),

\begin{equation}
\X{\U}{0}\perp \rxvtt{\U}{0}|\left(\X{\neigh{\U}}{[0,\rt{1})},\X{\neigh{\UU}}{[0,\rtt{1})}\right).
\label{sec::Proof1:eqn::induction_intermediate_1}
\end{equation}
\labe{sec::Proof1:eqn::induction\_intermediate\_1}

By Lemma \ref{sec::Proof1:Lem::Decomposition}, we can express \(\X{\U}{[0,\rt{1})}\) in terms of \(\X{\cl{\U}}{0}\) and \(\poiss{\U}([0,\rt{1})\times\mb{R}\times\S)\). We can equivalently describe \(\X{\U}{[0,\rt{1})}\) in terms of \(\X{\U}{0}\), \(\X{\neigh{\U}}{[0,\rt{1})}\) and \(\poiss{\U}([0,\rt{1})\times \mb{R}\times \S)\) which is independent of all terms in expression \eqref{sec::Proof1:eqn::induction_intermediate_1}. Applying a similar argument for \(\X{\UU}{}\), we can apply Lemmas \ref{sec::TL:Lem::Props}(a) and (e) to get

\[\X{\U}{[0,\rt{1})}\perp \X{\UU}{[0,\rtt{1})}|\left(\X{\neigh{\U}}{[0,\rt{1})},\X{\neigh{\UU}}{[0,\rtt{1})}\right)\]

This proves that Lemma \ref{sec::Proof1:Lem::Induction} holds in the base case where \(\itt = \ittt = 1\).

\ind Now, we prove the general case. Suppose Lemma \ref{sec::Proof1:Lem::Induction} holds for \(\alt{\apath} \in \pathset{\itt}{\ittt}\). Then there exists a unique extension, \(\apath \in \pathset{\itt+1}{\ittt}\), of \(\alt{\apath}\). It suffices to prove that Lemma \ref{sec::Proof1:Lem::Induction} holds for \(\apath\) (by symmetry it will also hold for the unique extension of \(\alt{\apath} \te{ to } \pathset{\itt}{\ittt+1}\)). First, note that

\begin{equation}
\mb{I}_{\apath} = \mb{I}_{\alt{\apath}}\mb{I}_{\rt{\itt} \leq \rtt{\ittt}}
\label{sec::Proof1:eqn::extpath}
\end{equation}
\labe{sec::Proof1:eqn::extpath}

By assumption,

\[\X{\U}{[0,\rt{\itt})}\mb{I}_{\alt{\apath}}\perp \X{\UU}{[0,\rtt{\ittt})}\mb{I}_{\alt{\apath}}|\left(\X{\neigh{\U}}{[0,\rt{\itt})},\X{\neigh{\UU}}{[0,\rtt{\ittt})}\right)\mb{I}_{\alt{\apath}}\]

By Lemma \ref{sec::TL:Lem::Props}(d), we can multiply everything by \(\mb{I}_{\rt{\itt} \leq \rtt{\ittt}}\):

\[\X{\U}{[0,\rt{\itt})}\mb{I}_{\apath}\perp \X{\UU}{[0,\rtt{\ittt})}\mb{I}_{\apath}|\left(\X{\neigh{\U}}{[0,\rt{\itt})},\X{\neigh{\UU}}{[0,\rtt{\ittt})}\right)\mb{I}_{\apath}.\]

By definition of \(\rt{\itt}\), there is an event in \(\poiss{\neigh{\U}}\) at time \(\rt{\itt}\) for every \(\itt \in \mb{ N}\). Let \(\rv\) be the random vector signifying in which node of \(\neigh{\U}\) the event is located as well as the height and mark of the event. Because Poisson processes are simple, \(\rv\) is well-defined. Furthermore, \(\rv\) is independent of all terms in the equation above. We can specifically describe the distribution of \(\rv\). Let \(\rv^1\) be uniform over \(\neigh{\U}\). Let \(\rv^2\) be an \(\S\)-valued random variable with distribution \(\Sm\). Finally, let \(\rv^3\) be a uniform \([0,\const{}]\) random variable. Then, if \(\rv=(\rv^1,\rv^2,\rv^3)\),

\[\X{\neigh{\U}}{\rt{\itt}} = \begin{cases}
\X{\neigh{\U}}{\rt{\itt}-} + \rv^2\ev{\rv^1} &\te{ if } \rv^3< \rate{\rv^1}(\X{}{\rt{\itt}-}, \rv^2)\\
\X{\neigh{\U}}{\rt{\itt}-} &\te{ otherwise}
\end{cases}\]

Note, because \(\X{}{}\) satisfies assumption \ref{subsec::Assum:Assu::CI}, \(\X{\neigh{\U}}{\rt{\itt}}\) only depends on \(\X{\cl{\cl{\U}}}{\rt{\itt}-}\) and \(\rv\). By Lemma \ref{sec::TL:Lem::Props}(c), 

\[\X{\U}{[0,\rt{\itt})}\mb{I}_{\apath}\perp \X{\UU}{[0,\rtt{\ittt})}\mb{I}_{\apath}|\left(\X{\neigh{\U}}{[0,\rt{\itt}]},\X{\neigh{\UU}}{[0,\rtt{\ittt})}\right)\mb{I}_{\apath}.\]

\(\rt{\itt+1} - \rt{\itt}\) is \(\sigma(\poiss{\neigh{\U}}(\rt{\itt},\infty))\) measurable, so it is independent of all terms above. Therefore, by Lemma \ref{sec::TL:Lem::Props}(b),

\[\X{\U}{[0,\rt{\itt})}\mb{I}_{\apath}\perp \X{\UU}{[0,\rtt{\ittt})}\mb{I}_{\apath}|\left(\X{\neigh{\U}}{[0,\rt{\itt}]},\X{\neigh{\UU}}{[0,\rtt{\ittt})},\rt{\itt+1} - \rt{\itt}\right)\mb{I}_{\apath}.\]

\(\X{\neigh{\U}}{}\) is constant on \([\rt{\itt},\rt{\itt+1})\), so we can use a 1-to-1 function and Lemma \ref{sec::TL:Lem::Props}(a) to reduce the above statement to

\[\X{\U}{[0,\rt{\itt})}\mb{I}_{\apath}\perp \X{\UU}{[0,\rtt{\ittt})}\mb{I}_{\apath}|\left(\X{\neigh{\U}}{[0,\rt{\itt+1})},\X{\neigh{\UU}}{[0,\rtt{\ittt})}\right)\mb{I}_{\apath}.\]

Now, \(\X{\U}{\rt{\itt}}\) is \(\left(\X{\U}{[0,\rt{\itt})}, \X{\neigh{\U}}{[0,\rt{\itt})}, \poiss{\U}(\{\rt{\itt}\}\times [0,\const{}]\times\S)\right)\) measurable. Applying lemmas \ref{sec::TL:Lem::Props} (a) and (e), we get

\[\X{\U}{[0,\rt{\itt}]}\mb{I}_{\apath}\perp \X{\UU}{[0,\rtt{\ittt})}\mb{I}_{\apath}|\left(\X{\neigh{\U}}{[0,\rt{\itt+1})},\X{\neigh{\UU}}{[0,\rtt{\ittt})}\right)\mb{I}_{\apath}.\]

Combining Lemmas \ref{sec::Proof1:Lem::Decomposition}, \ref{sec::TL:Lem::Props}(a) and \ref{sec::TL:Lem::Props}(e) as in the base case, we get

\[\X{\U}{[0,\rt{\itt+1})}\mb{I}_{\apath}\perp \X{\UU}{[0,\rtt{\ittt})}\mb{I}_{\apath}|\left(\X{\neigh{\U}}{[0,\rt{\itt+1})},\X{\neigh{\UU}}{[0,\rtt{\ittt})}\right)\mb{I}_{\apath}.\]

which completes the proof.
\end{proof}

\lin

\begin{lem}
Notice that for any \((\itt,\ittt) \in \mb{N}^2\), \(\pathset{\itt}{\ittt}\) is a space of disjoint events. Define

\[\pathsete{\itt}{\ittt} := \bigcup_{\apath\in\pathset{\itt}{\ittt}} \apath\]

Then \(\pathsete{\itt}{\ittt}\) differs from \(\{\rt{\itt} > \rtt{\ittt-1}, \rtt{\ittt} > \rt{\itt-1}\}\) by a set of probability zero.
\label{sec::Proof1:Lem::Ckk'}
\end{lem}
\labe{sec::Proof1:Lem::Ckk'}

\purpose This allows us to combine all possible paths to get a simple event which we can use to reduce to the deterministic time case.

\pfsum Direct argument.

\begin{proof}
In this proof, we will implicitly work in the equivalence class of events given by \(\evnt^1 = \evnt^2\) if \(\pr(\evnt^1 \triangle \evnt^2) = 0\).  

\ind First, \(\pathsete{1}{1} = \{\rt{1} > 0,\rtt{1} > 0\} = \{\rt{1} > \rtt{0},\rtt{1}>\rt{0}\}\). For any \(\it > 1\),

\begin{align*}
\pathsete{\it}{1} &= \bigcup_{\apath \in \pathset{\it}{1}} \apath = \{((1,1),\dots,(\it,1))\} = \bigcap_{\itt < \it} \{\rt{\itt} < \rtt{1}\} = \{\rt{\it-1} < \rtt{1}\} = \{\rt{\it} > \rtt{0},\rtt{1} > \rt{\it-1}\}
\end{align*}

Similarly, \(\pathsete{1}{\it} = \{\rt{1} > \rtt{\it-1}, \rtt{\it} > \rt{0}\}\). Suppose that there exists some \(\numb\geq 3\) such that

\begin{equation}
\pathsete{\itt}{\ittt} = \{\rt{\itt} > \rtt{\ittt-1},\rtt{\ittt} > \rt{\itt-1}\}
\label{sec::Proof1:eqn::Ckk'}
\end{equation}
\labe{sec::Proof1:eqn::Ckk'}

for all \(\itt, \ittt\in \mb{N}\) such that \(\itt+\ittt = \numb\). Fix one such pair such that both \(\itt \geq 2\). We know that away from a set of probability zero, \(\{\rt{\cdot}\}\) and \(\{\rtt{\cdot}\}\) are strictly increasing sequences such that \(\rt{\it} \neq \rtt{\it'}\) for all \((\it,\it')\in \mb{N}^2\). By applying equation \eqref{sec::Proof1:eqn::extpath}, we get

\begin{align*}
\pathsete{\itt}{\ittt+1} &= \left(\pathsete{\itt-1}{\ittt+1} \cap \{\rt{\itt - 1} < \rtt{\ittt+1}\}\right) \cup \left(\pathsete{\itt}{\ittt}\cap \{\rtt{\ittt} < \rt{\itt}\}\right)\\
&= \{\rt{\itt - 1} > \rtt{\ittt}, \rtt{\ittt+1} > \rt{\itt - 2},  \rtt{\ittt+1} > \rt{\itt -1}\}\cup\{\rt{\itt} > \rtt{\ittt-1}, \rtt{\ittt} > \rt{\itt - 1},\rt{\itt} > \rtt{\ittt}\}\\
&= \{\rt{\itt - 1} > \rtt{\ittt}, \rtt{\ittt+1} > \rt{\itt - 1}\}\cup\{\rtt{\ittt} > \rt{\itt - 1},\rt{\itt} > \rtt{\ittt}\}\\
&:= \pathsete{\itt}{\ittt+1}' \cup\pathsete{\itt}{\ittt+1}''
\end{align*}

Now, it is clear that for any \(\apath \in \pathsete{\itt}{\ittt+1}'\) or \(\apath \in \pathsete{\itt}{\ittt+1}''\), \(\apath\in \{\rt{\itt} > \rtt{\ittt},\rtt{\ittt+1} > \rt{\it-1}\}\);

\[\pathsete{\itt}{\ittt+1} \subseteq \{\rt{\itt} > \rtt{\ittt},\rtt{\ittt+1} > \rt{\itt-1}\}.\]

In the other direction, we can enumerate all orderings of \(\rt{\itt-1},\rt{\itt},\rtt{\ittt}\te{ and } \rtt{\ittt+1}\) in \(\{\rt{\itt} > \rtt{\ittt}, \rtt{\ittt+1} > \rt{\it-1}\}\):

\begin{align*}
\{\rt{\itt} > \rtt{\ittt},\rtt{\ittt+1} > \rt{\itt-1}\} &= \{\rt{\itt-1} < \rtt{\ittt} < \rtt{\ittt+1} < \rt{\itt}\} \cup \{\rtt{\ittt} < \rt{\itt-1} < \rtt{\ittt+1} < \rt{\itt}\}\\
&\cup \{\rt{\itt-1} < \rtt{\ittt} < \rt{\itt} < \rtt{\ittt+1}\} \cup \{\rtt{\ittt} < \rt{\itt-1} <\rt{\itt} < \rtt{\ittt+1}\}
\end{align*}

Each set in the union above is an element of either \(\pathsete{\itt}{\ittt+1}'\) or \(\pathsete{\itt}{\ittt+1}''\). Thus,

\[\pathsete{\itt}{\ittt+1} = \{\rt{\itt} > \rtt{\ittt},\rtt{\ittt+1} > \rt{\itt-1}\}.\]

By an identical argument, \(\pathsete{\itt+1}{\ittt} = \{\rtt{\ittt} > \rt{\itt},\rt{\itt+1} > \rtt{\ittt-1}\}\) when \(\itt + \ittt = \numb\) and \(\ittt \geq 2\).

Then we proved directly that equation \eqref{sec::Proof1:eqn::Ckk'} holds for \(\itt = \ittt=1\) in which case \(\numb = 2\). For any \(\numb > 2\) and any \(\itt,\ittt\in \mb{N}\) such that \(\itt + \ittt = \numb\), one of the following holds:

\begin{itemize}
\item \(\min\{\itt,\ittt\} = 1\). We've shown directly that equation \eqref{sec::Proof1:eqn::Ckk'} holds in this case.

\item both \(\itt\) and \(\ittt\) are greater than 2. In this case, we can inductively assume that equation \eqref{sec::Proof1:eqn::Ckk'} holds for \(\pathsete{\itt-1}{\ittt}\) and \(\pathsete{\itt}{\ittt-1}\). In this case we've proven that it also holds for \(\pathsete{\itt}{\ittt}\).
\end{itemize}

So by induction, equation \eqref{sec::Proof1:eqn::Ckk'} holds for all \(\itt,\ittt\in \mb{N}\).
\end{proof}

\lin

\begin{proof}[Proof of Theorem \ref{sec::Main:Thm::CI}]

Fix \((\itt,\ittt) \in \mb{N}^2\). By Lemma \ref{sec::Proof1:Lem::Induction}, 

\[\X{\U}{[0,\rt{\itt})}\mb{I}_{\apath}\perp \X{\UU}{[0,\rtt{\ittt})}\mb{I}_{\apath}\big|\left(\X{\neigh{\U}}{[0,\rt{\itt})},\X{\neigh{\UU}}{[0,\rtt{\ittt})}\right)\mb{I}_{\apath}\te{ for all }\apath \in \pathset{\itt}{\ittt}.\]

Notice that all terms have disjoint support for different \(\apath\). By Lemma \ref{sec::TL:Lem::Props}(f), 

\[\sum_{\apath\in\pathset{\itt}{\ittt}}\X{\U}{[0,\rt{\itt})}\mb{I}_{\apath}\perp \sum_{\apath\in\pathset{\itt}{\ittt}}\X{\UU}{[0,\rtt{\ittt})}\mb{I}_{\apath}\bigg|\sum_{\apath\in\pathset{\itt}{\ittt}}\left(\X{\neigh{\U}}{[0,\rt{\itt})},\X{\neigh{\UU}}{[0,\rtt{\ittt})}\right)\mb{I}_{\apath}\te{ for all }\apath \in \pathset{\itt}{\ittt}.\]

By Lemma \ref{sec::Proof1:Lem::Ckk'}, this simplifies to 

\begin{equation}
\X{\U}{[0,\rt{\itt})}\mb{I}_{\pathsete{\itt}{\ittt}}\perp \X{\UU}{[0,\rtt{\ittt})}\mb{I}_{\pathsete{\itt}{\ittt}}\big|\left(\X{\neigh{\U}}{[0,\rt{\itt})},\X{\neigh{\UU}}{[0,\rtt{\ittt})}\right)\mb{I}_{\pathsete{\itt}{\ittt}}.
\label{sec::Proof1:eqn::thmint1}
\end{equation}
\labe{sec::Proof1:eqn::thmint1}

Define

\begin{align*}
\pathseted{\itt}{\ittt}(\t) :&= \pathsete{\itt}{\ittt}\cap \{\rt{\itt-1}\leq \t < \rt{\itt}\}\cap \{\rtt{\ittt-1} \leq \t < \rtt{\ittt}\}\\
&=\pathsete{\itt}{\ittt}\cap\{\rt{\itt-1}\vee\rtt{\ittt-1} \leq \t < \rt{\itt}\wedge \rtt{\ittt}\}\\
&=\{\rt{\itt-1}\vee\rtt{\ittt-1}  < \rt{\itt}\wedge \rtt{\ittt}\} \cap \{\rt{\itt-1}\vee\rtt{\ittt-1} \leq \t < \rt{\itt}\wedge \rtt{\ittt}\}\\
&= \{\rt{\itt-1}\vee\rtt{\ittt-1} \leq \t < \rt{\itt}\wedge \rtt{\ittt}\}.
\end{align*}

It should be clear that for any \(\t > 0\), \(\{\pathseted{\itt}{\ittt}(\t)\}_{(\itt,\ittt)\in\mb{N}_0^2}\) forms a partition of all possible events up to an event of probability zero (the event that two stopping times coincide). Furthermore, for any \(t > 0\) and \(\itt,\ittt\in \mb{N}\), \(\mb{I}_{\pathsete{\itt}{\ittt}}\mb{I}_{\pathseted{\itt}{\ittt}} = \mb{I}_{\pathseted{\itt}{\ittt}}\).

\ind Fix \(\t \geq 0\) and apply Lemma \ref{sec::TL:Lem::Props}(d) by multiplying equation\eqref{sec::Proof1:eqn::thmint1} by \(\mb{I}_{\pathseted{\itt}{\ittt}}\) to get

\[\X{\U}{[0,\rt{\itt})}\mb{I}_{\pathseted{\itt}{\ittt}(\t)}\perp\X{\UU}{[0,\rtt{\ittt})}\mb{I}_{\pathseted{\itt}{\ittt}(\t)}\big|\left(\X{\neigh{\U}}{[0,\rt{\itt})},\X{\neigh{\UU}}{[0,\rtt{\ittt})}\right)\mb{I}_{\pathseted{\itt}{\ittt}(\t)}.\]


Notice by definition of \(\mb{I}_{\pathseted{\itt}{\ittt}(\t)}\), \(\X{\U}{[0,\rt{\itt})}\mb{I}_{\pathseted{\itt}{\ittt}(\t)} \mapsto \X{\U}{[0,t]}\mb{I}_{\pathseted{\itt}{\ittt}(\t)}\) is measurable. We can map \(\X{\UU}{}\) similarly. Finally, \(\left(\X{\neigh{\U}}{[0,\rt{\itt})},\X{\neigh{\UU}}{[0,\rtt{\ittt})}\right)\mb{I}_{\pathseted{\itt}{\ittt}(\t)}\mapsto (\X{\dneigh{\U}}{[0,t]}, \rt{\itt},\rtt{\ittt})\mb{I}_{\pathseted{\itt}{\ittt}(\t)}\) is a 1-to-1 mapping. By Lemma \ref{sec::TL:Lem::Props}(a),

\[\X{\U}{[0,t]}\mb{I}_{\pathseted{\itt}{\ittt}(\t)}\perp\X{\UU}{[0,t]}\mb{I}_{\pathseted{\itt}{\ittt}(\t)}\big|\left(\X{\dneigh{\U}}{[0,t]},\rt{\itt},\rtt{\ittt}\right)\mb{I}_{\pathseted{\itt}{\ittt}(\t)}.\]

But \(\poiss{\dneigh{\U}}\) is a strong Markov process, so 

\[(\rt{\itt},\rtt{\ittt})\mb{I}_{\pathseted{\itt}{\ittt}(\t)}\perp \X{}{[0,t]}\mb{I}_{\pathseted{\itt}{\ittt}(\t)}|\mb{I}_{\pathseted{\itt}{\ittt}(\t)}.\]

By Lemma \ref{sec::TL:Lem::Props}(g), this gives us

\[\X{\U}{[0,t]}\mb{I}_{\pathseted{\itt}{\ittt}(\t)}\perp\X{\UU}{[0,t]}\mb{I}_{\pathseted{\itt}{\ittt}(\t)}\big|\X{\dneigh{\U}}{[0,t]}\mb{I}_{\pathseted{\itt}{\ittt}(\t)}.\]

Applying Lemma \ref{sec::TL:Lem::Props}(f),

\[\sum_{(\itt,\ittt)\in\mb{N}^2}\X{\U}{[0,t]}\mb{I}_{\pathseted{\itt}{\ittt}(\t)}\perp\sum_{(\itt,\ittt)\in\mb{N}^2}\X{\UU}{[0,t]}\mb{I}_{\pathseted{\itt}{\ittt}(\t)}\bigg|\sum_{(\itt,\ittt)\in\mb{N}^2}\X{\dneigh{\U}}{[0,t]}\mb{I}_{\pathseted{\itt}{\ittt}(\t)},\]

which simplifies to 

\[\X{\U}{[0,\t]}\perp\X{\UU}{[0,\t]}\big|\X{\dneigh{\U}}{[0,\t]}.\]

Because \(|\dneigh{\U}| < \infty\), the event \(\{\X{\dneigh{\U}}{\t} = \X{\dneigh{\U}}{\t-}\}\) occurs with probability 1 for all \(\t \in [0,\T]\). It is also \(\X{\dneigh{\U}}{[0,\t]}\)-measurable. By Lemma \ref{sec::TL:Lem::Props}(d),

\[\X{\U}{[0,t]}\mb{I}_{\X{\dneigh{\U}}{\t} = \X{\dneigh{\U}}{\t-}}\perp\X{\UU}{[0,t]}\mb{I}_{\X{\dneigh{\U}}{\t} = \X{\dneigh{\U}}{\t-}}\big|\X{\dneigh{\U}}{[0,t]}\mb{I}_{\X{\dneigh{\U}}{\t} = \X{\dneigh{\U}}{\t-}}.\]

Applying Lemma \ref{sec::TL:Lem::Props}(a),

\[\X{\U}{[0,t)}\mb{I}_{\X{\dneigh{\U}}{\t} = \X{\dneigh{\U}}{\t-}}\perp\X{\UU}{[0,t)}\mb{I}_{\X{\dneigh{\U}}{\t} = \X{\dneigh{\U}}{\t-}}\big|\X{\dneigh{\U}}{[0,t)}\mb{I}_{\X{\dneigh{\U}}{\t} = \X{\dneigh{\U}}{\t-}}.\]

Finally, by Lemma \ref{sec::TL:Lem::Props}(h),

\[\X{\U}{[0,\t)}\perp\X{\UU}{[0,\t)}\big|\X{\dneigh{\U}}{[0,\t)}.\]
\end{proof}

\lin

\section{Proof of Theorem \ref{sec::Main:Thm::Local SDE}}
\label{sec::Proof2}\labe{sec::Proof2}

\subsection{Proof of Existence}
\label{subsec::ProofE:sec::Proof2}\labe{subsec::ProofE:sec::Proof2}

\pfsum \(\piV{\tree{1}}{\T}(\X{}{})\) can be expressed as a sum of a random variable and a non-explosive marked point process. The trick is to find a \(\piV{\tree{1}}{\T}(\X{}{})\)-measurable intensity for that point process. However, theorems that allow us to do that require that the candidate intensity have certain measurability properties, so we begin by proving those.

\lin

\begin{defn}
Let \(\U\subseteq \V\) and suppose \(\X{}{} \in \Omega{\U}{\T-}\) is a stochastic process adapted to its own natural filtration. Then define the marked point process \(\pmap{}(\X{}{})\) as a random measure on \((0,\T) \times \S^\U\) defined by,

\[\pmap{}(\X{}{})(\{(\rt{},\mark{})\}) = \begin{cases}
1 &\te{ if } \X{}{\rt{}} - \X{}{\rt{}-} = \mark{}\\
0 &\te{ otherwise}
\end{cases}.\]

Similarly, for \(\UU \subseteq \U\), \(\pmap{\UU}(\X{}{}) = \pmap{}\left(\piV{\UU}{\T}(\X{}{})\right)\). For any \(\v\in \U\), \(\pmap{\v}(\X{}{})\) is a random measure on \((0,\T) \times \S\) given by,

\[\pmap{\v}(\X{}{})(\{(\rt{},\mark{})\}) = \begin{cases}
1 &\te{ if } \X{\v}{\rt{}} - \X{\v}{\rt{}-} = \mark{}\\
0 &\te{ otherwise}
\end{cases}.\]
\label{subsec::ProofE:Defn::pmap}
\end{defn}
\labe{subsec::ProofE:Defn::pmap}

\lin

\begin{assu}
Let \(\tree\pup{1}\subseteq\U \subseteq \V\). Let \(\X{}{}\in \Omega{\U}{\T-}\) be a stochastic process. For each \(\v\in \U\), \(\pmap{\v}(\X{}{})\) has an \(\X{}{}\)-predictable intensity, \(\ratee{\v}\), and there exists a constant \(\const{} < \infty\) such that \(\sup_{\v\in\U} \ratee{\v} \leq \const{}\). Furthermore, \(\lambda: \S^{\degr+1}\times \S\ra[0,\const{}]\) is some function.
\label{subsec::ProofE:Assu::Eassu}
\end{assu}
\labe{subsec::ProofE:Assu::Eassu}

\lin

\begin{lem}
Let \(\rp{}\) be an \(\F{}{}\)-adapted marked point process with \(\F{}{}\)-predictable intensity \(\ratee{}\) and a countable mark space. For all \(\t \in [0,\T]\), let \(\sigma(\rp{\t}) \subseteq \alt{\F{}{\t}}\subset \F{}{\t}\) define a subfiltration of \(\F{}{}\) containing the history of \(\rp{}\). If there exists an \(\Sm\times \pr\)-almost sure left-continuous modification of \(\cratee{}{}(\t,\mark{}) := \ex{\ratee{}(\t,\mark{})|\alt{\F{}{}}^{\t-}}\) with respect to \(\t\) for all \(\mark{}\) in the mark space, then \(\cratee{}{}\) is the \(\alt{\F{}{}}\)-predictable intensity of \(\rp{}\).
\label{subsec::ProofE:Lem::filtering}
\end{lem}
\labe{subsec::ProofE:Lem::filtering}

\purpose This allows us to derive a new intensity on the cruder filtration that arises once we project to \(\S^{\tree^1}\).

\begin{proof}
This is a restatement of \cite[Theorem 14.3.III]{DalVer08}.
\end{proof}

\lin

\begin{lem}
Suppose Assumption \ref{subsec::ProofE:Assu::Eassu} holds. Let \(\m{}{}{} = \law(\X{}{})\). Suppose,

\[\crate{\v}{\t}(\s) := \crate{}{}(\X{\{\v,\root\}}{[0,\t)},\s) = \exmu{\cm_\t(\X{\{\v,\root\}}{[0,\t)},\m{}{}{})}{\rate{}(\X{\tree\pup{1}}{\t-},\s)}.\]


Then \(\crate{\v}{\t}(\s)\) has an almost surely left-continuous modification on \([0,\T)\) with respect to \(\t\) for every \(\v \in \tree\pup{1}\setminus\{\root\}\) and \(\s \in \S\).
\label{subsec::ProofE:Lem::leftmod}
\end{lem}
\labe{subsec::ProofE:Lem::leftmod}

\purpose This is used to prove that \(\crate{}{}\) satisfies the conditions of Lemma \ref{subsec::ProofE:Lem::filtering}.

\pfsum Apply Lemmas \ref{subsec::ProofE:Lem::leftmodgen} and \ref{subsec::ProofE:Lem::bddvar}. The proof is provided after lemma \ref{subsec::ProofE:Lem::bddvar}.

\lin

\begin{defn}
A set \(\evnt\) is called elementary with respect to a filtration \(\{\F{}{\t}\}\) if it is a finite union of sets of the form \((\tt,\t]\times \alt{\evnt}\) where \(\alt{\evnt} \in \F{}{\tt}\).
\label{subsec::ProofE:Defn::elementary}
\end{defn}
\labe{subsec::ProofE:Defn::elementary}

\purpose This definition is used in the statement of Lemma \ref{subsec::ProofE:Lem::leftmodgen}.

\lin

\begin{lem}
Let \(\X{}{\t}\) be a stochastic process that is left continuous in probability and such that \(\sup_{\evnt\te{ elementary}}\ex{\int_0^\T \mb{I}_\evnt\,d\X{}{}} < \infty\). Then there exists a left-continuous modification of \(\X{}{}\).
\label{subsec::ProofE:Lem::leftmodgen}
\end{lem}
\labe{subsec::ProofE:Lem::leftmodgen}

\purpose Lemma \ref{subsec::ProofE:Lem::leftmod} is a direct application of this lemma.

\pfsum The website Almost Sure (url: https://almostsure.wordpress.com/2009/12/18/cadlag-modifications/) has a statement of a similar result along with a partial proof. Completing the proof and adapting it to left-continuous modifications instead of c\`adl\`ag functions is simple.

\begin{proof}
This is a completed proof based off of the partial proof provided in the link above.

\ind Fix some \(0\leq a < b < \infty\). Let \(\alt{T} \subset [0,\T]\) be a finite set. Let \(U_{\alt{\T}}[a,b]\) denote the number of upcrossings of \(\X{}{}\) restricted to \(\alt{\T}\) with respect to the interval \([a,b]\).

\ind It can be shown directly that there exists an elementary set \(\evnt\) such that,

\begin{equation}
(b-a)U_{\alt{T}}[a,b] \leq \int_0^\T \mb{I}_{\evnt}\,d\X{}{} + \max\{a - \X{}{\T},0\}.
\label{subsec::ProofE:eqn::upcrossingineq}
\end{equation}
\labe{subsec::ProofE:eqn::upcrossingineq}

(see https://almostsure.wordpress.com/2009/12/06/upcrossings-downcrossings-and-martingale-convergence/). For every \(M \in [0,\infty)\), define

\[\rt{M}_{\alt{T}} := \inf\{\t\in \alt{\T}: \X{}{\t} > M\}.\]

Because \(\alt{T}\) is finite, \(\mb{I}_{(\rt{M}_{\alt{T}},\T]}\) is an elementary set.

\[\int_0^\T \mb{I}_{(\rt{M}_{\alt{T}},\T]}\,d\X{}{} = \mb{I}_{\sup_{\t\in \alt{T}} \X{}{\t} > M}(\X{}{\T} - \X{}{\rt{M}_{\alt{T}}}) \leq |\X{}{\T}| - M\mb{I}_{\sup_{\t \in \alt{T}} \X{}{\t} > M}.\]

\[M\mb{I}_{\sup_{\t\in\alt{T}} \X{}{\t} > M} \leq |\X{}{\T}| - \int_0^T \mb{I}_{(\rt{M}_{\alt{T}},\T]}\,d\X{}{}.\]


Replacing \(\X{}{}\) by \(-\X{}{}\) gives us the inequality,

\[M\mb{I}_{\inf_{\t\in\alt{T}} \X{}{\t} < -M} \leq |\X{}{\T}| + \int_0^T \mb{I}_{(\alt{\rt{M}_{\alt{T}}},\T]}\,d\X{}{},\]

where \(\alt{\rt{M}_{\alt{T}}} = \inf\{\t\in \alt{T}: \X{}{\t} < -M\}\). Summing yields,

\begin{equation}
M\mb{I}_{\sup_{\t\in\alt{T}}|\X{}{\t}| > M} \leq M\mb{I}_{\sup_{\t\in\alt{T}}\X{}{\t} > M} + M\mb{I}_{\inf_{\t\in\alt{T}}\X{}{\t} < -M} \leq 2|\X{}{\T}| + \int_0^\T \mb{I}_{(\alt{\rt{M}_{\alt{T}}},\T]}\,d\X{}{} - \int_0^\T \mb{I}_{(\rt{M}_{\alt{T}},\T]}\,d\X{}{}
\label{subsec::ProofE:eqn::bdd}
\end{equation}
\labe{subsec::ProofE:eqn::bdd}

By assumption there exists a constant \(\const{} < \infty\) such that \(\ex{\int_0^\T \mb{I}_{\evnt}\,d\X{}{}} \leq \const{}\) for all elementary \(\evnt\). Taking an expectation of equations \eqref{subsec::ProofE:eqn::upcrossingineq} and \eqref{subsec::ProofE:eqn::bdd}, we get:

\begin{align}
(b-a)\ex{U_{\alt{T}}[a,b]} &\leq \const{} + \ex{\max\{a-\X{}{\T},0\}}
\label{subsec::ProofE:eqn::expupcrossingineq}\\
\pr\left(\sup_{\t\in\alt{T}} |\X{}{\T}| > M\right) &\leq \frac{2}{M}\left(\ex{|\X{}{\T}|} + \const{}\right)
\label{subsec::ProofE:eqn::expbdd}
\end{align}
\labe{subsec::ProofE:eqn::expupcrossingineq}

\labe{subsec::ProofE:eqn::expbdd}

By the monotone convergence theorem, equations \eqref{subsec::ProofE:eqn::expupcrossingineq} and \eqref{subsec::ProofE:eqn::expbdd} hold for any countable \(\alt{T}\). Furthermore, the right side of both equations is constant (with respect to \(\alt{T}\)). Thus, for any \(a < b \in \mb{Q}\), \(U_{\alt{T}}[a,b]\) is almost surely finite and \(\X{}{}\) is almost surely bounded on \(\alt{T}\).

\ind Because \(\X{}{}\) is bounded on \(\alt{T}\) and because \(U_{\alt{T}}[a,b]\) is almost surely finite for all rational \(a < b\), we can conclude that \(\lim_{\substack{\tt \nearrow \t\\ \tt \in \alt{T}}} \X{}{\tt}\) and \(\lim_{\substack{\tt \searrow \t\\ \tt \in \alt{T}}} \X{}{\tt}\) exist for all \(\t \in [0,\T]\). Define,

\[\rxvtt{}{\t} := \lim_{\substack{\tt \nearrow \t\\\tt \in \alt{T}}} \X{}{\tt}\te{ for all } \t \in [0,\T].\]

Then \(\rxvtts{}{}\) has left and right limits everywhere and it is almost surely left-continuous. Furthermore, if \(\alt{\rxvtts{}{}}\) is generated by \(\alt{T'}\), where \(\alt{T'}\) is the union of \(\alt{T}\) and a countable number of points, then \(\rxvtts{}{}\) and \(\alt{\rxvtts{}{}}\) are identical processes. 

\ind For each \(\numb \in \mb{N}\), let \(\typset\pup{\numb} \subset [0,\T]\) be defined by,

\[\typset\pup{\numb} := \left\{\t\in [0,\T]: \pr\left(|\X{}{\t} - \rxvtt{}{\t}| > 1/\numb\right) > 1/\numb\right\}.\] 

Suppose \(\typset\pup{\numb}\) is not finite. Then there exists an increasing or decreasing sequence \(\{\t\pup{\it}:\it\in \mb{N}\}\subseteq \typset\pup{\numb}\). Since this sequence is contained in the bounded interval \([0,\T]\), it is convergent. Without loss of generality, we can enlarge \(\alt{T}\) to contain this sequence so that

\[\lim_{\it \ra\infty} \X{}{\t\pup{\it}} = \lim_{\it\ra\infty} \rxvtt{}{\t\pup{\it}} \te{ almost surely.}\]

Thus, \(\pr(|\X{}{\t\pup{\it}} - \rxvtt{}{\t\pup{\it}}| > 1/\numb) \ra 0\), which contradicts the fact that \(\t\pup{\it} \in \typset\pup{\numb}\) for all \(\it\in\mb{N}\). We can then conclude that,

\[\typset:= \{\t\in [0,\T]: \pr(\X{}{\t} \neq \rxvtt{}{\t}) > 0\} = \cap_{\numb = 1}^\infty \typset\pup{\numb}\]

is a finite set. Define,

\[\rxvttt{}{\t}= \begin{cases}
\rxvtt{}{\t} &\te{ for } \t \notin \typset\\
\X{}{\t} &\te{ otherwise.}
\end{cases}\]

Then \(\rxvttts{}{}\) differs from \(\rxvtts{}{}\) at an almost surely finite number of points, so left and right limits exist everywhere for \(\rxvttts{}{}\) and it is left-continuous on \(\typset^c\). Furthermore, by definition, \(\rxvttts{}{}\) is a modification of \(\X{}{}\). Recall that \(\X{}{}\) is left-continuous in probability. That means,

\[\te{plim}_{\tt\nearrow \t} \X{}{\tt} = \X{}{\t}.\]

More specifically,

\[\te{plim}_{\substack{\tt\pup{\it}\nearrow \t\\\{\tt\pup{\it}\} \subseteq \alt{T}}} \X{}{\tt\pup{\it}} = \X{}{\t}\]

Convergence in probability implies almost sure convergence of a subsequence:

\[\lim_{\substack{\tt\pup{\it\pup{\itt}} \nearrow \t\\\{\tt\pup{\it}\}\subseteq \alt{T}}} \X{}{\tt\pup{\it\pup{\itt}}} = \X{}{\t} = \rxvtt{}{\t} \te{ almost surely.}\]

By definition of \(\rxvttts{}{}\), \(\rxvttt{}{\t} = \rxvtt{}{\t}\). However, this holds for all \(\t \in (0,\T]\), so \(\rxvttts{}{} = \rxvtts{}{}\) on the interval \((0,\T]\) (as in the two processes are identical on \((0,\T]\), not just almost surely equal at every point). Since \(\rxvtts{}{}\) is left-continuous, it follows that \(\rxvttts{}{}\) is a left-continuous modification of \(\X{}{}\) (note: the value of \(\rxvttt{}{0}\) has no effect on the left-continuity of the process on \([0,\T]\)).
\end{proof}

\lin

\begin{lem}
Let \(\X{}{},\ratee{}{}\) and \(\rate{}\) satisfy the conditions of Assumption \ref{subsec::ProofE:Assu::Eassu}. Let \(\crate{\v}{\t}(\s)\) be defined as in Lemma \ref{subsec::ProofE:Lem::leftmod}. Then \(\crate{\v}{\t}(\s)\) is left-continuous in probability for \(\v \in \tree\pup{1}\setminus\{\root\}\) and \(\s \in \S\setminus\{0\}\). That is, for every \(\t \in (0,\T]\), \(\s \in \S\), \(\ep > 0\) and \(\v\in \{1,\dots,\degr\}\),

\[\lim_{\tt \nearrow \t}\pr\left(|\crate{\v}{\t}(\s)- \crate{\v}{\t-\tt}(\s)| > \ep\right) = 0.\]

Furthermore, consider the event,

\[\evnt^\U_{\tt,\t} := \{\X{\U}{} \te{ is constant over the interval } [\t-\tt,\t)\}.\]

Then there exists an \(O(s)\) function, \(f:[0,\infty)\ra[0,\infty)\), such that 

\[\mb{I}_{\evnt^{\{\v,\root\}}_{\tt,\t}}|\crate{\v}{\t}(\s) - \crate{\v}{\t-\tt}(\s)| \leq f(s) \te{ almost surely.}\]
\label{subsec::ProofE:Lem::pleft}
\end{lem}
\labe{subsec::ProofE:Lem::pleft}

\purpose This is one of the conditions of Lemma \ref{subsec::ProofE:Lem::leftmodgen}.

\pfsum Use the fact that over any small interval \([t-s,t)\), \(X^U\) is constant with high probability for all finite \(U\). Thus \(\ov{\lambda}^v_{t-s}\) will vary by only a tiny amount from \(\ov{\lambda}^v_t\) with very high probability. We can actually estimate how quickly this probability converges to 1 as a function of \(s\).

\begin{proof}
Fix \(\v\in \V\). By Assumption \ref{subsec::ProofE:Assu::Eassu}, \(\pmap{}(\X{\{\v,\root\}}{})\) has intensity bounded from above by \(2\const{}\). Therefore, for every \(\t > 0\) there almost surely exists an \(\tt\) small enough such that \(\evnt^{\{\v,\root\}}_{\tt,\t}\) holds. Fix \(\tt < \t\). Let \(\const{}\) be the upper bound of \(\rate{}\). Fix any \(\s\in \S\). We begin by computing

\[\ex{\mb{I}_{\evnt^{\{\v,\root\}}_{\tt,\t}}|\crate{\v}{\t}(\s) - \crate{\v}{\t-\tt}(\s)|}.\]

Fix some \(\x{}{}\in \evnt^{\{\v,\root\}}_{\tt,\t}\). Let 

\[\alt{\evnt}_\t = \{\X{\{\root,1\}}{[0,\t)} = \x{\{\v,\root\}}{[0,\t)}\}.\]

Then we will write,

\begin{align*}
\crate{\v}{\t}(\x{}{},\s) &:=\crate{}{}(\x{\{\v,\root\}}{[0,\t)},\s) = \ex{\rate{}(\X{\tree\pup{1}}{\t-},\s)|\alt{\evnt}_\t}\\
\crate{\v}{\t-\tt}(\x{}{},\s) &:= \crate{}{}(\x{\{\v,\root\}}{[0,\t-\tt)},\s) = \ex{\rate{}(\X{\tree\pup{1}}{(\t-\tt)-},\s)|\alt{\evnt}_{\t-\tt}}
\end{align*}

Then,

\begin{align*}
\crate{\v}{\t}(\x{}{},\s) &= \ex{\rate{}(\X{\tree\pup{1}}{\t-},\s)|\alt{\evnt}_\t}\\
&= \sum_{\sv{}{\tree\pup{1}} \in \S^{\tree\pup{1}}} \rate{}(\sv{}{\tree\pup{1}},\s)\pr\left(\X{\tree\pup{1}}{\t-} = \sv{}{\tree\pup{1}}|\alt{\evnt}_\t\right)\\
&= \sum_{\sv{}{\tree\pup{1}} \in \S^{\tree\pup{1}}} \rate{}(\sv{}{\tree\pup{1}},\s) \sum_{\alt{\sv{}{\tree\pup{1}}} \in \S^{\tree\pup{1}}} \pr\left(\X{\tree\pup{1}}{\t-} = \sv{}{\tree\pup{1}},\X{\tree\pup{1}}{(\t-\tt)-} = \alt{\sv{}{\tree\pup{1}}}|\alt{\evnt}_\t\right)\\
&= \sum_{\sv{}{\tree\pup{1}},\alt{\sv{}{\tree\pup{1}}} \in \S^{\tree\pup{1}}} \rate{}(\sv{}{\tree\pup{1}},\s)\pr\left(\X{\tree\pup{1}}{\t-} = \sv{}{\tree\pup{1}}|\X{\tree\pup{1}}{(\t-\tt)-}=\alt{\sv{}{\tree\pup{1}}},\alt{\evnt}_\t\right)\pr\left(\X{\tree\pup{1}}{(\t-\tt)-}=\alt{\sv{}{\tree\pup{1}}}|\alt{\evnt}_\t\right)\\
\end{align*}

Because the jump rate of \(\pmap{\v}(\X{}{})\) is bounded from above by \(\const{}\) for any \(\v\in\tree\pup{1}\),  when \(\sv{}{\tree\pup{1}}\neq\alt{\sv{}{\tree\pup{1}}}\), 

\[\pr\left(\X{\tree\pup{1}}{\t-} = \sv{}{\tree\pup{1}}|\X{\tree\pup{1}}{(\t-\tt)-}=\alt{\sv{}{\tree\pup{1}}},\alt{\evnt}_\t\right) \leq 1-e^{-\tt(\degr+1)\const{}}\]

and when \(\sv{}{\tree\pup{1}}=\alt{\sv{}{\tree\pup{1}}}\),

\[\pr\left(\X{\tree\pup{1}}{\t-} = \sv{}{\tree\pup{1}}|\X{\tree\pup{1}}{(\t-\tt)-}=\alt{\sv{}{\tree\pup{1}}},\alt{\evnt}_\t\right) \geq e^{-\tt(\degr+1)\const{}}.\]

So,

\begin{equation}
e^{-\tt(\degr+1)\const{}}\sum_{\sv{}{\tree\pup{1}}\in \S^{\tree\pup{1}}} \rate{}(\sv{}{\tree\pup{1}},\s)\pr\left(\X{\tree\pup{1}}{(\t-\tt)-}=\sv{}{\tree\pup{1}}|\alt{\evnt}_\t\right) \leq \crate{\v}{\t}(\x{}{},\s),
\label{subsec::ProofE:eqn::partlowbd}
\end{equation}
\labe{subsec::ProofE:eqn::partlowbd}

and

\begin{align}
\crate{\v}{\t}(\x{}{},\s)&\leq (1 - e^{-\tt(\degr+1)\const{}})\sum_{\sv{}{\tree\pup{1}}\neq \alt{\sv{}{\tree\pup{1}}} \in \S^{\tree\pup{1}}} \rate{}(\sv{}{\tree\pup{1}},\s)\pr\left(\X{\tree\pup{1}}{(\t-\tt)-}=\alt{\sv{}{\tree\pup{1}}}|\alt{\evnt}_\t\right)\nonumber\\
&\hspace{24 pt} +\sum_{\sv{}{\tree\pup{1}} \in \S^{\tree\pup{1}}} \rate{}(\sv{}{\tree\pup{1}},\s)\pr\left(\X{\tree\pup{1}}{(\t-\tt)-}=\sv{}{\tree\pup{1}}|\alt{\evnt}_\t\right)\nonumber\\
&\leq \const{}(1 - e^{-\tt(\degr+1)\const{}})|\S|^{\degr(\degr+1)/2} + \sum_{\sv{}{\tree\pup{1}} \in \S^{\tree\pup{1}}} \rate{}(\sv{}{\tree\pup{1}},\s)\pr\left(\X{\tree\pup{1}}{(\t-\tt)-}=\sv{}{\tree\pup{1}}|\alt{\evnt}_\t\right)
\label{subsec::ProofE:eqn::partupbd}
\end{align}
\labe{subsec::ProofE:eqn::partupbd}

So we simply need to understand \(\pr\left(\X{\tree\pup{1}}{(\t-\tt)-}=\sv{}{\tree\pup{1}}|\alt{\evnt}_\t\right)\). Recalling that \(\x{}{} \in \evnt^{\{\v,\root\}}_{\tt,\t}\), notice that

\[\alt{\evnt}_\t = \alt{\evnt}_{\t-\tt}\cap \evnt^{\{\root,1\}}_{\tt,\t}.\]

\begin{align*}
\pr\left(\X{\tree\pup{1}}{(\t-\tt)-}=\sv{}{\tree\pup{1}}|\alt{\evnt}_\t\right) &= \pr\left(\X{\tree\pup{1}}{(\t-\tt)-}=\sv{}{\tree\pup{1}}|\alt{\evnt}_{\t-\tt},\evnt^{\{\root,1\}}_{\tt,\t}\right)\\
&=\pr\left(\X{\tree\pup{1}}{(\t-\tt)-}=\sv{}{\tree\pup{1}}|\alt{\evnt}_{\t-\tt}\right)\frac{\pr\left(\evnt^{\{\root,1\}}_{\tt,\t}|\X{\tree\pup{1}}{(\t-\tt)-}=\sv{}{\tree\pup{1}},\alt{\evnt}_{\t-\tt}\right)}{\pr\left(\evnt^{\{\root,1\}}_{\tt,\t}|\alt{\evnt}_{\t-\tt}\right)}
\end{align*}

Notice that for any non-null \(\X{\tree\pup{1}}{[0,\t-\tt)}\)-measurable set \(\typset\), 

\[\pr(\evnt^{\{\root,1\}}_{\tt,\t}|\typset) \geq e^{-2\tt\const{}}\]

Then,

\begin{align}
e^{-2\tt\const{}}\pr\left(\X{\tree\pup{1}}{(\t-\tt)-}=\sv{}{\tree\pup{1}}|\alt{\evnt}_{\t-\tt}\right) &\leq \pr\left(\X{\tree\pup{1}}{(\t-\tt)-}=\sv{}{\tree\pup{1}}|\alt{\evnt}_{\t}\right)\nonumber\\
&\leq e^{2\tt\const{}}\pr\left(\X{\tree\pup{1}}{(\t-\tt)-}=\sv{}{\tree\pup{1}}|\alt{\evnt}_{\t-\tt}\right).
\label{subsec::ProofE:eqn::secpartbd}
\end{align}
\labe{subsec::ProofE:eqn::secpartbd}

Now

\[\crate{\v}{\t-\tt}(\x{\tree\pup{1}}{},\s) = \ex{\rate{}(\X{\tree\pup{1}}{(\t-\tt)-},\s)|\alt{\evnt}_{\t-\tt}} = \sum_{\sv{}{\tree\pup{1}}\in \S^{\tree\pup{1}}}\rate{}(\sv{}{\tree\pup{1}},\s)\pr\left(\X{\tree\pup{1}}{(\t-\tt)-} = \sv{}{\tree\pup{1}}|\alt{\evnt}_{\t-\tt}\right)\]

Applying equation \eqref{subsec::ProofE:eqn::secpartbd},

\[e^{-2\tt\const{}}\crate{\v}{\t-\tt}(\x{\tree\pup{1}}{},\s) \leq \sum_{\sv{}{\tree\pup{1}}\in \S^{\tree\pup{1}}} \lambda(\sv{}{\tree\pup{1}},\s)\pr(\X{\tree\pup{1}}{(\t-\tt)-} = \sv{}{\tree\pup{1}}|\alt{\evnt}_\t)\leq e^{2\tt\const{}}\crate{\v}{\t-\tt}(\x{\tree\pup{1}}{},\s)\]

Additionally, we can apply equations \eqref{subsec::ProofE:eqn::partlowbd} and  \eqref{subsec::ProofE:eqn::partupbd} to get,

\[e^{-\tt(\degr+3)\const{}}\crate{\v}{\t-\tt}(\x{\tree\pup{1}}{},\s) \leq \crate{\v}{\t}(\x{\tree\pup{1}}{},\s) \leq \const{}(1 - e^{-\tt(\degr+1)\const{}})|S|^{\degr(\degr+1)/2} + e^{2\tt\const{}}\crate{\v}{\t-\tt}(\x{\tree\pup{1}}{},\s)\]

Then for all \(\x{}{} \in \evnt^{\{\v,\root\}}_{\tt,\t}\), we can bound \(|\crate{\v}{\t}(\x{}{},\s) - \crate{\v}{\t-\tt}(\x{}{},\s)|\):

\begin{align*}
&|\crate{\v}{\t}(\x{}{},\s) - \crate{\v}{\t-\tt}(\x{}{},\s)| \\
&\hspace{24pt}\leq \max\left\{\crate{\v}{\t-\tt}(\x{}{},\s)\left(1 - e^{-\tt(\degr+3)\const{}}\right),\const{}(1-e^{-\tt(\degr+1)\const{}})|\S|^{\degr(\degr+1)/2} + \crate{\v}{\t-\tt}(\x{}{},\s)\left(e^{2\tt\const{}} - 1\right)\right\}\\
&\hspace{24pt}\leq \const{}\max\left\{\left(1 - e^{-\tt(\degr+3)\const{}}\right),(1-e^{-\tt(\degr+1)\const{}})|\S|^{\degr(\degr+1)/2} + \left(e^{2\tt\const{}} - 1\right)\right\}\\
\end{align*}

which is an \(O(s)\) function. Then,

\begin{align*}
\ex{|\crate{\v}{\t}(\x{}{},\s) - \crate{\v}{\t-\tt}(\x{}{},\s)|} &\leq \const{}\pr\left(\te{not }\evnt^{\{\v,\root\}}_{\tt,\t}\right) + \ex{\mb{I}_{\evnt^{\{\v,\root\}}_{\tt,\t}}|\crate{\v}{\t}(\x{}{},\s) - \crate{\v}{\t-\tt}(\x{}{},\s)|}\\
&\leq \const{}(1 - e^{-2\tt\const{}}) + O(s) = O(s).
\end{align*}

The result follows by Chebyshev's inequality.
\end{proof}

\lin

\begin{lem}
Suppose Assumption \ref{subsec::ProofE:Assu::Eassu} holds. Let \(\crate{\v}{\t}(\s)\) be defined as in Lemma \ref{subsec::ProofE:Lem::leftmod}. Then \(\crate{\v}{\t}(\s)\) is integrable and 

\[\sup_{\typset\te{ elementary}} \ex{\int_0^\T \mb{I}_\typset\,d\crate{\v}{\t}(\s)} < \infty\]
\label{subsec::ProofE:Lem::bddvar}
\end{lem}
\labe{subsec::ProofE:Lem::bddvar}

\purpose This is one of the conditions of Lemma \ref{subsec::ProofE:Lem::leftmodgen}.

\pfsum Look at the variation of \(\ov{\lambda}\) where it is continuous (which is obtained from an estimate in the proof of Lemma \ref{subsec::ProofE:Lem::pleft}) and use the fact that the number of jumps is finite in expectation.

\begin{proof}
Any elementary set can be expressed in the form

\[\typset = \bigcup_{\it = 1}^\numb [\tt^\it,\t^\it)\times \typset\pup{\it},\]

where \(\{[\tt^\it,\t^\it):\it=1,\dots,\numb\}\) are disjoint, if \(\tt^\it = \t^\it = 0\), then \([\tt^\it,\t^\it) = \{0\}\) and \(\typset\pup{\it}\) are all \(\sigma(\crate{\v}{\t}(\s):\s \in \S,\t\in [0,\tt^\it])\)-measurable. 

By Lemma \ref{subsec::ProofE:Lem::pleft}, there exists a \(\const{1} < \infty\) such that,

\begin{equation}
\mb{I}_{\evnt^{\{\v,\root\}}_{\tt,\t}}|\crate{\v}{\t}(\s) - \crate{\v}{\t-\tt}(\s)| \leq \const{1}\tt.
\label{subsec::ProofE:eqn::driftbound}
\end{equation}
\labe{subsec::ProofE:eqn::driftbound}

Furthermore, since \(\crate{\v}{\t}(\s)\) is a \([0,\const{}]\)-valued process, jumps of \(\crate{\v}{\t}(\s)\) are bounded by \(\const{}\). Thus, for any \(\numb \in \mb{N}\),

\[\mb{I}_{\{\X{\{\v,\root\}}{}\te{ has }\numb\te{ jumps in } [\t-\tt,\t)\}}|\crate{\v}{\t}(\s) - \crate{\v}{\t-\tt}(\s)|\leq C_1\tt + \numb \const{}.\]

\tr{This holds even with random times because inequality \eqref{subsec::ProofE:eqn::driftbound} holds for all \(\tt\) almost surely.} Then,

\begin{align*}
\ex{\int_0^\T \mb{I}_\typset\,d\crate{\v}{\t}(\s)} &= \sum_{\it = 1}^\numb \mb{I}_{\typset^\it}\ex{\left|\crate{\v}{\t^k}(\s) - \crate{\v}{\tt^k}(\s)\right|}\\
&\leq \sum_{\it=1}^\numb \const{1}|\t^\it - \tt^\it| + \const{}\ex{\te{\# of jumps of }\X{\{\v,\root\}}{[\tt^\it,\t^\it)}}\\
&\leq \const{1}\T + \const{}\ex{\te{\# of jumps in }\X{\{\v,\root\}}{[0,\T)}}\\
&\leq \const{1}\T + 2\const{}^2\T < \infty.
\end{align*}

Thus,

\[\sup_{\typset\te{ elementary}} \ex{\int_0^\T \mb{I}_\typset\,d\crate{\v}{\t}(\s)} \leq \const{1}\T + 2\const{}^2\T < \infty.\]
\end{proof}

\lin

\begin{proof}[Proof of Lemma \ref{subsec::ProofE:Lem::leftmod}]

By Lemma \ref{subsec::ProofE:Lem::pleft}, \(\crate{\{\v,\root\}}{\t}(\s)\) is left-continuous in probability. By Lemma \ref{subsec::ProofE:Lem::bddvar},

\[\sup_{\typset\te{ elementary}} \ex{\int_0^\T \mb{I}_{\typset}\,d\crate{\v}{\t}(\s)} < \infty.\]

Therefore \(\crate{\v}{\t}(\s)\) satisfies the conditions of Lemma \ref{subsec::ProofE:Lem::leftmodgen}, so there exists a left-continuous modification of \(\crate{\v}{\t}(\s)\).
\end{proof}

\lin

\begin{proof}[Proof of existence in Theorem \ref{sec::Main:Thm::Local SDE}]

Let \(\{\F{\tree\pup{1}}{\t}:\t\in [0,\T]\}\) be the natural filtration of \(\X{\tree\pup{1}}{}\). Recall that by Proposition \ref{subsec::Well-:Prop::SDE=IG}, \(\X{}{}\) can be expressed as the unique solution to,

\[\X{\v}{\t} = \X{\v}{0} + \int_\S\int_0^\t \s\,\poiss{\v}\left(d\tt,\left(0,\rate{\v}(\X{}{\tt-},\s)\right],d\s\right) \te{ for all } \v \in \V.\]

Then,

\[\left(\piV{\tree\pup{1}}{\T}(\X{}{})\right)^\t = \left(\piV{\tree\pup{1}}{\T}(\X{}{})\right)^0 + \sum_{\v \in \tree\pup{1}}\ev{\v}\int_\S\int_0^\t \s\,\poiss{\v}\left(d\tt,\left(0,\rate{\v}(\X{}{\tt-},\s)\right],d\s\right).\]

However, this is not \(\F{\tree\pup{1}}{\t}\)-adapted. Let \(\rp{} = \{(\rt{\it},\mark{\it})\} = \pmap{\tree\pup{1}}(\X{}{}).\) Then,

\[\left(\piV{\tree\pup{1}}{\T}(\X{}{})\right)^\t = \left(\piV{\tree\pup{1}}{\T}(\X{}{})\right)^0 + \sum_{0 < \rt{\it} \leq t}\mark{\it}\]

Therefore it suffices to derive the \(\F{\tree\pup{1}}{\t}\)-intensity of \(\rp{}\). \(\rp{}\) has \(\F{\V}{\t}\)-intensity \(\rate{\rp{}}(\X{}{\t-},\mark{}) := \sum_{\v \in \tree^1}\sum_{\s\in S}\mb{I}_{\mark{} = \s\ev{\v}}\rate{\v}(\X{}{\t-},\s)\). Each \(\rate{\v}\) is clearly left-continuous in time, so \(\rate{\rp{}}\) is also left-continuous in time. Recall that \(\m{}{}{}\) is the law of \(\X{}{}\). Then,

\[\exmu{\m{}{}{}}{\rate{\rp{}}(\X{}{\t-},\mark{})|\F{\tree\pup{1}}{\t-}} = \sum_{\v \in \tree\pup{1}}\sum_{\s\in S} \mb{I}_{\mark{} = \s\ev{\v}}\exmu{\m{}{}{}}{\rate{\v}(\X{}{\t-},\s)|\F{\tree\pup{1}}{\t-}}.\]

Applying Theorem \ref{sec::Main:Thm::CI} and symmetry of \(\m{}{}{}\) yields,

\begin{align*}
\exmu{\m{}{}{}}{\rate{\v}(\X{}{\t-},\s)|\F{\tree\pup{1}}{\t-}} &= \exmu{\m{}{}{}}{\rate{\v}(\X{}{\t-},\s)|\X{\tree\pup{1}}{[0,\t)}}\\
&\os{\te{Thm \ref{sec::Main:Thm::CI}}}{=} \exmu{\m{}{}{}}{\rate{}(\X{\cl{\v}}{\t-},\s)|\X{\{\v,\root\}}{[0,\t)}} \\
&\os{\te{Sym}}{=} \exmu{\rxvtts{}{}\sim \m{}{}{}}{\rate{}(\rxvtt{\tree\pup{1}}{\t-},\s)|\rxvtts{\{\root,1\}}{[0,\t)} = \X{\{\v,\root\}}{[0,\t)}}\\
&= \exmu{\rxvtts{}{}\sim \piV{\tree\pup{1}}{\T}(\m{}{}{})}{\rate{}(\rxvtt{\tree\pup{1}}{\t-},\s)|\rxvtts{\{\root,1\}}{[0,\t)} = \X{\{\v,\root\}}{[0,\t)}}\\
&= \exmu{\cm_\t\left(\X{\{\v,\root\}}{[0,\t)},\piV{\tree\pup{1}}{\T}(\m{}{}{})\right)}{\rate{}(\X{\tree\pup{1}}{\t-},\s)}\\
&=\crate{}{}(\X{\{\v,\root\}}{[0,\t)},\s) = \crate{\v}{\t}(\s).
\end{align*}

By Lemma \ref{subsec::ProofE:Lem::leftmod}, \(\crate{\v}{\t}(\s)\) has a left-continuous modification. Then, by Lemma \ref{subsec::ProofE:Lem::filtering}, \(\crate{\v}{\t}(\s)\) is a \(\F{\tree\pup{1}}{}\)-predictable filtration of \(\rxvtts{}{}\).

\ind By lemma \ref{subsec::Some:Lem::PPtoSDE}, we can characterize the law of \(\piV{\tree\pup{1}}{\T}(\X{}{})\) as the law of the unique solution (given \(\piV{\tree\pup{1}}{\T}(\m{}{}{})\)) to the SDE

\begin{align*}
\X{\v}{\t} &= \X{\v}{0} + \int_0^\t\int_\S \s\,\poiss{\v}(d\s,(0,\crate{\v}{\tt}(\s)],d\tt) \te{ for } \v \in \{1,\dots,\degr\},\\
\X{\root}{\t} &= \X{\root}{0} + \int_0^\t\int_\S \s\,\poiss{\root}(d\s,(0,\rate{\root}(\X{}{\tt-},\s)],d\tt).
\end{align*}
\end{proof}

\subsection{Proof of Uniqueness}
\label{subsec::ProofU:sec::Proof2}\labe{subsec::ProofU:sec::Proof2}

\pfsum We start with an arbitrary measure \(\mmm{}{}{1}\) satisfying the characterization provided in Theorem \ref{sec::Main:Thm::Local SDE}. We characterize the density of this measure with respect to a simple process. Using these densities, we extend the process to an infinite dimensional process whose marginal distribution is \(\mmm{}{}{1}\). We then prove this infinite dimensional process is precisely \(\m{}{}{}\).

\begin{proof}[Proof of Theorem \ref{sec::Main:Thm::Local SDE}]

Assume \(\mmm{}{}{1}\) is a probability measure on \(\Omega{\tree\pup{1}}{\T-}\) and suppose that \(\mmm{}{}{1}\) is a solution to equation \eqref{sec::Main:eqn::Local SDE}.

\ind Let \(\X{}{}{1}\) be a process with law \(\mmm{}{}{1}\) embedded in \(\Omega{\V}{\T-}\). That is, \(\X{\v}{}{1} \equiv 0\) for \(\v \notin \tree\pup{1}\). Recall that, for \(\v \in \tree\pup{1}\setminus\{\root\}\),

\[\crate{}{}(\X{\{\v,\root\}}{[0,\t)}{1},\s) = \exmu{\cm_\t(\X{\{\v,\root\}}{[0,\t)}{1},\mmm{}{}{1})}{\rate{}(\X{}{\t-}{1},\s)}.\]

\ind We will prove uniqueness of the local SDE by showing that \(\mmm{}{}{1}\) is the marginal distribution of \(\m{}{}{}\), which is the law of \(\X{}{}\) (as defined in equation \eqref{subsec::Notat:Eqn::IG}). To do that, we will construct a sequence of random variables \(\{\X{}{}{\numb}:\numb\in\mb{N}\}\) on \(\Omega{\tree\pup{\numb}}{\T-}\) converging weakly to \(\X{}{}\). 

\lin

\begin{lem}
The marginal distribution of \(\mmm{}{}{1}\) on \(\Omega{\{\v,\root\}}{\T}\) for \(\v \in \tree\pup{1}\setminus\{\root\}\) is the law of the unique solution to the following SDE:

\begin{align}
\X{\{\v,\root\}}{\t}{1} = \X{\{\v,\root\}}{0}{1} &+ \ev{\v}\int_\S\int_{(0,\crate{}{}(\X{\{\v,\root\}}{[0,\tt)}{1},\s)]}\int_{(0,t]}\s\,\poiss{\v}(d\tt,d\r,d\s)\nonumber\\
&+ \ev{\root}\int_\S\int_{(0,\crate{}{}(\X{\{\root,\v\}}{[0,\tt)}{1},\s)]}\int_{(0,t]}\s\,\poiss{\root}(d\tt,d\r,d\s)
\label{subsec::ProofU:eqn::Marginal}
\end{align}
\labe{subsec::ProofU:eqn::Marginal}
\label{subsec::ProofU:Lem::Marginal}
\end{lem}
\labe{subsec::ProofU:Lem::Marginal}

\purpose This allows us to derive the marginal density of the double neighborhood of \((\tree\pup{n})^c\) for all \(\numb\). With this marginal density, we can derive conditional intensities that can be used to extend \(\mmm{}{}{1}\) to more nodes.

\pfsum By Lemma \ref{subsec::ProofE:Lem::leftmod}, \(\crate{}{}\) has a left-continuous modification so we can directly apply Lemma \ref{subsec::ProofE:Lem::filtering}.

\begin{proof}
Let \(\rp{} = \pmap{\tree\pup{1}}(\X{}{}{1})\) be defined as in Definition \ref{subsec::ProofE:Defn::pmap}. Then \(\rp{}\) has \(\F{\tree\pup{1}}{}\)-predictable intensity,

\[\crate{\rp{}}{\t}(\X{}{[0,\t)}{1},\mark{}) = \sum_{\v\in \tree\pup{1}\setminus\{\root\}}\sum_{\s\in \S} \mb{I}_{\mark{} = \s\ev{\v}}\crate{}{}(\X{\{\v,\root\}}{[0,\t)}{1},\s) + \sum_{\s\in\S}\mb{I}_{\mark{} = \s\ev{\root}}\rate{\root}(\X{}{\t-}{1},\s).\]

Then \(\piV{\{\v,\root\}}{\T}(\rp{})\defeq \pmap{\{\v,\root\}}(\X{}{}{1})\) \tr{notation?} has \(\F{\tree\pup{1}}{}\)-predictable intensity,

\[\rate{\piV{\{\v,\root\}}{\T}(\rp{})}^{\t}(\X{}{[0,\t)}{1},\mark{}) = \sum_{\s\in \S} \left(\mb{I}_{\mark{} = \s\ev{\v}}\crate{}{}(\X{\{\v,\root\}}{[0,\t)}{1},\s) + \mb{I}_{\mark{} = \s\ev{\root}}\rate{\root}(\X{}{\t-}{1},\s)\right)\te{ for } \kappa \in \S^{\{\v,\root\}}.\]

Consider the candidate rate \(\crate{\piV{\{\v,\root\}}{\T}(\rp{})}{\t}\) defined in the following manner:

\begin{align*}
\crate{\piV{\{\v,\root\}}{\T}(\rp{})}{\t}(\kappa) &= \exmu{\m{}{}{1}}{\rate{\piV{\{\v,\root\}}{\T}(\rp{})}^{\t}(\X{}{[0,\t)}{1},\kappa)\middle|\F{\{\v,\root\}}{\t-}}\\
&=\exmu{\m{}{}{1}}{\sum_{\s\in \S}\left(\mb{I}_{\kappa = \s\ev{\v}} \crate{}{}(\X{\{\v,\root\}}{[0,\t)}{1},\s) + \mb{I}_{\kappa = \s\ev{\root}}\rate{\root}(\X{}{\t-}{1},\s)\right)\middle|\F{\{\v,\root\}}{\t-}}\\
&=\sum_{\s\in \S}\mb{I}_{\kappa = \s\ev{\v}} \crate{}{}(\X{\{\v,\root\}}{[0,\t)}{1},\s) + \sum_{\s\in \S}\mb{I}_{\kappa = \s\ev{\root}}\exmu{\m{}{}{1}}{\rate{\root}(\X{}{\t-}{1},\s)\middle|\F{\{\v,\root\}}{\t-}}\\
&=\sum_{\s\in \S}\mb{I}_{\kappa = \s\ev{\v}} \crate{}{}(\X{\{\v,\root\}}{[0,\t)}{1},\s) + \sum_{\s\in \S}\mb{I}_{\kappa = \s\ev{\root}}\exmu{\rxvttts{}{} \sim \m{}{}{1}}{\rate{}(\rxvttt{\tree\pup{1}}{\t-},\s)\middle|\rxvttts{\{\root,\v\}}{[0,\t)} = \X{\{\root,\v\}}{[0,\t)}{1}}\\
&=\sum_{\s\in \S}\mb{I}_{\kappa = \s\ev{\v}} \crate{}{}(\X{\{\v,\root\}}{[0,\t)}{1},\s) + \sum_{\s\in \S}\mb{I}_{\kappa = \s\ev{\root}}\exmu{\cm_t(\X{\{\root,\v\}}{[0,\t)}{1},\m{}{}{1})}{\rate{}(\X{\tree\pup{1}}{\t-}{1},\s)}\\
&=\sum_{\s\in \S}\left(\mb{I}_{\kappa = \s\ev{\v}} \crate{}{}(\X{\{\v,\root\}}{[0,\t)}{1},\s) + \mb{I}_{\kappa = \s\ev{\root}}\crate{}{}(\X{\{\root,\v\}}{[0,\t)}{1},\s)\right)\\
\end{align*}

Notice that \(\X{}{}{1}\) and \(\rate{}\) satisfy Assumption \ref{subsec::ProofE:Assu::Eassu}. Thus, \(\crate{}{}(\X{\{\root,\v\}}{[0,\t)}{1},\s)\) has a left-continuous modification by Lemma \ref{subsec::ProofE:Lem::leftmod}. Then \(\crate{\piV{\{\v,\root\}}{\T}(\rp{})}{\t}(\mark{})\) also has a left-continuous modification. By Lemma \ref{subsec::ProofE:Lem::filtering}, \(\crate{\piV{\{\v,\root\}}{\T}(\rp{})}{\t}(\kappa)\) is the \(\F{\{\v,\root\}}{}\)-predictable intensity of \(\rp{}\). By Lemma \ref{subsec::Some:Lem::genfiniteSDE}, equation \eqref{subsec::ProofU:eqn::Marginal} has a unique solution and by Lemma \ref{subsec::Some:Lem::PPtoSDE}, that solution has jump intensity given by the above.

\end{proof}

\lin

\tr{TODO::standardize space, time and mark orderings of Poisson processes.}

\begin{defn}
Suppose \(\{\poiss{}\}\) is Poisson process with intensity \(\leb\otimes \Sm\) on \(\mb{R}^2\times \S\). Define,

\[\rxvtt{}{\t} = \rxvtt{}{0} + \int_{(0,\t]}\int_{(0,1]}\int_\S\s\,\poiss{}(d\s,d\r,d\tt).\]

Let \(\mm{}{}{} = \law(\rxvtts{}{})\). Suppose \(\mmm{\v}{0,}{1}\ll\mm{}{0}{}\) for all \(\v\in\tree\pup{1}\). Let \(\{\mm{\v}{}{}:\v\in\V\}\) be the distributions of a sequence of i.i.d. \(\S^{\v}\)-valued c\`adl\`ag processes. For any \(\U\subseteq \V\), let 

\[\mm{\U}{}{} = \otimes_{\v\in\U} \mm{\v}{}{}.\]

Finally, for any \(\t\in [0,\T)\), let \(\mm{\U}{\t,}{}\) be the projection of \(\mm{\U}{}{}\) to \(\pmsr(\Omega{\U}{\t-})\). Use a similar system for all measures.
\label{subsec::ProofU:Defn::nu}
\end{defn}
\labe{subsec::ProofU:Defn::nu}

\lin

\begin{lem}
For any \(\v \in \V\setminus\{\root\}\), let \(\p{\v}\) be the parent node of \(\v\) (neighboring node of \(\v\) closest to \(\root\)). Fix \(\numb \in \mb{N}\). Let \(\mmm{}{}{\numb} \in \pmsr\left(\Omega{\tree\pup{\numb}}{\T-}\right)\) be the law of the unique solution to the following SDE:

\begin{equation}
\X{\v}{\t} = \begin{cases}
\X{\v}{0} + \int_{(0,\t]}\int_\S\int_{\left(0,\crate{}{}(\X{\{\v,\p{\v}\}}{[0,\tt)},\s)\right]}\s\,\poiss{\v}(d\r,d\s,d\tt)\te{ if } \v \in \tree\pup{\numb}\setminus \tree\pup{\numb-1}\\
\X{\v}{0} + \int_{(0,\t]}\int_\S\int_{\left(0,\rate{}(\X{\cl{\v}}{\tt-},\s\right)}\s\,\poiss{\v}(d\r,d\s,d\tt)\te{ if } \v \in \tree\pup{\numb-1}
\end{cases}
\label{subsec::ProofU:eqn::extendedSDE}
\end{equation}
\labe{subsec::ProofU:eqn::extendedSDE}

Then for any \(\alt{\numb} < \numb\), \(\mmm{}{\t}{\alt{\numb}} = \piV{\tree\pup{\alt{\numb}}}{\t}(\mmm{}{\t}{\numb})\).
\label{subsec::ProofU:Lem::extendedSDE}
\end{lem}
\labe{subsec::ProofU:Lem::extendedSDE}

\purpose By constructing larger processes with the whose marginal distribution is \(\mmm{}{}{1}\), we can, in the limit, construct an interacting particle system on \(V\) that projects down to \(\mmm{}{}{}\). All that will remain will be to prove that this process is equal in distribution to \(\m{}{}{}\).

\pfsum Using Lemmas \ref{subsec::ProofU:Lem::Marginal} and \ref{subsec::Some:Lem::radnik} \tr{rrewrite}, we can construct a conditional density which can be used to extend \(\mu\pup{1}\). We can use simple density arguments to prove the marginal properties we can use Lemma \ref{subsec::Some:Lem::radnik} \tr{rrewrite} to get the SDE formulation.

\begin{proof}
\tr{I'm not being consistent about the intervals I am using. Everything is in half open intervals. I should make the final result the same.}

Let \(\mm{}{}{} \in \pmsr(\Omega{\V}{\T-})\) be as defined in Definition \ref{subsec::ProofU:Defn::nu}.

\ind Recall that \(\rp{} \defeq \pmap{}(\X{}{}{1})\) maps \(\X{}{}{1}\) to the point process coinciding with the jumps of \(\X{}{}{1}\). This point process has intensity,

\[\ratee{}(\rp{}[0,\t),\mark{}) = \begin{cases}
\crate{}{}(\X{\{\v,\root\}}{[0,\t)}{1},\s) &\te{ if } \v\in \tree\pup{1}\setminus\{\root\}\te{ and } \mark{} = \s\ev{\v}\\
\rate{}(\X{\tree\pup{1}}{\t-}{1},\s) &\te{ if } \mark{} = \s\ev{\root}\\
0 &\te{ otherwise}.
\end{cases}\]

Let \(\mm{}{}{1} \defeq \mm{\tree\pup{1}}{}{}\). Then \(\pmap{}(\mm{}{}{1})\) has constant intensity \(\mb{I}_{\kappa \in\{\s\ev{\v}:\s\in\S\setminus\{0\},\v\in\tree\pup{1}\}}\). 

\ind Define the following mapping,

\begin{align}
\ds{\v}{\t}(\rxvttts{}{},f) &\defeq \sum_{0 < \rt{\it}_\v \leq \t} \log{f(\rxvttts{}{[0,\rt{\it}_\v)},\mark{\it}_\v)} - \int_{(0,\t]\times \S} [f(\rxvttts{}{[0,\tt)},\s) - 1]\,ds\,\Sm(d\s) \label{subsec::ProofU:eqn::shortdense}\\
f&\te{ is a }[0,\const{}] \te{-valued mapping and } \pmap{\v}(\rxvttts{}{}) = \{(\rt{\it}_\v,\mark{\it}_\v):\it\in\mb{N}\}.\nonumber
\end{align} 
\labe{subsec::ProofU:eqn::shortdense}

Let \(\{(\rt{\it},\mark{\it})\}\) be the events of \(\pmap{}(\X{}{}{1})\). By Lemma \ref{subsec::Some:Lem::radnik},

\begin{align}
\dense{1}{\t}(\X{\tree\pup{1}}{})&\defeq \frac{d\mmm{}{\t}{1}}{d\mm{}{\t}{1}}\nonumber\\
&= \frac{d\mmm{}{0}{1}}{d\mm{}{0,}{1}}\exp\left(\sum_{0< \rt{\it} \leq \t} \log{\ratee{}(\X{}{[0,\rt{\it})}{1},\mark{\it})} - \int_{(0,\t]\times\S} [\ratee{}(\X{}{[0,\tt)}{1},\s) - 1]\,d\tt\,\Sm(d\s)\right)\nonumber\\
&= \frac{d\mmm{}{0}{1}}{d\mm{}{0,}{1}}\exp\Bigg(\sum_{\v\in\tree\pup{1}\setminus\{\root\}}\left(\sum_{0< \rt{\it}_\v \leq \t} \log{\crate{}{}(\X{\{\v,\root\}}{[0,\rt{\it}_\v)}{1},\mark{\it})} - \int_{(0,\t]\times\S} [\crate{}{}(\X{\{\v,\root\}}{[0,\tt)}{1},\s) - 1]\,d\tt\,\Sm(d\s)\right)\nonumber\\
&\hspace{24pt} + \left(\sum_{0 < \rt{\it}_\root \leq \t} \log{\rate{}(\X{\tree\pup{1}}{\rt{\it}_\root-}{1},\mark{\it}_\root)} - \int_{(0,\t]\times\S} [\rate{}(\X{\tree\pup{1}}{\tt-}{1},\s) - 1]\,ds\,\Sm(d\s)\right)\Bigg)\nonumber\\
&= \frac{d\mmm{}{0}{1}}{d\mm{}{0}{1}}\exp\left(\sum_{\v\in\tree\pup{1}\setminus\{\root\}} \ds{\v}{\t}(\X{\{\v,\root\}}{}{1},\crate{}{}) + \ds{\root}{\t}(\X{\tree\pup{1}}{}{1},\rate{})\right).
\label{subsec::ProofU:eqn::L1 density}
\end{align}

By a similar calculation, we can apply Lemmas \ref{subsec::Some:Lem::radnik} and \ref{subsec::ProofU:Lem::Marginal} to get,

\begin{equation}
\alt{\dense{}{\t}}(\X{\{\v,\root\}}{}{1}) \defeq \frac{d\mmm{\{\v,\root\}}{\t,}{}}{d\mm{\{\v,\root\}}{\t,}{}} = \frac{d\mmm{\{\v,\root\}}{0,}{}}{d\mm{\{\v,\root\}}{0,}{}}\exp\left(\ds{\v}{\t}(\X{\{\v,\root\}}{}{1},\crate{}{}) + \ds{\root}{\t}(\X{\{\root,\v\}}{}{1},\crate{}{})\right).
\label{subsec::ProofU:eqn::Margdense}
\end{equation}
\labe{subsec::ProofU:eqn::Margdense}

Define,

\begin{align*}
\cdense{}{\t}&(\X{\{\tree\pup{1}\setminus\{\root\}\}}{}{1};\x{\{\root,1\}}{})\\
& \defeq\frac{d\mmm{\tree\pup{1}\setminus\{\root,1\}}{0,}{}}{d\mm{\tree\pup{1}\setminus\{\root,1\}}{0,}{}}\exp\left(\sum_{\v\in \tree\pup{1}\setminus\{\root,1\}} \ds{\v}{\t}([\X{\{v\}}{}{1},\x{\root}{}],\crate{}{}) + \ds{\root}{\t}([\X{\tree\pup{1}\setminus\{\root,1\}}{}{1},\x{\{\root,1\}}{}],\rate{}) - \ds{\root}{\t}(\x{\{\root,1\}}{},\crate{}{})\right)\\
\end{align*}

Then,

\[\cdense{}{\t}(\X{\tree\pup{1}\setminus\{\root\}}{}{1};\x{\{\root,1\}}{}) = \frac{\dense{1}{\t}([\X{\tree\pup{1}\setminus\{\root\}}{}{1},\x{\{\root,1\}}{}])}{\alt{\dense{}{\t}}(\x{\{1,\root\}}{})}.\]

By definition,

\[\alt{\dense{}{\t}}(\X{\{1,\root\}}{}{1}) = \exmu{\mm{\tree\pup{1}\setminus\{1,\root\}}{\t,}{}(\X{\tree\pup{1}\setminus\{1,\root\}}{}{1})}{\dense{1}{\t}([\X{\tree\pup{1}\setminus\{\root\}}{}{1},\x{\{\root,1\}}{}])}.\]

So,

\[\exmu{\mm{\tree\pup{1}\setminus\{1,\root\}}{\t,}{}}{\cdense{}{\t}(\X{\tree\pup{1}\setminus\{\root\}}{}{1};\x{\{1,\root\}}{})} = 1.\]

The important thing is that this can be used to extend \(\X{}{}{1}\) to a process with nodes in \(\tree\pup{2}\) whose marginal distribution with respect to the nodes on \(\tree\pup{1}\) is equal to \(\X{}{}{1}\). To do that, consider the following notation:

\ind Let \(\v \in \V\setminus\{\root\}\). Let \(\c{}:\V\setminus\{\root\} \ra \V^{\degr-1}\) be defined such that \(\c{\v} = (c^1(\v),\dots,c^{\degr-1}(\v))\) are the children of \(\v\). Let \(\p{}:\V\setminus\{\root\}\ra\V\) map nodes to their parents.

\ind We can define the sequence of functions \(\dense{\numb}{\t}: \Omega{\tree\pup{\numb}}{\t-} \ra [0,\infty)\) by,

\[\dense{\numb}{\t}(\X{}{}{\numb}) := \dense{\numb-1}{\t}(\X{\tree\pup{\numb-1}}{}{\numb})\prod_{\v\in \tree\pup{\numb-1}\setminus\tree\pup{\numb-2}} \cdense{}{\t}(\X{\c{\v}}{}{\numb};\X{\{\v,\root\}}{}{\numb})\]

for \(\numb > 1\) (\(\tree\pup{0} = \{\root\}\)). We can show using induction,

\ind Let \(\mm{\tree\pup{\numb}}{}{} = \mm{}{}{\numb}\) and assume for any \(\U \subseteq \V\), \(\mmm{\U}{0,}{} = \otimes_{\v\in\U}\mmm{\v}{0,}{}\) where \(\{\mmm{\v}{0,}{}:\v\in\V\}\) describes a sequence of i.i.d. \(\S\)-valued random variables. We can show using induction that,

\begin{equation}
\dense{\numb}{\t}(\X{}{}{\numb}) = \frac{d\mmm{}{\t}{\numb}}{d\mm{}{0}{\numb}}\exp\left(\sum_{\v\in\tree\pup{\numb-1}}\ds{\v}{\t}(\X{\cl{\v}}{}{\numb},\rate{}) + \sum_{\v\in\tree\pup{\numb}\setminus\tree\pup{\numb-1}} \ds{\v}{\t}(\X{\{v,\p{\v}\}}{}{\numb},\crate{}{})\right).
\label{subsec::ProofU:eqn::densen}
\end{equation}
\labe{subsec::ProofU:eqn::densen}

Assume equation \eqref{subsec::ProofU:eqn::densen} holds for \(\dense{\numb-1}{\t}\). Then,

\begin{align*}
\dense{\numb}{\t}(\X{}{}{\numb}) &= \dense{\numb-1}{\t}(\X{\tree\pup{\numb-1}}{}{\numb})\prod_{\v\in\tree\pup{\numb-1}\setminus\tree\pup{\numb-2}} \cdense{}{\t}(\X{\c{\v}}{}{2};\X{\{\v,\p{\v}\}}{}{2})\\
&=\left(\frac{d\mmm{}{0}{\numb-1}}{d\mm{}{0}{\numb-1}}\prod_{\v\in\tree\pup{\numb-1}\setminus\tree\pup{\numb-2}}\frac{d\mmm{\c{\v}}{0,}{}}{d\mm{\c{\v}}{0,}{}}\right)\exp\Bigg(\sum_{\v\in\tree\pup{\numb-2}}\ds{\v}{\t}(\X{\cl{\v}}{}{\numb},\rate{}) + \sum_{\v\in\tree\pup{\numb-1}\setminus\tree\pup{\numb-2}} \ds{\v}{\t}(\X{\{\v,\p{\v}\}}{}{\numb},\crate{}{})\\
&\ind + \sum_{\v\in\tree\pup{\numb-1}\setminus\tree\pup{\numb-2}}\left(\sum_{\vv\in \c{\v}} \ds{\vv}{\t}(\X{\{\vv,\v\}}{}{\numb},\crate{}{}) + \ds{\v}{\t}(\X{\cl{\v}}{}{\numb},\rate{}) - \ds{\v}{\t}(\X{\{\v,\p{\v}\}}{}{\numb},\crate{}{})\right)\Bigg)\\
&=\frac{d\mmm{}{0}{\numb}}{d\mm{}{0}{\numb}}\exp\left(\sum_{\v\in\tree\pup{\numb-1}}\ds{\v}{\t}(\X{\cl{\v}}{}{\numb},\rate{}) + \sum_{\v\in\tree\pup{\numb}\setminus\tree\pup{\numb-1}} \ds{\v}{\t}(\X{\{\v,\p{\v}\}}{}{\numb},\crate{}{})\right).
\end{align*}

By a simple calculation analogous to what we did earlier to show that \(\dense{1}{\t}\) was a Radon-Nykodim derivative, we can apply Proposition \ref{subsec::Prope:Prop::radnikder} to prove that this is the Radon-Nikodym derivative of a marked point process. 

\ind For each \(\numb > 1\), define \(\mmm{}{}{\numb} \in \pmsr(\Omega{\tree\pup{\numb}}{\T-})\) by,

\[\frac{d\mmm{}{\t}{\numb}}{d\mm{}{\t}{\numb}} = \dense{\numb}{\t}(\X{}{}{\numb}).\]

Then,

\begin{align*}
\frac{d\piV{\tree\pup{\numb-1}}{\t}(\mmm{}{\t}{\numb})}{d\mm{}{\t}{\numb-1}} &= \int_{\Omega{\tree\pup{\numb}\setminus\tree\pup{\numb-1}}{\t-}} \frac{d\mmm{}{\t}{\numb}}{d\mm{}{\t}{\numb}}\,\mm{\tree\pup{\numb}\setminus\tree\pup{\numb-1}}{\t,}{}(d\X{\tree\pup{\numb}\setminus\tree\pup{\numb-1}}{}{\numb})\\
&=\int_{\Omega{\tree\pup{\numb}\setminus\tree\pup{\numb-1}}{\t-}} \dense{\numb}{\t}(\X{}{}{\numb})\,\mm{\tree\pup{\numb}\setminus\tree\pup{\numb-1}}{\t,}{}(d\X{\tree\pup{\numb}\setminus\tree\pup{\numb-1}}{}{\numb})\\
&= \int_{\Omega{\tree\pup{\numb}\setminus\tree\pup{\numb-1}}{\t-}} \dense{\numb-1}{\t}(\X{\tree\pup{\numb-1}}{}{\numb})\prod_{\v\in \tree\pup{\numb-1}\setminus\tree\pup{\numb-2}} \cdense{}{\t}(\X{\c{\v}}{}{\numb};\X{\{v,\p{\v}\}}{}{\numb})\,\mm{\tree\pup{\numb}\setminus\tree\pup{\numb-1}}{\t,}{}(d\X{\tree\pup{\numb}\setminus\tree\pup{\numb-1}}{}{\numb})\\
&= \dense{\numb-1}{\t}(\X{\tree\pup{\numb-1}}{}{\numb})\prod_{\v\in \tree\pup{\numb-1}\setminus\tree\pup{\numb-2}}\int_{\Omega{\c{\v}}{\t-}} \cdense{}{\t}(\X{\c{\v}}{}{\numb};\X{\{v,\p{\v}\}}{}{\numb})\,\mm{\c{\v}}{\t,}{}(d\X{\c{\v}}{}{\numb})\\
&= \dense{\numb-1}{\t}(\X{\tree\pup{\numb-1}}{}{\numb})\prod_{\v\in \tree\pup{\numb-1}\setminus\tree\pup{\numb-2}}\exmu{\mm{\c{\v}}{\t,}{}}{\cdense{}{\t}(\X{\c{\v}}{}{\numb};\X{\{v,\p{\v}\}}{}{\numb})}\\
&= \dense{\numb-1}{\t}(\X{\tree\pup{\numb-1}}{}{\numb}).
\end{align*}

This proves that \(\piV{\tree\pup{\numb-1}}{\t}(\mmm{}{\t}{\numb}) = \mmm{}{\t}{\numb-1}\). Furthermore, for any \(\alt{\numb} < \numb\),

\[\piV{\tree\pup{\alt{\numb}}}{\t}(\mmm{}{\t}{\numb}) = \piV{\tree\pup{\alt\numb}}{\t}\circ\piV{\tree\pup{\alt{\numb} + 1}}{\t} \circ\cdots\circ \piV{\tree\pup{\numb-1}}{\t}(\mmm{}{\t}{\numb}) = \piV{\tree\pup{\alt\numb}}{\t}\circ\piV{\tree\pup{\alt{\numb} + 1}}{\t} \circ\cdots\circ \piV{\tree\pup{\numb-2}}{\t}(\mmm{}{\t}{\numb-1}) = \cdots = \mmm{}{\t}{\alt{\numb}}.\]

\ind Fix \(\numb\in\mb{N}\). By Lemma \ref{subsec::Some:Lem::radnik}, \(\mmm{}{}{\numb}\) can be described as the law of the unique solution to equation \eqref{subsec::ProofU:eqn::extendedSDE}.
\end{proof}

\lin

For any \(\U\subseteq \V\), we can consider the embedding \(\pmsr\left(\Omega{\U}{\t-}\right) = \pmsr\left((\Omega{\U}{\t-},\F{\U}{\t-})\right) \subseteq \pmsr\left((\Omega{\V}{\t-},\F{\U}{\t-})\right)\). That is, a measure \(\mmm{}{}{}\in \pmsr\left(\Omega{\U}{\t-}\right)\) can be considered as a \(\F{\U}{}\)-adapted measure on \(\Omega{\V}{\t-}\).

\ind Let's summarize what we have so far. We have a sequence of measures \(\{\mmm{}{}{\numb}:\numb\in\mb{N}\} \subset \pmsr(\Omega{\V}{\T-})\) satisfying:

\begin{enumerate}[(a)]
\item \(\mmm{}{}{1}\) solves equation \eqref{sec::Main:eqn::Local SDE}.

\item \(\mmm{}{}{\numb}(\X{\tree\pup{\alt{\numb}}}{}{\numb} \in \cdot) = \mmm{}{}{\alt{\numb}}(\X{\tree\pup{\alt{\numb}}}{}{\alt{\numb}}\in \cdot)\) for all \(\numb \geq \alt{\numb}\).

\item \(\frac{d\mmm{}{\t}{\numb}}{d\mm{}{\t}{\numb}} = \dense{\numb}{\t}(\X{}{}{\numb})\).
\end{enumerate}

Let \(\{\mmm{\U}{\t,}{}:\t \leq \T\}_{\U\subset \V,\U\te{ finite}}\) be a collection of measures defined by

\[\mmm{\U}{\t,}{}(\cdot) = \mmm{}{\t}{\numb}(\X{}{[0,\t)}{\numb} \in \cdot) \te{ for any }\numb\te{ s.t. }\U \subseteq \tree\pup{\numb}.\]

By property (b) above, this is well-defined. Since each \(\mmm{\U}{}{}\) is a probability measure defined on the Borel sets of \(\Omega{\U}{\T-}\), they are all inner regular (\tr{citation?}). Now, fix some finite \(\U\subseteq \V\) and let \(\UU \subseteq \U\). Suppose \(\numb\) is such that \(\U \subseteq \tree\pup{\numb}\). Then \(\UU\subseteq \tree\pup{\numb}\), so

\[\piV{\UU}{\t}(\mmm{\U}{\t,}{})(\cdot) = \mmm{\U}{\t,}{}\left(\piV{\UU}{\t}(\X{\U}{}{\numb}) \in \cdot\right) = \mmm{}{\t}{\numb}\left(\X{\UU}{}{\numb} \in \cdot\right) = \mmm{\UU}{\t,}{}(\cdot).\]

Therefore the conditions of the Daniell-Kolmogorov extension theorem are satisfied. Therefore, there exists a \(\mmm{}{}{}\in \ms{P}(\Omega{\U}{\T-})\) such that \(\piV{\U}{\T-}(\mmm{}{}{}) =\mmm{\U}{}{}\) for all finite \(\U\). \tr{citation needed (Reading off of Lecture notes (Theorem 2.4.3) which were used as the basis of Terence Tao's measure theory book)}.

\ind In particular, there exists a probability space with canonical process \(\X{}{}\) such that \(\mmm{}{}{} = \law(\X{}{[0,\T)})\) and \(\mmm{\v}{}{} = \law(\X{\v}{[0,\T)})\) for all \(\v \in \V\). In particular, this means that \(\law(\X{\tree\pup{\numb}}{[0,\T)}) = \mmm{\tree\pup{\numb}}{}{} = \mmm{}{}{\numb}\). Since \(\X{\tree\pup{\numb}}{} \ra \X{}{}\) almost surely (we are in the topology of componentwise convergence), \(\mmm{}{}{\numb} \Rightarrow \mmm{}{}{}\). In order to characterize \(\X{}{}\) and \(\mmm{}{}{}\), we construct a stochastic differential equation on a probability space on which \(\X{}{}{\numb} \sim \mmm{}{}{\numb}\) and \(\X{}{}{\numb} = \X{\tree\pup{\numb}}{}\) almost surely. \tr{I don't know if it's clear, but we are taking \(\X{}{}{\numb}\) and \(\X{}{}\) as given in this probability space.}

\ind On this space, we construct a sequence of i.i.d Poisson processes as follows (Construction is based on the proof of \cite[Theorem 14.7.1(b)]{DalVer08}. The result is given in \cite[Exercise 14.7.1]{DalVer08} \tr{TODO: rigorously solve this exercise myself}).

\ind Let \(\alt{\S}^\numb = \{\s\ev{\v}: \s\in\S,\v \in \tree\pup{\numb}\}\). For each \(\numb\), consider \(\alt{\S}^\numb\) as embedded in \(\S^\V\). Thus, \(\alt{\S}^1 \subset \alt{\S}^2 \subset \cdots\). Let \(\alt{\Sm}\pup{\numb}\) be the measure on \(\alt{\S}^\numb\) defined by \(\alt{\Sm}\pup{\numb}(\{\s\ev{\v}\}) = \mb{I}_{\v \in \tree\pup{\numb}}\Sm(\s)\). Let \(\{\rt{\numb,\it}_\v,\mark{\numb,\it}_{\v}\}\) be the jump sizes and jump times of \(\X{\v}{}{\numb}\). Let \(\alt{\poiss{\numb}}\) be a sequence Poisson processes on \(\mb{R}^+\times\alt{S}^\numb\times \mb{R}^+\) with intensity measure \(d\t\times\alt{\Sm}^\numb\times d\r\) and such that if \(\evnt \in \ms{B}(\mb{R}^+\times\alt{S}^{\numb-1}\times \mb{R}^+)\), then \(\alt{\poiss{\numb}}(\evnt) = \alt{\poiss{\numb-1}}(\evnt)\). Assume \(\{\alt{\poiss{\numb}}:\numb\in\mb{N}\}\) are independent of \(\{\X{}{},\X{}{}{\numb}:\numb\in\mb{N}\}\). Let \(\{\rv_{\v}^{\itt}\}\) be a sequence of i.i.d. uniform random variables with support on \([0,1]\).

\ind Recall the mapping \(\pmap{}(\cdot)\) from Definition \ref{subsec::ProofE:Defn::pmap}. Define the Marked point process \(\rp{\numb} = \pmap{}(\X{}{}{\numb})\). Then the intensity of \(\rp{\numb}\) is given by,

\[\rate{\numb}(\t,\sv{\tree\pup{\numb}}) = \begin{cases}
\rate{}(\X{\cl{\v}}{\t-}{\numb},\s) &\te{ if } \sv{\tree\pup{\numb}} = \s\ev{\v},\s \in \S\setminus\{0\},\v\in\tree\pup{\numb-1}\\
\crate{}{}(\X{\{\v,\p{\v}\}}{[0,\t)}{\numb},\s) &\te{ if } \sv{\tree\pup{\numb}} = \s\ev{\v},\s\in\S\setminus\{0\},\v\in\tree\pup{\numb}\setminus\tree\pup{\numb-1}\\
0 &\te{ otherwise.}
\end{cases}\]

For any \(\evnt \in \ms{B}(\mb{R}^+\times\alt{\S}^\numb\times\mb{R}^+)\), define

\begin{equation}
\poiss{\numb}(\evnt) = \alt{\poiss{\numb}}\left(\evnt\cap\{(t,\sv{\tree\pup{\numb}},\r):\r > \rate{\numb}(\t,\sv{\tree\pup{\numb}})\}\right) + \#\{(\rt{\numb,\it}_\v,\mark{\numb,\it}_\v,\rv_{\v}^{\it}\rate{\numb}(\rt{\numb,\it}_\v,\mark{\numb,\it}_\v) \in \evnt: \v\in \tree\pup{\numb}\}.
\label{subsec::ProofU:eqn::Poissonexpl}
\end{equation}
\labe{subsec::ProofU:eqn::Poissonexpl}

Then \(\poiss{\numb}\) is a Poisson random measure on \(\mb{R}^+\times\alt{\S}^\numb\times \mb{R}^+\) with intensity measure \(d\t\times \alt{\Sm}^\numb\times d\r\) (see proof of \cite[Theorem 14.7.1(b)]{DalVer08})

\ind Notice that for any \(\evnt \in \ms{B}(\mb{R}^+\times \alt{\S}^{\numb-2}\times \mb{R}^+)\), \(\poiss{\numb}(\evnt) = \poiss{\numb-1}(\evnt)\) almost surely. Define the random measure \(\poiss{}\) on \(\ms{B}(\mb{R}^+\times \{\s\ev{\v}:\s\in \S,\v \in \V\}\times \mb{R}^+)\) by,

\[\poiss{}(\evnt) = \lim_{\numb \ra\infty}\poiss{\numb}\left(\piV{\tree\pup{\numb-1}}{}(\evnt)\right).\]

Here \(\piV{\tree\pup{\numb}}{}(\evnt)\) is the restriction of \(\evnt\) to \(\mb{R}^+\times \alt{\S}^\numb\times\mb{R}^+\). 

\ind Notice that this limit exists almost surely, because it is the limit of an almost surely monotonically increasing sequence. Let \(\poiss{\v}\) be random measures on \(\mb{R}^+\times\S\times\mb{R}^+\) with intensity \(d\t\times\Sm(d\s)\times d\r\). Define it by,

\[\poiss{\v}(\evnt) = \poiss{}\left(\{(\t,\s\ev{\v},\r):(\t,\s,\r)\in \evnt\}\right) \te{ for } \evnt \in \ms{B}(\mb{R}^+\times\S\times\mb{R}^+).\]

Similarly define,

\[\alt{\poiss{\v}}(\evnt) = \poiss{\numb}\left(\{(\t,\s\ev{\v},\r):(\t,\s,\r)\in \evnt\}\right)\te{ for } \evnt \in \ms{B}(\mb{R}^+\times\S\times\mb{R}^+)\te{ and }\numb\te{ such that } \v\in \tree\pup{\numb}\setminus\tree\pup{\numb-1}.\]

Then \(\{\poiss{\v}\}\) and \(\{\alt{\poiss{\v}}\}\) are both sequences of i.i.d. Poisson processes. Furthermore, for any \(\numb \in \mb{N}\), \(\{\poiss{\vv},\alt{\poiss{\vvv}}:\vv\in \tree\pup{\numb-1},\vvv\in\tree\pup{\numb}\setminus\tree\pup{\numb-1}\}\) are i.i.d.

\lin

\begin{lem}
The claims above are true. Namely, \(\poiss{\numb}\) are all Poisson processes with intensity measure \(d\t\times\alt{\Sm^{\numb}}\times d\r\), \(\{\poiss{\v}:\v\in\V\}\) is a sequence of i.i.d. Poisson processes with intensity measure \(d\t\times\Sm\times d\r\) and \(\{\poiss{\vv},\alt{\poiss{\vvv}}:\vv\in \tree\pup{\numb-1},\vvv\in\tree\pup{\numb}\setminus\tree\pup{\numb-1}\}\) are i.i.d. for any \(\numb \in \mb{N}\).

\label{subsec::ProofU:Lem::Poisson}
\end{lem}
\labe{subsec::ProofU:Lem::Poisson}
\begin{proof}

Fix \(\numb \in \mb{N}\). Notice that most of the assumptions of \cite[Proposition 14.7.I(b)]{DalVer08} are satisfied, except the filtration with respect to which \(\rate{\numb}\) is predictable is slightly larger (the proposition requires the filtration to only contain the jumps of \(\X{}{}{\numb}\), but not the initial state). However, the proof of the proposition does not fail when the initial state is included in the filtration (Lemma \ref{sec::TL:Lem::embedding}). Furthermore, \(\poiss{\numb}\) is the Poisson process constructed in the proof, so it is a Poisson process with intensity \(d\t\times \alt{\Sm^\numb}\times d\r\).

\ind By construction, \(\poiss{\v}\) is the restriction of \(\poiss{\numb}\) to \(\mb{R}^+ \times \{\s\ev{\v}: \s\in \S\}\times \mb{R}^+\) for all \(\v\in \tree\pup{\numb-1}\). Thus, for any finite \(\U \subset \V\), there exists a \(\numb\) such that \(\U \subseteq \tree\pup{\numb-1}\), so \(\{\poiss{\v}: \v\in \U\}\) are i.i.d. Thus, \(\{\poiss{\v}: \v\in \V\}\) are i.i.d.

\ind Similarly, for any \(\numb \in \mb{N}\), \(\{\poiss{\v},\alt{\poiss{\vv}}: \v \in \tree\pup{\numb-1},\vv\in\tree\pup{\numb}\setminus\tree\pup{\numb-1}\}\) is just the set of restrictions of \(\poiss{\numb}\) to \(\mb{R}^+\times\{\s\ev{\v}\}\times\mb{R}^+\) for each \(\v\in \tree\pup{\numb}\), so they are i.i.d. Poisson processes with intensity measure \(d\t\times \Sm\times d\r\) because \(\poiss{\numb}\) is a Poisson process with intensity measure \(d\t\times\alt{\Sm^\numb}\times d\r\).
\end{proof}

\lin

Let \(\{\poiss{\v},\alt{\poiss{\v}}:\v\in\V\}\) be constructed as above. Then \(\X{}{}{\numb}\) almost surely solves the equation,

\begin{equation}
\X{\v}{\t}{\numb} = \begin{cases}
\X{\v}{0}{} + \int_{(0,\t]}\int_\S\int_{(0,\crate{}{}(\X{\{\v,\p{\v}\}}{[0,\tt)}{\numb},\s)]}\s\alt{\poiss{\v}}(d\tt,d\s,d\r)\te{ for } \v \in \tree\pup{\numb}\setminus\tree\pup{\numb-1}\\
\X{\v}{0}{} + \int_{(0,\t]}\int_\S\int_{(0,\rate{}(\X{\cl{\v}}{\tt-}{\numb},\s)]}\s\,\poiss{\v}(d\tt,d\s,d\r)\te{ for } \v \in \tree\pup{\numb-1}.
\end{cases}
\label{subsec::ProofU:eqn::ExtendedSDE_fixedPoisson}
\end{equation}
\labe{subsec::ProofU:eqn::ExtendedSDE\_fixedPoisson}

By Lemma \ref{subsec::ProofU:Lem::Poisson}, these Poisson processes are i.i.d. By Lemma \ref{subsec::ProofU:Lem::extendedSDE}, \(\te{law}(\X{}{}{\numb}) = \mmm{}{}{\numb}\). By construction, \(\piV{\tree\pup{\numb}}{\T-}(\X{}{}) = \X{}{}{\numb}\) for all \(\numb\in\mb{N}\).

\ind Fix any \(\v\in\V\). Let \(\numb\in \mb{N}\) be any natural number such that \(\v\in \tree\pup{\numb-1}\). Then for any \(\t \in [0,\T)\),

\begin{align*}
\X{\v}{0} + \int_{(0,\t]}\int_\S\int_{(0,\rate{}(\X{\cl{\v}}{\tt-},\s)]}\s\poiss{\v}(d\r,d\s,d\tt) &= \X{\v}{0} + \int_{(0,\t]}\int_\S\int_{(0,\rate{}(\X{\cl{\v}}{\tt-}{\numb},\s)]}\s\poiss{\v}(d\r,d\s,d\tt)\\
&=\X{\v}{\t}{\numb} = \X{\v}{\t}.
\end{align*}

Thus, \(\X{}{}\) is a solution to the coupled equation,

\begin{equation}
\X{\v}{\t} = \X{\v}{0} + \int_{(0,\t]}\int_\S \int_{(0,\rate{}(\X{}{\tt-},\s)]}\s\,\poiss{\v}(d\r,d\s,d\tt).
\label{subsec::ProofU:eqn::XSDE}
\end{equation}
\labe{subsec::ProofU:eqn::XSDE}

However, by Propositions \ref{subsec::Well-:Prop::SDEWP} and \ref{subsec::Well-:Prop::SDE=IG}, equation \eqref{subsec::ProofU:eqn::XSDE} has a unique solution, and that solution has distribution \(\m{}{}{}\). Thus, \(\mmm{}{}{} = \m{}{}{}\). We conclude that \(\mmm{}{}{1} = \piV{\tree\pup{1}}{\T-}(\m{}{}{})\).

\end{proof}
\newpage
\appendix

\section{Infinitesimal Generators}
\label{sec::Infin}\labe{sec::Infin}

Let \(\mc{X}\) be a compact and countable set. \tr{For most of the paper, \(\mc{X} = S^V\) which is compact with respect to the topology of componentwise convergence.}

Let \(\mc{C}(\mc{X})= \{f:\mc{X} \ra \mb{R} \te{ continuous}\}\).

\lin

\begin{defn}
A Feller process on \(\mc{X}\) is a collection of probability measures \(\{\pr^x:x \in \mc{X}\}\) on \(\cad([0,\infty),\mc{X})\) with canonical process \(X\) such that

\begin{enumerate}[(a)]
\item \(\pr^x(X_0 = x) = 1\) for all \(x \in \mc{X}\).

\item The mapping \(x \mapsto \pr^x(A)\) is measurable for every \(\sigma(X)\)-measurable set \(A\).

\item \(\pr^x(X_{s+\cdot} \in A|X_r:r \in [0,s]) = \pr^{X_s}(A)\) for all \(A \in \sigma(X)\) and \(x \in \mc{X}\).

\item For all \(f\in \mc{C}(\mc{X})\), the mapping \(x\mapsto \mb{E}^x[f(X_t)]\) is also continuous.
\end{enumerate}
\label{sec::Infin:Def::Feller}
\end{defn}
\labe{sec::Infin:Def::Feller}

\textbf{Source: } This definition is adapted from \cite[Definition 1.1,1.2]{Lig85}.

\textbf{Remark: } We will also refer to a probability measure \(\mu \in \mc{P}(\cad([0,T],\mc{X}))\) as Feller if

\begin{enumerate}[(a)]
\item There exists an measure \(\ov{\mu}\in \mc{P}(\cad([0,\infty),\mc{X}))\) such that \(\ov{\mu}|_{\cad([0,T],\mc{X})} = \mu\).

\item There exists a probability measure \(\nu\in \mc{P}(\mc{X})\) and a Feller process \(\{\ov{\mu}^x:x \in \mc{X}\}\) such that 

\[\ov{\mu}(\cdot) = \int_{\mc{X}} \ov{\mu}^x(\cdot)\,d\nu(x).\]
\end{enumerate}

\textbf{Another Remark: } Given a c\`adl\`ag \(\mc{X}\)-valued random process \(\X{}{}\), we say \(\X{}{}\) is Feller if,

\[\left\{\law\left(\X{}{}\middle|\X{}{0} = \x{}{}\right): \x{}{} \in \mc{X}\right\}\]

satisfies Definition \ref{sec::Infin:Def::Feller}.

\purpose As shown later, there is a bijection between Feller processes and Infinitesimal generators. This allows us to express the process \(\mu\) in terms of its infinitesimal generator in equation \eqref{subsec::Notat:Eqn::IG}.

\lin

\begin{defn}
An infinitesimal generator is a (possibly unbounded) linear operator \(\IG{}\) on the space of continuous functions \(\mc{C}(\mc{X})\) paired with a dense domain \(\mc{D}(\IG{}) \subseteq \mc{C}(\mc{X})\) satisfying the following properties:

\begin{enumerate}
\item If \(f \in \mc{D}(\IG{})\), \(a \geq 0\) and \(g:= f - a\IG{} f\), then 

\[\inf_{x \in S} f(x) \geq \inf_{x \in S} g(x)\]

\noindent In particular, this implies that \(\|f\| \leq \|f - a\IG{} f\|\).

\item For all sufficiently small \(a > 0\), \(I - a\IG{}\) is surjective as a mapping from \(\mc{D}(\IG{})\) to \(\mc{C}(\mc{X})\).

\item \(1 \in \mc{D}(\IG{})\) and \(\IG{} 1 = 0\).
\end{enumerate}
\label{sec::Infin:Def::IG}
\end{defn}
\labe{sec::Infin:Def::IG}

\textbf{Source: }\cite[Definitions 2.1,2.7]{Lig85}

\purpose This is an abstract definition of the class of unbounded operators that can be infinitesimal generators. The more well-known definition of infinitesimal generators arises from the bijection between Feller Processes and infinitesimal generators (Proposition \ref{sec::Infin:Thm::Bij}).

\lin

\begin{thms}
There is a bijection between infinitesimal generators and Feller processes. Furthermore, the infinitesimal generator \(\IG{}\) can be obtained from the Feller process \(\mu\) by the following relation:

\begin{equation}
\mc{A}f(x) = \lim_{t\searrow 0} \frac{1}{t}\left(\mb{E}^\mu[f(X_t)|X_0=x] - f(x)\right)
\label{sec::Infin:eqn::FellerIG}
\end{equation}
\labe{sec::Infin:eqn::FellerIG}
\label{sec::Infin:Thm::Bij}
\end{thms}
\labe{sec::Infin:Thm::Bij}

\purpose This proves that infinitesimal generators characterize Feller processes.

\pfsum Apply \cite[Theorem 1.5,2.9]{Lig85}.

\lin

\begin{defn}
Let \(\IG{}\) be an infinitesimal generator. A dense subset \(\core\subset \core(\IG{})\) is called a core of \(\IG{}\) if \(\IG{}\) is the closure of the operator \(\IG{}|_\core\).
\label{sec::Infin:Def::core}
\end{defn}
\labe{sec::Infin:Def::core}

\textbf{Source: }\cite[Definition 2.11]{Lig85}

\purpose \(\core(\IG{})\) is extremely difficult to characterize in general. However, we can explicitly derive the core of the processes we are interested in.

\lin

\begin{thms}[Trotter-Kurtz]
Suppose \(\IG{n}\) and \(\IG{}\) are generators of Feller processes \(\mu_n\) and \(\mu\) respectively. If there is a core \(\core\) for \(\IG{}\) such that \(\core \subset \mc{D}(\IG{n})\) for all \(n\) and \(\IG{n} f \ra \IG{} f\) for all \(f \in \core\), then 

\[\exmu{\mu_n}{f(Z_t)|Z_0=\cdot} \ra \exmu{\mu}{f(Z_t)|Z_0=\cdot}\]

uniformly in \(t\) for all \(f \in \mc{C}(\mc{X})\).
\label{sec::Infin:Thm::TrotterKurtz}
\end{thms}
\labe{sec::Infin:Thm::TrotterKurtz}

\purpose This shows that convergence of infinitesimal generators implies convergence of the process in "a sense." This is used to prove Corollary \ref{sec::Infin:Cor::Convergence}, which tells us when convergence of infinitesimal generators gives us weak convergence of the corresponding Feller processes.

\pfsum Apply \cite[Theorem 2.12]{Lig85}

\lin

\begin{coro}
In addition to the conditions of Theorem \ref{sec::Infin:Thm::TrotterKurtz}, suppose that \(\{\mu_n\}\) are tight and that \((\mu_n)_0 \Rightarrow \mu_0\). Then \(\mu_n \Rightarrow \mu'\).
\label{sec::Infin:Cor::Convergence}
\end{coro}
\labe{sec::Infin:Cor::Convergence}

\purpose We use this theorem to prove that our exact local representation on the infinite graph is a good approximation on large finite graphs.

\pfsum Use the same methods as in the proof of \cite[Theorem 4.2]{Kur81} to show weak convergence of the finite dimensional distributions. Apply \cite[Theorem 13.1]{Bil99} to get weak convergence.

\begin{proof}
By \cite[Theorem 13.1]{Bil99} (tightness + weak convergence of the finite dimensional distributions implies weak convergence), it suffices to prove weak convergence of the finite-dimensional distributions of \(\mu'_n\). Let the initial conditions (i.e. restriction to time 0) of \(\mu'_n\) be denoted \(\nu'_n\) and let \(\nu'\) denote the initial condition of \(\mu'\). Let \(f\) be any continuous (and therefore bounded function since we are assuming \(S'\) is compact) function from \((S')^k\ra\mb{R}\). Since \(\mu'_n\) are Feller, \(\exmu{\mu'_n}{f(Z_t)|Z_0 = \cdot}\) is continuous for all \(t\). By the monotone class theorem, both the positive and negative parts of \(f\) can be approximated arbitrarily closely from below by functions of the form \(\sum_{i=1}^n f_i(z_1)g_i(z_2,\dots,z_k)\). By monotone convergence, we can assume without loss of generality that \(f(z_1,\dots,z_k) = f_1(z_1)f_2(z_2,\dots,z_k)\).

\ind By Theorem \ref{sec::Infin:Thm::TrotterKurtz}, \(\exmu{\mu'_n}{f(Z_t)|Z_0} \ra \exmu{\mu'}{f(Z_t)|Z_0}\). Then, by bounded convergence and convergence of the initial condition,

\[\exmu{\mu'_n}{f(Z_t)}  = \exmu{\nu'_n}{\exmu{\mu'_n}{f(Z_t)|Z_0}} \ra \exmu{\nu'_n}{\exmu{\mu'}{f(Z_t)|Z_0}} \ra \exmu{\nu'}{\exmu{\mu'}{f(Z_t)|Z_0}} = \exmu{\mu'}{f(Z_t)}\]

Thus all of the one-dimensional distributions converge. Assume that,

\[\exmu{\mu'_n}{g(Z_{t_1},\dots,Z_{t_{k-1}})|Z_0=z} \ra \exmu{\mu'}{g(Z_{t_1},\dots,Z_{t_{k-1}})|Z_0=z}\]

\noindent for any continuous function \(g\) and for any \(\{t_1,\dots,t_{k-1}\} \subset [0,T]\). Fix \(0\leq t_1 <t_2 <\cdots < t_k\leq T\). Let \(f\) be from \((S')^k \ra \mb{R}\). We can assume without loss of generality that \(f\) is non-negative (consider negative and positive parts separately).

\begin{align}
\exmu{\mu'_n}{f(Z_{0},Z_{t_2},\dots,Z_{t_k})|Z_0 = z}&= \exmu{\mu'_n}{f_1(Z_{0})f_2(Z_{t_2},\dots,Z_{t_{k}})|Z_0=z}\nonumber\\
&= f_1(z)\exmu{\mu'_n}{f_2(Z_{t_2},\dots,Z_{t_{k}})|Z_0=z}\nonumber\\
&\os{\te{Induction}}{\ra} f_1(z)\exmu{\mu'}{f_2(Z_{t_2},\dots,Z_{t_{k}})|Z_0=z}\nonumber\\
&= \exmu{\mu'}{f(Z_0,Z_{t_2},\dots,Z_{t_k})|Z_0=z}
\label{sec::Infin:eqn::zerocase}
\end{align}
\labe{sec::Infin:eqn::zerocase}

So,

\begin{align*}
\exmu{\mu'_n}{f(Z_0,Z_{t_2},\dots,Z_{t_k})} &= \exmu{\nu'_n}{\exmu{\mu'_n}{f(Z_0,Z_{t_2},\dots,Z_{t_k})|Z_0}}\\
&\ra \exmu{\nu'}{\exmu{\mu'}{f(Z_0,Z_{t_2},\dots,Z_{t_k})|Z_0}}\\
&= \exmu{\mu'}{f(Z_0,Z_{t_2},\dots,Z_{t_k})}
\end{align*}

then,

\begin{align*}
\exmu{\mu'_n}{f(Z_{t_1},\dots,Z_{t_k})|Z_0=z}&=\exmu{Z\sim\mu'_n}{\exmu{Y\sim \mu'_n}{f(Y_{t_1},\dots,Y_{t_k})|Y_{t_1}=Z_{t_1},Y_0=z}|Z_0=z}\\
&=\exmu{Z\sim\mu'_n}{\exmu{Y\sim \mu'_n}{f(Y_{0},\dots,Y_{t_k-t_1})|Y_{0}=Z_{t_1}}|Z_0=z}\\
&\os{\te{Eqn \eqref{sec::Infin:eqn::zerocase}}}{\ra} \exmu{Z\sim\mu'_n}{\exmu{Y\sim \mu'}{f(Y_{0},\dots,Y_{t_k-t_1})|Y_{0}=Z_{t_1}}|Z_0=z}\\
&\os{\te{Theorem \ref{sec::Infin:Thm::TrotterKurtz}}}{\ra} \exmu{Z\sim\mu'}{\exmu{Y\sim \mu'}{f(Y_{0},\dots,Y_{t_k-t_1})|Y_{0}=Z_{t_1}}|Z_0=z}\\
&=\exmu{\mu'}{f(Z_{t_1},\dots,Z_{t_k})|Z_0=z}
\end{align*}

\begin{align*}
\exmu{\mu'_n}{f(Z_{t_1},\dots,Z_{t_k})}&= \exmu{Y\sim Z_{t_1}}{\exmu{\mu'_n}{f(Z_{t_1},\dots,Z_{t_k})|Z_{t_1}=Y}}\\
&=\exmu{Y\sim \mu'_n|_{t_1}}{\exmu{\mu'_n}{f(Z_{0},Z_{t_2-t_1},\dots,Z_{t_k-t_1})|Z_0=Y}}\\
&\os{\te{Eqn \eqref{sec::Infin:eqn::zerocase}}}{\ra} \exmu{Y\sim \mu'_n|_{t_1}}{\exmu{\mu}{f(Z_{0},Z_{t_2-t_1},\dots,Z_{t_k-t_1})|Z_0=Y}}\\
&\os{\te{Theorem \ref{sec::Infin:Thm::TrotterKurtz}}}{\ra} \exmu{Y\sim \mu'|_{t_1}}{\exmu{\mu}{f(Z_{0},Z_{t_2-t_1},\dots,Z_{t_k-t_1})|Z_0=Y}}\\
&=\exmu{\mu'}{f(Z_{t_1},\dots,Z_{t_k})}
\end{align*}

It follows by induction that the finite-dimensional distributions of \(\mu'_n\) converge weakly. Note: this proof is similar to the proof of \cite[Theorem 4.2]{Kur81}, but with the details filled in.
\end{proof}

\lin 

\section{Point Processes}
\label{sec::Point}\labe{sec::Point}

\subsection{Properties of Point Processes}
\label{subsec::Prope:sec::Point}\labe{subsec::Prope:sec::Point}

\lin

\begin{defn}
Let \(\mc{X}\) be a Polish space. Let \(Y\) be a random non-negative integer valued measure on \(\mc{X}\) such that \(\sup_{x \in \mc{X}} Y(\{x\})\leq 1\) almost surely. Then \(Y\) is called a simple point process on \(\mc{X}\) and the random set \(E = \{x \in \mc{X}: Y(\{x\}) = 1\}\) is the set of events in \(\mc{X}\). In the case where \(\mc{X} \subseteq [0,\infty)\), we use the notation \(Y_t := Y([0,t])\). We also use the notation \(E = \{\tau_i\}_{i=1}^{\infty}\) where \(\tau_i < \tau_{i+1}\) almost surely for all \(i\). We will use \(E = \{t_i\}\) to denote a sample from \(\{\tau_i\}\).
\label{subsec::Prope:Def::SPP}
\end{defn}
\labe{subsec::Prope:Def::SPP}

\textbf{Source: }\cite[Definition 9.1.II]{DalVer08}

\purpose Used to define Marked point processes.

\lin

\begin{defn}
Let \(\mc{K}\) be a Polish space. Let \(Y\) be a simple point process on \([0,\infty)\times \mc{K}\). Define \(Y_g\) by \(Y_g(A) = Y(A\times \mc{K})\) for all \(A \in \ms{B}([0,\infty))\). If \(Y_g\) is a simple point process on \([0,\infty)\), then \(Y\) is a simple marked point process on \([0,\infty)\times \mc{K}\). If \((t,k) \in E\), then we call \(t\) an event of \(Y\) and \(k\) is the corresponding mark. We will generally write \(E = \{(\tau_i,\kappa_i)\}_{i=1}^{\infty}\) where \(\tau_i < \tau_{i+1}\) almost surely for all \(i\). Sample events are written as \(E = \{(t_i,k_i)\}\). 
\label{subsec::Prope:Def::MPP}
\end{defn}
\labe{subsec::Prope:Def::MPP}

\textbf{Source: }\cite[Definition 6.4.I]{DalVer03}.

\purpose Jump Markov processes can be characterized by marked point processes. This allows us to apply point process theory to processes that satisfy Assumption \ref{subsec::Assum:Assu::Local}.

\lin

\begin{defn}
A marked point process \(Y\) is called non-explosive if \(\ex{(Y_g)_T} < \infty\). (Based on boundedly finite measures \cite[Definition 9.1.I]{DalVer08}.
\label{subsec::Prope:Def::non-explosive}
\end{defn}
\labe{subsec::Prope:Def::non-explosive}

\textbf{Source: } Called boundedly finite measures in \cite[Definition 9.1.I]{DalVer08}.

\purpose This is an assumption used in several theorems in \cite{DalVer03} and \cite{DalVer08}.

\lin

\begin{defn}
A non-explosive simple point process \(Y\) on \([0,\infty)\) adapted to some filtration \(\{\mc{F}_t\}\) is said to have intensity \(\lambda_t\) if \(\lambda_t\) is \(\mc{F}_t\)-predictable and \(Y_{t\wedge \tau_n} - \int_0^{t\wedge \tau_n} \lambda_s\,ds\) is a Martingale for all \(n\) where \(\tau_n = \sup\{t \in \mb{R}_+: Y_t < n\}\). 
\label{subsec::Prope:Def::SI defn}
\end{defn}
\labe{subsec::Prope:Def::SI defn}

\textbf{Source: } \cite[Definitions 14.3.I,14.1.I]{DalVer08}

\purpose See Definition \ref{subsec::Prope:Def::MI defn}.

\lin

\begin{defn}
Let \(Y\) be a non-explosive marked point process on the Polish space \([0,\infty)\times \mc{K}\) adapted to some filtration \(\mc{F}_t\). Let \(\ell\) be some fixed non-negative measure on \(\mc{K}\) which we will call the reference measure on \(\mc{K}\). Then \(Y\) is said to have \(\mc{F}_t\)-predictable intensity \(\lambda(t,k)\) if for all \(K \in \ms{B}(\mc{K})\), \(\int_K \lambda(t,k)\ell(dk)\) is the \(\mc{F}_t\)-predictable intensity of \(Y([0,t]\times K)\). 
\label{subsec::Prope:Def::MI defn}
\end{defn}
\labe{subsec::Prope:Def::MI defn}

\textbf{Source: }\cite[Definition 14.3.I]{DalVer08}

\purpose Section \ref{subsec::ProofU:sec::Proof2} makes heavy use of relative likelihoods of Marked point processes which can be written in terms of the intensity of the process.

\lin

\begin{prop}
Suppose \(Y\) is a \(\mc{F}\)-adapted non-explosive marked point process on \([0,\infty)\times \mc{K}\) with \(\mc{F}\)-predictable intensity \(\lambda\). Suppose \(\mc{F}_t\) can be expressed in the form \(\mc{F}_t = \mc{F}_0\wedge \mc{H}_t\) where \(\mc{H}_t\) is the natural history of \(Y\) and \(\mc{F}_0 = \sigma(X_0)\) for some random variable \(X_0\). Let \(E = \{(\tau_n,\kappa_n)\}\) be the sequence of events of \(Y\) increasing in \(\tau\). Then \(\lambda\) uniquely characterizes \(Y\).
\label{subsec::Prope:Prop::intense char}
\end{prop}
\labe{subsec::Prope:Prop::intense char}

\purpose This means that for non-explosive point processes, it is enough to know the intensity. This is why the statement of Proposition \ref{subsec::Prope:Prop::radnikder} is meaningful.

\pfsum Apply \cite[Propositions 14.3.II(b),14.2.IV(c) and 9.2.III]{DalVer08}. There is one extra technical condition that we have to proof holds which we can show using \cite[Proposition A1.5.III]{DalVer03}.

\begin{proof}
Assume that \(\law((\tau_n,\kappa_n)|\mc{F}_{\tau_{n-1}})\) is a regular distribution for all \(n\). Then uniqueness of the intensity is given by \cite[Proposition 14.3.II (b)]{DalVer08}. By \cite[Proposition 14.2.IV (c)]{DalVer08}, the compensator of \(Y\) uniquely defines the finite dimensional distributions of \(Y\), which uniquely define \(Y\) in distribution \cite[Proposition 9.2.III]{DalVer08}. However, the intensity of \(Y\) uniquely defines its compensator, so all that remains is to prove that the regular conditional distribution above exists.

\ind Fix \(n\). Suppose \(Z\) is a \(\mc{X}\)-valued random variable. Let \(\mu\) be the law of \(Y\). Then \(\left([0,\infty)\times \mc{K}\right)^{n-1}\times\mc{X}\) and \([0,\infty)\times \mc{K}\) are both Polish spaces, and \(\tilde{\mu}\) defined by 

\[\tilde{\mu}((t_n,k_n),(t_i,k_i)_{i=1}^{n-1},z) = \mu\left((\tau_i,\kappa_i) = (t_i,k_i)\te{ for } i=1,\dots,n, Z = z\right)\]

is a Borel measure. Therefore, by \cite[Proposition A1.5.III]{DalVer03}, the regular conditional distribution \(\ms{L}((\tau_n,\kappa_n)|\mc{F}'_{\tau_{n-1}})\) exists.
\end{proof}


\lin

\begin{lem}
Suppose \(Y\) is a marked process with \(\mc{F}'_t\)-predictable ground intensity \(\lambda_t\) bounded by some \(B < \infty\). Assume \(Y\) has marks in \(K\) and \(\lambda\) is defined with respect to the reference measure \(\ell\) on \(K\). Then for all \(K \in \ms{B}(\mc{K})\), \(Y([0,t]\times K) - \int_0^t\int_K \lambda(s,\kappa)\,\ell(d\kappa)\,ds\) is a Martingale.
\label{Subsec::Prope:Lem::easier}
\end{lem}
\labe{Subsec::Prope:Lem::easier}

\begin{proof}
Fix some \(K \in \ms{B}(\mc{K})\). Let \(\lambda_K(t) = \lambda(t,K)\). Let \(Y_K(\cdot) = Y(\cdot\times K)\). Then \(\lambda_K(t) \leq \lambda(t,\mc{K}) \leq B\). Therefore \(Y_K\) is a simple point process with bounded intensity. Reduce to the case of a simple point process (\(\mc{K} = \{0\}, K = \mc{K}, Y = Y_K,\lambda(t) = \lambda_K(t)\)).

Let \(M(t) = Y(t) - \int_0^t \lambda(s)\,ds\). Let \(\tau_n\) be as in definition \ref{subsec::Prope:Def::SI defn}. Notice for all \(n\),

\[|M(t\wedge \tau_n)| \leq \max\{Y(t\wedge \tau_n),tB\}\leq \max\{Y(t),tB\}\]

So \(M(t\wedge\tau_n)\) is dominated by \(\max\{Y(t),tB\}\), and \(\ex{\max\{Y(t),tB\}} \leq \ex{Y(t) + tB} \leq 2tB < \infty\). By dominated convergence,

\[\ex{M(t)|\mc{F}'_s} = \ex{\lim_{n\ra\infty} M(t\wedge \tau_n)\middle|\mc{F}'_s} = \lim_{n\ra\infty}\ex{M(t\wedge \tau_n)|\mc{F}'_s} = \lim_{n\ra\infty} M(s\wedge \tau_n) = M(s)\]
\end{proof}

\lin

\begin{lem}
Let \(Y\) be a marked point process with bounded \(\mc{F}'_t\)-predictable ground intensity \(\lambda_g\leq B\). Suppose that for any \(K \subseteq \mc{K}\), \(\lambda(t,K)\) is almost surely left-continuous. Then for any \(K \subseteq \mc{K}\),

\[\lambda(t,K) = \lim_{s\searrow 0}\frac{1}{s}\ex{Y((t,t+s]\times K)|\mc{F}'_{t-}}\]

\tb{There is a slight subtlety here. We need to know that the intensity exists and that it is left-continuous and uniformly bounded for this lemma to hold. Otherwise, this can fail in a number of ways. Proving existence of the intensity is fine, but left-continuity can be tedious.}

\label{Subsec::Prope:Lem::easy intense calc}
\end{lem}
\labe{Subsec::Prope:Lem::easy intense calc}

\begin{proof}
By Lemma \ref{Subsec::Prope:Lem::easier}, we can use the Martingale definition of intensity.

\begin{align*}
\lim_{s\searrow 0}\frac{1}{s}\ex{Y((t,t+s]\times K)|\mc{F}'_{t-}}& = \lim_{s\searrow 0}\frac{1}{s}\ex{\ex{Y((t,t+s]\times K)|\mc{F}'_t}\middle|\mc{F}'_{t-}}\\
&= \lim_{s\searrow 0}\frac{1}{s}\ex{\ex{\int_t^{t+s} \lambda(r,K)\,dr\middle|\mc{F}'_t}\middle|\mc{F}'_{t-}}\\
&= \ex{\ex{\lim_{s \searrow 0} \frac{1}{s}\int_t^{t+s} \lambda(r,K)\,dr\middle|\mc{F}'_t}\middle|\mc{F}'_{t-}}\\
&=\ex{\ex{\lambda(t+,K)|\mc{F}'_t}\middle|\mc{F}'_{t-}}\\
&=\lambda(t,K)
\end{align*}

We were able to move the limit inside the expectation by bounded convergence. Then we apply Lebesgue differentiation getting a right-continuous modification by virtue of the integral chosen in the prelimit.
\end{proof}

\lin

\tr{Commented out and unused proposition. Revisit later.}
%\begin{prop}
%Suppose \(\rp{}\) is a \(\F{}{}\)-adapted point process on \([0,\T)\times \spce\) with \(\F{}{}\)-predictable intensity \(\ratee{\t}:\spce \ra\mb{R}^+\) with respect to the reference probability measure \(\Sm\) on \(\spce\). Suppose there exists a constant \(\const{} < \infty\) such that \(\rate{}\) is bounded from above by \(\const{}\). Then for any interval \(I \subseteq [0,\T)\) and any measurable \(\typset \subseteq \spce\),
%
%\[\pr(\rp{}(I\times\typset) = 0) = \exp\left(-\ex{\int_I\int_\typset \ratee{\t}(\mark{})\,\Sm(d\mark{})\,d\t}\right).\]
%\label{subsec::Prope:Prop::voidprob}
%\end{prop}
%\labe{subsec::Prope:Prop::voidprob}
%
%\begin{proof}
%The proof is similar to the proof of \cite[Lemma 1]{BreMas96}. By Lemma \ref{Subsec::Prope:Lem::easier}, \(M(t) = \rp{}([0,\t]\times \typset) - \int_0^\t \int_{\typset} \ratee{\tt}(\mark{})\,\Sm{}(d\mark{})\,d\tt\) is a Martingale. Then,
%
%\[\ex{\rp{}(I\times\typset)} = \ex{\int_I\int_\typset \ratee{\t}(\mark{})\,\Sm(d\mark{})\,d\t} \os{\te{Tonelli}}{=} \int_I\int_\typset \ex{\ratee{\t}(\mark{})}\,\Sm(d\mark{})\,d\t.\]
%
%Let \(\rp{\typset}(\t) \defeq \rp{}([0,\t]\times \typset)\). Since \(\ratee{}\) is bounded, we can assume without loss of generality that \(I = (a,b]\) for some \(0 \leq a < b < \T\). Then,
%
%\[\mb{I}_{\rp{}{(a,b]\times \typset} = 0} = 1 - \int_{(a,b]} \mb{I}_{\rp{}((a,\t)\times \typset) = 0}\,\rp{\typset}(d\t).\]
%
%
%Taking an expectation,
%
%\[\pr\left(\rp{}(I\times\typset)=0\right) = 1 - \ex{\int_{(a,b]}\mb{I}_{\rp{}((a,\t)\times \typset) = 0}\,\rp{\typset}(d\t)}.\]
%
%\tr{for me: Since \(\mb{I}_{\rp{}((a,\t)\times \typset) = 0}\) is \(\F{}{\t}\)-predictable, we can replace the integral with respect to \(\rp{\typset}\) with an integral with density \(\ratee{}\). To prove this fact, it suffices to show it for elementary predictable functions and then extend to all predictable processes.}
%
%\ind Then,
%
%\begin{align*}
%\pr\left(\rp{}(I\times\typset)=0\right) &= 1 - \ex{\int_{(a,b]}\mb{I}_{\rp{}((a,\t)\times \typset) = 0}\int_\typset\ratee{\t}(\mark{})\,\Sm(d\mark{})\,d\t}\\
%& = 1 - \int_{I\times \typset} \pr\left(\rp{}((a,\t)\times\typset) = 0\right)\ex{\ratee{\t}(\mark{})|\rp{}((a,\t)\times\typset) = 0}\,\Sm(d\mark{})\,d\t.\\
%& = 1 - \int_{I\times \typset} \pr\left(\rp{}((a,\t]\times\typset) = 0\right)\ex{\ratee{\t}(\mark{})|\rp{}((a,\t)\times\typset) = 0}\,\Sm(d\mark{})\,d\t.
%\end{align*}
%
%Letting \(f(\t) = \pr(\rp{}((a,\t]\times \typset) = 0)\) and \(g(\t) = \int_A\ex{\ratee{\t}(\mark{})|\rp{}((a,\t)\times \typset) = 0}\Sm(d\mark{})\), this simplifies to
%
%\[f(\t) = 1 - \int_a^\t f(\tt)g(\tt)\,d\tt.\]
%
%This has the unique solution,
%
%\[f(\t) = \exp\left(-\int_a^\t g(\tt)\,d\tt\right).\]
%
%That is,
%
%\[\pr\left(\rp{}(I\times\typset) = 0\right) = \exp\left(-\int_{I\times\typset} \ex{\ratee{\t}(\mark{})|\rp{}((a,\t)\times\typset) = 0}\,\Sm(d\mark{})\,d\t\right).\]
%
%\end{proof}


\lin

\begin{prop}
Let \(Y\) be a marked process adapted to the filtration \(\mc{F}_t := \mc{F}_0\wedge \mc{H}_t\) where \(\mc{H}\) is its natural filtration on the sample space \((\Omega,\mc{F})\). Let the events and marks of \(Y\) be given by \(\{(\tau_j,\kappa_j)\}\) such that \(\{\tau_j\}\) is an almost surely increasing sequence. For \(i \in \{1,2\}\), let \(\pr^i\) be probability measures on the probability space such that \(Y\) is non-explosive and simple with respect to both probability measures. Let \(\pr^i_t\) be the restriction of \(\pr^i\) to \(\mc{F}_t\). Suppose \(\mc{F}_0\) describes a random variable, \(X\), with law \(\nu^i\) under \(\pr^i\). If \(Y\) has a strictly positive \(\pr^1,\mc{F}\)-predictable intensity \(\lambda^1\), then \(\pr^2_t \ll \pr^1_t\) for all \(t \in [0,T]\) if and only if there exists a non-negative, \(\mc{F}\)-predictable process \(\mu\) such that \(Y\) admits the \(\mc{F}\)-intensity \(\lambda^2 = \mu\lambda^1\) under \(\pr^2\) and \(\nu^2 \ll \nu^1\). When this is satisfied, the likelihood ratio is the \(\pr^1\)-a.s. c\`adl\`ag process defined by 

\begin{equation}
L_t:= \frac{d\pr^2_t}{d\pr^1_t}(Y) = \frac{d\nu^2}{d\nu^1}\left(\prod_{0<\tau^i\leq t} \mu(\tau^i,\kappa^i)\right)\exp\left(-\int_{(0,t]\times \mc{K}}[\mu(t,\kappa) - 1]\lambda^1(t,\kappa)\,ds\,\ell(d\kappa)\right)
\label{subsec::Prope:eqn::Lnat}
\end{equation}
\labe{subsec::Prope:eqn::Lnat}
\label{subsec::Prope:Prop::radnikder}
\end{prop}
\labe{subsec::Prope:Prop::radnikder}

\purpose We can define a standard process by choosing some fixed intensity \(\lambda^1\) and use it to completely characterize Markov processes. In fact, a large portion of section \ref{subsec::ProofU:sec::Proof2} involves manipulations of such Radon-Nykodim derivatives to construct various processes.

\pfsum In the case where \(\mc{F}_0\) is trivial, we can directly apply \cite[Theorem 14.4.I]{DalVer08}. To extend, we define \(\pr^i\) as an integral of a class of regular conditional probabilities and apply \cite[Theorem 14.4.I]{DalVer08} accordingly.

\begin{proof}
Let \(f\) be a bounded, \(\mc{F}'_t\) measurable function to the real numbers. Let \(\mu(t,k;y,x)\) be the value \(\mu\) takes when \(Y[0,t)=y[0,t)\) and \(\{X=x\}\). Since \(\mu\) is \(\mc{F}'\)-predictable, this is deterministic for any \(y,x\).

\[\mb{E}^2[f(X,Y[0,t])] = \int_\mc{X} \mb{E}^2[f(x,Y[0,t])|X=x]\,d\nu^2(x)\]

Note that for any fixed \(x \in \te{supp}(X)\) and any \(i \in \{1,2\}\), there exists a regular conditional distribution \(\pr^i_x\) which describes the law of \(Y\) conditioned on \(X = x\).

\[\mb{E}^2[f(X,Y[0,t])] = \int_\mc{X} \mb{E}^2_x[f(x,Y[0,t])]\,d\nu^2(x)\]

Note that for any fixed \(x\), \(\pr^i_x\) and \(Y\) satisfy the conditions of \cite[Theorem 14.4.I]{DalVer08}. So,

\[L_t(Y,x):=\frac{d\pr^2_{t,x}}{d\pr^1_{t,x}}(Y) = \left(\prod_{0<\tau^i\leq t} \mu(\tau^i,\kappa^i;Y,x)\right)\exp\left(-\int_{(0,t]\times\mc{K}} [\mu(s,k;Y,x) - 1]\lambda^1(s,k;Y,x)\,ds\,\ell(dk)\right)\]

Giving us,

\begin{align*}
\mb{E}^2\left[f(X,Y[0,t])\right] &= \int_\mc{X} \mb{E}^2_x[f(x,Y[0,t])]\,d\nu^2(x)\\
&=\int_{\mc{X}} \mb{E}^1_x[f(x,Y[0,t])L_t(Y,x)]\,d\nu^2(x)\\
&= \int_{\mc{X}} \frac{d\nu^2}{d\nu^1}(x) \mb{E}^1_x[f(x,Y[0,t])L_t(Y,x)]\,d\nu^1(x)\\
&= \mb{E}^1\left[f(X,Y[0,t])L_t(Y,X)\frac{d\nu^2}{d\nu^1}\right]
\end{align*}
\end{proof}

\lin

\subsection{Some Results on History-Dependent Poisson SDEs}
\label{subsec::Some:sec::Point}\labe{subsec::Some:sec::Point}

\lin

\begin{lem}
Let \(\G = (\V,\E)\) be a finite graph and let \(0 < \const{}< \infty\). Let \(\X{}{0}\) be an \(\S^\V\)-valued random variable. Let \(\Sm\) be a probability measure over \(\S\) with positive weight on all elements in \(S\setminus\{0\}\) and 0 weight on \(\{0\}\). Let \(\{\ratee{\t,\v}\}_{\v \in \V,\t\in [0,\T]}\) be a set of measurable mappings from \(\Omega{\V}{\t-} \times \S\) to \([0,\const{}]\) such that if \(h \in \Omega{\V}{\t-}\), then \(\t\mapsto \ratee{\t,\v}(h[0,\t),\s)\) is left-continuous for all \(\v \in \V\) and \(\s \in \S\). Let \(\{\poiss{\v}\}_{\v \in \V}\) be i.i.d. Poisson processes on \(\mb{R}^+\times \S\times\mb{R}^+\) with intensity measure \(\leb\otimes\Sm\otimes\leb\) where \(\leb\) is the Lebesgue measure on \(\mb{R}\).

\ind Then given any \(\S^\V\)-valued random variable, \(\X{}{0}\), the following SDE has a unique strong solution:

\begin{equation}
\X{\v}{\t} = \X{0}{\v} + \int_{(0,\t]}\int_\S\int_{(0,\ratee{\tt,\v}(\X{}{[0,\tt)},\s)]}  \s\,\poiss{\v}(d\r,d\s,d\tt)
\label{subsec::Some:eqn::genfiniteSDE}
\end{equation}
\labe{subsec::Some:eqn::genfiniteSDE}
\label{subsec::Some:Lem::genfiniteSDE}
\end{lem}
\labe{subsec::Some:Lem::genfiniteSDE}

\purpose The local representation is given by a fixed point SDE of this form. We will create several processes that solve similar equations and we need them to be well-posed.

\pfsum Direct construction.

\begin{proof}
Since \(\ratee{\tt,\v} \leq \const{}\), we can view \(\{\poiss{\v}:\v\in\V\}\) as a sequence of Poisson random measures on \([0,\T)\times \S\times [0,\const{}]\). Notice that,

\[\ex{\sum_{\v\in\V}\poiss{\v}([0,\T)\times\S\times[0,\const{}])} = \const{}\T|\V|.\]

Thus, \(\sum_{\v\in\V}\poiss{\v}\) is an almost surely finite measure on \([0,\T)\times \S\times [0,\const{}]\). Let \(\{(\rt{\it},\mark{\it},\r^\it,\v^\it):\it = 0,\dots,\numb, \numb\in \mb{N}\}\) be the set of events of \(\sum_{\v\in\V}\) in \([0,\T)\times\S\times [0,\const{})\times \V\) ordered so that \(0=\rt{0} < \rt{1} < \cdots < \rt{\numb} < \T\). In each event, \(\rt{\it} \in [0,\T)\), \(\mark{\it}\in \S\setminus\{0\}, \r^\it \in [0,\const{}]\) and \(\v^\it \in \V\) denotes which process went off.

\ind Let \(\X{}{}\) be the c\`adl\`ag process constructed below:

\begin{enumerate}
\item \(\X{}{0}\) is given as in the statement of the Lemma.

\item \(\X{}{\t} = \X{}{0}\) on \([0,\rt{1})\).

\item 

\[\X{}{\rt{1}} = \begin{cases}
\X{}{0} + \mark{1}\ev{\v^1} &\te{ if } \r^1 \leq \ratee{\rt{1},\v^1}(\X{}{[0,\rt{1})},\mark{1})\\
\X{}{0} &\te{ otherwise.}
\end{cases}
\] 

\item Continue on. In general, \(\X{}{\t} = \X{}{\rt{\it-1}}\) on \(\t \in [\rt{\it-1},\rt{\it})\) for \(\it= 1,\dots,\numb\).

\item 

\[\X{}{\rt{\it}} = \begin{cases}
\X{}{\rt{\it-1}} + \mark{\it}\ev{\v^\it} &\te{ if } \r^\it \leq \ratee{\rt{\it},\v^\it}(\X{}{[0,\rt{\it})},\mark{\it})\\
\X{}{\rt{\it-1}} &\te{ otherwise.}
\end{cases}\]

\item Then \(\X{}{\t} = \X{}{\rt{\numb}}\) for \(\t\in [\rt{\numb},\T)\).
\end{enumerate}

\(\X{}{}\) solves equation \eqref{subsec::Some:eqn::genfiniteSDE} by construction. Furthermore, if \(\rxvtts{}{}\) also solves \eqref{subsec::Some:eqn::genfiniteSDE}, then 

\begin{enumerate}
\item \(\rxvtt{}{0} = \X{}{0}\) by assumption.

\item \(\rxvtt{}{\t} = \rxvtt{}{0} = \X{}{0} = \X{}{\t}\) for all \(\t\in [0,\rt{1})\).

\item 

\begin{align*}
\rxvtt{}{\rt{1}} &= \begin{cases}
\rxvtt{}{0} + \mark{1}\ev{\v^1} &\te{ if } \r^1 \leq \ratee{\rt{1},\v^1}(\rxvtts{}{[0,\rt{1})},\mark{1})\\
\rxvtt{}{0} &\te{ otherwise.}
\end{cases}\\
&= \begin{cases}
\X{}{0} + \mark{1}\ev{\v^1} &\te{ if } \r^1 \leq \ratee{\rt{1},\v^1}(\X{}{[0,\rt{1})},\mark{1})\\
\X{}{0} &\te{ otherwise.}
\end{cases}\\
&= \X{}{\rt{1}}.
\end{align*}

\item Inductive hypothesis: \(\rxvtt{}{\t} = \X{}{\t}\) for \(\t\in [0,\rt{\it})\). 

\item 

\begin{align*}
\rxvtt{}{\rt{\it}} &= \begin{cases}
\rxvtt{}{\rt{\it-1}} + \mark{\it}\ev{\v^\it} &\te{ if } \r^\it \leq \ratee{\rt{\it},\v^\it}(\rxvtts{}{[0,\rt{\it})},\mark{\it})\\
\rxvtt{}{\rt{\it-1}} &\te{ otherwise.}
\end{cases}\\
&= \begin{cases}
\X{}{\rt{\it-1}} + \mark{\it}\ev{\v^\it} &\te{ if } \r^\it \leq \ratee{\rt{\it},\v^\it}(\X{}{[0,\rt{\it})},\mark{\it})\\
\X{}{\rt{\it-1}} &\te{ otherwise.}
\end{cases}\\
&= \X{}{\rt{\it}}.
\end{align*}

\item Then \(\rxvtt{}{\t} = \rxvtt{}{\rt{\it}} = \X{}{\rt{\it}} = \X{}{\t}\) for \(\t \in [\rt{\it},\rt{\it+1})\). Then, \(\rxvtt{}{\t} = \X{}{\t}\) for \(\t\in [0,\rt{\it+1})\).

\item Finally, \(\rxvtt{}{\t} = \rxvtt{}{\rt{\numb}} = \X{}{\rt{\numb}} = \X{}{\t}\) for \(\t\in [\rt{\numb},\T)\), so \(\rxvtts{}{} = \X{}{}\) almost surely.
\end{enumerate}
\end{proof}

\lin

\begin{lem}
Suppose that \(\V\) is finite. Recall that \(\pmap{}\) maps c\`adl\`ag processes to marked point processes (see definition \ref{subsec::ProofE:Defn::pmap}). Suppose \(\rp{} = \pmap{}(\rxvtts{}{})\) for some \(\Omega{\V}{\T-}\)-valued stochastic process, \(\rxvtts{}{}\). Suppose also that \(\rp{}\) has \(\rxvtts{}{}\)-predictable, left-continuous \tr{(If we can remove the left-continuous assumption in Lemma \ref{subsec::Some:Lem::genfiniteSDE}, then this becomes unnecessary.)} intensity \(\ratee{\t}(\cdot)\) bounded from above by \(\const{}\). Suppose there exist mappings \(\{\ratee{\t,\v}:\Omega{}{\t-}\times \S \ra [0,\const{}]\}_{\t\in[0,\T),\v\in \V}\) such that 

\begin{equation}
\ratee{\t}(\sv{}{\V}) := \begin{cases}
\ratee{\t,\v}(\rxvtts{}{[0,\t)},\s) &\te{ if } \sv{}{\V} = \s\ev{\v}\\
0 &\te{ otherwise,}
\end{cases}
\label{subsec::Some:eqn::intense}
\end{equation}
\labe{subsec::Some:eqn::intense}

and such that \(\t\mapsto \ratee{\t,\v}(\rxvtts{}{[0,\t)},\sv{}{\V})\) is almost-surely left continuous on \([0,\T)\) for all \(\v\in \V,\sv{}{\V}\in \S^\V\). Then there is a unique solution, \(\X{}{}\), to equation \eqref{subsec::Some:eqn::genfiniteSDE}, and if \(\X{}{0} \deq \rxvtt{}{0}\), then \(\X{}{} \deq \rxvtts{}{}\).

\label{subsec::Some:Lem::PPtoSDE}
\end{lem}
\labe{subsec::Some:Lem::PPtoSDE}

\begin{proof}

We can assume without loss of generality that \(\ratee{\t,\v}(\xvtts{}{[0,\t)},\s) = 0\) for all \(\xvtts{}{[0,\t)}\in \Omega{}{\t-}\) such that \(\pr(\rxvtts{}{[0,\t)} = \xvtts{}{[0,\t)}) = 0\). Then since \(\ratee{\t}(\cdot)\) is almost surely left-continuous, we can conclude that \(\ratee{\t,\v}(\cdot,\s)\) is left-continuous with respect to \(\t\) given c\`adl\`ag inputs for all \(\v\in \V,\s\in\S\). By Lemma \ref{subsec::Some:Lem::genfiniteSDE}, the following equation has a unique solution:

\[\X{\v}{\t} = \X{0}{\v} + \int_{(0,\t]}\int_\S\int_{(0,\ratee{\tt,\v}(\X{}{[0,\tt)},\s)]}  \s\,\poiss{\v}(d\r,d\s,d\tt).\]

By \cite[Exercise 14.7.1]{DalVer08}, \(\pmap{\v}(\X{}{})\) has \(\X{}{}\)-predictable intensity \(\ratee{\t,\v}(\X{}{[0,\t)},\s)\) for \(\s \in \S\). Then \(\alt{\rp{}} \defeq \pmap{}(\X{}{})\) has \(\X{}{}\)-predictable intensity,

\[\ratee{\t}(\X{}{[0,\t)},\sv{}{\V}) = \begin{cases}
\ratee{\t,\v}(\X{}{[0,\t)},\sv{}{\V}) &\te{ if } \sv{}{\V} = \s\ev{\v}\\
0&\te{ otherwise.}
\end{cases}\]

By assumption, \(\X{}{0} \deq \rxvtt{}{0}\). Thus, \(\rp{}\) and \(\alt{\rp{}}\) have the same intensity. By Proposition \ref{subsec::Prope:Prop::intense char}, \(\rp{} \deq \alt{\rp{}}\).
\end{proof}
\lin

\begin{lem}
Assume the notation and assumptions from Lemmas \ref{subsec::Some:Lem::genfiniteSDE} and \ref{subsec::Some:Lem::PPtoSDE} hold under the probability measure \(\m{}{}{}\). Suppose under \(\mm{}{}{}\), \(\X{}{}\) solves,

\[\X{\v}{\t} = \X{\v}{0} +\int_{(0,\t]}\int_\S\int_{(0,1]} \s \poiss{\v}(d\r,d\s,d\tt),\]

where \(\{\X{\v}{0}\}_{\v \in \V}\) are i.i.d uniformly distributed over \(\S\). Let \(\rp{} \defeq \pmap{}(\X{}{}) = \{(\rt{\it},\mark{\it}):\it\in \mb{N}\}\).

\ind Let \(\ov{\ell}\) be the extension of \(\Sm\) to \(\alt{\S} = \{\s\ev{\v}: \s \in \S, \v \in \V\}\) given by \(\alt{\Sm}(\typset\ev{\v}) = \Sm(\typset)\) for any \(\typset \subseteq \S\). Then,

\begin{equation}
\frac{d\m{}{\t}{}}{d\mm{}{\t}{}}= \frac{d\m{}{0}{}}{d\mm{}{0}{}}\left(\prod_{0< \rt{\it}\leq t} \ratee{\t}(\mark{\it})\right)\exp\left(-\int_{(0,\t]\times \S} (\ratee{\tt}(\s) - 1)\,d\tt\alt{\Sm}(d\s)\right)
\label{subsec::Some:eqn::radnik}
\end{equation}
\labe{subsec::Some:eqn::radnik}
\label{subsec::Some:Lem::radnik}
\end{lem}
\labe{subsec::Some:Lem::radnik}

\purpose This lemma combined with Lemma \ref{subsec::Some:Lem::genfiniteSDE} allow us to freely alternate between SDE and density formulations of finite node Markov processes.

\pfsum The key is to express \(X\) in terms of a Marked point process. Then we can compute the intensities of the point process under \(\mu\) and \(\nu\) respectively and apply Proposition \ref{subsec::Prope:Prop::radnikder}.

\begin{proof}
Notice that \(\X{}{} \mapsto (\X{}{0},\pmap{\X{}{}})\) is a one-to-one mapping from c\`adl\`ag processes on \(\S^\V\) to marked point processes with marks in \(\alt{\S}\). Thus, we can consider \(\rp{}\) a marked point process with marks in \(\alt{\S}\). In both cases, \(\rp{}\) is \(\F{}{\t}\)-adapted, where \(\F{}{\t} = \F{}{0}\vee \FH{}{\t}\) and \(\FH{}{\t}\) is the natural filtration of \(\rp{}\).

\ind By Lemma \ref{subsec::Some:Lem::PPtoSDE}, \(\rp{}\) has predictable intensity \(\ratee{\t}(\cdot)\) with respect to \(\F{}{\t}\) and \(\m{}{}{}\). \(\rp{}\) has predictable intensity 1 with respect to \(\F{}{\t}\) and \(\mm{}{}{}\). This holds all of the information about the original process \(\X{}{}\), so we can consider \(\frac{d\m{}{\t}{}}{d\mm{}{\t}{}}\) as a change of measure affecting \(\rp{}\) instead of \(\X{}{}\). In Lemma \ref{subsec::Some:Lem::genfiniteSDE}, it was assumed that \(\ratee{\t,\v}\) is bounded. Thus, the result follows directly from Proposition \ref{subsec::Prope:Prop::radnikder}. 
\end{proof}

\lin
\section{Other Technical Lemmas}
\label{sec::TL}\labe{sec::TL}

\begin{lem}
Assume \(X,Y\) and \(Z\) are random elements such that \(X\perp Y|Z\). Assume also that \(\pr(X=0) = \pr(Y=0) = \pr(Z=0) = 0\).

\begin{enumerate}[(a)]
\item If \(\phi,\psi\) are measurable functions and \(\theta\) is a 1-to-1 function, then \(\phi(X)\perp \psi(Y)|\theta(Z)\).

\item If \(T\perp(X,Y,Z)\), then \(X\perp Y|(Z,T)\), \((X,T)\perp Y|Z\) and \(X\perp (Y,T)|Z\).

\item If \(T\perp (X,Y,Z)\) and \(\phi\) is a measurable function, then

\[X\perp Y|(Z,\phi(X,Z,T))\]

\item If \(A\) is \(\sigma(Z)\) measurable, then 

\[X\mb{I}_A\perp Y\mb{I}_A|Z\mb{I}_A\]

\item If \(U\perp V\) and \((U,V)\perp(X,Y,Z)\), then 

\[(X,Z,U)\perp (Y,Z,V)|Z\]

\item Suppose \(X\mb{I}_{A_i}\perp Y\mb{I}_{A_i}|Z\mb{I}_{A_i}\) for all \(i\in I\) where \(I\) is a finite or countably infinite set and \(\{A_i\}\) is a family of disjoint sets. Then,

\[X\mb{I}_{\cup_i A_i}\perp Y\mb{I}_{\cup_i A_i}|Z\mb{I}_{\cup_i A_i}\]

\item Let \(A\) be any event such that \(\pr(A) > 0\). Suppose \(U\mb{I}_A\perp \mb{I}_A(X,Y,Z)|\mb{I}_A\). Suppose also that \(X\mb{I}_A\perp Y\mb{I}_A|\mb{I}_A(Z,U)\), but do not necessarily assume \(X\perp Y|Z\). Then 

\[X\mb{I}_A\perp Y\mb{I}_A|Z\mb{I}_A\]

\item If \(A\) is an event that happens with probability 1, and \(X\mb{I}_A \perp Y\mb{I}_A |Z\mb{I}_A\), then 

\[X\perp Y |Z\]
\end{enumerate}
\label{sec::TL:Lem::Props}
\end{lem}
\labe{sec::TL:Lem::Props}

\begin{proof}
For all parts of this lemma, I use the following two results:

\begin{itemize}
\item \(X\perp Y|Z\) if and only if

\[\ex{\ex{f(X)|Z}g(Y)h(Z)} = \ex{f(X)g(Y)h(Z)}\]

for all bounded non-negative measurable functions \(f,g\) and \(h\).

\item Any bounded non-negative measurable function in two variables \(f(x,y)\) can be approximated by a sum of a product of two bounded non-negative measurable functions in one variable:

\[f(x,y) = \sum_{k=1}^\infty f^k_1(x)f^k_2(y)\]

Within this lemma, I will assume without loss of generality that all functions of the form \(f(x,y)\) can be written as a product: \(f(x,y) = f_1(x)f_2(y)\).
\end{itemize}

\begin{enumerate}[(a)]
\item \(\tilde{f}(X):=f(\phi(X))\) and \(\tilde{g}(Y):=g(\psi(Y))\) are non-negative, bounded measurable functions, and \(\sigma(\theta(Z)) = \sigma(Z)\) because \(\theta\) is 1-to-1. Let \(\tilde{h}(Z):= h(\theta(Z))\). Then,

\begin{align*}
\ex{\ex{f(\phi(X))|\theta(Z)}g(\psi(Y))h(\theta(Z))} &= \ex{\ex{\tilde{f}(X)|Z}\tilde{g}(Y)\tilde{h}(Z)}\\
& = \ex{\tilde{f}(X)\tilde{g}(Y)\tilde{h}(X)}\\
& = \ex{f(\phi(X))g(\psi(Y))h(\theta(Z))}
\end{align*}

\item Since \(T\perp (X,Y,Z)\), notice that by the tower property,

\[\ex{\ex{f_1(X)f_2(Y)|Z}g(Z)h(T)} = \ex{f_1(X)f_2(Y)g(Z)}\ex{h(T)} = \ex{f_1(X)f_2(Y)g(Z)h(T)}\]

So \((X,Y)\perp T|Z\). In particular, that means that 

\[\ex{\ex{f(X)|Z,T}g(Y)h(Z,T)} = \ex{\ex{f(X)|Z}g(Y)h_1(Z)}\ex{h_2(T)} = \ex{f(X)g(Y)h(Z,T)}\]

which proves that \(X\perp Y|Z,T\).

\[\ex{\ex{f_1(X)f_2(T)|Z}g(Y)h(Z)} = \ex{f_2(T)}\ex{\ex{f_1(X)|Z}g(Y)h(Z)} = \ex{f(X,T)g(Y)h(Z)}\]

So \((X,T)\perp Y|Z\). Then \(X\perp (Y,T)|Z\) by symmetry.

\item By part (b), 

\[(X,T)\perp Y|Z.\]

By \cite[Lemma 2.10]{RamCur} \tr{See if this has changed}, 

\[(X,T)\perp Y|(Z,\phi(Z,X,T)).\]

By part (a),

\[X\perp Y|(Z,\phi(Z,X,T))\]

\item Notice that the event \(A^c\) is an atom in \(\sigma(Z\mb{I}_A)\). For any \(B \in \sigma(Z)\) such that \(B\subset A\), \(B \in \sigma(Z\mb{I}_A)\). Therefore, we can represent all sets \(C \in \sigma(Z\mb{I}_A)\) by \(C = B\) or \(C = B\sqcup A^c\) where \(\{B\subset A\}\te{ and } B \in \sigma(Z)\). Suppose \(C = B\sqcup A^c\). Then,

\begin{align*}
\ex{\ex{f(X\mb{I}_A)|Z\mb{I}_A}\mb{I}_C} &= \ex{f(X\mb{I}_A)\mb{I}_A}+\ex{f(X\mb{I}_A)\mb{I}_B} = \ex{f(0)\mb{I}_A} + \ex{\ex{f(X)|Z}\mb{I}_B}\\
\end{align*}

So we can write

\begin{equation}
\ex{f(X\mb{I}_A)|Z\mb{I}_A}(\omega) = \begin{cases}
\ex{f(X)|Z}(\omega) &\te{ if } \omega \in A\\
f(0) &\te{ otherwise}
\end{cases}
\label{sec::TL:eqn::disjoint CE}
\end{equation}
\labe{sec::TL:eqn::disjoint CE}

Then

\begin{align*}
\ex{\ex{f(X\mb{I}_A)|Z\mb{I}_A}g(Y\mb{I}_A)h(Z\mb{I}_A)} &= \ex{\mb{I}_A\ex{f(X)|Z}g(Y)h(Z)} + \ex{\mb{I}_{A^c}f(0)g(0)h(0)}\\
&=\ex{\mb{I}_Af(X)g(Y)h(Z)}+\ex{\mb{I}_{A^c}f(0)g(0)h(0)}\\
&= \ex{f(X\mb{I}_A)g(\mb{I}_A)h(\mb{I}_A)}
\end{align*}

which completes the proof.

\item We can show this directly:

\begin{align*}
\mb{E}\bigg[\ex{f_1(X)f_2(Z)f_3(U)|Z}g_1(Y)&g_2(Z)g_3(V)h(Z)\bigg]\\
&= \ex{f_3(U)g_3(V)}\ex{\ex{f_1(X)|Z}g_1(Y)(f_2(Z)g_2(Z)h(Z))}\\
&= \ex{f_3(U)g_3(V)}\ex{f_1(X)g_1(Y)f_2(Z)g_2(Z)h(Z)}\\
&= \ex{f(X,Z,U)g(Y,Z,V)h(Z)}
\end{align*}

\item First, if \(I\) is finite, then it suffices to prove conditional independence for \(I =\{1,2\}\). Notice that any set \(B \in \sigma(Z\mb{I}_{A_1\sqcup A_2})\) can be expressed as \(B = C\sqcup D\sqcup\{(A_1\sqcup A_2)^c\}\) or \(B = C\sqcup D\) where \(C\in \sigma(Z\mb{I}_{A_1})\), \(D \in \sigma(Z\mb{I}_{A_2})\), \(C \subseteq A_1\) and \(D \subseteq A_2\). Notice also that the unions defining \(B\) are disjoint unions. Let \(B = C\sqcup D\sqcup \{(A_1\sqcup A_2)^c\}\).

\begin{align*}
\mb{E}\bigg[\ex{f(X\mb{I}_{A_1\sqcup A_2})|Z\mb{I}_{A_1\sqcup A_2}}&\mb{I}_B\bigg]= \ex{f(X\mb{I}_{A_1\sqcup A_2})\mb{I}_B}\\
&= \ex{\mb{I}_Cf(X\mb{I}_{A_1\sqcup A_2})} + \ex{\mb{I}_Df(X\mb{I}_{A_1\sqcup A_2})} + \ex{\mb{I}_{(A_1\sqcup A_2)^c}f(X\mb{I}_{A_1\sqcup A_2})}\\
&= \ex{\mb{I}_C f(X\mb{I}_{A_1})} + \ex{\mb{I}_D f(X\mb{I}_{A_2})} + \ex{\mb{I}_{(A_1\sqcup A_2)^c}f(0)}\\
&= \ex{\mb{I}_{C}\ex{f(X\mb{I}_{A_1})|Z\mb{I}_{A_1}}} + \ex{\mb{I}_{D}\ex{f(X\mb{I}_{A_2})|Z\mb{I}_{A_2}}} + \ex{\mb{I}_{(A_1\sqcup A_2)^c}f(0)}
\end{align*}

In particular, we can write

\begin{equation}
\ex{f(X\mb{I}_{A_1\sqcup A_2})|Z\mb{I}_{A_1\sqcup A_2}} = \mb{I}_{A_1}\ex{f(X\mb{I}_{A_1})|Z\mb{I}_{A_1}} + \mb{I}_{A_2}\ex{f(X\mb{I}_{A_2})|Z\mb{I}_{A_2}} + \mb{I}_{(A_1\sqcup A_2)^c}f(0)
\label{sec::TL:eqn::disjoint sum CE}
\end{equation}
\labe{sec::TL:eqn::disjoint sum CE}

Then,

\begin{align*}
\mb{E}\bigg[\ex{f(X\mb{I}_{A_1\sqcup A_2})|Z\mb{I}_{A_1\sqcup A_2}}&g(Y\mb{I}_{A_1\sqcup A_2})h(Z\mb{I}_{A_1\sqcup A_2})\bigg]\\
&= \ex{\mb{I}_{A_1}\ex{f(X\mb{I}_{A_1})|Z\mb{I}_{A_1}}g(Y\mb{I}_{A_1})h(Z\mb{I}_{A_1})} +\\
&\hspace{1 cm} \ex{\mb{I}_{A_2}\ex{f(X\mb{I}_{A_2})|Z\mb{I}_{A_2}}g(Y\mb{I}_{A_2})h(Z\mb{I}_{A_2})} + \\
&\hspace{1 cm} \ex{\mb{I}_{(A_1\sqcup A_2)^c}f(0)g(0)h(0)}\\
&= \ex{\mb{I}_{A_1}f(X\mb{I}_{A_1})g(Y\mb{I}_{A_1})h(Z\mb{I}_{A_1})} + \ex{\mb{I}_{A_2}f(X\mb{I}_{A_2})g(Y\mb{I}_{A_2})h(Z\mb{I}_{A_2})} +\\
&\hspace{1 cm} \ex{\mb{I}_{(A_1\sqcup A_2)^c}f(0)g(0)h(0)}\\
&= \ex{f(X\mb{I}_{A_1\sqcup A_2})g(Y\mb{I}_{A_1\sqcup A_2})h(Z\mb{I}_{A_1\sqcup A_2})}
\end{align*}

Now suppose \(I\) is countably infinite. Without loss of generality, assume \(I = \mb{N}\). Furthermore, assume \(f(0) = g(0) = h(0) = 0\).

Then for any \(n \in \mb{N}\),

\[\ex{f(X\mb{I}_{\sqcup_{i=1}^n A_i})|Z\mb{I}_{\sqcup_{i=1}^n A_i}} = \sum_{i=1}^n \mb{I}_{A_i}\ex{f(X\mb{I}_{A_i})|Z\mb{I}_{A_i}} + \mb{I}_{\left(\sqcup_{i=1}^n A_i\right)^c} f(0)\]

Therefore,

\[\ex{f(X\mb{I}_{\sqcup_{i=1}^n A_i})|Z\mb{I}_{\sqcup_{i=1}^n A_i}} \nearrow \ex{f(X\mb{I}_{\sqcup_{i=1}^\infty A_i})|Z\mb{I}_{\sqcup_{i=1}^\infty A_i}} \te{ almost surely}\]

furthermore, 

\[(g(Y\mb{I}_{\sqcup_{i=1}^n A_i}),h(Z\mb{I}_{\sqcup_{i=1}^n A_i})) \nearrow (g(Y\mb{I}_{\sqcup_{i=1}^\infty A_i}),h(Z\mb{I}_{\sqcup_{i=1}^\infty  A_i})) \te{ almost surely}\]

By the monotone convergence theorem,

\begin{align*}
\lim_{n\ra\infty} \mb{E}\bigg[\ex{f(X\mb{I}_{\sqcup_{i=1}^n A_i})|Z\mb{I}_{\sqcup_{i=1}^n A_i}}&g(Y\mb{I}_{\sqcup_{i=1}^n A_i})h(Z\mb{I}_{\sqcup_{i=1}^n A_i})\bigg]\\
& = \ex{\ex{f(X\mb{I}_{\sqcup_{i=1}^\infty A_i})|Z\mb{I}_{\sqcup_{i=1}^\infty A_i}}g(Y\mb{I}_{\sqcup_{i=1}^\infty A_i})h(Z\mb{I}_{\sqcup_{i=1}^\infty A_i})}
\end{align*}

Similarly by monotone convergence,

\begin{align*}
\lim_{n\ra\infty} \mb{E}\bigg[f(X\mb{I}_{\sqcup_{i=1}^n A_i})&g(Y\mb{I}_{\sqcup_{i=1}^n A_i})h(Z\mb{I}_{\sqcup_{i=1}^n A_i})\bigg] = \ex{f(X\mb{I}_{\sqcup_{i=1}^\infty A_i})g(Y\mb{I}_{\sqcup_{i=1}^\infty A_i})h(Z\mb{I}_{\sqcup_{i=1}^\infty A_i})}
\end{align*}

So,

\begin{align*}
\mb{E}\bigg[\ex{f(X\mb{I}_{\sqcup_{i=1}^\infty A_i})|Z\mb{I}_{\sqcup_{i=1}^\infty A_i}}&g(Y\mb{I}_{\sqcup_{i=1}^\infty A_i})h(Z\mb{I}_{\sqcup_{i=1}^\infty A_i})\bigg]\\
&= \lim_{n\ra\infty} \ex{\ex{f(X\mb{I}_{\sqcup_{i=1}^n A_i})|Z\mb{I}_{\sqcup_{i=1}^n A_i}}g(Y\mb{I}_{\sqcup_{i=1}^n A_i})h(Z\mb{I}_{\sqcup_{i=1}^n A_i})}\\
&= \lim_{n\ra\infty} \ex{f(X\mb{I}_{\sqcup_{i=1}^n A_i})g(Y\mb{I}_{\sqcup_{i=1}^n A_i})h(Z\mb{I}_{\sqcup_{i=1}^n A_i})}\\
&= \ex{f(X\mb{I}_{\sqcup_{i=1}^\infty A_i})g(Y\mb{I}_{\sqcup_{i=1}^\infty A_i})h(Z\mb{I}_{\sqcup_{i=1}^\infty A_i})}
\end{align*}

By linearity, this also holds for all bounded and measurable \(f,g\) and \(h\) with no restrictions on \(f(0),g(0),h(0)\), so the proof is complete.

\item 

\begin{align*}
\mb{E}\bigg[\ex{f(X\mb{I}_A)| Z\mb{I}_A}g(\mb{I}_AZ)&h(\mb{I}_AU)\bigg] = \ex{\mb{I}_A\ex{f(X\mb{I}_A)|Z\mb{I}_A}g(Z\mb{I}_A)h(\mb{I}_A)} + f(0)g(0)h(0)\pr(A^c)\\
&=\frac{\ex{\mb{I}_A\ex{f(X\mb{I}_A)|Z\mb{I}_A}g(Z\mb{I}_A)}\ex{\mb{I}_Ah(U\mb{I}_A)}}{\pr(A)} + f(0)g(0)h(0)\pr(A^c)\\
&=\frac{\ex{\mb{I}_Af(X\mb{I}_A)g(Z\mb{I}_A)}\ex{\mb{I}_Ah(U\mb{I}_A)}}{\pr(A)} + f(0)g(0)h(0)\pr(A^c)\\
&=\ex{\mb{I}_Af(X\mb{I}_A)g(Z\mb{I}_A)h(U\mb{I}_A)} + f(0)g(0)h(0)\pr(A^c)\\
&= \ex{f(X\mb{I}_A)g(Z\mb{I}_A)h(U\mb{I}_A)}
\end{align*}

So \(\ex{f(X\mb{I}_A|Z\mb{I}_A} = \ex{f(X\mb{I}_A|Z\mb{I}_A,U\mb{I}_A}\). Then 

\begin{align*}
\ex{\ex{f(X\mb{I}_A)|Z\mb{I}_A}g(Y\mb{I}_A)h(Z\mb{I}_A)} &= \ex{\ex{f(X\mb{I}_A)|\mb{I}_A(Z,U)}g(Y\mb{I}_A)h(Z\mb{I}_A)}\\
&=\ex{f(X\mb{I}_A)g(Y\mb{I}_A)h(Z\mb{I}_A)}
\end{align*}

\item 
\begin{align*}
\ex{\ex{f(X)|Z}g(Y)h(Z)} &= \ex{\ex{f(X\mb{I}_A)|Z\mb{I}_A}g(Y\mb{I}_A)h(Z\mb{I}_A)}\\
&= \ex{f(X\mb{I}_A)g(Y\mb{I}_A)h(Z\mb{I}_A)} = \ex{f(X)g(Y)h(Z)}
\end{align*}
\end{enumerate}
\end{proof}

\lin

\begin{lem}
Let \(\phi: \mb{R}^+ \ra \mb{R}^+\) be a monotonic function such that \(\phi(0+) = 0\). Suppose also that \(\phi \leq C\) for some constant \(C\). Then for every \(\ep > 0\), there exists a continuous monotonic concave function \(\psi_\ep:\mb{R}^+\ra \mb{R}^+\) such that \(\psi_\ep(0) = \ep\) and \(\phi \leq \psi_\ep\leq C\). \tr{Take an infimum and I get a continuous monotonic concave function \(\psi\) such that \(\psi(0) = 0\)?}
\label{sec::TL:Lem::concbd}
\end{lem}
\labe{sec::TL:Lem::concbd}

\purpose This is used in Proposition \ref{subsec::Well-:Prop::SDE=IG} for a technical result.

\begin{proof}
Since \(\phi(0+) = 0\), there exists a \(\delta > 0\) such that \(\phi(\delta) < \ep/2\). Let \(\ov{\phi} = \min\{\phi+\ep/2, C\}\).

\ind Let \(a_1 = \inf\{a \geq 0: ax + \ep \geq \ov{\phi}_1(x)\te{ for all } x\geq 0\}\). Note that \(0\leq a \leq C/\delta\). 

Then \(\psi_\ep(x) = \min\{ax+\ep,C\}\) is continuous, concave and \(\psi_\ep \geq \phi\).
\end{proof}

\lin

\begin{defn}
Let \(\{t_i\}\) be denote a finite set of times \(0=t_0 <t_1 <\cdots < t_n=1\). Let \(X\in \cad([0,T],\mc{X})\) where \(\mc{X}\) is a separable and complete space with respect to the metric \(d\). Define,

\[\omega_X([t_{i-1},t_i)) = \sup_{s,t\in [t_{i-1},t_i)} d(X(t),X(s)).\]

Then for all \(\delta \in (0,T)\),

\[\omega_X'(\delta) = \inf_{\{t_i\}: \max_i |t_i - t_{i-1}| > \delta} \min_{i} \omega_X([t_{i-1},t_i))\]

is called the c\`adl\`ag modulus of continuity.
\label{sec::TL:Def::modulus}
\end{defn}
\labe{sec::TL:Def::modulus}

\purpose This modulus of continuity is useful for the c\`adl\`ag version of the Arzela-Ascoli Theorem.

\lin

\begin{thms}
Let \(\{\mu^i\}\subseteq \mc{P}\left(\cad([0,T],\mc{X})\right)\) where \(\mc{X}\) is a separable and complete normed space. Assume \(X^i\) is a random process with law \(\mu^i\) for each \(i\). Then \(\{\mu_i\}\) is tight if and only if:

\begin{enumerate}[(1)]
\item 

\[\lim_{a \ra \infty}\limsup_{n \ra\infty} \pr\left(\sup_{t \in [0,T]} |X^i_t| \geq a\right) = 0.\]

\item For all \(\ep > 0\),

\[\lim_{\delta \searrow 0}\limsup_{n\ra\infty} \pr\left(\omega'_{X^i}(\delta) \geq \ep\right) = 0.\]
\end{enumerate}
\label{sec::TL:Thm::Tight}
\end{thms}
\labe{sec::TL:Thm::Tight}

\begin{proof}
This is simply a restatement of \cite[Theorem 13.2]{Bil99}.
\end{proof}

\lin

\begin{lem}
Let \(\{\X{}{}{\numb}\}\) be a sequence \(\Omega{\V}{\T}\)-valued Feller processes satisfying Assumption \ref{subsec::Assum:Assu::CI}. Let the infinitesimal generators of these processes be given by the equation:

\[\IG\pup{\numb}f(\sv{}{\V}) = \sum_{\v\in \V}\sum_{\s \in \S} \IGr{\v}\pup{\numb}(\sv{}{\V},\s)[f(\sv{}{\V} + \s\ev{\v}) - f(\sv{}{\V})].\]

If there exists some \(\const{} < \infty\) such that

\[\sup_{\numb}\sup_{\sv{}{\V}\in \S^\V}\sup_{\v\in\V}\sup_{\s\in \S} \IGr{\v}\pup{\numb}(\sv{}{\V},\s) \leq \const{},\]

then for all finite \(\U \subseteq \V\),

\[\lim_{\delta \searrow 0} \sup_\numb \pr\left(\omega'_{\piV{\U}{\T}\left(\X{}{}{\numb}\right)}(\delta) \geq \ep\right) = 0\]

for all \(\ep > 0\).
\label{sec::TL:Lem::TightSupport}
\end{lem}
\labe{sec::TL:Lem::TightSupport}

\purpose This allows us to obtain the c\`adl\`ag version of the equicontinuity condition necessary for Theorem \ref{sec::TL:Thm::Tight}. Note: The first time this lemma is applied is in the proof of Proposition \ref{subsec::Well-:Prop::IGApprox}. The proof refers to Proposition \ref{subsec::Well-:Prop::SDE=IG}.

\begin{proof}
Fix any \(\numb \in \mb{N}\). Let \(M = \sup_{\s,\ss \in \S} |\s - \ss|\). Let \(\rxvtts{}{}\) be the \(\cad([0,\T],\mb{R}^\U)\)-valued process defined by the following stochastic integral:

\[\rxvtt{}{\t} = \sum_{\v \in \U}M\ev{\v}\int_0^\t\int_0^{\const{}}\alt{\poiss{\v}}(d\r, d\tt)\]

where \(\{\alt{\poiss{\v}}:\v \in \U\}\) are a sequence of i.i.d. unit rate Poisson processes on \(\mb{R}^2\). 

\ind By Proposition \ref{subsec::Well-:Prop::SDE=IG}, there exists a sequence of i.i.d Poisson processes, \(\{\poiss{\v}:\v\in \V\}\), on \(\S\times\mb{R}^2\) with intensity measure \(\Sm\otimes \leb\) such that,

\[\X{\v}{\t}{\numb} = \X{\v}{0}{\numb} + \int_\S\int_0^\t \s\,\poiss{\v}(d\tt,(0,\rate{\v}(\X{}{\tt-}{\numb})],d\s)\]

for all \(\v\in \V\). Let

\[\alt{\poiss{\v}}(\cdot) = \int_\S\,\poiss{\v}(\cdot\times \S).\]

Since \(\Sm\) is a probability measure on \(\S\) and \(\{\poiss{\v}:\v\in \V\}\) are i.i.d., it follows that \(\{\alt{\poiss{\v}}:\v\in \U\}\) is a sequence of unit rate i.i.d. Poisson processes as desired. Under this coupling, every time \(\piV{\U}{\T}(\X{}{}{\numb})\) experiences a jump, \(\rxvtts{}{}\) also experiences a jump. Furthermore, the magnitude of the jump of \(\rxvtts{}{}\) is larger. For any \(\tt<\ttt\in [0,\T]\) and \(\v\in \U\),

\begin{align*}
|\X{\v}{\tt}{\numb} - \X{\v}{\ttt}{\numb}|&\leq M\left|\{\#\te{ of jumps in }\X{\v}{(\tt,\ttt]}{\numb}\}\right| \\
&\leq M\left|\{\#\te{ of jumps in }\rxvtts{\v}{(\tt,\ttt]}\}\right| = \left|\rxvtt{\v}{\tt} - \rxvtt{\v}{\ttt}\right|
\end{align*}

It follows that for any partition \(\{\t\pup{\it}\}\) of \([0,\T]\),

\begin{align*}
\sup_\it\sup_{\tt,\ttt \in [\t\pup{\it-1},\t\pup{\it})} \sum_{\v\in \U} \b{\v}|\X{\v}{\tt}{\numb} - \X{\v}{\ttt}{\numb}|\leq \sup_\it\sup_{\tt,\ttt \in [\t\pup{\it-1},\t\pup{\it})} \sum_{\v\in \U} \b{\v}|\rxvtt{\v}{\tt} - \rxvtt{\v}{\ttt}|.
\end{align*}

Fix \(\delta > 0\). Taking the infimum over all partitions with minimum interval length \(\delta\) yields,

\begin{align*}
\omega'_{\piV{\U}{\T}\left(\X{}{}{\numb}\right)}(\delta) &= \inf_{\{\t\pup{\it}\}}\sup_\it\sup_{\tt,\ttt \in [\t\pup{\it-1},\t\pup{\it})} \sum_{\v\in \U} \b{\v}|\X{\v}{\tt}{\numb} - \X{\v}{\ttt}{\numb}|\\
&\leq \inf_{\{\t\pup{\it}\}}\sup_\it\sup_{\tt,\ttt \in [\t\pup{\it-1},\t\pup{\it})} \sum_{\v\in \U} \b{\v}|\rxvtt{\v}{\tt} - \rxvtt{\v}{\ttt}|\\
&= \omega'_{\rxvtts{}{}}(\delta).
\end{align*}

Thus,

\[\pr\left(\omega'_{\piV{\U}{\T}\left(\X{}{}{\numb}\right)}(\delta) \geq \ep\right) \leq \pr\left(\omega'_{\rxvtts{}{}}(\delta) \geq \ep\right).\]

By applying this same argument to arbitrary \(\numb\in \mb{N}\) and noticing that the distribution of \(\rxvtts{}{}\) does not vary with respect to our choice of coupling, we get,

\[\sup_{\numb}\pr\left(\omega'_{\piV{\U}{\T}\left(\X{}{}{\numb}\right)}(\delta)\geq \ep\right) \leq \pr\left(\omega'_{\rxvtts{}{}}(\delta) \geq \ep\right).\]

However, \(\rxvtts{}{}\) is just a homogeneous Poisson point process, so the c\`adl\`ag modulus of continuity of \(\rxvtts{}{}\) converges to 0 in probability as \(\delta \ra 0\). Thus,

\[\lim_{\delta \searrow 0}\sup_{\numb}\pr\left(\omega'_{\piV{\U}{\T}\left(\X{}{}{\numb}\right)}(\delta) \geq \ep\right) \leq \lim_{\delta\searrow 0}\pr\left(\omega'_{\rxvtts{}{}}(\delta)\geq \ep\right) = 0.\]


\end{proof}

\lin

\begin{lem}
We can apply \cite[Proposition 14.7.I(b)]{DalVer08} to the proof of Lemma \ref{subsec::ProofU:Lem::Poisson} even though it does not satisfy all of the assumptions.
\label{sec::TL:Lem::embedding}
\end{lem}
\begin{proof}
I use the notation of section \ref{subsec::ProofU:sec::Proof2}. The assumptions of \cite[Proposition 14.7.I(b)]{DalVer08} are as follows:

\begin{itemize}
\item \(\poiss{}(\cdot,\cdot)\) is a marked point process with internal history \(\mc{H}\).

\item \(\poiss{}(\cdot,\cdot)\) has \(\mc{H}\)-predictable intensity \(\rate{}(\t,\kappa)\).
\end{itemize}

If we let \(\poiss{}(\cdot,\cdot) = \pmap{}(\X{}{}{\numb})\) (see Definition \ref{subsec::ProofE:Defn::pmap}), then the proof of \cite[Proposition 14.7.I(b)]{DalVer08} shows that the point process defined in equation \eqref{subsec::ProofU:eqn::Poissonexpl} is a Poisson point process with intensity \(d\t\times \alt{\Sm^\numb}\times d\r\) and adapted to a larger filtration.

\ind However, our intensity is actually only predictable with respect to \(\mc{F} \supseteq \mc{H}\) which includes the value of \(\X{}{0}{\numb}\). This can be fixed simply. Let \(\rate{\v}^{\sv{}{\tree\pup{\numb}}}(\cdot,\cdot) \sim \law(\rate{\v}(\cdot,\cdot)|\X{}{0}{\numb} = \sv{}{\tree\pup{\numb}})\). Then \(\rate{\v}^{\sv{}{\tree\pup{\numb}}}(t,\kappa)\) satisfies the conditions above. Then,

\[\poiss{\numb}^{\sv{}{\tree\pup{\numb}}}(\evnt) = \alt{\poiss{\numb}}\left(\evnt\cap\{(t,\sv{}{\tree\pup{\numb}},\r):\r > \rate{\numb}^{\sv{}{\tree\pup{\numb}}}(\t,\sv{}{\tree\pup{\numb}})\}\right) + \#\{(\rt{\numb,\it}_\v,\mark{\numb,\it}_\v,\rv_{\v}^{\it}\rate{\numb}^{\sv{}{\tree\pup{\numb}}}(\rt{\numb,\it}_\v,\mark{\numb,\it}_\v) \in \evnt: \v\in \tree\pup{\numb}\}\]

is a Poisson process with intensity \(d\t\times \alt{\Sm^\numb}\times d\r\). Let \(R \subseteq \alt{\S^\numb}\), and let \(\inte\) and \(\alt{\inte}\) be intervals in \(\mb{R}^+\). Then,

\begin{align*}
\pr\left(\poiss{\numb}\left(\inte\times R\times \alt{\inte}\right) = 0\right) &= \sum_{\sv{}{\tree\pup{\numb}} \in \alt{S}^\numb} \pr\left(\poiss{\numb}^{\sv{}{\tree\pup{\numb}}}\left(\inte\times R\times \alt{\inte}\right) = 0\right)\pr(\X{}{0}{\numb} = \sv{}{\tree\pup{\numb}})\\
&= \exp\left(-|R| |\inte||\alt{\inte}|\right)\sum_{\sv{}{\tree\pup{\numb}} \in \alt{S^\numb}} \pr(\X{}{0}{\numb} = \sv{}{\tree\pup{\numb}})\\
&=\exp\left(-|R| |\inte||\alt{\inte}|\right)
\end{align*}

Since this holds for every rectangle, \(\poiss{\numb}\) is a Poisson process on \([0,T]\times \alt{\S^\numb}\times [0,\const{}]\) by R\'enyi, M\"onch \cite[Theorem 9.2.XII]{DalVer08}.



\end{proof}
\newpage
\bibliographystyle{plain}
\bibliography{weekly_refs}
\end{document}
