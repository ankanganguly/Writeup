\documentclass[12pt]{article}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{color}
\usepackage{mathrsfs}
\usepackage{fullpage}
\usepackage{commath}
\usepackage{graphicx}
\usepackage{pdfcomment}
%\usepackage{coffee4}
\usepackage{lipsum}
%\usepackage{showkeys}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{verbatim}
\usepackage{longtable}

%General Shorthand Macros
\newcommand{\skipLine}{\vspace{12pt}}
\newcommand{\mb}{\mathbb}
\newcommand{\mc}{\mathcal}
\newcommand{\ms}{\mathscr}
\newcommand{\ra}{\rightarrow}
\newcommand{\ov}{\overline}
\newcommand{\os}{\overset}
\newcommand{\un}{\underline}
\newcommand{\te}{\text}
\newcommand{\ep}{\epsilon}
\newcommand{\tr}{\textcolor{red}}
\newcommand{\tb}{\textcolor{blue}}
\newcommand{\tg}{\textcolor{green}}
\newcommand{\labe}[1]{\tr{\texttt{Label: #1}}}
\newcommand{\tbs}{\textbackslash}
\newcommand{\purpose}{\textbf{Purpose: }}
\newcommand{\pfsum}{\textbf{Proof Summary: }}
\newcommand{\usein}{\textbf{Used in: }}
\newcommand{\app}{\textbf{Applies: }}
\newcommand{\ind}{\hspace{24pt}}
\newcommand{\lin}{\rule{\linewidth}{0.4 pt}}
\newcommand{\pr}{\mb{P}}							%probability
\newcommand{\ex}[1]{\mb{E}\left[#1\right]}			%expectation
\newcommand{\exmu}[2]{\mb{E}^{#1}\left[#2\right]}	%exp wrt a measure
\newcommand{\deq}{\overset{\text{(d)}}{=}}			%equal in dist
\newcommand{\defeq}{:=}								%definition equal
\newcommand{\msr}{\mc{M}}							%space of measures
\newcommand{\pmsr}{\mc{P}}							%space of pmsrs
\newcommand{\cad}{\mb{D}}							%Cadlag space


%Paper macros
%Section 2.1
%base commands
\renewcommand{\root}{\mathbf{0}}				%root
\renewcommand{\v}{v}							%typical vertex
\newcommand{\vv}{u}								%typical 2nd vertex
\newcommand{\vvv}{w}							%typical 3rd vertex
\renewcommand{\U}{U}							%typical vertex set
\newcommand{\UU}{W}								%typical 2nd vert set
\newcommand{\UUU}{R}							%typical 3rd vert
\renewcommand{\S}{S}							%State space
\newcommand{\s}{\sigma}							%elt of \S	
\newcommand{\sv}{\vec{\s}}						%typ elt of \XState
\renewcommand{\b}{b}							%inf dim norm coeffs
\newcommand{\ev}{\ep}							%standard basis
\newcommand{\T}{T}								%time bound
\newcommand{\x}{x}								%typical elt of Omega
\renewcommand{\t}{t}							%typical time
\newcommand{\sset}{\Omega}						%sample set
\newcommand{\proj}{\pi}							%projection operator
%\newcommand{\svnorm}[1]{\|#1\|_{\b}}			%norm of \S\carp{V}
%\newcommand{\omenorm}[1]{\|#1\|_{\b,\t}}		%norm on Omega
\renewcommand{\tt}{s}							%typical time 2
\newcommand{\ttt}{s'}							%typical time 3
\newcommand{\F}{\mc{F}}							%Filtrations
\newcommand{\FG}{\mc{G}}						%Filtrations
\newcommand{\FH}{\mc{H}}						%Filtrations
\newcommand{\X}{X}								%typ random process
\newcommand{\IG}{\mc{A}}						%Infinitesimal gens
\newcommand{\IGr}{c}							%IG rate
\newcommand{\f}{f}								%generic function
\newcommand{\neigh}{\mc{N}}						%neighbor
\newcommand{\dneigh}{\mc{N}^2}					%double neighbor


%Modifiers
\newcommand{\vind}[1]{^{#1}}					%indexed by v,V,U etc.
\newcommand{\carp}[1]{^{#1}}					%Cartesian power
\newcommand{\vsi}[1]{^{#1}}						%vertex set identifier
\newcommand{\cind}[1]{_{#1}}					%component index
\newcommand{\cl}{\ov}							%closure
\newcommand{\tp}[1]{(#1)}						%Time of process
\newcommand{\tip}[1]{#1}						%time interval process	
\newcommand{\ts}[1]{_{#1}}						%time bound of set
\newcommand{\vindsln}[2]{^{#1,#2}}				%vindsln combine

%Section 2.2
%Base commands
\newcommand{\const}{C}							%Constant
\newcommand{\degr}{D}							%Max degree of graph
\newcommand{\IGrg}{\ov{c}}						%Fixed rate function
\newcommand{\gdist}{d_G}						%Graph distance
\newcommand{\tree}{\mc{T}}						%Tree

%Modifiers
\newcommand{\sln}[1]{^{#1}}						%sublimit numbering

%Section 2.3
%Base commands
\newcommand{\core}{\mc{D}}						%Core
\newcommand{\cont}{\mc{C}}						%space of cont. fs
\newcommand{\delt}{\triangle}					%change in f
\renewcommand{\ss}{\tilde{\s}}					%2nd elt of \S
\renewcommand{\SS}{\tilde{\S}}					%sub state space
\newcommand{\poisses}{\mathbf{N}}				%all Poisson processes
\newcommand{\poiss}{N}							%Poisson process
\newcommand{\leb}{\te{Leb}}						%Lebesgue measure
\newcommand{\Sm}{\ell}							%std msr on \S
\newcommand{\rate}{\lambda}						%rate
\newcommand{\Fpo}{F_{\poisses}}					%Picard mapping of SDE
\renewcommand{\r}{r}							%space var for poiss
\newcommand{\cconst}{M}							%second constant
\newcommand{\modu}{\omega}						%modulus of continuity
\newcommand{\cmodu}{\omega'}					%cadlag moc

%Modifier
\newcommand{\deltf}[1]{_{#1}}					%Specify delt function
\newcommand{\alt}[1]{\widetilde{#1}}			%alternate val
\newcommand{\pra}[1]{_{#1}}						%Append process

%Section 3
%Base commands
\newcommand{\m}{\mu}							%typ measure
\newcommand{\mm}{\nu}							%typ measure 2
\newcommand{\mmm}{\eta}							%typ measure 3
\newcommand{\cm}{\gamma}						%conditional msr funct
\newcommand{\law}{\te{Law}}						%Law of a process

%Modifiers
\newcommand{\me}[1]{^{#1}}						%Append measure


%Section 4
\newcommand{\XX}{Y}								%second random element
\newcommand{\XXX}{Z}							%third random elt
\newcommand{\rt}{\tau}							%typical rand time
\newcommand{\rtt}{\theta}						%typical rand time 2
\renewcommand{\it}{k}							%iterator
\newcommand{\mutex}{\|}							%Mutually exclusive
\newcommand{\apath}{\Gamma}						%path for CI proof
\newcommand{\pathset}[2]{\Lambda_{#1,#2}}		%A space of paths
\newcommand{\pathsete}[2]{C_{#1,#2}}			%union over pathset
\newcommand{\pathseted}[2]{H_{#1,#2}}			%pathsete with \t
\newcommand{\evnt}{\mc{E}}						%Typical event
\newcommand{\rv}{A}								%Typical rand elt

%Section 5.1
%Base commands
\newcommand{\pmap}{\Gamma}						%Markov to MPP	
\renewcommand{\mark}{\kappa}					%Typical mark
\newcommand{\rp}{P}								%typ point process
\newcommand{\Tset}{\alt{T}}						%finite time subset
\newcommand{\typset}{A}							%Typical set
\newcommand{\ratee}{\Lambda}					%general rate
\newcommand{\crate}{\alt{\lambda}}				%conditional rate
\newcommand{\upcrs}{U}							%upcrossing
\newcommand{\cratee}{\alt{\Lambda}} 			%general conditional rate

%Section 5.2
%Base commands
\newcommand{\dense}{L}							%Typ density
\newcommand{\cdense}{M}							%Cond density
\newcommand{\ds}{\Upsilon}						%mapping in density
\renewcommand{\c}{c}							%child function
\newcommand{\p}{p}								%parent function

%Appendix A
%Base Commands
\newcommand{\spce}{\mc{X}}						%arbitrary space
\newcommand{\xx}{y}								%typ path val2
\newcommand{\xxx}{z}							%typ path val3

%Appendix B
%Base Commands
\newcommand{\evs}{E}							%Set of events
\newcommand{\mspce}{\mc{K}}						%Mark space
\newcommand{\rpg}{\rp_g}						%ground process

%Appendix C
%Base commands
\newcommand{\dist}{d}							%general metric
\newcommand{\inte}{I}							%Interval

\newtheorem{thms}{Theorem}[section]
\newtheorem{conj}[thms]{Conjecture}
\newtheorem{prop}[thms]{Proposition}
\newtheorem{coro}[thms]{Corollary}
\newtheorem{lem}[thms]{Lemma}
%\newtheorem{sublem}{Sublemma}[lem]
\newtheorem{defn}[thms]{Definition}
\newtheorem{assu}[thms]{Assumption}

\setlength{\parindent}{0pt}

\begin{document}

\title{A Local Approximation of Finite State Interacting Particle Systems on a Tree (Working Title)}
\author{Ankan Ganguly}

\maketitle

\begin{abstract}
\tg{There will be an abstract here soon enough!}

Title possibilities: Transient dynamics of a typical neighborhood of particles on a regular tree. \tr{Too long and still lacks relevant info!}
\end{abstract}

\newpage
\tableofcontents

\newpage

\section*{For The Author's Use Only (FTAUO)}
\subsection*{Notation}

\begin{longtable}{c|c|c|c}
Macro Command & Arguments & Symbol & Meaning\\\hline
\tbs pr&0&\(\pr\)	& probability\\
\end{longtable}

\subsection*{TODO}

Resolve notation problems:

\begin{itemize}
\item Complete notation macros

\item Try removing references to measure space \(\pmsr(\cdot)\) in section 2.

\item Finish all proofs.
\end{itemize}

\section{Introduction}
\label{sec::Intro}\labe{sec::Intro}

Partial Lit Review: \tr{A lot of these results are specifically for diffusions. Consider whether they are still relevant.}

Convergence of the Empirical Measure (relevant if I prove equivalence of limiting empirical distribution and limiting typical particle dynamics.):

\begin{itemize}
\item \cite{Yin15} uses Stein's method to proof convergence and estimate rate of convergence.

\item \cite{DupRamWu16} study convergence in finite state space case and analyze Large deviations.

\item \cite{VveDobKar96} and \cite{Mit01} apply analysis to power of two load balancing on a complete network. 
\end{itemize}

McKean-Vlasov Equations:

\begin{itemize}
\item \cite{Mck66} introduces the notation of non-linear Markov processes.

\item \cite{Oel84} uses standard Martingale convergence arguments to prove the McKean-Vlasov weak limit for diffusions and jump processes.

\item \cite{Szn91} uses a fixed point algorithm to prove the McKean-Vlasov limit for diffusions. Explicitly provided a coupling in which the path of a typical particle converges.

\item \cite{Lac15} provides a brief summary of methods by which the McKean-Vlasov limit has been proved. He also addresses cases in which the limiting equation does not have a unique solution and the case of shared noise. Most of the thesis considers a control process derived from these processes.

\item \cite{SzpTanTse17} develop multilevel Monti Carlo estimation of McKean-Vlasov SDEs using Sznitman's fixed point argument.
\end{itemize}

Dense Graph Approximation:

\begin{itemize}
\item \cite{BhaBudWu17} show convergence to McKean-Vlasov of diffusions over asymptotically dense random networks.

\item \cite{MukBorLee17} analyze join-the-shortest-neighboring-queue load balancing over asymptotically dense random networks. \cite{BudMukWu17} also address heterogeneous deterministic networks.

\item \cite{MieBov15},\cite{GreKisKao06} study mean-field numerically for various epidemic models. They demonstrate that it works well for dense graphs and that it's inaccurate for sparse graphs.
\end{itemize}

Alternatives:

\begin{itemize}
\item \cite{Gas15} demonstrates the pairwise approximation. It's better than mean-field, but tail probabilities are still inaccurate.

\item Cavity method may provide an alternative approach. It is currently known as a discrete time algorithm \cite{Lac15}\cite{KanMon11}. There is current work extending it to continuous time \tr{(Citation needed)}.
\end{itemize}

\tg{Outline will be here someday somehow!}


\section{Preliminaries}
\label{sec::Preli}\labe{sec::Preli}

\subsection{Notation}
\label{subsec::Notat:sec::Preli}\labe{subsec::Notat:sec::Preli}

Let \(G = (V,E)\) be an at most countably infinite simple, connected graph with bounded degree and a root node \(\root \in V\). For any \(\v \in V\), let \(\neigh\vind{\v}\) be the set of nodes adjacent to \(\v\). Similarly, for any \(\U \subseteq V\), let \(\neigh\vind{\U}\) be the set of nodes adjacent to \(\U\) but not in \(\U\). Let \(\cl{\v} = \{\v\}\cup\neigh\vind{\v}\) and \(\cl{\U} = \U\cup \neigh\vind{\U}\). 

\ind Let \(S = \mb{Z}/m\mb{Z}\) for some finite \(m < 0\). \tr{All of our results extend to the case where \(\S\) is an arbitrary finite set (remove this sentence, or add a proof?)}.

\ind Let \(\S\carp{V}\) be the set of vectors \(\sv\cind{}\vsi{V}\) with components \(\sv\cind{\v}\vsi{V} \in \S\) indexed by \(\v\in V\). Let \(\{\ev\vind{\v}\in\S\carp{V}: \v\in V\}\) be the standard basis vectors of \(\S\carp{V}\): that is, for any \(\v,\vv\in V\), \(\ev\vind{\v}\cind{\vv} = \mb{I}_{\v = \vv}\). Let \(\{\b\cind{\v}:\v\in V\}\) be a sequence of positive numbers such that \(\sum_{\v\in V} \b\cind{\v} < \infty\). Then let \(\|\cdot\|_{\b}\) be the norm on \(\S\carp{V}\) defined by \(\|\sv\cind{}\vsi{V}\|_{\b} = \sum_{\v\in V} \b\cind{\v}|\sv\cind{\v}\vsi{V}|\). For any \(\U\subseteq V\), we will generally assume \(\S\carp{\U}\) is embedded in \(\S\carp{V}\). That is, for any \(\sv\cind{}\vsi{\U}\in \S\carp{\U}\), we can regard \(\sv\vsi{\U}\) as an element in \(\S\carp{V}\) which coincides with \(\sv\vsi{\U}\) on \(\U\) and satisfies \(\sv\vsi{\U}\cind{\v} = 0\) for all \(\v\in V\setminus \U\). Thus, we can also define the norm on \(\S\carp{\U}\) by \(\|\sv\cind{}\vsi{\U}\|_{\b} = \sum_{\v\in\U} \b\cind{\v}|\sv\cind{\v}\vsi{\U}|\). \(\S\carp{V}\) acts as the state space of an interacting particle system on \(G\) whose nodes have state space \(\S\).

\ind Fix some \(\T < \infty\). For any \(\U\subseteq V\) and \(\t\in [0,\T]\), let \(\sset\vsi{\U}\ts{\t} = \cad([0,\t],\S\carp{\U})\) and \(\sset\vsi{\U}\ts{\t-} = \cad([0,\t),\S\carp{\U})\). For any \(\x\cind{}\tip{} \in \sset\vsi{V}\ts{\T}\), \(\v\in V\) and  \(\t \in [0,\T]\), let \(\x\cind{\v}\tp{\t}\) be the value of the \(\v\)-node of \(\x\cind{}\tip{}\) at time \(\t\). For any \(U\subseteq V\), let \(\proj\vsi{\U}\ts{\t}: \sset\vsi{V}\ts{\t} \ra \sset\vsi{\U}\ts{\t}\) be the projection mapping defined by,

\[\left(\proj\vsi{\U}\ts{\t}(\x)\right)\cind{\v}\tp{\t} = \begin{cases}
\x\cind{\v}\tp{\t} &\te{ if } \v \in \U\\
0 &\te{ otherwise}
\end{cases}.\]

We will at times interpret \(\proj\vsi{\U}\ts{\t}\) as a mapping from \(\sset\vsi{\alt{\U}}\ts{\t}\) to \(\sset\vsi{\U}\ts{\t}\) for \(\alt{\U}\subset V\) by embedding \(\sset\vsi{\alt{U}}\ts{\t}\) in \(\sset\vsi{V}\ts{\t}\). This will not be indicated in the notation if \(\alt{\U}\) is clear from context. Let \(\proj\vsi{\U}\ts{} \defeq \proj\vsi{\U}\ts{0}\) be the corresponding projection mapping to \(\S\carp{\U}\). For any \(\U\subseteq V\), define the norm on \(\sset\vsi{\t}\ts{\U}\) by \(\|\x\cind{\U}\tip{}\|_{\b,\t} \defeq \sup_{\tt \leq \t} \|\x\cind{\U}\tp{\tt}\|_{\b}\). Let \(\F\vsi{\U}\ts{\t}\) be the Borel \(\sigma\)-algebra of \(\sset\vsi{\U}\ts{\t}\) with respect to the Skorokhod topology. 

\ind Let \(\X = \{\X\cind{\v}\tp{\t}:\v\in V,\t\in [0,\infty)\}\) be a c\`adl\`ag, \(\S\carp{V}\)-valued pure jump process. Assume \(\X\cind{}\tip{}\) is a Feller process with infinitesimal generator \(\IG\) given by,

\begin{equation}
\IG f(\sv\cind{}\vsi{V}) = \sum_{\v \in V}\sum_{\s \in \S} \IGr\vind{\v}(\sv\cind{}\vsi{V},\s)[f(\sv\cind{}\vsi{V} + \s \ev\vind{\v}) - f(\sv\cind{}\vsi{V})], \quad \sv\vsi{V} \in \S\carp{V}.
\label{subsec::Notat:Eqn::IG}
\end{equation}
\labe{subsec::Notat:Eqn::IG}

where \(\{\IGr\vind{\v}:\v\in V\}\) are suitable jump rates such that \(\X\cind{}\tip{}\) is well-defined (See Appendix \ref{sec::Infin} for more information. See sections \ref{subsec::Assum:sec::Preli} and \ref{subsec::Well-:sec::Preli} for examples of such \(\IGr\vind{\v}\) relevant to this paper). 

\tr{I have not mentioned any probability measure stuff yet.}

\subsection{Assumptions}
\label{subsec::Assum:sec::Preli}\labe{subsec::Assum:sec::Preli}

Throughout this paper, we will assume that \(\X\cind{}\tp{0}\) is a vector of i.i.d. \(\S\)-valued random variables with respect to \(\pr\).

\lin

\begin{assu}
The following three conditions hold:
\begin{enumerate}
\item There exists a constant \(\const{} < \infty\) such that,

\begin{equation}
\sup_{\v\in V,\s \in \S,\sv\cind{}\vsi{V}\in \S\carp{V}} \IGr\vind{\v}(\sv\cind{}\vsi{V},\s) = \const{}.
\label{subsec::Assum:Eqn::bddcv}
\end{equation}
\labe{subsec::Assum:Eqn::bddcv}

\item For every \(\v\in V\), there exists a mapping, \(\IGrg\vind{\v}:\S\carp{\cl{\v}} \times \S \ra [0,\infty)\) such that,

\[\IGr\vind{\v}(\sv\cind{}\vsi{V},\s) = \IGrg\vind{\v}(\sv\cind{\cl{\v}}\vsi{V},\s), \quad \sv\vsi{V} \in \S\carp{V},\s\in \S.\]

\item \(G\) has bounded degree given by \(\degr \defeq \sup_\v |\neigh\vind{\v}| < \infty\).
\end{enumerate}
\label{subsec::Assum:Assu::CI}\labe{subsec::Assum:Assu::CI}
\end{assu}

\purpose Intuitively, we are assuming that each node of the process changes state at a bounded rate and that the number of nodes that any one node interacts with is bounded. This assumption (along with independent initial conditions) yields sufficient conditions for well-posedness of the infinitesimal generator and SDE. It is also all that is required to prove the conditional independence property (Theorem \ref{sec::Main:Thm::CI}). 

\usein All of section \ref{subsec::Well-:sec::Preli}. Theorem \ref{sec::Main:Thm::CI}. All of section \ref{sec::Proof1}.

\lin

\begin{assu}
There exists a fixed \(\degr\in \mb{N}\) such that:

\begin{enumerate}
\item There exists a mapping \(\IGrg: \S\carp{\degr+1} \times \S \ra [0,\infty)\) such that:

\begin{equation}
\IGr\vind{\v}(\sv\cind{}\vsi{V},\s) = \IGrg(\sv\cind{\cl{\v}}\vsi{V},\s) \te{ for all } \v\in V, \s\in \S\te{ and } \sv\cind{}\vsi{V} \in \S\carp{V}
\label{subsec::Assum:Eqn::Symmetry}
\end{equation}
\labe{subsec::Assum:Eqn::Symmetry}

\item \(G\) is a regular \(\degr\)-tree. In this case we call an arbitrary node \(\root\in V\) the root. Let \(\gdist\) be the graph distance. Define \(\tree\sln{n} = \{\v \in V: \gdist(\v,\root) \leq n\}\) for all \(n\in \mb{N}\).
\end{enumerate}
\label{subsec::Assum:Assu::Local}\labe{subsec::Assum:Assu::Local}
\end{assu}

\purpose Assumption \ref{subsec::Assum:Assu::Local} implies Assumption \ref{subsec::Assum:Assu::CI}, so all results for Assumption \ref{subsec::Assum:Assu::CI} hold for Assumption \ref{subsec::Assum:Assu::Local}. This assumption adds an additional symmetry assumption. We also work on trees so we do not have to deal with cycles (which add extra dependencies making the problem harder to analyze). Furthermore, this assumption is sufficient for Theorem \ref{sec::Main:Thm::Local SDE} (existence and uniqueness of a local representation of \(\m{}{}{} \defeq \law(\X\cind{}\tip{})\)).

\usein Theorem \ref{sec::Main:Thm::Local SDE}, all of section \ref{sec::Proof2}.

\ind \(\tree\sln{n}\) is the tree rooted at \(\root\) with \(n\) generations such that \(\root\) has \(\degr\) children and all other non-leaf nodes have \(\degr-1\) children.

\lin

\subsection{Well-Posedness Results}
\label{subsec::Well-:sec::Preli}\labe{subsec::Well-:sec::Preli}

\rule{\linewidth}{0.4 pt}

\begin{prop}
Suppose \(\X\cind{}\tip{}\) is the Feller process defined by equation \eqref{subsec::Notat:Eqn::IG}. If \(\X\cind{}\tip{}\) satisfies Assumption \ref{subsec::Assum:Assu::CI}, then there exists a domain \(\core(\IG)\) such that operator \(\IG\) defined in equation \eqref{subsec::Notat:Eqn::IG} on \(\mc{D}(\IG)\) is an infinitesimal generator with core \(\core\) defined by,

\begin{equation}
\core \defeq \left\{f \in \cont(\S\carp{V}): \sum_{\v\in V} \delt\deltf{\f}\vind{\v} < \infty\right\},
\label{subsec::Well-:Eqn::core}
\end{equation}
\labe{subsec::Well-:Eqn::core}

where we define,

\begin{equation}
\delt\deltf{\f}\vind{\v} \defeq \sup\left\{|f(\sv\cind{}\vsi{V}) - f(\sv\cind{}\vsi{V}+\s\ev\vind{\v})|: \sv\cind{}\vsi{V} \in \S\carp{V},\s \in \S\right\}.
\label{subsec::Well-:Eqn::fvar}
\end{equation}
\labe{subsec::Well-:Eqn::fvar}

\label{subsec::Well-:Prop::Welldef}
\end{prop}
\labe{subsec::Well-:Prop::Welldef}

\purpose This is necessary for obvious reasons. If \(\X\cind{}\tip{}\) is not well-defined, then there is no longer any point in deriving any results about its properties. The infinitesimal generator representation of \(\X\cind{}\tip{}\) is used to prove convergence of the finite-dimensional approximations of \(\X\cind{}\tip{}\) to \(\X\cind{}\tip{}\).

\usein This is important for Propositions \ref{subsec::Well-:Prop::SDE=IG} and \ref{subsec::Well-:Prop::IGApprox}. It is only implicitly used in \ref{subsec::Well-:Prop::SDE=IG}.

\app \cite[Theorem 3.9]{Lig85} and Assumption \ref{subsec::Assum:Assu::CI}.

\begin{proof}
By \cite[Theorem 3.9 (a) and (b)]{Lig85}, it suffices to show that:

\begin{enumerate}[i)]
\item 

\[\sup_{\v \in V,\sv\cind{}\vsi{V} \in \S\carp{V}} \sum_{\s \in \S} \IGr\vind{\v}(\sv\cind{}\vsi{V},\s) < \infty.\]

\item 

\[\sup_{\v\in V}\sum_{\vv\neq \v} \sup_{\substack{\sv\cind{}\vsi{V} \in \S\carp{V}\\ \s\in \S\\ \SS \subseteq \S}} \left|\sum_{\ss \in \SS} (\IGr\vind{\v}(\sv\cind{}\vsi{V},\ss) - \IGr\vind{\v}(\sv\cind{}\vsi{V}+\s \ev\vind{\vv},\ss))\right| < \infty.\]
\end{enumerate}

We have,

\begin{enumerate}[i)]
\item This is just statement 1 of Assumption \ref{subsec::Assum:Assu::CI}.

\item By statement 2 of Assumption \ref{subsec::Assum:Assu::CI}, 

\[\sup_{\substack{\sv\cind{}\vsi{V} \in \S\carp{V}\\ \s\in \S\\ \SS\subseteq \S}} \left|\sum_{\ss \in \SS} (\IGr\vind{\v}(\sv\cind{}\vsi{V},\ss) - \IGr\vind{\v}(\sv\cind{}\vsi{V}+\s \ev\vind{\vv},\ss))\right| = 0 \te{ for all } \vv \notin \cl{\v}\]

Furthermore, \(\IGr\vind{\v}\) is non-negative and bounded from above by some \(\const{} < \infty\) (statement 1 of Assumption \ref{subsec::Assum:Assu::CI}). Therefore, 

\[\left|\sum_{\ss \in \SS} (\IGr\vind{\v}(\sv\cind{}\vsi{V},\ss) - \IGr\vind{\v}(\sv\cind{}\vsi{V}+\s\ev\vind{\vv},\ss))\right| \leq \const{}|\S| \te{ for all } \sv\cind{}\vsi{V} \in \S\carp{V},\v \in V, \vv \in \cl{\v}, \s \in \S \te{ and } \SS\subseteq \S\]

Finally, by statement 3 of Assumption \ref{subsec::Assum:Assu::CI}, \(|\neigh\vind{\v}| \leq \degr\) for all \(\v \in V\). Thus,

\begin{align*}
\sup_{\v\in V}\sum_{\vv \neq \v} \sup_{\substack{\sv\cind{}\vsi{V} \in \S\carp{V}\\ \s\in \S\\ \SS\subseteq \S}}& \left|\sum_{\ss \in \SS} (\IGr\vind{\v}(\sv\cind{}\vsi{V},\ss) - \IGr\vind{\v}(\sv\cind{}\vsi{V}+\s\ev\vind{\vv},\ss))\right|\\
&  = \sup_{\v\in V}\sum_{\vv\in \neigh\vind{\v}} \sup_{\substack{\sv\cind{}\vsi{V} \in \S\carp{V}\\ \s\in \S\\ \SS\subseteq \S}} \left|\sum_{\ss \in \SS} (\IGr\vind{\v}(\sv\cind{}\vsi{V},\ss) - \IGr\vind{\v}(\sv\cind{}\vsi{V}+\s\ev\vind{\vv},\ss))\right|\\
&\leq \sup_{\v\in V} \sum_{\vv \in \neigh\vind{\v}} \const{}|\S|\\
&\leq \degr \const{}|\S| < \infty.
\end{align*}


\end{enumerate}
\end{proof}

\lin

\begin{prop}
Let \(\poisses \defeq \{\poiss\vind{\v}:\v\in V\}\) be a sequence of i.i.d. Poisson processes on \(\mb{R}^2\times \S\) with intensity measure \(\leb\otimes \Sm\) where \(\leb\) is the Lebesgue measure on \(\mb{R}^2\) and \(\Sm\) is a probability measure on \(\S\) having 0 weight on 0 and unit weight on \(\S\setminus \{0\}\). Suppose \(\IGr\vind{\v}\) and \(G\) satisfy Assumption \ref{subsec::Assum:Assu::CI}. Then the coupled equation,

\begin{equation}
\X\cind{\v}\tp{\t} = \X\cind{\v}\tp{0} + \int_\S\int_0^\t \s\poiss\vind{\v}\left(d\tt,\left(0,\IGr\vind{\v}(\X\cind{}\tp{\tt-},\s)\right],d\s\right) \te{ for all }\v \in V
\label{subsec::Well-:Eqn::SDE}
\end{equation}
\labe{subsec::Well-:Eqn::SDE}

has a unique strong solution.
\label{subsec::Well-:Prop::SDEWP}
\end{prop}
\labe{subsec::Well-:Prop::SDEWP}

\purpose The SDE representation of \(\X\cind{}\tip{}\) is used to prove the conditional independence property. I also make heavy use of this representation in proving uniqueness of the local characterization.

\pfsum Prove uniqueness using Gronwall's inequality. Prove existence using Picard iterations. Proof is provided after Lemma \ref{subsec::Well-:Lem::GronwallPrep}.

\usein Proposition \ref{subsec::Well-:Prop::SDE=IG}, Lemma \ref{sec::Proof1:Lem::Decomposition} and section \ref{subsec::ProofU:sec::Proof2}.

\app Lemma \ref{subsec::Well-:Lem::GronwallPrep} and Assumption \ref{subsec::Assum:Assu::CI}. Lemma \ref{subsec::Well-:Lem::SDEWP} is an intermediate result used to prove Lemma \ref{subsec::Well-:Lem::GronwallPrep}.

\lin

\begin{lem}
Suppose Assumption \ref{subsec::Assum:Assu::CI} holds. Consider the mapping \(\Fpo: \sset\vsi{V}\ts{\T} \ra \sset\vsi{V}\ts{\T}\) parameterized by a sequence of Poisson processes and defined by,

\[\left(\Fpo(\x\cind{}\tip{})\right)\cind{\v}\tp{\t} := \x\cind{\v}\tp{0} + \int_\S\int_0^\t \s \,\poiss\vind{\v}(d\tt,(0,\IGr\vind{\v}(\x\cind{}\tp{\tt-},\s)],d\s) \te{ for all }\x\cind{}\tip{} \in \sset\vsi{V}\ts{\T}, \v \in V\te{ and }\t \in [0,\T].\]

Then for any pair of random processes \(\X\cind{}\tip{},\alt{\X}{}{}:\sset\vsi{V}\ts{\T} \ra \sset\vsi{V}\ts{\T}\), \(\v\in V\) and \(\t \in [0,\T]\),

\[\ex{\|\Fpo(\X\cind{}\tip{})\cind{\v} - \Fpo(\alt{\X}{}{})\cind{\v}\|_\t} \leq \ex{|\X\cind{\v}\tp{0} - \alt{\X}{\v}{0}|} +  \const{1}\int_0^\t \sum_{\vv\in \cl{\v}} \ex{\|\X\cind{\vv}\tip{} - \alt{\X}{\vv}{}\|_\tt}\,d\tt\]

for some constant \(\const{1} < \infty\).

\label{subsec::Well-:Lem::SDEWP}
\end{lem}
\labe{subsec::Well-:Lem::SDEWP}

\purpose Proposition \ref{subsec::Well-:Prop::SDEWP} is proved using Picard iterations to prove existence and a similar inequality to prove uniqueness. This lemma is also applied in the proof of Proposition \ref{subsec::Well-:Prop::SDE=IG}. Furthermore, the proof that any strong solution, \(\X\cind{}\tip{}\), to equation \eqref{subsec::Well-:Eqn::SDE} also involves a similar computation. This Lemma allows us to do the computation a single time to avoid repetition or citing results found within proofs.

\usein Lemma \ref{subsec::Well-:Lem::GronwallPrep} and Proposition \ref{subsec::Well-:Prop::SDE=IG}. Proof is referenced in Lemma \ref{sec::Proof1:Lem::Decomposition}.

\app Assumption \ref{subsec::Assum:Assu::CI}.

\begin{proof}
Recall that \(\{\IGr\vind{\v}:\v\in V\}\) is necessarily bounded from above by some \(\const{} < \infty\) (Statement 1 of Assumption \ref{subsec::Assum:Assu::CI}). 

\ind By statement 2 of Assumption \ref{subsec::Assum:Assu::CI}, 

\[\inf_{\substack{\sv\cind{}\vsi{V},\alt{\sv}{}{V} \in \S\carp{V}, \s\in \S\\ \IGr\vind{\v}(\sv\cind{}\vsi{V},\s) \neq \IGr\vind{\v}(\alt{\sv}{}{V},\s)}} \sum_{\vv \in \cl{\v}} |\sv\cind{\vv}\vsi{V} - \alt{\sv}{\vv}{V}| \geq 1.\]

Then,

\[\sup_{\v\in V} \sup_{\substack{\sv\cind{}\vsi{V},\alt{\sv}{}{V} \in \S\carp{V}, \s\in \S\\ \IGr\vind{\v}(\sv\cind{}\vsi{V},\s) \neq \IGr\vind{\v}(\alt{\sv}{}{V},\s)}} \frac{|\IGr\vind{\v}(\sv\cind{}\vsi{V},\s) - \IGr\vind{\v}(\alt{\sv}{}{V},\s)|}{\sum_{\vv \in \cl{\v}} |\sv\cind{\vv}\vsi{V} - \alt{\sv}{\vv}{V}|} \leq \const{}\]

So,

\[|\IGr\vind{\v}(\sv\cind{}\vsi{V},\s) - \IGr\vind{\v}(\alt{\sv}{}{V},\s)|\leq \const{}\sum_{\vv \in \cl{\v}} |\sv\cind{\vv}\vsi{V} - \alt{\sv}{\vv}{V}| \te{ for all } \sv\cind{}\vsi{V},\alt{\sv}{}{V}\in \S\carp{V},\s\in \S\te{ and }\v\in V.\]

That is, \(\IGr\vind{\v}\) satisfies a Lipschitz-like condition with coefficient bounded from above by \(\const{}\). For any \(\v\in V\),

\begin{align*}
\mb{E}\bigg[&\|\Fpo(\X\cind{}\tip{})\cind{\v} - \Fpo(\alt{\X})\cind{\v}\|_\t\bigg] - \ex{|\X\cind{\v}\tp{0} - \alt{\X}{\v}{0}|}\\
&= \ex{\sup_{\ttt \leq \t}\left|\int_\S\int_0^{\ttt} \s\poiss\vind{\v}\left(d\tt,\left(0,\IGr\vind{\v}(\X\cind{}\tp{\tt-},\s)\right],d\s\right) -  \int_\S\int_0^{\ttt} \s\poiss\vind{\v}\left(d\tt,\left(0,\IGr\vind{\v}(\alt{\X}{}{\tt-},\s)\right],d\s\right)\right|}\\
&=\ex{\sup_{\ttt\leq \t} \left|\int_\S \int_0^{\const{}} \int_0^{\ttt} \s\left(\mb{I}_{\r < \IGr\vind{\v}(\X\cind{}\tp{\tt-},\s)} - \mb{I}_{\r < \IGr\vind{\v}(\alt{\X}{}{\tt-},\s)}\right)\,\poiss\vind{\v}(d\tt\,d\r\,d\s)\right|}\\
&\leq \ex{\int_\S\int_0^{\const{}}\int_0^\t \left|\s\left(\mb{I}_{\r < \IGr\vind{\v}(\X\cind{}\tp{\tt-},\s)} - \mb{I}_{\r < \IGr\vind{\v}(\alt{\X}{}{\tt-},\s)}\right)\right|\,\poiss\vind{\v}(d\tt\,d\r\,d\s)}\\
&=\int_\S\int_0^\t\int_0^{\const{}} |\s|\ex{\mb{I}_{\IGr\vind{\v}(\X\cind{}\tp{\tt-},\s) \leq \r < \IGr\vind{\v}(\alt{\X}{}{\tt-},\s)} + \mb{I}_{\IGr\vind{\v}(\alt{\X}{}{\tt-},\s) \leq \r < \IGr\vind{\v}(\X\cind{}\tp{\tt-},\s)}}\,d\r\,d\tt\,\Sm(d\s)\\
&= \int_\S\int_0^\t|\s|\ex{\left|\IGr\vind{\v}(\X\cind{}\tp{\tt-},\s) - \IGr\vind{\v}(\alt{\X}{}{\tt-},\s)\right|}\,d\tt\,\Sm(d\s)\\
&\leq \const{}\int_\S\int_0^\t |\s| \ex{\sum_{\vv \in \cl{\v}}|\X\cind{\vv}\tp{\tt-} - \alt{\X}{\vv}{\tt-}|}\,d\tt\,\Sm(d\s)\\
&\leq \const{}|\S|\int_0^\t \sum_{\vv \in \cl{\v}}\ex{\|\X\cind{\vv}\tip{} - \alt{\X}{\vv}{}\|_\tt}\,d\tt\\
\end{align*}

Then,

\[\ex{\|\Fpo(\X\cind{}\tip{})\cind{\v} - \Fpo(\alt{\X})\cind{\v}\|_\t} \leq \ex{|\X\cind{\v}\tp{0} - \alt{\X}{\v}{0}|} +  \const{1}\int_0^\t \sum_{\vv\in \cl{\v}} \ex{\|\X\cind{\vv}\tip{} - \alt{\X}{\vv}{}\|_\tt}\,d\tt.\]

\end{proof}

\lin

\begin{lem}
Given the conditions and notation of Lemma \ref{subsec::Well-:Lem::SDEWP}, assume that \(\X\cind{}\tp{0} = \alt{\X}{}{0}\) almost surely. Then,

\[\sup_{\v \in V} \ex{\left\|\Fpo(\X\cind{}\tip{})\cind{\v} - \Fpo(\alt{\X}{}{})\cind{\v}\right\|_\t} \leq (\degr+1)\const{1}\int_0^\t \sup_{\v \in V} \ex{\|\X\cind{\v}\tip{} - \alt{\X}{\v}{}\|_\tt}\,d\tt.\]
\label{subsec::Well-:Lem::GronwallPrep}
\end{lem}
\labe{subsec::Well-:Lem::GronwallPrep}

\purpose Provides a nice Gronwall-like inequality for use in proving Proposition \ref{subsec::Well-:Prop::SDEWP}.

\usein Proposition \ref{subsec::Well-:Prop::SDEWP}.

\app Lemma \ref{subsec::Well-:Lem::SDEWP} and Assumption \ref{subsec::Assum:Assu::CI}.

\begin{proof}
By statement 3 of Assumption \ref{subsec::Assum:Assu::CI}, every node \(v \in V\) has degree less than or equal to \(\degr\). By Lemma \ref{subsec::Well-:Lem::SDEWP},

\begin{align*}
\sup_{\v \in V} \ex{\left\|\Fpo(\X\cind{}\tip{})\cind{\v} - \Fpo(\alt{\X}{}{})\cind{\v}\right\|_\t} &\leq \sup_{\v\in V}\left(\ex{|\X\cind{\v}\tp{0} - \alt{\X}{\v}{0}|} +  \const{1}\int_0^\t \sum_{\vv\in \cl{\v}} \ex{\|\X\cind{\vv}\tip{} - \alt{\X}{\vv}{}\|_\tt}\,d\tt\right)\\
&=\sup_{\v \in V} \const{1}\int_0^\t \sum_{\vv \in \cl{\v}} \ex{\|\X\cind{\vv}\tip{} - \alt{\X}{\vv}{}\|_\tt}\,d\tt\\
&\leq \const{1}\int_0^\t \sup_{\v \in V}\sum_{\vv \in \cl{\v}} \ex{\|\X\cind{\vv}\tip{} - \alt{\X}{\vv}{}\|_\tt}\,d\tt\\
&\leq \const{1}\int_0^\t \sup_{\v \in V}\sum_{\vv \in \cl{\v}}\sup_{\vvv\in V} \ex{\|\X\cind{\vvv}\tip{} - \alt{\X}{\vvv}{}\|_\tt}\,d\tt\\
&= \const{1}\int_0^\t \sup_{\v \in V}(\degr+1)\sup_{\vvv\in V} \ex{\|\X\cind{\vvv}\tip{} - \alt{\X}{\vvv}{}\|_\tt}\,d\tt\\
&= (\degr+1)\const{1}\int_0^\t \sup_{\v\in V} \ex{\|\X\cind{\v}\tip{} - \alt{\X}{\v}{}\|_\tt}\,d\tt\\
\end{align*}
\end{proof}
\lin

\begin{proof}[Proof of Proposition \ref{subsec::Well-:Prop::SDEWP}]

This proof is fairly standard. We begin by proving uniqueness. Suppose \(\X\cind{}\tip{}\) and \(\alt{\X}{}{}\) are both strong solutions to equation \ref{subsec::Well-:Eqn::SDE}. Let \(\Fpo\) be the mapping introduced in Lemmas \ref{subsec::Well-:Lem::SDEWP} and \ref{subsec::Well-:Lem::GronwallPrep}. Then,

\[\X\cind{}\tip{} = \Fpo(\X\cind{}\tip{})\te{ and } \alt{\X}{}{} = \Fpo(\alt{\X}{}{}),\]

and \(\X\cind{}\tp{0} = \alt{\X}{}{0}\) almost surely. By Lemma \ref{subsec::Well-:Lem::GronwallPrep}, for any \(\t\in [0,\T]\),

\begin{align*}
\sup_{\v\in V}\ex{\|\X\cind{\v}\tip{} - \alt{\X}{\v}{}\|_\t} \leq (\degr+1)\const{1}\int_0^\t\sup_{\v\in V} \ex{\|\X\cind{\v}\tip{} - \alt{\X}{\v}{}\|_\tt}\,d\tt.
\end{align*}

By Gronwall's inequality, \(\sup_{\v \in V} \ex{\|\X\cind{\v}\tip{} - \alt{\X}{\v}{}\|_\T} = 0\), so \(\X\cind{}\tip{} = \alt{\X}{}{}\) almost surely.

\skipLine

To prove existence, we use Picard iterations. Define \(\X\cind{}\tp{\t}{0} \defeq \X\cind{}\tp{0}\) for all \(\t \in [0,\T]\). Define,

\[\X\cind{}\tip{}{n+1} = \Fpo(\X\cind{}\tip{}{n}).\]

Once again, by Lemma \ref{subsec::Well-:Lem::GronwallPrep},

\[\sup_{\v \in V} \ex{\|\X\cind{\v}\tip{}{n+1} - \X\cind{\v}\tip{}{n}\|_\t} \leq (\degr+1)\const{1} \int_0^\t \sup_{\v \in V} \ex{\|\X\cind{\v}\tip{}{n} - \X\cind{\v}\tip{}{n-1}\|_\tt}\,d\tt\] 

Furthermore, 

\begin{align*}
\ex{\|\X\cind{\v}\tip{}{1} - \X\cind{\v}\tip{}{0}\|_\t} &\leq \ex{\int_\S\int_0^\t |\s|\,\poiss\vind{\v}\left(d\tt,\left(0,\IGr\vind{\v}(\X\cind{}\tp{0},\s)\right],d\s\right)}\\
&\leq \ex{\int_\S\int_0^\t |\s|\,\poiss\vind{\v}\left(d\tt,\left(0,\const{}\right],d\s\right)}\\
&= \const{}\int_\S\int_0^\t |\s|\,d\tt\,\Sm(d\s)\\
&=\const{}\t\int_\S |\s|\,\Sm(\s)\\
&\leq \const{}\t|\S|
\end{align*}

here we use the fact that \(\IGr\vind{\cdot}(\cdot,\cdot)\) is bounded by some \(\const{} < \infty\) which does not depend on \(\v\), and the fact that \(\S\) is finite and \(\Sm\) is a probability measure. This gives us,

\[\sup_{\v \in V}\ex{\|\X\cind{\v}\tip{}{1} - \X\cind{\v}\tip{}{0}\|_\t} \leq \t\const{2} \defeq \t\const{}|\S|\]

Iterating yields

\[\sup_{\v \in V} \ex{\|\X\cind{\v}\tip{}{n+1} - \X\cind{\v}\tip{}{n}\|_\t} \leq \t\const{2}\frac{(\t(\degr+1)\const{1})^n}{(n+1)!}\]

Then,

\begin{align*}
\sum_{n=0}^\infty \sup_{\v \in V} \ex{\|\X\cind{\v}\tip{}{n+1} - \X\cind{\v}\tip{}{n}\|_\T} &= \sum_{n=1}^\infty \frac{\const{2}}{(\degr+1)\const{1}}\frac{(\T(\degr+1)\const{1})^{n}}{n !}\\
& = \frac{\const{2}}{(\degr+1)\const{1}}(e^{\T(\degr+1)\const{1}} - 1) < \infty
\end{align*}


So \(\X\cind{}\tip{}{n} \ra \X\cind{}\tip{}\) for some \(\X\cind{}\tip{}\) componentwise almost surely (fast convergence in expectation implies almost sure convergence). Let 

\[\alt{\X}{}{} = \Fpo(\X\cind{}\tip{}).\]

By Lemma \ref{subsec::Well-:Lem::GronwallPrep}, for any \(n\in\mb{N}\),

\begin{align*}
\sup_{\v \in V} \ex{\|\alt{\X}{\v}{} - \X\cind{\v}\tip{}{n+1}\|_\T} &\leq (\degr+1)\const{1}\int_0^\T \sup_{\v \in V}\ex{\|\X\cind{\v}\tip{} - \X\cind{\v}\tip{}{n}\|_\tt}\,d\tt \\
&\leq \T\const{1}(\degr+1)\sup_{\v\in V} \ex{\|\X\cind{\v}\tip{} - \X\cind{\v}\tip{}{n}\|_\T}.
\end{align*}

Taking a limit as \(n\) goes to infinity on both sides yields

\[\lim_{n\ra\infty} \sup_{\v \in V} \ex{\|\alt{\X}{\v}{} - \X\cind{\v}\tip{}{n}\|_\T} = 0.\]

So \(\X\cind{}\tip{}= \Fpo(\X\cind{}\tip{})\) almost surely.
\end{proof}

\lin

\begin{prop}
Let \(\X\cind{}\tip{}\) be defined as in Proposition \ref{subsec::Well-:Prop::SDEWP}. Suppose Assumption \ref{subsec::Assum:Assu::CI} holds. Then \(\X\cind{}\tip{}\) is the unique Feller process with initial condition \(\X\cind{}\tp{0}\) and infinitesimal generator given by \eqref{subsec::Notat:Eqn::IG}:

\[\IG f(\sv\cind{}\vsi{V}) = \sum_{\v\in V}\sum_{\s \in \S} \IGr\vind{\v}(\sv\cind{}\vsi{V},\s)[f(\sv\cind{}\vsi{V} + \ev\vind{\v}\s) - f(\sv\cind{}\vsi{V})].\]
\label{subsec::Well-:Prop::SDE=IG}
\end{prop}
\labe{subsec::Well-:Prop::SDE=IG}

\purpose This proves the two representations of \(\X\cind{}\tip{}\) are equivalent.

\pfsum We prove \(\X\cind{}\tip{}\) is Feller, then directly apply the bijection between Feller processes and infinitesimal generators given in the appendix. (Proposition \ref{sec::Infin:Thm::Bij}).

\usein Theorem \ref{sec::Main:Thm::Local SDE} (both existence and uniqueness). Lemma \ref{sec::TL:Lem::TightSupport}.

\app Assumption \ref{subsec::Assum:Assu::CI}, Proposition \ref{subsec::Well-:Prop::SDEWP}, Definition \ref{sec::Infin:Def::Feller}, Lemma \ref{subsec::Well-:Lem::SDEWP}, Lemma \ref{sec::TL:Lem::concbd} and Theorem \ref{sec::Infin:Thm::Bij}.

\begin{proof}
First, we show that \(\X\cind{}\tip{}\) is a Feller process. Notice that \(\X\cind{}\tip{}\) conditioned on the event \(\X\cind{}\tp{0} = \sv\cind{}\vsi{V}\) is given by the law of the unique solution (Proposition \ref{subsec::Well-:Prop::SDEWP}) to the equation

\begin{equation}
\X\cind{\v}\tp{\t} = \sv\cind{\v}\vsi{V} + \int_\S\int_0^\t \s\,\poiss\vind{\v}(d\tt,(0,\IGr\vind{\v}(\X\cind{}\tp{\tt-},\s)],d\s).
\label{subsec::Well-:Eqn::condSDE}
\end{equation}
\labe{subsec::Well-:Eqn::condSDE}

For all \(\sv\cind{}\vsi{V}\in\S\carp{V}\), suppose \(\X\cind{}\tp{0}{\sv\cind{}\vsi{V}}\) is the unique strong solution to equation \eqref{subsec::Well-:Eqn::condSDE}. By Definition \ref{sec::Infin:Def::Feller}, we need to prove that for all \(\sv\cind{}\vsi{V}\in \S\carp{V}\),

\begin{enumerate}[(a)]
\item \(\X\cind{}\tp{0}{\sv\cind{}\vsi{V}} = \sv\cind{}\vsi{V}\) almost surely.

\item The mapping \(\sv\cind{}\vsi{V}\mapsto \pr\left(\X\cind{}\tp{0}{\sv\cind{}\vsi{V}}\in A\right)\) is measurable for all \(A\in \F\vsi{\U}\ts{\T}\).

\item \(\pr\left(\X\cind{}\tp{\t+\cdot}{\sv\cind{}\vsi{V}}\in A\middle|\X\cind{}\tp{\tt}{\sv\cind{}\vsi{V}}:\tt \in [0,\t]\right) = \pr\left(\X\cind{}\tp{\cdot}{\X\cind{}\tp{\t}{\sv\cind{}\vsi{V}}} \in A\middle| \X\cind{}\tp{\t}{\sv\cind{}\vsi{V}} \right)\) for all \(A \in \F\vsi{\U}\ts{\T}\).

\item For all \(f \in \cont(\S\carp{V})\) (that is, for all continuous \(f\)), the mapping \(\sv\cind{}\vsi{V}\mapsto \ex{f(\X\cind{}\tp{\t}{\sv\cind{}\vsi{V}})}\) is also continuous for all \(\t\geq 0\).
\end{enumerate}

The proof that \(\X\cind{}\tip{}{\sv\cind{}\vsi{V}}\) satisfies these properties is as follows:

\begin{enumerate}[(a)]
\item This is trivially true.

\item Since \(\S\) is finite, \(\S\carp{V}\) is countably infinite. Thus \(\ms{B}(\S\carp{V})\) is the set of subsets of \(\S\carp{V}\). But then for any \(A \in \F\vsi{\U}\ts{\T}\) and \(E \in \ms{B}([0,1])\), we have \(\S\carp{V} \supseteq \left\{\sv\cind{}\vsi{V}: \pr\left(\X\cind{}\tip{}{\sv\cind{}\vsi{V}} \in A\right) \in E\right\}\), so the mapping is measurable.

\item Notice that we can write,

\[\X\cind{\v}\tp{\t+\cdot}{\sv\cind{}\vsi{V}} = \X\cind{\v}\tp{\t}{\sv\cind{}\vsi{V}} + \int_\S\int_\t{\t+\cdot} \s\,\poiss\vind{\v}(d\tt,(0,\IGr\vind{\v}(\X\cind{}\tp{\tt-}{\sv\cind{}\vsi{V}},\s)],d\s).\]

Let \(\alt{\X}{}{}\) be given by the unique solution to the following equation (Proposition \ref{subsec::Well-:Prop::SDEWP}),

\[\alt{\X}{\v}{\cdot} = \X\cind{\v}\tp{\t}{\sv\cind{}\vsi{V}} + \int_\S \int_0^\cdot \s\,\poiss\vind{\v}(d\tt,(0,\IGr\vind{\v}(\alt{\X}{}{\tt-},\s)],d\s).\]

Then \(\X\cind{}\tp{\t+\cdot}{\sv\cind{}\vsi{V}} \deq \alt{\X}{}{\cdot}\). By the definition of \(\X\cind{}\tip{}{\sv\cind{}\vsi{V}}\), \(\alt{\X}{}{} \deq \X\cind{}\tip{}{\X\cind{}\tp{\t}{\sv\cind{}\vsi{V}}}\) as desired.

\item Let \(\root \in V\). Define the sequence of sets \(V\sln{0}\subset V\sln{1}\subset \cdots \subseteq V\) as follows: let \(V\sln{0} = \{\root\}\). For \(n \geq 1\), let \(V\sln{n+1} = \cl{V\sln{n}}\).

\ind Now suppose for \(\sv\cind{}\vsi{V},\alt{\sv}{}{V}\in \S\carp{V}\),

\begin{align*}
\X\cind{\v}\tp{\t} &= \sv\cind{\v}\vsi{V} + \int_\S\int_0^\t \s\,\poiss\vind{\v}(d\tt\,(0,\IGr\vind{\v}(\X\cind{}\tp{\tt-},\s)],d\s)&\te{ for all } \v \in V\\
\alt{\X}{\v}{\t} &= \alt{\sv}{\v}{V} + \int_\S\int_0^\t \s\,\poiss\vind{\v}(d\tt\,(0,\IGr\vind{\v}(\alt{\X}{}{\tt-},\s)],d\s)&\te{ for all } \v \in V\\
\end{align*}

Then by Lemma \ref{subsec::Well-:Lem::SDEWP},

\[\ex{\|\X\cind{\v}\tip{} - \alt{\X}{\v}{}\|_\t} \leq |\sv\cind{\v}\vsi{V} - \alt{\sv}{\v}{V}| + \const{1}\int_0^\t \sum_{\vv\in \cl{\v}} \ex{\|\X\cind{\vv}\tip{} - \alt{\X}{\vv}{}\|_\tt}\,d\tt\]

for all \(\t \in [0,\T]\).

\ind Unfortunately, we cannot just directly apply Gronwall's inequality to the supremum of the above expression. This is because we are trying to prove continuity with respect to the topology of pointwise convergence. Instead, let \(\b > \degr\) and let \(\{\b\cind{\v}\}_{\v \in V}\) be a sequence of positive real numbers defined by \(\b\cind{\v} = \b^{-n}\) if \(\v \in V\sln{n}\setminus V\sln{n-1}\) and \(\b\cind{\root} = 1\). Because the degree of each node in \(G\) is bounded by \(\degr\), we know that \(|V\sln{n}\setminus V\sln{n-1}| \leq \degr^{n}\) for all \(n\in \mb{N}\). Then \(\sum_{\v \in V} \b\cind{\v} \leq \sum_{n=0}^\infty \left(\frac{\degr}{\b}\right)^{n} < \infty\). Since \(\S\) is finite, the norm \(\|\sv\cind{}\vsi{V}\|_{\b} := \sum_{\v \in V} \b\cind{\v}|\sv\cind{\v}\vsi{V}|\) generates the topology of componentwise convergence on \(\S\carp{V}\). We can now apply Gronwall's inequality:

\begin{align*}
\ex{\|\X\cind{}\tip{} - \alt{\X}{}{}\|_{\b,\t}} &= \sum_{\v \in V} \b\cind{\v}\ex{\|\X\cind{\v}\tip{} - \alt{\X}{\v}{}\|_\t}\\
&\leq \|\sv\cind{}\vsi{V} - \alt{\sv}{}{V}\|_{\b} + \sum_{\v \in V}\const{1}\int_0^\t \sum_{\vv \in \cl{\v}} \ex{\b\cind{\v}\|\X\cind{\vv}\tip{} - \alt{\X}{\vv}{}\|_\tt}\,d\tt\\
&\os{\b\cind{\v}\leq \b(\b\cind{\vv})}{\leq} \|\sv\cind{}\vsi{V} - \alt{\sv}{}{V}\|_{\b} + \sum_{\v \in V}\const{1}\int_0^\t \sum_{\vv \in \cl{\v}} \b\ex{\b\cind{\vv}\|\X\cind{\vv}\tip{} - \alt{\X}{\vv}{}\|_\tt}\,d\tt\\
&= \|\sv\cind{}\vsi{V} - \alt{\sv}{}{V}\|_{\b} + \b\const{1}\int_0^\t \sum_{\v \in V}\sum_{\vv \in \cl{\v}} \ex{\b\cind{\vv}\|\X\cind{\vv}\tip{} - \alt{\X}{\vv}{}\|_\tt}\,d\tt\\
&=\|\sv\cind{}\vsi{V} - \alt{\sv}{}{V}\|_{\b} + \b(\degr+1)\const{1}\int_0^\t \ex{\|\X\cind{}\tip{} - \alt{\X}{}{}\|_{\b,\tt}}\,d\tt\\
\end{align*}

Applying Gronwall's inequality:

\[\ex{\|\X\cind{}\tip{} - \alt{\X}{}{}\|_{\b,\T}} \leq \|\sv\cind{}\vsi{V} - \alt{\sv}{}{V}\|_{\b}e^{\T\b(\degr+1)\const{1}}\]

Now, let \(f: \S\carp{V} \ra \mb{R}\) be a continuous function. Since \(\S\carp{V}\) is compact, \(f\) must be uniformly continuous. Then there exists a continuous monotonic function \(\phi: \mb{R}_+ \ra \mb{R}_+\) such that \(\phi(0) = 0\) and \(|f(\sv\cind{}\vsi{V}) - f(\alt{\sv}{}{V})| \leq \phi(|\sv\cind{}\vsi{V} - \alt{\sv}{}{V}|)\) for all \(\sv\cind{}\vsi{V},\alt{\sv}{}{V}\in \S\carp{V}\). Furthermore, since \(f\) is necessarily bounded, we can assume that \(\phi\) is bounded.

\ind Fix any \(\ep > 0\). Let \(\psi\) be a concave, monotonic, upper-bound of \(\phi\) such that \(\psi(0) = 0\) (see Lemma \ref{sec::TL:Lem::concbd}). By Jensen's inequality,

\begin{align*}
\ex{\|f(\X\cind{}\tip{}) - f(\alt{\X}{}{})\|_\T} &\leq \ex{\psi\left(\|\X\cind{}\tip{} - \alt{\X}{}{}\|_{\T,\b}\right)}\\
&\leq \psi\left(\ex{\|\X\cind{}\tip{} - \alt{\X}{}{}\|_{\T,\b}}\right)\\
&\leq \psi\left(\|\sv\cind{}\vsi{V} - \alt{\sv}{}{V}\|_{\b}e^{\T\b(\degr+1)\const{1}}\right) \os{\sv\cind{}\vsi{V} \ra\alt{\sv}{}{V}}{\ra} \ep.
\end{align*}

This concludes the proof that \(\X\cind{}\tip{}\) is Feller.
\end{enumerate}

Let \(f \in \core\). Recall that \(\core\) is the core of \(\IG\). Then \(f\) can be represented by the SDE

\[f(\X\cind{}\tp{\t}) = f(\X\cind{}\tp{0}) + \sum_{\v \in V} \int_\S\int_0^\t [f(\X\cind{}\tp{\tt-} + \s\ev\vind{\v}) - f(\X\cind{}\tp{\tt-})]\,\poiss\vind{\v}\left(d\tt,(0,\IGr\vind{\v}(\X\cind{}\tp{\tt-},\s)],d\s\right)\]


By Theorem \ref{sec::Infin:Thm::Bij}, the infinitesimal generator of \(\X\cind{}\tip{}\) applied to \(f\) is given by 

\begin{align*}
\IG f(\sv\cind{}\vsi{V}) &= \lim_{\t \searrow 0} \frac{1}{\t} \ex{f(\X\cind{}\tp{\t}) - f(\sv\cind{}\vsi{V})|\X\cind{}\tp{0} = \sv\cind{}\vsi{V}}\\
&= \lim_{\t \searrow 0} \ex{\sum_{\v \in V} \frac{1}{\t}\int_\S\int_0^\t \left[f(\X\cind{}\tp{\tt-} + \s\ev\vind{\v}) - f(\X\cind{}\tp{\tt-})\right]\,\poiss\vind{\v}\left(d\tt,(0,\IGr\vind{\v}(\X\cind{}\tp{\tt-},\s)],d\s\right)\middle|\X\cind{}\tp{0} = \sv\cind{}\vsi{V}}\\
&\os{f \in \mc{D}}{=} \lim_{\t \searrow 0}\sum_{\v \in V} \frac{1}{\t}\int_\S\int_0^\t \ex{\left[f(\X\cind{}\tp{\tt-} + \s\ev\vind{\v}) - f(\X\cind{}\tp{\tt-})\right]\IGr\vind{\v}(\X\cind{}\tp{\tt-},\s)\middle|\X\cind{}\tp{0} = \sv\cind{}\vsi{V}}d\tt\,\Sm(d\s)\\
&\os{\te{Lebesgue Differentiation}}{=} \sum_{\v \in V} \int_\S \IGr\vind{\v}(\sv\cind{}\vsi{V},\s)[f(\sv\cind{}\vsi{V} + \s\ev\vind{\v}) - f(\sv\cind{}\vsi{V})]\,\Sm(d\s)\\
&= \sum_{\v \in V} \sum_{\s \in \S} \IGr\vind{\v}(\sv\cind{}\vsi{V},\s)[f(\sv\cind{}\vsi{V} + \s\ev\vind{\v}) - f(\sv\cind{}\vsi{V})]
\end{align*}
\end{proof}

\lin

\begin{prop}
Suppose Assumption \ref{subsec::Assum:Assu::CI} holds. Let \(\root \in V\) be some node. Let \(V\sln{0} = \{\root\}\) and \(V\sln{n+1} = \cl{V\sln{n}}\) for all \(n \in \mb{N}\). For all \(\U \subseteq V\) and \(\t \in [0,\T]\), let \(\sset\vsi{\U}\ts{\t}\) be embedded in \(\sset\vsi{V}\ts{\t}\) in the standard way. Let \(\X\cind{}\tp{0}{n} = \proj\vsi{V\sln{n}}\ts{0}(\X\cind{}\tp{0})\). For each \(n\in\mb{N}\), let the \(\sset\vsi{V\sln{n}}\ts{\T}\)-valued random element \(\X\cind{}\tip{}{n}\) be the unique Feller process with initial condition \(\X\cind{}\tp{0}{n}\) and infinitesimal generator,

\begin{equation}
\IG\sln{n}f(\sv\cind{}\vsi{V\sln{n}}) = \sum_{\v\in V\sln{n}}\sum_{\s\in \S} \IGr\vind{\v}(\sv\cind{}\vsi{V\sln{n}}, \s)[f(\sv\cind{}\vsi{V\sln{n}} + \s\ev\vind{\v}) - f(\sv\cind{}\vsi{V\sln{n}})]\te{ for all } \sv\cind{}\vsi{V\sln{n}} \in \S\carp{V\sln{n}}.
\label{subsec::Well-:eqn::FinIG}
\end{equation}
\labe{subsec::Well-:eqn::FinIG}

(Here we use the embedding \(\sv\cind{\v}\vsi{V\sln{n}} = \mb{I}_{\v\in V\sln{n}} \sv\cind{\v}\vsi{V\sln{n}}\) for all \(\v \in V\)) Then \(\X\cind{}\tip{}{n} \Rightarrow \X\cind{}\tip{}\).
\label{subsec::Well-:Prop::IGApprox}
\end{prop}
\labe{subsec::Well-:Prop::IGApprox}

\purpose Our goal is to apply the local representation to finite networks. In order for that to work, we must first know that the marginals converge so that representations of the marginals on the infinite network are asymptotically valid for finite networks.

\pfsum Use Theorem \ref{sec::TL:Thm::Tight} to prove that the sequence is tight. Then show that the infinitesimal generators converge using properties of the core. Finally apply Corollary \ref{sec::Infin:Cor::Convergence} from the appendix to obtain weak convergence.

\usein Nowhere (I should write a corollary to Theorem \ref{sec::Main:Thm::Local SDE} making use of this proposition).

\app Assumption \ref{subsec::Assum:Assu::CI}, Proposition \ref{subsec::Well-:Prop::Welldef}, Definition \ref{sec::TL:Def::modulus}, Lemma \ref{sec::TL:Lem::TightSupport}, Theorem \ref{sec::TL:Thm::Tight} and Corollary \ref{sec::Infin:Cor::Convergence}.

\begin{proof}
First, for each \(n\in\mb{N}\), \(\X\cind{}\tip{}{n}\) satisfies Assumption \ref{subsec::Assum:Assu::CI}, so by Proposition \ref{subsec::Well-:Prop::Welldef}, \(\X\cind{}\tip{}{n}\) is uniquely defined by its initial condition \(\X\cind{}\tp{0}{n}\) and its infinitesimal generator \(\IG\sln{n}\).

\ind To prove weak convergence, we first begin by showing that \(\{\X\cind{}\tip{}{n}:n\in \mb{N}\}\) is tight. Note that \(\S\carp{V}\) is compact, so \(\sup_{\sv\cind{}\vsi{V} \in \S\carp{V}} \|\sv\cind{}\vsi{V}\|_{\b} < \infty\) (recall that \(\|\sv\cind{}\vsi{V}\|_{\b} = \sum_{\v \in V} \b\cind{\v} |\sv\cind{\v}\vsi{V}|\) where \(\b\cind{\v} = \b^{-n}\) for some \(\b > \degr\) if \(\v \in V\sln{n}\setminus V\sln{n-1}\)).

\ind Now fix \(\ep > 0\). Let \(\cconst\) be large enough that

\[\sup_{\sv\cind{}\vsi{\left(V\sln{\cconst}\right)^c} \in \S\carp{\left(V\sln{\cconst}\right)^c}} \left\|\sv\cind{}\vsi{\left(V\sln{\cconst}\right)^c}\right\|_{\b} \leq |\S|\sum_{\v \notin V\sln{\cconst}} \b\cind{\v} < \ep/4.\]

Recall from Definition \ref{sec::TL:Def::modulus}, the c\`adl\`ag version of the modulus of continuity is given by,

\[\cmodu{\X\cind{}\tip{}}(\delta) = \inf_{\{\t{\it}\}} \sup_\it \sup_{\tt,\ttt \in [\t{\it-1},\t{\it})} \|\X\cind{}\tp{\tt} - \X\cind{}\tp{\ttt}\|_{\b},\]

where \(\{\t{\it}\} := 0 \leq \t{1} < \t{2} < \cdots < \t{\cdot} = \T\) and \(\min_\it|\t{\it} - \t{\it-1}| > \delta\). Note that \(\X\cind{}\tip{}{n}\) is \(\sset\vsi{V\sln{n}}\ts{\T}\)-valued and can be embedded in \(\sset\vsi{V}\ts{\T}\) the same way we embed \(\S\carp{V\sln{n}}\) in \(\S\carp{V}\): let \(\X\cind{\v}\tip{}{n} \equiv 0\) for \(\v \notin V\sln{n}\). Recall also that \(\proj\vsi{\U}\ts{\T}\) is the projection to \(\sset\vsi{\U}\ts{\T}\) for all \(\U\subseteq V\). Then for any \(n\in \mb{N}\),

\begin{align*}
\pr\left(\sup_n \cmodu{\X\cind{}\tip{}{n}}(\delta) > \epsilon\right) &= \pr\left(\sup_n\inf_{\{\t{\it}\}}\sup_\it\sup_{\tt,\ttt \in [\t{\it-1},\t{\it})} \sum_{\v \in V} \b\cind{\v}|(\X\cind{\v}\tp{\tt}{n} - \X\cind{\v}\tp{\ttt}{n}| > \epsilon \right)\\
&\leq \pr\left(\sup_n \left(\cmodu{\proj\vsi{V\sln{\cconst}}\ts{\T}(\X\cind{}\tip{}{n})}(\delta) + \cmodu{\proj\vsi{\left(V\sln{\cconst}\right)^c}\ts{\T}(\X\cind{}\tip{}{n})}(\delta)\right) > \ep\right)\\
&\leq \pr\left(\sup_n \cmodu{\proj\vsi{V\sln{\cconst}}\ts{\T}(\X\cind{}\tip{}{n})}(\delta) > \ep/2\right) \os{\delta\searrow 0}{\ra} 0.
\end{align*}

The last inequality arises because

\[\cmodu{\proj\vsi{\left(V\sln{\cconst}\right)^c}\ts{\T}(\X\cind{}\tip{}{n})}(\delta) \leq 2 \sup_{\t\in [0,\T]} \left\|\proj\vsi{\left(V\sln{\cconst}\right)^c}\ts{\T}(\X\cind{}\tip{}{n})\right\|_{\b} \leq 2 \sup_{\sv\cind{}\vsi{\left(V\sln{\cconst}\right)^c} \in \S\carp{\left(V\sln{\cconst}\right)^c}} \left\|\sv\cind{}\vsi{\left(V\sln{\cconst}\right)^c}\right\|_{\b} < \ep/2\]

Finally, the convergence to 0 at the end is the result of a direct application of Lemma \ref{sec::TL:Lem::TightSupport}. Thus, \(\{\X\cind{}\tip{}{n}:n\in \mb{N}\}\) is tight, and therefore relatively compact with respect to the topology of weak convergence (Theorem \ref{sec::TL:Thm::Tight}).

Now, suppose \(f\in \core\). Then for all \(\sv\cind{}\vsi{V} \in \S\carp{V}\),

\begin{align*}
\big|\IG&\sln{n}f(\sv\cind{}\vsi{V}) - \IG f(\sv\cind{}\vsi{V})\big|\\
&= \left|\sum_{\v \in V\sln{n}} \sum_{\s \in \S} \IGr\vind{\v}(\proj\vsi{V\sln{n}}\ts{}(\sv\cind{}\vsi{V}),\s)[f(\sv\cind{}\vsi{V}+\s\ev\vind{\v}) - f(\sv\cind{}\vsi{V})] - \sum_{\v \in V}\sum_{\s \in \S} \IGr\vind{\v}(\sv\cind{}\vsi{V},\s)[f(\sv\cind{}\vsi{V}+\s\ev\vind{\v}) - f(\sv\cind{}\vsi{V})]\right|\\
&\leq  \left|\sum_{\v \in V\sln{n}} \sum_{\s \in \S} \IGr\vind{\v}(\proj\vsi{V\sln{n}}\ts{}(\sv\cind{}\vsi{V}),\s)[f(\sv\cind{}\vsi{V}+\s\ev\vind{\v}) - f(\sv\cind{}\vsi{V})] - \sum_{\v \in V\sln{n}}\sum_{\s \in \S} \IGr\vind{\v}(\sv\cind{}\vsi{V},\s)[f(\sv\cind{}\vsi{V}+\s\ev\vind{\v}) - f(\sv\cind{}\vsi{V})]\right|\\
&\ind  +\left|\sum_{\v \notin V\sln{n}} \sum_{\s\in \S} \IGr\vind{\v}(\sv\cind{}\vsi{V},\s)[f(\sv\cind{}\vsi{V}+\s\ev\vind{\v}) - f(\sv\cind{}\vsi{V})]\right|\\
&\leq \sum_{\v \in V\sln{n}}\sum_{\s \in \S} \left|\IGr\vind{\v}(\proj\vsi{V\sln{n}}\ts{}(\sv\cind{}\vsi{V}),\s) - \IGr\vind{\v}(\sv\cind{}\vsi{V},\s)\right|\delt\deltf{\f}\vind{\v} + \sum_{\v \in V\setminus V\sln{n}} \const{}\delt\deltf{\f}\vind{\v}\\
&\os{Assump. \ref{subsec::Assum:Assu::CI}.2}{=} \sum_{\v \in V\sln{n}\setminus V\sln{n-1}} |\S|\const{} \delt\deltf{\f}\vind{\v} + \sum_{\v \in V\setminus V\sln{n}} \const{}\delt\deltf{\f}\vind{\v}\\
&\leq |\S|C\sum_{\v \in V\setminus V\sln{n-1}} \delt\deltf{\f}\vind{\v} \os{n\ra\infty}{\ra} 0.
\end{align*}

Here \(\delt\deltf{\f}\vind{\v} = \sup\left\{|f(\sv\cind{}\vsi{V}) - f(\sv\cind{}\vsi{V} + \s\ev\vind{\v}): \sv\cind{}\vsi{V}\in \S\carp{V},\s \in \S\right\}\) as defined in equation \eqref{subsec::Well-:Eqn::fvar}. By Corollary \ref{sec::Infin:Cor::Convergence}, \(\X\cind{}\tip{}{n}\Rightarrow \X\cind{}\tip{}\).
\end{proof}


\lin
\section{Main Results}
\label{sec::Main}\labe{sec::Main}

Some further notation. Let \(\X\cind{}\tip{[0,\t]}\) denote the trajectory of \(\X\cind{}\tip{}\) on the time interval \([0,\t]\). Similarly, \(\X\cind{}\tip{[0,\t)}\) is \(\X\cind{}\tip{}\) on the interval \([0,\t)\) and so on.

\ind For \(\U \subseteq V\), let \(\dneigh{\U} = \neigh\vind{\U} \cup \neigh\vind{\ov{\U}}\). 

\ind For random elements \(\X\cind{}\tip{},\XX{}{}\) and \(\XXX{}{}\), we say that \(\X\cind{}\tip{}\) is conditionally independent of \(\XX{}{}\) given \(\XXX{}{}\) if \(\X\cind{}\tip{}\perp\XX{}{}|\XXX{}{}\).

\lin

\begin{thms}
Suppose Assumption \ref{subsec::Assum:Assu::CI} holds. Suppose \(\U \subset V\). Let \(\UU =V\setminus \ov{\ov{\U}}\). Let \(\UUU= \dneigh{U}\) and suppose that \(|\UUU| < \infty\). Then for all \(\t < \infty\),

\[\X\cind{\U}\tip{[0,\t)}\perp \X\cind{\UU}\tip{[0,\t)}|\X\cind{\UUU}\tip{[0,\t)}\]
\label{sec::Main:Thm::CI}
\end{thms}
\labe{sec::Main:Thm::CI}

\purpose This property may be of independent interest elsewhere. However, in this paper it is vital because it allows us to use a crucial recursion in the local representation of \(\X\cind{}\tip{}\).

\pfsum See Section \ref{sec::Proof1}.

\lin

\begin{thms}
Let \(\X\cind{}\tip{}\) be a Feller process satisfying Assumption \ref{subsec::Assum:Assu::Local} with infinitesimal generator \(\IG\). Let \(\m{}{}{} = \law(\X\cind{}\tip{})\). Let \(\root\) be the root of \(G\) and let \(\{1,\dots,\degr\}\) be the children of \(\root\) in \(G\). For any \(\sset\vsi{}\ts{} \supseteq\sset\vsi{\tree\sln{1}}\ts{\T}\), \(\t\in (0,\T]\) and \(\mmm{}{}{} \in \pmsr(\sset\vsi{}\ts{})\), define \(\cm{\t}:\sset\vsi{\{\root,1\}}\ts{\t-}\times \pmsr(\sset\vsi{}\ts{}) \ra \pmsr(\sset\vsi{\{2,\dots,\degr\}}\ts{\t-})\) by,

\begin{equation}
\cm{\t}(\x\cind{\{\root,1\}}\tip{[0,\t)},\mmm{}{}{})(\cdot) = \pr{\mmm{}{}{}}\left(\X\cind{\{2,\dots,\degr\}}\tip{[0,\t)} \in \cdot|\X\cind{\{\root,1\}}\tip{[0,\t)} = \x\cind{\{\root,1\}}\tip{[0,\t)}\right).
\label{sec::Main:eqn::gamma}
\end{equation}
\labe{sec::Main:eqn::gamma}

Then there exists a unique solution, \(\alt{\m{}{}{}} \in \pmsr(\sset\vsi{\tree\sln{1}}\ts{\T})\), to the following equation:

\begin{align}
\X\cind{\v}\tp{\t} &= \X\cind{\v}\tp{0} + \int_0^\t\int_\S \s\,\poiss\vind{\v}(d\s,(0,\crate{}(\X\cind{\{\v,\root\}}\tip{[0,\tt)},\s)],d\tt) \te{ for } \v \in \{1,\dots,\degr\}\nonumber\\
\X\cind{\root}\tp{\t} &= \X\cind{\root}\tp{0} + \int_0^\t\int_\S \s\,\poiss\vind{\root}(d\s,(0,\IGr\vind{\root}(\X\cind{}\tp{\tt-},\s)],d\tt)\nonumber\\
\alt{\m{}{}{}} &= \law(\X\cind{}\tip{})
\label{sec::Main:eqn::Local SDE}
\end{align}
\labe{sec::Main:eqn::Local SDE}

where

\[\crate{}(\X\cind{\{\v,\root\}}\tip{[0,\t)},\s) = \exmu{\cm{\t}(\X\cind{\{\v,\root\}}\tip{[0,\t)},\alt{\m{}{}{}})}{\IGr\vind{\root}(\X\cind{}\tp{\t-},\s)}\]

for all \(\s\in \S\). Furthermore, \(\alt{\m{}{}{}} = \proj\vsi{\tree\sln{1}}\ts{\T}(\m{}{}{})\).
\label{sec::Main:Thm::Local SDE}
\end{thms}
\labe{sec::Main:Thm::Local SDE}

\purpose This is the main result of the paper. 

\pfsum See section \ref{sec::Proof2}.

\lin

\section{Proof of Theorem \ref{sec::Main:Thm::CI}}
\label{sec::Proof1}\labe{sec::Proof1}

\pfsum We consider two sets of stopping times. The events driving \(\X\cind{}\tip{}^{\neigh\vind{\U}}\) and the events driving \(\X\cind{}\tip{}^{\neigh\vind{\UU}}\). Because \(|\UUU| < \infty\), these are well behaved. We apply induction by iterating over one of the stopping times along a path in \(\mb{N}^2\). At each inductive step, we combine various properties of conditional independence with a breakdown of each path into its component random elements to prove the result. By combining all possible paths, we change from stopping times to deterministic times. There is a minor adaptation we have to make at the end to change from closed intervals to half-open intervals.

\skipLine

\textbf{Remark:} In this section we will distinguish between the events \(\{\X\cind{}\tip{[0,\t]} = 0\}\) and \(\{\X\cind{}\tip{[0,\t]}\equiv 0\}\). The first event is an event of probability 0 when \(\X\cind{}\tip{}\) is a \(\sset\vsi{\U}\ts{\t}\) or \(\sset\vsi{\U}\ts{\t-}\)-valued random variable for some \(\U\subseteq V\) and \(\t \in [0,\T]\) (because 0 is not a path) while the second event is the event that \(\X\cind{}\tp{\tt} = 0\) for all \(\tt \in [0,\t]\).

\ind Given three random elements \(\X\cind{}\tip{},\XX{}{} \te{ and } \XXX{}{}\), we say \(\X\cind{}\tip{}\perp \XX{}{}\) if \(\X\cind{}\tip{}\) and \(\XX{}{}\) are independent. We say \(\X\cind{}\tip{}\mutex \XX{}{}\) if the events \(\{\X\cind{}\tip{}\neq 0\}\) and \(\{\XX{}{} \neq 0\}\) are mutually exclusive. We say \(\X\cind{}\tip{}\perp \XX{}{}|\XXX{}{}\) if \(\X\cind{}\tip{}\) and \(\XX{}{}\) are conditionally independent given \(\XXX{}{}\).

\lin

\begin{defn}
We define the pair of sequences of stopping times:

\begin{align*}
\rt{i} &= \inf \left\{\t > 0: \poiss\vind{\neigh\vind{\U}}\left([0,\t],(0,\const{}],\S\right) = i\right\}\\
\rtt{j} &= \inf \left\{\t > 0: \poiss\vind{\neigh\vind{\UU}}\left([0,\t],(0,\const{}],\S\right) = j\right\}.
\end{align*}

Here \(\const{}\) is as defined in Assumption \ref{subsec::Assum:Assu::CI}. We also define the set of paths along \(\mb{N}^2\) by,

\begin{align}
\pathset{i}{j} = \{\apath{} \in (\mb{N}^2)^{i+j-1}: &\apath{}(1) = (1,1)\te{, } \apath{}(i+j-1) = (i,j)\te{, and } \nonumber\\
&\apath{}(\it+1) - \apath{}(\it)\in \{\ev\vind{1},\ev\vind{2}\}\te{ for }\it\in \{1,\dots, i+j-2\}\}.
\label{sec::Proof1:eqn::Lambda}
\end{align}
\labe{sec::Proof1:eqn::Lambda}

\(\ev\vind{1},\ev\vind{2}\) are assumed to be the standard basis vectors on \(\mb{N}^2\). We equivalently define a path \(\apath{} \in \pathset{i}{j}\) as an event:

\begin{align}
\apath{}(\it) &= \begin{cases}
\left\{\rt{\apath{1}(\it)} \leq \rtt{\apath{2}(\it)}\right\} &\te{ if } \apath{}(\it+1) - \apath{}(\it) = \ev\vind{1}\\
\left\{\rt{\apath{1}(\it)} > \rtt{\apath{2}(\it)}\right\} &\te{ if } \apath{}(\it+1) - \apath{}(\it) = \ev\vind{2}
\end{cases}\\
\apath{} &= \bigcap_{\it=1}^{i+j-2} \apath{}(\it)
\label{sec::Proof1:eqn::Gamma}
\end{align}
\labe{sec::Proof1:eqn::Gamma}
\label{sec::Proof1:Def::GammaLambda}
\end{defn}
\labe{sec::Proof1:Def::GammaLambda}

\purpose The core of the proof of Theorem \ref{sec::Main:Thm::CI} comes from iterating over these stopping times in such a way that no stopping time gets too large with respect to the other. \(\apath{}\) tracks the route taken while \(\pathset{i}{j}\) is the set of all possible values of \(\apath{}\) given the current state of induction.

\lin

\begin{lem}
For all \((i,j)\in \mb{N}_0^2\) and \(\apath{} \in \pathset{i}{j}\),

\[\X\cind{\U}\tip{[0,\rt{i})}\mb{I}_{\apath{}}\perp \X\cind{\UU}\tip{[0,\rtt{j})}\mb{I}_{\apath{}}|\left(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{\it})},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{j})}\right)\mb{I}_{\apath{}}\]
\label{sec::Proof1:Lem::Induction}
\end{lem}
\labe{sec::Proof1:Lem::Induction}

\purpose This is the inductive step on the stopping times given a certain path of induction.

\pfsum Using Lemma \ref{sec::Proof1:Lem::Decomposition}, we break \(\X\cind{}\tip{}\) into its component random elements and manipulate it using the properties of conditional independence proven in Appendix \ref{sec::TL}.

\lin

\begin{lem}
For all \((i,j)\in \mb{N}^2\), there exist measurable mappings \(\phi\) and \(\psi\) such that 

\begin{equation}
\X\cind{\U}\tip{[0,\rt{i+1})} = \phi\left(\X\cind{\cl{\U}}\tip{[0,\rt{i}]}, \poiss\vind{\U}\left((\rt{i}, \rt{i+1}]\times \mb{R}\times \S\right)\right)
\label{sec::Proof1:eqn::XU forward map}
\end{equation}
\labe{sec::Proof1:eqn::XU forward map}

and

\begin{equation}
\X\cind{\UU}\tip{[0,\rtt{j+1})} = \phi\left(\X\cind{\cl{\UU}}\tip{[0,\rtt{j}]}, \poiss\vind{\UU}\left((\rtt{j}, \rtt{j+1}]\times \mb{R}\times \S\right)\right)
\label{sec::Proof1:eqn::XW forward map}
\end{equation}
\labe{sec::Proof1:eqn::XW forward map}

\label{sec::Proof1:Lem::Decomposition}
\end{lem}
\labe{sec::Proof1:Lem::Decomposition}

\purpose This is an intermediate step required to prove Lemma \ref{sec::Proof1:Lem::Induction}.

\pfsum Take the SDE definition of \(\X\cind{}\tip{}\). Use the existence of a unique solution to break down exactly which random elements need to be known to derive \(\X\cind{\U}\tip{[0,\rt{i+1})}\). The same idea holds for \(\X\cind{\UU}\tip{[0,\rtt{j+1})}\).


\begin{proof}
By symmetry, it suffices to prove that equation \ref{sec::Proof1:eqn::XU forward map} holds (if we proof equation \eqref{sec::Proof1:eqn::XU forward map} holds for all \(\U \subseteq V\), then we can proof equation \eqref{sec::Proof1:eqn::XW forward map} holds by swapping the definitions of \(\U\) and \(\UU\)). By Proposition \ref{subsec::Well-:Prop::SDEWP}, for any sequence of i.i.d. Poisson processes, \(\poisses\), on \(\mb{R}^2\times \S\) with intensity measure \(\leb\times\Sm\) we can write,

\[\X\cind{\v}\tp{\t} = \X\cind{\v}\tp{0} + \int_\S\int_0^\t \s\,\poiss\vind{\v}\left(d\tt,\left(0,\IGr\vind{\v}(\X\cind{}\tp{\tt-},\s)\right],d\s\right)\te{ for all } \v\in V.\]

Consider the following coupled equations:

\begin{align}
\XX{\vv}{\t} &= \X\cind{\vv}\tp{\rt{i}} + \int_\S\int_0^\t \s\alt{\poiss}{\vv}\left(d\tt,\left(0,\IGr\vind{\vv}(\XX{}{\tt-},\s)\right],d\s\right)\te{ for } \vv \in \cl{\U} \te{ on } \rt{i} < \infty \label{sec::Proof1:eqn::alternate SDE}\\
\XX{\vv}{} &\equiv 0\te{ for } \vv\notin \cl{\U}\nonumber\\
\alt{\poiss}{\vv}(d\tt,d\r,d\s) &= \poiss\vind{\vv}(\rt{i} + d\tt,d\r,d\s) \te{ for all }\vv\in \cl{\U}\nonumber\\
\alt{\X}{\vv}{\t} &= \begin{cases}
\X\cind{\vv}\tp{\t} &\te{ on } \t \leq \rt{i}\\
\XX{\vv}{\t - \rt{i}} &\te{ on } \t > \rt{i}
\end{cases} \te{ for all } \vv\in \cl{\U} \nonumber
\end{align}
\labe{sec::Proof1:eqn::alternate SDE}

It's easy to see that \(\rt{i}\) is almost surely finite for every finite \(i\) \(\left(\ex{\rt{i}} = \frac{i}{\const{}|\neigh\vind{\U}|} < \infty\right)\). 

\ind \tr{Originally I used the strong Markov property to reduce to the case of \(i = 0\). However, since \(\rt{i}\) is not an \(\X\cind{}\tip{}\)-stopping time, I need to show that \(\X\cind{}\tip{}\) is strong-Markov or Feller with respect to the larger filtration containing the driving Poisson processes. While this is not that difficult, the argument is tedious and long, so I chose not to use this reduction.}

\ind By Proposition \ref{subsec::Well-:Prop::SDEWP}, equation \eqref{sec::Proof1:eqn::alternate SDE} has a unique solution, so \(\alt{\X}{}{}\) is well-defined. To prove this lemma, we first show that \(\X\cind{\U}\tip{[0,\rt{i+1})} = \alt{\X}{\U}{}{[0,\rt{i+1})}\) almost surely. 

\ind Fix any \(\t > 0\). Let \(\evnt{\t} = \{\t < \rt{i+1}\}\) and \(\alt{\evnt}{	} = \{\t\in [\rt{i},\rt{i+1})\}\). Notice that \(\evnt{\tt} \supseteq \evnt{\t}\) for all \(\tt\in [0,\t]\) when \(\t > 0\). 

\ind Notice that \(\rt{i} \perp \poiss\vind{\v}\) for all \(\v \in \U\). Thus, \(\poiss\vind{\v}(d\tt+\rt{i},dr,d\s) \deq \poiss\vind{\v}(d\tt,dr,d\s)\). Now, \(\alt{\X}{\neigh\vind{\U}}{}[0,\rt{i}] = \X\cind{\neigh\vind{\U}}\tip{[0,\rt{i}]}\) almost surely by definition. Furthermore,

\[\alt{\X}{\neigh\vind{\U}}{\t}\mb{I}_{\rt{i}\leq \t < \rt{i+1}} = \alt{\X}{\neigh\vind{\U}}{\rt{i}}\mb{I}_{\rt{i}\leq \t < \rt{i+1}} = \X\cind{\neigh\vind{\U}}\tp{\rt{i}}\mb{I}_{\rt{i}\leq \t < \rt{i+1}} = \X\cind{\neigh\vind{\U}}\tp{\t}\mb{I}_{\rt{i}\leq \t < \rt{i+1}}\]

so

\[\alt{\X}{\neigh\vind{\U}}{}[0,\rt{i+1}) = \X\cind{\neigh\vind{\U}}\tip{[0,\rt{i+1})} \te{ a.t.}\]

Furthermore, by the same argument presented in the beginning of the proof of Lemma \ref{subsec::Well-:Lem::SDEWP}, we can assume without loss of generality that 

\[|\IGr\vind{\v}(\sv\cind{V}\vsi{},\s) - \IGr\vind{\v}(\alt{\sv}{V}{},\s)| \leq \const{}\sum_{\vv\in \cl{\v}} |\sv\cind{V}\vsi{\vv} - \alt{\sv}{V}{\vv}|\te{ for all } \sv\cind{V}\vsi{},\alt{\sv}{V}{}\in \S\carp{V},\s \in \S \te{ and } \v \in V.\]

\tr{For any \(a,b\in \mb{R}\), I use the shorthand \((a,b]\) to denote the interval \((a\wedge b,a\vee b]\)}. Then for all \(v\in \U\) and \(\t > 0\),

\begin{align*}
&\ex{\left\|\alt{\X}{\v}{} - \X\cind{\v}\tip{}\right\|_{\t}\mb{I}_{\t < \rt{i+1}}} = \ex{\left\|\alt{\X}{\v}{} - \X\cind{\v}\tip{}\right\|_{\t}\mb{I}_{\evnt{\t}}}\os{\alt{\X}{\cl{\U}}{}[0,\rt{i}] = \X\cind{\cl{\U}}\tip{[0,\rt{i}]}}{=} \ex{\left\|\alt{\X}{\v}{} - \X\cind{\v}\tip{}\right\|_{\t}\mb{I}_{\alt{\evnt}{	}}}\\
&\ind\leq \ex{\mb{I}_{\alt{\evnt}{	}}\left|\int_\S\int{(\rt{i},\t]} \s\,\poiss\vind{\v}\left(d\tt,\left(0,\IGr\vind{\v}(\X\cind{}\tp{\tt-},\s)\right]\,d\s\right) - \int_\S\int{(\rt{i},\t]} \s\,\alt{\poiss}{\v}\left(d\tt,\left(0,\IGr\vind{\v}(\alt{\X}{}{\tt-},\s)\right]\,d\s\right)\right|}\\
&\ind \leq \ex{\int_\S\int{\mb{R}}\int{(\rt{i},\t]}|\s|\mb{I}_{\alt{\evnt}{	}}\mb{I}_{\r\in \left(\IGr\vind{\v}(\X\cind{}\tp{\tt-},\s), \IGr\vind{\v}(\alt{\X}{}{\tt-},\s)\right]}\,\poiss\vind{\v}\left(d\tt,d\r,d\s\right)}\\
&\ind \os{\alt{\X}{\cl{\U}}{}[0,\rt{i}] = \X\cind{\cl{\U}}\tip{[0,\rt{i}]}}{=} \ex{\int_\S\int{\mb{R}}\int{(0,\t]}|\s|\mb{I}_{\evnt{\t}}\mb{I}_{\r\in \left(\IGr\vind{\v}(\X\cind{}\tp{\tt-},\s), \IGr\vind{\v}(\alt{\X}{}{\tt-},\s)\right]}\,\poiss\vind{\v}\left(d\tt,d\r,d\s\right)}\\
&\ind = \int_\S\int_\mb{R}\int_0^\t |\s|\ex{\mb{I}_{\evnt{\t}}\mb{I}_{\r\in\left(\IGr\vind{\v}(\X\cind{}\tp{\tt-},\s),\IGr\vind{\v}(\alt{\X}{}{\tt-},\s)\right]}}\,d\tt\,d\r\,\Sm(d\s)\\
&\ind = \int_\S |\s|\int_0^\t \ex{\mb{I}_{\evnt{\t}}\left|\IGr\vind{\v}(\alt{\X}{}{\tt-},\s) - \IGr\vind{\v}(\X\cind{}\tp{\tt-},\s)\right|}\,d\tt\,\Sm(d\s)\\
&\ind \leq \const{}\int_\S|\s|\int_0^\t\ex{\mb{I}_{\evnt{\t}}\sum_{\vv\in \cl{\v}}\left|\alt{\X}{\vv}{\tt-} - \X\cind{\vv}\tp{\tt-}\right|}\,d\tt\\
&\ind \os{\mb{I}_{\evnt{\t}}\|\alt{\X}{\neigh\vind{\U}}{} - \X\cind{\neigh\vind{\U}}\tip{}\|_\t = 0}{\leq} \left(\int_\S|\s|\,\Sm(d\s)\right)\const{} \int_0^\t \sum_{\vv\in \cl{\v}\cap\U}\ex{\mb{I}_{\evnt{\t}}\|\alt{\X}{\vv}{} - \X\cind{\vv}\tip{}\|_\tt}\,d\tt\\
&\ind \os{\evnt{\tt} \supseteq \evnt{\t}}{\leq} |\S|\const{}(\degr+1) \int_0^\t \sup_{\v\in \U}\ex{\mb{I}_{\evnt{\tt}}\|\alt{\X}{\v}{} - \X\cind{\v}\tip{}\|_\tt}\,d\tt.
\end{align*}

We can conclude that

\[\sup_{\v\in \U}\ex{\left\|\alt{\X}{\v}{} - \X\cind{\v}\tip{}\right\|_{\t}\mb{I}_{\t <\rt{i+1}}} \leq |\S|\const{}(\degr+1)\int_0^\t\sup_{v\in\U}\ex{\left\|\alt{\X}{\v}{} - \X\cind{\v}\tip{}\right\|_\tt\mb{I}_{\tt < \rt{i+1}}}\,d\tt.\]

By Gronwall's inequality,

\[\sup_{v\in \U}\ex{\left\|\alt{\X}{\v}{} - \X\cind{\v}\tip{}\right\|_\t\mb{I}_{\t < \rt{i+1}}} = 0 \te{ for all } \t > 0,\]

so \(\alt{\X}{\U}{}[0,\rt{i+1}) = \X\cind{\U}\tip{[0,\rt{i+1})}\) almost surely. However, \(\alt{\X}{\U}{}[0,\rt{i+1})\) is uniquely defined by \(\X\cind{\cl{\U}}\tip{[0,\rt{i}]}\) and \(\poiss\vind{\cl{\U}}\left((\rt{i},\rt{i+1}]\times \mb{R}\times \S\right)\).
\end{proof}

\lin

\begin{proof}[Proof of Lemma \ref{sec::Proof1:Lem::Induction}:]
Begin the proof with the base case of \(i=j =1\). \(\pathset{1}{1}\) contains a single element \(\apath{} = ((1,1))\). In addition, \(\mb{I}_{\apath{}} = 1\).

By independence of initial conditions,

\[\X\cind{\U}\tp{0}\perp \X\cind{\UU}\tp{0}|\X\cind{\dneigh{\U}}\tp{0}.\]

\(\rt{1}\) is \(\sigma\left(\poiss\vind{\vv}:\vv\in \neigh\vind{\U}\right)\) measurable and \(\rtt{1}\) is \(\sigma\left(\poiss\vind{\vv}:\vv\in \neigh\vind{\UU}\right)\) measurable. Therefore, both stopping times are independent of each other and of the initial conditions. By Lemma \ref{sec::TL:Lem::Props}(b), 

\[\X\cind{\U}\tp{0}\perp \X\cind{\UU}\tp{0}|\left(\X\cind{\neigh\vind{\U}}\tp{0},\X\cind{\neigh\vind{\UU}}\tp{0},\rt{1},\rtt{1}\right).\]

Since \(\X\cind{\neigh\vind{\U}}\tip{}\) is constant on \([0,\rt{1})\) and \(\X\cind{\neigh\vind{\UU}}\tip{}\) is constant on \([0,\rtt{1})\), the mapping \((\X\cind{\dneigh{\U}}\tp{0},\rt{1},\rtt{1}) \mapsto (\X\cind{\neigh\vind{\U}}\tip{[0,\rt{1})},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{1})})\) is 1-to-1. By Lemma \ref{sec::TL:Lem::Props}(a),

\begin{equation}
\X\cind{\U}\tp{0}\perp \XX{\U}{0}|\left(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{1})},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{1})}\right).
\label{sec::Proof1:eqn::induction_intermediate_1}
\end{equation}
\labe{sec::Proof1:eqn::induction\_intermediate\_1}

By Lemma \ref{sec::Proof1:Lem::Decomposition}, we can express \(\X\cind{\U}\tip{[0,\rt{1})}\) in terms of \(\X\cind{\cl{\U}}\tp{0}\) and \(\poiss\vind{\U}([0,\rt{1})\times\mb{R}\times\S)\). We can equivalently describe \(\X\cind{\U}\tip{[0,\rt{1})}\) in terms of \(\X\cind{\U}\tp{0}\), \(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{1})}\) and \(\poiss\vind{\U}([0,\rt{1})\times \mb{R}\times \S)\) which is independent of all terms in expression \eqref{sec::Proof1:eqn::induction_intermediate_1}. Applying a similar argument for \(\X\cind{\UU}\tip{}\), we can apply Lemmas \ref{sec::TL:Lem::Props}(a) and (e) to get

\[\X\cind{\U}\tip{[0,\rt{1})}\perp \X\cind{\UU}\tip{[0,\rtt{1})}|\left(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{1})},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{1})}\right)\]

This proves that Lemma \ref{sec::Proof1:Lem::Induction} holds in the base case where \(i = j = 1\).

\ind Now, we prove the general case. Suppose Lemma \ref{sec::Proof1:Lem::Induction} holds for \(\alt{\apath{}} \in \pathset{i}{j}\). Then there exists a unique extension, \(\apath{} \in \pathset{i+1}{j}\), of \(\alt{\apath{}}\). It suffices to prove that Lemma \ref{sec::Proof1:Lem::Induction} holds for \(\apath{}\) (by symmetry it will also hold for the unique extension of \(\alt{\apath{}} \te{ to } \pathset{i}{j+1}\)). First, note that

\begin{equation}
\mb{I}_{\apath{}} = \mb{I}_{\alt{\apath{}}}\mb{I}_{\rt{i} \leq \rtt{j}}
\label{sec::Proof1:eqn::extpath}
\end{equation}
\labe{sec::Proof1:eqn::extpath}

By assumption,

\[\X\cind{\U}\tip{[0,\rt{i})}\mb{I}_{\alt{\apath{}}}\perp \X\cind{\UU}\tip{[0,\rtt{j})}\mb{I}_{\alt{\apath{}}}|\left(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{i})},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{j})}\right)\mb{I}_{\alt{\apath{}}}\]

By Lemma \ref{sec::TL:Lem::Props}(d), we can multiply everything by \(\mb{I}_{\rt{i} \leq \rtt{j}}\):

\[\X\cind{\U}\tip{[0,\rt{i})}\mb{I}_{\apath{}}\perp \X\cind{\UU}\tip{[0,\rtt{j})}\mb{I}_{\apath{}}|\left(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{i})},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{j})}\right)\mb{I}_{\apath{}}.\]

By definition of \(\rt{i}\), there is an event in \(\poiss\vind{\neigh\vind{\U}}\) at time \(\rt{i}\) for every \(i \in \mb{ N}\). Let \(\rv\) be the random vector signifying in which node of \(\neigh\vind{\U}\) the event is located as well as the height and mark of the event. Because Poisson processes are simple, \(\rv\) is well-defined. Furthermore, \(\rv\) is independent of all terms in the equation above. We can specifically describe the distribution of \(\rv\). Let \(\rv^1\) be uniform over \(\neigh\vind{\U}\). Let \(\rv^2\) be an \(\S\)-valued random variable with distribution \(\Sm\). Finally, let \(\rv^3\) be a uniform \([0,\const{}]\) random variable. Then, if \(\rv=(\rv^1,\rv^2,\rv^3)\),

\[\X\cind{\neigh\vind{\U}}\tp{\rt{i}} = \begin{cases}
\X\cind{\neigh\vind{\U}}\tp{\rt{i}-} + \rv^2\ev\vind{\rv^1} &\te{ if } \rv^3< \rate{\rv^1}(\X\cind{}\tp{\rt{i}-}, \rv^2)\\
\X\cind{\neigh\vind{\U}}\tp{\rt{i}-} &\te{ otherwise}
\end{cases}\]

Note, because \(\X\cind{}\tip{}\) satisfies assumption \ref{subsec::Assum:Assu::CI}, \(\X\cind{\neigh\vind{\U}}\tp{\rt{i}}\) only depends on \(\X\cind{\cl{\cl{\U}}}\tp{\rt{i}-}\) and \(\rv\). By Lemma \ref{sec::TL:Lem::Props}(c), 

\[\X\cind{\U}\tip{[0,\rt{i})}\mb{I}_{\apath{}}\perp \X\cind{\UU}\tip{[0,\rtt{j})}\mb{I}_{\apath{}}|\left(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{i}]},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{j})}\right)\mb{I}_{\apath{}}.\]

\(\rt{i+1} - \rt{i}\) is \(\sigma(\poiss\vind{\neigh\vind{\U}}(\rt{i},\infty))\) measurable, so it is independent of all terms above. Therefore, by Lemma \ref{sec::TL:Lem::Props}(b),

\[\X\cind{\U}\tip{[0,\rt{i})}\mb{I}_{\apath{}}\perp \X\cind{\UU}\tip{[0,\rtt{j})}\mb{I}_{\apath{}}|\left(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{i}]},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{j})},\rt{i+1} - \rt{i}\right)\mb{I}_{\apath{}}.\]

\(\X\cind{\neigh\vind{\U}}\tip{}\) is constant on \([\rt{i},\rt{i+1})\), so we can use a 1-to-1 function and Lemma \ref{sec::TL:Lem::Props}(a) to reduce the above statement to

\[\X\cind{\U}\tip{[0,\rt{i})}\mb{I}_{\apath{}}\perp \X\cind{\UU}\tip{[0,\rtt{j})}\mb{I}_{\apath{}}|\left(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{i+1})},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{j})}\right)\mb{I}_{\apath{}}.\]

Now, \(\X\cind{\U}\tp{\rt{i}}\) is \(\left(\X\cind{\U}\tip{[0,\rt{i})}, \X\cind{\neigh\vind{\U}}\tip{[0,\rt{i})}, \poiss\vind{\U}(\{\rt{i}\}\times [0,\const{}]\times\S)\right)\) measurable. Applying lemmas \ref{sec::TL:Lem::Props} (a) and (e), we get

\[\X\cind{\U}\tip{[0,\rt{i}]}\mb{I}_{\apath{}}\perp \X\cind{\UU}\tip{[0,\rtt{j})}\mb{I}_{\apath{}}|\left(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{i+1})},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{j})}\right)\mb{I}_{\apath{}}.\]

Combining Lemmas \ref{sec::Proof1:Lem::Decomposition}, \ref{sec::TL:Lem::Props}(a) and \ref{sec::TL:Lem::Props}(e) as in the base case, we get

\[\X\cind{\U}\tip{[0,\rt{i+1})}\mb{I}_{\apath{}}\perp \X\cind{\UU}\tip{[0,\rtt{j})}\mb{I}_{\apath{}}|\left(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{i+1})},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{j})}\right)\mb{I}_{\apath{}}.\]

which completes the proof.
\end{proof}

\lin

\begin{lem}
Notice that for any \((i,j) \in \mb{N}^2\), \(\pathset{i}{j}\) is a space of disjoint events. Define

\[\pathsete{i}{j} := \bigcup_{\apath{}\in\pathset{i}{j}} \apath{}\]

Then \(\pathsete{i}{j}\) differs from \(\{\rt{i} > \rtt{j-1}, \rtt{j} > \rt{i-1}\}\) by a set of probability zero.
\label{sec::Proof1:Lem::Ckk'}
\end{lem}
\labe{sec::Proof1:Lem::Ckk'}

\purpose This allows us to combine all possible paths to get a simple event which we can use to reduce to the deterministic time case.

\pfsum Direct argument.

\begin{proof}
In this proof, we will implicitly work in the equivalence class of events given by \(\evnt{}^1 = \evnt{}^2\) if \(\pr(\evnt{}^1 \triangle \evnt{}^2) = 0\).  

\ind First, \(\pathsete{1}{1} = \{\rt{1} > 0,\rtt{1} > 0\} = \{\rt{1} > \rtt{0},\rtt{1}>\rt{0}\}\). For any \(\it > 1\),

\begin{align*}
\pathsete{\it}{1} &= \bigcup_{\apath{} \in \pathset{\it}{1}} \apath{} = \{((1,1),\dots,(\it,1))\} = \bigcap_{i < \it} \{\rt{i} < \rtt{1}\} = \{\rt{\it-1} < \rtt{1}\} = \{\rt{\it} > \rtt{0},\rtt{1} > \rt{\it-1}\}
\end{align*}

Similarly, \(\pathsete{1}{\it} = \{\rt{1} > \rtt{\it-1}, \rtt{\it} > \rt{0}\}\). Suppose that there exists some \(n\geq 3\) such that

\begin{equation}
\pathsete{i}{j} = \{\rt{i} > \rtt{j-1},\rtt{j} > \rt{i-1}\}
\label{sec::Proof1:eqn::Ckk'}
\end{equation}
\labe{sec::Proof1:eqn::Ckk'}

for all \(i, j\in \mb{N}\) such that \(i+j = n\). Fix one such pair such that both \(i \geq 2\). We know that away from a set of probability zero, \(\{\rt{\cdot}\}\) and \(\{\rtt{\cdot}\}\) are strictly increasing sequences such that \(\rt{\it} \neq \rtt{\it'}\) for all \((\it,\it')\in \mb{N}^2\). By applying equation \eqref{sec::Proof1:eqn::extpath}, we get

\begin{align*}
\pathsete{i}{j+1} &= \left(\pathsete{i-1}{j+1} \cap \{\rt{i - 1} < \rtt{j+1}\}\right) \cup \left(\pathsete{i}{j}\cap \{\rtt{j} < \rt{i}\}\right)\\
&= \{\rt{i - 1} > \rtt{j}, \rtt{j+1} > \rt{i - 2},  \rtt{j+1} > \rt{i -1}\}\cup\{\rt{i} > \rtt{j-1}, \rtt{j} > \rt{i - 1},\rt{i} > \rtt{j}\}\\
&= \{\rt{i - 1} > \rtt{j}, \rtt{j+1} > \rt{i - 1}\}\cup\{\rtt{j} > \rt{i - 1},\rt{i} > \rtt{j}\}\\
&:= \pathsete{i}{j+1}' \cup\pathsete{i}{j+1}''
\end{align*}

Now, it is clear that for any \(\apath{} \in \pathsete{i}{j+1}'\) or \(\apath{} \in \pathsete{i}{j+1}''\), \(\apath{}\in \{\rt{i} > \rtt{j},\rtt{j+1} > \rt{\it-1}\}\);

\[\pathsete{i}{j+1} \subseteq \{\rt{i} > \rtt{j},\rtt{j+1} > \rt{i-1}\}.\]

In the other direction, we can enumerate all orderings of \(\rt{i-1},\rt{i},\rtt{j}\te{ and } \rtt{j+1}\) in \(\{\rt{i} > \rtt{j}, \rtt{j+1} > \rt{\it-1}\}\):

\begin{align*}
\{\rt{i} > \rtt{j},\rtt{j+1} > \rt{i-1}\} &= \{\rt{i-1} < \rtt{j} < \rtt{j+1} < \rt{i}\} \cup \{\rtt{j} < \rt{i-1} < \rtt{j+1} < \rt{i}\}\\
&\cup \{\rt{i-1} < \rtt{j} < \rt{i} < \rtt{j+1}\} \cup \{\rtt{j} < \rt{i-1} <\rt{i} < \rtt{j+1}\}
\end{align*}

Each set in the union above is an element of either \(\pathsete{i}{j+1}'\) or \(\pathsete{i}{j+1}''\). Thus,

\[\pathsete{i}{j+1} = \{\rt{i} > \rtt{j},\rtt{j+1} > \rt{i-1}\}.\]

By an identical argument, \(\pathsete{i+1}{j} = \{\rtt{j} > \rt{i},\rt{i+1} > \rtt{j-1}\}\) when \(i + j = n\) and \(j \geq 2\).

Then we proved directly that equation \eqref{sec::Proof1:eqn::Ckk'} holds for \(i = j=1\) in which case \(n = 2\). For any \(n > 2\) and any \(i,j\in \mb{N}\) such that \(i + j = n\), one of the following holds:

\begin{itemize}
\item \(\min\{i,j\} = 1\). We've shown directly that equation \eqref{sec::Proof1:eqn::Ckk'} holds in this case.

\item both \(i\) and \(j\) are greater than 2. In this case, we can inductively assume that equation \eqref{sec::Proof1:eqn::Ckk'} holds for \(\pathsete{i-1}{j}\) and \(\pathsete{i}{j-1}\). In this case we've proven that it also holds for \(\pathsete{i}{j}\).
\end{itemize}

So by induction, equation \eqref{sec::Proof1:eqn::Ckk'} holds for all \(i,j\in \mb{N}\).
\end{proof}

\lin

\begin{proof}[Proof of Theorem \ref{sec::Main:Thm::CI}]

Fix \((i,j) \in \mb{N}^2\). By Lemma \ref{sec::Proof1:Lem::Induction}, 

\[\X\cind{\U}\tip{[0,\rt{i})}\mb{I}_{\apath{}}\perp \X\cind{\UU}\tip{[0,\rtt{j})}\mb{I}_{\apath{}}\big|\left(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{i})},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{j})}\right)\mb{I}_{\apath{}}\te{ for all }\apath{} \in \pathset{i}{j}.\]

Notice that all terms have disjoint support for different \(\apath{}\). By Lemma \ref{sec::TL:Lem::Props}(f), 

\[\sum_{\apath{}\in\pathset{i}{j}}\X\cind{\U}\tip{[0,\rt{i})}\mb{I}_{\apath{}}\perp \sum_{\apath{}\in\pathset{i}{j}}\X\cind{\UU}\tip{[0,\rtt{j})}\mb{I}_{\apath{}}\bigg|\sum_{\apath{}\in\pathset{i}{j}}\left(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{i})},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{j})}\right)\mb{I}_{\apath{}}\te{ for all }\apath{} \in \pathset{i}{j}.\]

By Lemma \ref{sec::Proof1:Lem::Ckk'}, this simplifies to 

\begin{equation}
\X\cind{\U}\tip{[0,\rt{i})}\mb{I}_{\pathsete{i}{j}}\perp \X\cind{\UU}\tip{[0,\rtt{j})}\mb{I}_{\pathsete{i}{j}}\big|\left(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{i})},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{j})}\right)\mb{I}_{\pathsete{i}{j}}.
\label{sec::Proof1:eqn::thmint1}
\end{equation}
\labe{sec::Proof1:eqn::thmint1}

Define

\begin{align*}
\pathseted{i}{j}(\t) :&= \pathsete{i}{j}\cap \{\rt{i-1}\leq \t < \rt{i}\}\cap \{\rtt{j-1} \leq \t < \rtt{j}\}\\
&=\pathsete{i}{j}\cap\{\rt{i-1}\vee\rtt{j-1} \leq \t < \rt{i}\wedge \rtt{j}\}\\
&=\{\rt{i-1}\vee\rtt{j-1}  < \rt{i}\wedge \rtt{j}\} \cap \{\rt{i-1}\vee\rtt{j-1} \leq \t < \rt{i}\wedge \rtt{j}\}\\
&= \{\rt{i-1}\vee\rtt{j-1} \leq \t < \rt{i}\wedge \rtt{j}\}.
\end{align*}

It should be clear that for any \(\t > 0\), \(\{\pathseted{i}{j}(\t)\}_{(i,j)\in\mb{N}_0^2}\) forms a partition of all possible events up to an event of probability zero (the event that two stopping times coincide). Furthermore, for any \(\t > 0\) and \(i,j\in \mb{N}\), \(\mb{I}_{\pathsete{i}{j}}\mb{I}_{\pathseted{i}{j}} = \mb{I}_{\pathseted{i}{j}}\).

\ind Fix \(\t \geq 0\) and apply Lemma \ref{sec::TL:Lem::Props}(d) by multiplying equation\eqref{sec::Proof1:eqn::thmint1} by \(\mb{I}_{\pathseted{i}{j}}\) to get

\[\X\cind{\U}\tip{[0,\rt{i})}\mb{I}_{\pathseted{i}{j}(\t)}\perp\X\cind{\UU}\tip{[0,\rtt{j})}\mb{I}_{\pathseted{i}{j}(\t)}\big|\left(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{i})},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{j})}\right)\mb{I}_{\pathseted{i}{j}(\t)}.\]


Notice by definition of \(\mb{I}_{\pathseted{i}{j}(\t)}\), \(\X\cind{\U}\tip{[0,\rt{i})}\mb{I}_{\pathseted{i}{j}(\t)} \mapsto \X\cind{\U}\tip{[0,\t]}\mb{I}_{\pathseted{i}{j}(\t)}\) is measurable. We can map \(\X\cind{\UU}\tip{}\) similarly. Finally, \(\left(\X\cind{\neigh\vind{\U}}\tip{[0,\rt{i})},\X\cind{\neigh\vind{\UU}}\tip{[0,\rtt{j})}\right)\mb{I}_{\pathseted{i}{j}(\t)}\mapsto (\X\cind{\dneigh{\U}}\tip{[0,\t]}, \rt{i},\rtt{j})\mb{I}_{\pathseted{i}{j}(\t)}\) is a 1-to-1 mapping. By Lemma \ref{sec::TL:Lem::Props}(a),

\[\X\cind{\U}\tip{[0,\t]}\mb{I}_{\pathseted{i}{j}(\t)}\perp\X\cind{\UU}\tip{[0,\t]}\mb{I}_{\pathseted{i}{j}(\t)}\big|\left(\X\cind{\dneigh{\U}}\tip{[0,\t]},\rt{i},\rtt{j}\right)\mb{I}_{\pathseted{i}{j}(\t)}.\]

But \(\poiss\vind{\dneigh{\U}}\) is a strong Markov process, so 

\[(\rt{i},\rtt{j})\mb{I}_{\pathseted{i}{j}(\t)}\perp \X\cind{}\tip{[0,\t]}\mb{I}_{\pathseted{i}{j}(\t)}|\mb{I}_{\pathseted{i}{j}(\t)}.\]

By Lemma \ref{sec::TL:Lem::Props}(g), this gives us

\[\X\cind{\U}\tip{[0,\t]}\mb{I}_{\pathseted{i}{j}(\t)}\perp\X\cind{\UU}\tip{[0,\t]}\mb{I}_{\pathseted{i}{j}(\t)}\big|\X\cind{\dneigh{\U}}\tip{[0,\t]}\mb{I}_{\pathseted{i}{j}(\t)}.\]

Applying Lemma \ref{sec::TL:Lem::Props}(f),

\[\sum_{(i,j)\in\mb{N}^2}\X\cind{\U}\tip{[0,\t]}\mb{I}_{\pathseted{i}{j}(\t)}\perp\sum_{(i,j)\in\mb{N}^2}\X\cind{\UU}\tip{[0,\t]}\mb{I}_{\pathseted{i}{j}(\t)}\bigg|\sum_{(i,j)\in\mb{N}^2}\X\cind{\dneigh{\U}}\tip{[0,\t]}\mb{I}_{\pathseted{i}{j}(\t)},\]

which simplifies to 

\[\X\cind{\U}\tip{[0,\t]}\perp\X\cind{\UU}\tip{[0,\t]}\big|\X\cind{\dneigh{\U}}\tip{[0,\t]}.\]

Because \(|\dneigh{\U}| < \infty\), the event \(\{\X\cind{\dneigh{\U}}\tp{\t} = \X\cind{\dneigh{\U}}\tp{\t-}\}\) occurs with probability 1 for all \(\t \in [0,\T]\). It is also \(\X\cind{\dneigh{\U}}\tip{[0,\t]}\)-measurable. By Lemma \ref{sec::TL:Lem::Props}(d),

\[\X\cind{\U}\tip{[0,\t]}\mb{I}_{\X\cind{\dneigh{\U}}\tp{\t} = \X\cind{\dneigh{\U}}\tp{\t-}}\perp\X\cind{\UU}\tip{[0,\t]}\mb{I}_{\X\cind{\dneigh{\U}}\tp{\t} = \X\cind{\dneigh{\U}}\tp{\t-}}\big|\X\cind{\dneigh{\U}}\tip{[0,\t]}\mb{I}_{\X\cind{\dneigh{\U}}\tp{\t} = \X\cind{\dneigh{\U}}\tp{\t-}}.\]

Applying Lemma \ref{sec::TL:Lem::Props}(a),

\[\X\cind{\U}\tip{[0,\t)}\mb{I}_{\X\cind{\dneigh{\U}}\tp{\t} = \X\cind{\dneigh{\U}}\tp{\t-}}\perp\X\cind{\UU}\tip{[0,\t)}\mb{I}_{\X\cind{\dneigh{\U}}\tp{\t} = \X\cind{\dneigh{\U}}\tp{\t-}}\big|\X\cind{\dneigh{\U}}\tip{[0,\t)}\mb{I}_{\X\cind{\dneigh{\U}}\tp{\t} = \X\cind{\dneigh{\U}}\tp{\t-}}.\]

Finally, by Lemma \ref{sec::TL:Lem::Props}(h),

\[\X\cind{\U}\tip{[0,\t)}\perp\X\cind{\UU}\tip{[0,\t)}\big|\X\cind{\dneigh{\U}}\tip{[0,\t)}.\]
\end{proof}

\lin

\section{Proof of Theorem \ref{sec::Main:Thm::Local SDE}}
\label{sec::Proof2}\labe{sec::Proof2}

\subsection{Proof of Existence}
\label{subsec::ProofE:sec::Proof2}\labe{subsec::ProofE:sec::Proof2}

\pfsum \(\proj\vsi{\tree\sln{1}}\ts{\T}(\X\cind{}\tip{})\) can be expressed as a sum of a random variable and a non-explosive marked point process. The trick is to find a \(\proj\vsi{\tree\sln{1}}\ts{\T}(\X\cind{}\tip{})\)-measurable intensity for that point process. However, theorems that allow us to do that require that the candidate intensity have certain measurability properties, so we begin by proving those.

\lin

\begin{defn}
Let \(\U\subseteq V\) and suppose \(\X\cind{}\tip{} \in \sset\vsi{\U}\ts{\T-}\) is a stochastic process adapted to its own natural filtration. Then define the marked point process \(\pmap{}(\X\cind{}\tip{})\) as a random measure on \((0,\T) \times \S\carp{\U}\) defined by,

\[\pmap{}(\X\cind{}\tip{})(\{(\rt{},\mark{})\}) = \begin{cases}
1 &\te{ if } \X\cind{}\tp{\rt{}} - \X\cind{}\tp{\rt{}-} = \mark{}\\
0 &\te{ otherwise}
\end{cases}.\]

Similarly, for \(\UU \subseteq \U\), \(\pmap{\UU}(\X\cind{}\tip{}) = \pmap{}\left(\proj\vsi{\UU}\ts{\T}(\X\cind{}\tip{})\right)\). For any \(\v\in \U\), \(\pmap{\v}(\X\cind{}\tip{})\) is a random measure on \((0,\T) \times \S\) given by,

\[\pmap{\v}(\X\cind{}\tip{})(\{(\rt{},\mark{})\}) = \begin{cases}
1 &\te{ if } \X\cind{\v}\tp{\rt{}} - \X\cind{\v}\tp{\rt{}-} = \mark{}\\
0 &\te{ otherwise}
\end{cases},\]

and

\[\pmap{\v}(\X\cind{}\tip{})(\{(\rt{},\mark{}): \X\cind{\v}\tp{\rt{}} - \X\cind{\v}\tp{\rt{}-} \neq \mark{}\}) = 0.\]
\label{subsec::ProofE:Defn::pmap}
\end{defn}
\labe{subsec::ProofE:Defn::pmap}

\lin

\begin{assu}
Let \(\tree\sln{1}\subseteq\U \subseteq V\). Let \(\X\cind{}\tip{}\in \sset\vsi{\U}\ts{\T-}\) be a stochastic process. For each \(\v\in \U\), \(\pmap{\v}(\X\cind{}\tip{})\) has an \(\X\cind{}\tip{}\)-predictable intensity, \(\ratee{\v}\), and there exists a constant \(\const{} < \infty\) such that \(\sup_{\v\in\U} \ratee{\v} \leq \const{}\). Furthermore, \(\lambda: \S\carp{\degr+1}\times \S\ra[0,\const{}]\) is some function.
\label{subsec::ProofE:Assu::Eassu}
\end{assu}
\labe{subsec::ProofE:Assu::Eassu}

\lin

\begin{lem}
Let \(\rp{}\) be an \(\F\vsi{}\ts{}\)-adapted marked point process with \(\F\vsi{}\ts{}\)-predictable intensity \(\ratee{}\) and a countable mark space. For all \(\t \in [0,\T]\), let \(\sigma(\rp{\t}) \subseteq \alt{\F\ts{}}{\t}\subset \F\vsi{}\ts{\t}\) define a subfiltration of \(\F\vsi{}\ts{}\) containing the history of \(\rp{}\). If there exists an \(\Sm\times \pr\)-almost sure left-continuous modification of \(\cratee{}{}(\t,\mark{}) := \ex{\ratee{}(\t,\mark{})|\alt{\F\vsi{}\ts{}}^{\t-}}\) with respect to \(\t\) for all \(\mark{}\) in the mark space, then \(\cratee{}{}\) is the \(\alt{\F\vsi{}\ts{}}\)-predictable intensity of \(\rp{}\).
\label{subsec::ProofE:Lem::filtering}
\end{lem}
\labe{subsec::ProofE:Lem::filtering}

\purpose This allows us to derive a new intensity on the cruder filtration that arises once we project to \(\S\carp{\tree\sln{1}}\).

\begin{proof}
This is a restatement of \cite[Theorem 14.3.III]{DalVer08}.
\end{proof}

\lin

\begin{lem}
Suppose Assumption \ref{subsec::ProofE:Assu::Eassu} holds. Let \(\m{}{}{} = \law(\X\cind{}\tip{})\). Suppose,

\[\crate{\v}{\t}(\s) := \crate{}{}(\X\cind{\{\v,\root\}}\tip{[0,\t)},\s) = \exmu{\cm{\t}(\X\cind{\{\v,\root\}}\tip{[0,\t)},\m{}{}{})}{\IGrg(\X\cind{\tree\sln{1}}\tp{\t-},\s)}.\]


Then \(\crate{\v}{\t}(\s)\) has an almost surely left-continuous modification on \([0,\T)\) with respect to \(\t\) for every \(\v \in \tree\sln{1}\setminus\{\root\}\) and \(\s \in \S\).
\label{subsec::ProofE:Lem::leftmod}
\end{lem}
\labe{subsec::ProofE:Lem::leftmod}

\purpose This is used to prove that \(\crate{}{}\) satisfies the conditions of Lemma \ref{subsec::ProofE:Lem::filtering}.

\pfsum Apply Lemmas \ref{subsec::ProofE:Lem::leftmodgen} and \ref{subsec::ProofE:Lem::bddvar}. The proof is provided after lemma \ref{subsec::ProofE:Lem::bddvar}.

\lin

\begin{defn}
A set \(\evnt{}\) is called elementary with respect to a filtration \(\{\F\vsi{}\ts{\t}\}\) if it is a finite union of sets of the form \((\tt,\t]\times \alt{\evnt}\) where \(\alt{\evnt} \in \F\vsi{}\ts{\tt}\).
\label{subsec::ProofE:Defn::elementary}
\end{defn}
\labe{subsec::ProofE:Defn::elementary}

\purpose This definition is used in the statement of Lemma \ref{subsec::ProofE:Lem::leftmodgen}.

\lin

\begin{lem}
Let \(\X\cind{}\tp{\t}\) be a stochastic process that is left continuous in probability and such that \(\sup_{\evnt{}\te{ elementary}}\ex{\int_0^\T \mb{I}_\evnt{}\,d\X\cind{}\tip{}} < \infty\). Then there exists a left-continuous modification of \(\X\cind{}\tip{}\).
\label{subsec::ProofE:Lem::leftmodgen}
\end{lem}
\labe{subsec::ProofE:Lem::leftmodgen}

\purpose Lemma \ref{subsec::ProofE:Lem::leftmod} is a direct application of this lemma.

\pfsum The website Almost Sure (url: https://almostsure.wordpress.com/2009/12/18/cadlag-modifications/) has a statement of a similar result along with a partial proof. Completing the proof and adapting it to left-continuous modifications instead of c\`adl\`ag functions is simple.

\begin{proof}
This is a completed proof based off of the partial proof provided in the link above.

\ind Fix some \(0\leq a < b < \infty\). Let \(\Tset \subset [0,\T]\) be a finite set. Let \(\upcrs{\alt{\T}}[a,b]\) denote the number of upcrossings of \(\X\cind{}\tip{}\) restricted to \(\alt{\T}\) with respect to the interval \([a,b]\).

\ind It can be shown directly that there exists an elementary set \(\evnt{}\) such that,

\begin{equation}
(b-a)\upcrs{\Tset}[a,b] \leq \int_0^\T \mb{I}_{\evnt}\,d\X\cind{}\tip{} + \max\{a - \X\cind{}\tp{\T},0\}.
\label{subsec::ProofE:eqn::upcrossingineq}
\end{equation}
\labe{subsec::ProofE:eqn::upcrossingineq}

(see https://almostsure.wordpress.com/2009/12/06/upcrossings-downcrossings-and-martingale-convergence/). For every \(M \in [0,\infty)\), define

\[\rt{M}_{\Tset} := \inf\{\t\in \alt{\T}: \X\cind{}\tp{\t} > M\}.\]

Because \(\Tset\) is finite, \(\mb{I}_{(\rt{M}_{\Tset},\T]}\) is an elementary set.

\[\int_0^\T \mb{I}_{(\rt{M}_{\Tset},\T]}\,d\X\cind{}\tip{} = \mb{I}_{\sup_{\t\in \Tset} \X\cind{}\tp{\t} > M}(\X\cind{}\tp{\T} - \X\cind{}\tp{\rt{M}_{\Tset}}) \leq |\X\cind{}\tp{\T}| - M\mb{I}_{\sup_{\t \in \Tset} \X\cind{}\tp{\t} > M}.\]

\[M\mb{I}_{\sup_{\t\in\Tset} \X\cind{}\tp{\t} > M} \leq |\X\cind{}\tp{\T}| - \int_0^T \mb{I}_{(\rt{M}_{\Tset},\T]}\,d\X\cind{}\tip{}.\]


Replacing \(\X\cind{}\tip{}\) by \(-\X\cind{}\tip{}\) gives us the inequality,

\[M\mb{I}_{\inf_{\t\in\Tset} \X\cind{}\tp{\t} < -M} \leq |\X\cind{}\tp{\T}| + \int_0^T \mb{I}_{(\alt\{\rt\}\{M\}\{\Tset\},\T]}\,d\X\cind{}\tip{},\]

where \(\alt\{\rt\}\{M\}\{\Tset\} = \inf\{\t\in \Tset: \X\cind{}\tp{\t} < -M\}\). Summing yields,

\begin{equation}
M\mb{I}_{\sup_{\t\in\Tset}|\X\cind{}\tp{\t}| > M} \leq M\mb{I}_{\sup_{\t\in\Tset}\X\cind{}\tp{\t} > M} + M\mb{I}_{\inf_{\t\in\Tset}\X\cind{}\tp{\t} < -M} \leq 2|\X\cind{}\tp{\T}| + \int_0^\T \mb{I}_{(\alt\{\rt\}\{M\}\{\Tset\},\T]}\,d\X\cind{}\tip{} - \int_0^\T \mb{I}_{(\rt{M}_{\Tset},\T]}\,d\X\cind{}\tip{}
\label{subsec::ProofE:eqn::bdd}
\end{equation}
\labe{subsec::ProofE:eqn::bdd}

By assumption there exists a constant \(\const{} < \infty\) such that \(\ex{\int_0^\T \mb{I}_{\evnt}\,d\X\cind{}\tip{}} \leq \const{}\) for all elementary \(\evnt{}\). Taking an expectation of equations \eqref{subsec::ProofE:eqn::upcrossingineq} and \eqref{subsec::ProofE:eqn::bdd}, we get:

\begin{align}
(b-a)\ex{\upcrs{\Tset}[a,b]} &\leq \const{} + \ex{\max\{a-\X\cind{}\tp{\T},0\}}
\label{subsec::ProofE:eqn::expupcrossingineq}\\
\pr\left(\sup_{\t\in\Tset} |\X\cind{}\tp{\t}| > M\right) &\leq \frac{2}{M}\left(\ex{|\X\cind{}\tp{\T}|} + \const{}\right)
\label{subsec::ProofE:eqn::expbdd}
\end{align}
\labe{subsec::ProofE:eqn::expupcrossingineq}

\labe{subsec::ProofE:eqn::expbdd}

By the monotone convergence theorem, equations \eqref{subsec::ProofE:eqn::expupcrossingineq} and \eqref{subsec::ProofE:eqn::expbdd} hold for any countable \(\Tset\). Assume \(\Tset\) is dense. Furthermore, the right side of both equations is constant (with respect to \(\Tset\)). Thus, for any \(a < b \in \mb{Q}\), \(\upcrs{\Tset}[a,b]\) is almost surely finite and \(\X\cind{}\tip{}\) is almost surely bounded on \(\Tset\).

\ind Because \(\X\cind{}\tip{}\) is bounded on \(\Tset\) and because \(\upcrs{\Tset}[a,b]\) is almost surely finite for all rational \(a < b\), we can conclude that \(\lim_{\substack{\tt \nearrow \t\\ \tt \in \Tset}} \X\cind{}\tp{\tt}\) and \(\lim_{\substack{\tt \searrow \t\\ \tt \in \Tset}} \X\cind{}\tp{\tt}\) exist for all \(\t \in [0,\T]\). Define,

\[\XX{}{\t} := \lim_{\substack{\tt \nearrow \t\\\tt \in \Tset}} \X\cind{}\tp{\tt}\te{ for all } \t \in [0,\T].\]

Then \(\XX{}{}\) has left and right limits everywhere and it is almost surely left-continuous. Furthermore, if \(\alt{\XX{}{}}\) is generated by \(\alt{T'}\), where \(\alt{T'}\) is the union of \(\Tset\) and a countable number of points, then \(\XX{}{}\) and \(\alt{\XX{}{}}\) are identical processes. 

\ind For each \(n \in \mb{N}\), let \(\typset\sln{n} \subset [0,\T]\) be defined by,

\[\typset\sln{n} := \left\{\t\in [0,\T]: \pr\left(|\X\cind{}\tp{\t} - \XX{}{\t}| > 1/n\right) > 1/n\right\}.\] 

Suppose \(\typset\sln{n}\) is not finite. Then there exists an increasing or decreasing sequence \(\{\t{\it}:\it\in \mb{N}\}\subseteq \typset\sln{n}\). Since this sequence is contained in the compact interval \([0,\T]\), it is convergent. Without loss of generality, we can enlarge \(\Tset\) to contain this sequence so that

\[\lim_{\it \ra\infty} \X\cind{}\tp{\t{\it}} = \lim_{\it\ra\infty} \XX{}{\t{\it}} \te{ almost surely.}\]

Thus, \(\pr(|\X\cind{}\tp{\t{\it}} - \XX{}{\t{\it}}| > 1/n) \ra 0\), which contradicts the fact that \(\t{\it} \in \typset\sln{n}\) for all \(\it\in\mb{N}\). We can then conclude that,

\[\typset:= \{\t\in [0,\T]: \pr(\X\cind{}\tp{\t} \neq \XX{}{\t}) > 0\} = \cap_{n = 1}^\infty \typset\sln{n}\]

is a finite set. Define,

\[\XXX{}{\t}= \begin{cases}
\XX{}{\t} &\te{ for } \t \notin \typset\\
\X\cind{}\tp{\t} &\te{ otherwise.}
\end{cases}\]

Then \(\XXX{}{}\) differs from \(\XX{}{}\) at an almost surely finite number of points, so left and right limits exist everywhere for \(\XXX{}{}\) and it is left-continuous on \(\typset^c\). Furthermore, by definition, \(\XXX{}{}\) is a modification of \(\X\cind{}\tip{}\). Recall that \(\X\cind{}\tip{}\) is left-continuous in probability. That means,

\[\te{plim}_{\tt\nearrow \t} \X\cind{}\tp{\tt} = \X\cind{}\tp{\t}.\]

More specifically,

\[\te{plim}_{\substack{\tt{\it}\nearrow \t\\\{\tt{\it}\} \subseteq \Tset}} \X\cind{}\tp{\tt{\it}} = \X\cind{}\tp{\t}\]

Convergence in probability implies almost sure convergence of a subsequence:

\[\lim_{\substack{\tt{\it\sln{i}} \nearrow \t\\\{\tt{\it}\}\subseteq \Tset}} \X\cind{}\tp{\tt{\it\sln{i}}} = \X\cind{}\tp{\t} = \XX{}{\t} \te{ almost surely.}\]

By definition of \(\XXX{}{}\), \(\XXX{}{\t} = \XX{}{\t}\) almost surely for every \(\t \in (0,\T]\). However, by definition, \(\XXX{}{}\) and \(\XX{}{}\) can only differ at a finite number of points, so \(\XXX{}{}\) and \(\XX{}{}\) must be indistinguishable processes on \((0,\T]\). Since \(\XX{}{}\) is left-continuous, it follows that \(\XXX{}{}\) is a left-continuous modification of \(\X\cind{}\tip{}\) (note: the value of \(\XXX{}{0}\) has no effect on the left-continuity of the process on \([0,\T]\)).
\end{proof}

\lin

\begin{lem}
Let \(\X\cind{}\tip{},\ratee{}{}\) and \(\rate{}\) satisfy the conditions of Assumption \ref{subsec::ProofE:Assu::Eassu}. Let \(\crate{\v}{\t}(\s)\) be defined as in Lemma \ref{subsec::ProofE:Lem::leftmod}. Then \(\crate{\v}{\t}(\s)\) is left-continuous in probability for \(\v \in \tree\sln{1}\setminus\{\root\}\) and \(\s \in \S\setminus\{0\}\). That is, for every \(\t \in (0,\T]\), \(\s \in \S\), \(\ep > 0\) and \(\v\in \{1,\dots,\degr\}\),

\[\lim_{\tt \nearrow \t}\pr\left(|\crate{\v}{\t}(\s)- \crate{\v}{\t-\tt}(\s)| > \ep\right) = 0.\]

Furthermore, consider the event,

\[\evnt{\U}{\tt,\t} := \{\X\cind{\U}\tip{} \te{ is constant over the interval } [\t-\tt,\t)\}.\]

Then there exists an \(O(\tt)\) function, \(f:[0,\infty)\ra[0,\infty)\), such that 

\[\mb{I}_{\evnt{\{\v,\root\}}{\tt,\t}}|\crate{\v}{\t}(\s) - \crate{\v}{\t-\tt}(\s)| \leq f(\tt) \te{ almost surely.}\]
\label{subsec::ProofE:Lem::pleft}
\end{lem}
\labe{subsec::ProofE:Lem::pleft}

\purpose This is one of the conditions of Lemma \ref{subsec::ProofE:Lem::leftmodgen}.

\pfsum Use the fact that over any small interval \([\t-\tt,\t)\), \(\X^U\) is constant with high probability for all finite \(U\). Thus \(\crate{v}{\t-\tt}\) will vary by only a tiny amount from \(\crate{v}{\t}\) with very high probability. We can actually estimate how quickly this probability converges to 1 as a function of \(s\).

\begin{proof}
Fix \(\v\in V\). By Assumption \ref{subsec::ProofE:Assu::Eassu}, \(\pmap{}(\X\cind{\{\v,\root\}}\tip{})\) has intensity bounded from above by \(2\const{}\). Therefore, for every \(\t > 0\) there almost surely exists an \(\tt\) small enough such that \(\evnt{}^{\{\v,\root\}}_{\tt,\t}\) holds. Fix \(\tt < \t\). Let \(\const{}\) be the upper bound of \(\rate{}\). Fix any \(\s\in \S\). We begin by computing

\[\ex{\mb{I}_{\evnt{}^{\{\v,\root\}}_{\tt,\t}}|\crate{\v}{\t}(\s) - \crate{\v}{\t-\tt}(\s)|}.\]

Fix some \(\x\cind{}\tip{}\in \evnt{}^{\{\v,\root\}}_{\tt,\t}\). Let 

\[\alt{\evnt}{	} = \{\X\cind{\{\root,1\}}\tip{[0,\t)} = \x\cind{\{\v,\root\}}\tip{[0,\t)}\}.\]

Then we will write,

\begin{align*}
\crate{\v}{\t}(\x\cind{}\tip{},\s) &:=\crate{}{}(\x\cind{\{\v,\root\}}\tip{[0,\t)},\s) = \ex{\rate{}(\X\cind{\tree\sln{1}}\tp{\t-},\s)|\alt{\evnt}{	}}\\
\crate{\v}{\t-\tt}(\x\cind{}\tip{},\s) &:= \crate{}{}(\x\cind{\{\v,\root\}}\tip{[0,\t-\tt)},\s) = \ex{\rate{}(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-},\s)|\alt{\evnt}{\t-\tt}}
\end{align*}

Then,

\begin{align*}
\crate{\v}{\t}(\x\cind{}\tip{},\s) &= \ex{\rate{}(\X\cind{\tree\sln{1}}\tp{\t-},\s)|\alt{\evnt}{	}}\\
&= \sum_{\sv\cind{}\vsi{\tree\sln{1}} \in \S\carp{\tree\sln{1}}} \rate{}(\sv\cind{}\vsi{\tree\sln{1}},\s)\pr\left(\X\cind{\tree\sln{1}}\tp{\t-} = \sv\cind{}\vsi{\tree\sln{1}}|\alt{\evnt}{	}\right)\\
&= \sum_{\sv\cind{}\vsi{\tree\sln{1}} \in \S\carp{\tree\sln{1}}} \rate{}(\sv\cind{}\vsi{\tree\sln{1}},\s) \sum_{\alt{\sv}{}{\tree\sln{1}} \in \S\carp{\tree\sln{1}}} \pr\left(\X\cind{\tree\sln{1}}\tp{\t-} = \sv\cind{}\vsi{\tree\sln{1}},\X\cind{\tree\sln{1}}\tp{(\t-\tt)-} = \alt{\sv}{}{\tree\sln{1}}|\alt{\evnt}{	}\right)\\
&= \sum_{\sv\cind{}\vsi{\tree\sln{1}},\alt{\sv}{}{\tree\sln{1}} \in \S\carp{\tree\sln{1}}} \rate{}(\sv\cind{}\vsi{\tree\sln{1}},\s)\pr\left(\X\cind{\tree\sln{1}}\tp{\t-} = \sv\cind{}\vsi{\tree\sln{1}}|\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\alt{\sv}{}{\tree\sln{1}},\alt{\evnt}{	}\right)\pr\left(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\alt{\sv}{}{\tree\sln{1}}|\alt{\evnt}{	}\right)\\
\end{align*}

Because the jump rate of \(\pmap{\v}(\X\cind{}\tip{})\) is bounded from above by \(\const{}\) for any \(\v\in\tree\sln{1}\),  when \(\sv\cind{}\vsi{\tree\sln{1}}\neq\alt{\sv}{}{\tree\sln{1}}\), 

\[\pr\left(\X\cind{\tree\sln{1}}\tp{\t-} = \sv\cind{}\vsi{\tree\sln{1}}|\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\alt{\sv}{}{\tree\sln{1}},\alt{\evnt}{	}\right) \leq 1-e^{-\tt(\degr+1)\const{}}\]

and when \(\sv\cind{}\vsi{\tree\sln{1}}=\alt{\sv}{}{\tree\sln{1}}\),

\[\pr\left(\X\cind{\tree\sln{1}}\tp{\t-} = \sv\cind{}\vsi{\tree\sln{1}}|\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\alt{\sv}{}{\tree\sln{1}},\alt{\evnt}{	}\right) \geq e^{-\tt(\degr+1)\const{}}.\]

So,

\begin{equation}
e^{-\tt(\degr+1)\const{}}\sum_{\sv\cind{}\vsi{\tree\sln{1}}\in \S\carp{\tree\sln{1}}} \rate{}(\sv\cind{}\vsi{\tree\sln{1}},\s)\pr\left(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\sv\cind{}\vsi{\tree\sln{1}}|\alt{\evnt}{	}\right) \leq \crate{\v}{\t}(\x\cind{}\tip{},\s),
\label{subsec::ProofE:eqn::partlowbd}
\end{equation}
\labe{subsec::ProofE:eqn::partlowbd}

and

\begin{align}
\crate{\v}{\t}(\x\cind{}\tip{},\s)&\leq (1 - e^{-\tt(\degr+1)\const{}})\sum_{\sv\cind{}\vsi{\tree\sln{1}}\neq \alt{\sv}{}{\tree\sln{1}} \in \S\carp{\tree\sln{1}}} \rate{}(\sv\cind{}\vsi{\tree\sln{1}},\s)\pr\left(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\alt{\sv}{}{\tree\sln{1}}|\alt{\evnt}{	}\right)\nonumber\\
&\hspace{24 pt} +\sum_{\sv\cind{}\vsi{\tree\sln{1}} \in \S\carp{\tree\sln{1}}} \rate{}(\sv\cind{}\vsi{\tree\sln{1}},\s)\pr\left(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\sv\cind{}\vsi{\tree\sln{1}}|\alt{\evnt}{	}\right)\nonumber\\
&\leq \const{}(1 - e^{-\tt(\degr+1)\const{}})|\S|^{\degr(\degr+1)/2} + \sum_{\sv\cind{}\vsi{\tree\sln{1}} \in \S\carp{\tree\sln{1}}} \rate{}(\sv\cind{}\vsi{\tree\sln{1}},\s)\pr\left(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\sv\cind{}\vsi{\tree\sln{1}}|\alt{\evnt}{	}\right)
\label{subsec::ProofE:eqn::partupbd}
\end{align}
\labe{subsec::ProofE:eqn::partupbd}

So we simply need to understand \(\pr\left(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\sv\cind{}\vsi{\tree\sln{1}}|\alt{\evnt}{	}\right)\). Recalling that \(\x\cind{}\tip{} \in \evnt{}^{\{\v,\root\}}_{\tt,\t}\), notice that

\[\alt{\evnt}{	} = \alt{\evnt}{\t-\tt}\cap \evnt{}^{\{\root,1\}}_{\tt,\t}.\]

\begin{align*}
\pr\left(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\sv\cind{}\vsi{\tree\sln{1}}|\alt{\evnt}{	}\right) &= \pr\left(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\sv\cind{}\vsi{\tree\sln{1}}|\alt{\evnt}{\t-\tt},\evnt{}^{\{\root,1\}}_{\tt,\t}\right)\\
&=\pr\left(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\sv\cind{}\vsi{\tree\sln{1}}|\alt{\evnt}{\t-\tt}\right)\frac{\pr\left(\evnt{}^{\{\root,1\}}_{\tt,\t}|\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\sv\cind{}\vsi{\tree\sln{1}},\alt{\evnt}{\t-\tt}\right)}{\pr\left(\evnt{}^{\{\root,1\}}_{\tt,\t}|\alt{\evnt}{\t-\tt}\right)}
\end{align*}

Notice that for any non-null \(\X\cind{\tree\sln{1}}\tip{[0,\t-\tt)}\)-measurable set \(\typset\), 

\[\pr(\evnt{}^{\{\root,1\}}_{\tt,\t}|\typset) \geq e^{-2\tt\const{}}\]

Then,

\begin{align}
e^{-2\tt\const{}}\pr\left(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\sv\cind{}\vsi{\tree\sln{1}}|\alt{\evnt}{\t-\tt}\right) &\leq \pr\left(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\sv\cind{}\vsi{\tree\sln{1}}|\alt{\evnt}{\t}\right)\nonumber\\
&\leq e^{2\tt\const{}}\pr\left(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-}=\sv\cind{}\vsi{\tree\sln{1}}|\alt{\evnt}{\t-\tt}\right).
\label{subsec::ProofE:eqn::secpartbd}
\end{align}
\labe{subsec::ProofE:eqn::secpartbd}

Now

\[\crate{\v}{\t-\tt}(\x\cind{\tree\sln{1}}\tip{},\s) = \ex{\rate{}(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-},\s)|\alt{\evnt}{\t-\tt}} = \sum_{\sv\cind{}\vsi{\tree\sln{1}}\in \S\carp{\tree\sln{1}}}\rate{}(\sv\cind{}\vsi{\tree\sln{1}},\s)\pr\left(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-} = \sv\cind{}\vsi{\tree\sln{1}}|\alt{\evnt}{\t-\tt}\right)\]

Applying equation \eqref{subsec::ProofE:eqn::secpartbd},

\[e^{-2\tt\const{}}\crate{\v}{\t-\tt}(\x\cind{\tree\sln{1}}\tip{},\s) \leq \sum_{\sv\cind{}\vsi{\tree\sln{1}}\in \S\carp{\tree\sln{1}}} \lambda(\sv\cind{}\vsi{\tree\sln{1}},\s)\pr(\X\cind{\tree\sln{1}}\tp{(\t-\tt)-} = \sv\cind{}\vsi{\tree\sln{1}}|\alt{\evnt}{	})\leq e^{2\tt\const{}}\crate{\v}{\t-\tt}(\x\cind{\tree\sln{1}}\tip{},\s)\]

Additionally, we can apply equations \eqref{subsec::ProofE:eqn::partlowbd} and  \eqref{subsec::ProofE:eqn::partupbd} to get,

\[e^{-\tt(\degr+3)\const{}}\crate{\v}{\t-\tt}(\x\cind{\tree\sln{1}}\tip{},\s) \leq \crate{\v}{\t}(\x\cind{\tree\sln{1}}\tip{},\s) \leq \const{}(1 - e^{-\tt(\degr+1)\const{}})|\S|^{\degr(\degr+1)/2} + e^{2\tt\const{}}\crate{\v}{\t-\tt}(\x\cind{\tree\sln{1}}\tip{},\s)\]

Then for all \(\x\cind{}\tip{} \in \evnt{}^{\{\v,\root\}}_{\tt,\t}\), we can bound \(|\crate{\v}{\t}(\x\cind{}\tip{},\s) - \crate{\v}{\t-\tt}(\x\cind{}\tip{},\s)|\):

\begin{align*}
&|\crate{\v}{\t}(\x\cind{}\tip{},\s) - \crate{\v}{\t-\tt}(\x\cind{}\tip{},\s)| \\
&\hspace{24pt}\leq \max\left\{\crate{\v}{\t-\tt}(\x\cind{}\tip{},\s)\left(1 - e^{-\tt(\degr+3)\const{}}\right),\const{}(1-e^{-\tt(\degr+1)\const{}})|\S|^{\degr(\degr+1)/2} + \crate{\v}{\t-\tt}(\x\cind{}\tip{},\s)\left(e^{2\tt\const{}} - 1\right)\right\}\\
&\hspace{24pt}\leq \const{}\max\left\{\left(1 - e^{-\tt(\degr+3)\const{}}\right),(1-e^{-\tt(\degr+1)\const{}})|\S|^{\degr(\degr+1)/2} + \left(e^{2\tt\const{}} - 1\right)\right\}\\
\end{align*}

which is an \(O(\tt)\) function. Then,

\begin{align*}
\ex{|\crate{\v}{\t}(\x\cind{}\tip{},\s) - \crate{\v}{\t-\tt}(\x\cind{}\tip{},\s)|} &\leq \const{}\pr\left(\te{not }\evnt{}^{\{\v,\root\}}_{\tt,\t}\right) + \ex{\mb{I}_{\evnt{}^{\{\v,\root\}}_{\tt,\t}}|\crate{\v}{\t}(\x\cind{}\tip{},\s) - \crate{\v}{\t-\tt}(\x\cind{}\tip{},\s)|}\\
&\leq \const{}(1 - e^{-2\tt\const{}}) + O(\tt) = O(\tt).
\end{align*}

The result follows by Chebyshev's inequality.
\end{proof}

\lin

\begin{lem}
Suppose Assumption \ref{subsec::ProofE:Assu::Eassu} holds. Let \(\crate{\v}{\t}(\s)\) be defined as in Lemma \ref{subsec::ProofE:Lem::leftmod}. Then \(\crate{\v}{\t}(\s)\) is integrable and 

\[\sup_{\typset\te{ elementary}} \ex{\int_0^\T \mb{I}_\typset\,d\crate{\v}{\t}(\s)} < \infty\]
\label{subsec::ProofE:Lem::bddvar}
\end{lem}
\labe{subsec::ProofE:Lem::bddvar}

\purpose This is one of the conditions of Lemma \ref{subsec::ProofE:Lem::leftmodgen}.

\pfsum Look at the variation of \(\crate\) where it is continuous (which is obtained from an estimate in the proof of Lemma \ref{subsec::ProofE:Lem::pleft}) and use the fact that the number of jumps is finite in expectation.

\begin{proof}
Any elementary set can be expressed in the form

\[\typset = \bigcup_{\it = 1}^n [\tt{\it},\t{\it})\times \typset\sln{\it},\]

where \(\{[\tt{\it},\t{\it}):\it=1,\dots,n\}\) are disjoint, if \(\tt{\it} = \t{\it} = 0\), then \([\tt{\it},\t{\it}) = \{0\}\) and \(\typset\sln{\it}\) are all \(\sigma(\crate{\v}{\t}(\s):\s \in \S,\t\in [0,\tt{\it}])\)-measurable. 

By Lemma \ref{subsec::ProofE:Lem::pleft}, there exists a \(\const{1} < \infty\) such that,

\begin{equation}
\mb{I}_{\evnt{}^{\{\v,\root\}}_{\tt,\t}}|\crate{\v}{\t}(\s) - \crate{\v}{\t-\tt}(\s)| \leq \const{1}\tt.
\label{subsec::ProofE:eqn::driftbound}
\end{equation}
\labe{subsec::ProofE:eqn::driftbound}

Furthermore, since \(\crate{\v}{\t}(\s)\) is a \([0,\const{}]\)-valued process, jumps of \(\crate{\v}{\t}(\s)\) are bounded by \(\const{}\). Thus, for any \(n \in \mb{N}\),

\[\mb{I}_{\{\X\cind{\{\v,\root\}}\tip{}\te{ has }n\te{ jumps in } [\t-\tt,\t)\}}|\crate{\v}{\t}(\s) - \crate{\v}{\t-\tt}(\s)|\leq C_1\tt + n \const{}.\]

\tr{This holds even with random times because inequality \eqref{subsec::ProofE:eqn::driftbound} holds for all \(\tt\) almost surely.} Then,

\begin{align*}
\ex{\int_0^\T \mb{I}_\typset\,d\crate{\v}{\t}(\s)} &= \sum_{\it = 1}^n \mb{I}_{	ypset{\it}}\ex{\left|\crate{\v}{\t{k}}(\s) - \crate{\v}{\tt{\it}}(\s)\right|}\\
&\leq \sum_{\it=1}^n \const{1}|\t{\it} - \tt{\it}| + \const{}\ex{\te{\# of jumps of }\X\cind{\{\v,\root\}}\tip{[\tt{\it},\t{\it})}}\\
&\leq \const{1}\T + \const{}\ex{\te{\# of jumps in }\X\cind{\{\v,\root\}}\tip{[0,\T)}}\\
&\leq \const{1}\T + 2\const{}^2\T < \infty.
\end{align*}

Thus,

\[\sup_{\typset\te{ elementary}} \ex{\int_0^\T \mb{I}_\typset\,d\crate{\v}{\t}(\s)} \leq \const{1}\T + 2\const{}^2\T < \infty.\]
\end{proof}

\lin

\begin{proof}[Proof of Lemma \ref{subsec::ProofE:Lem::leftmod}]

By Lemma \ref{subsec::ProofE:Lem::pleft}, \(\crate{\{\v,\root\}}{\t}(\s)\) is left-continuous in probability. By Lemma \ref{subsec::ProofE:Lem::bddvar},

\[\sup_{\typset\te{ elementary}} \ex{\int_0^\T \mb{I}_{\typset}\,d\crate{\v}{\t}(\s)} < \infty.\]

Therefore \(\crate{\v}{\t}(\s)\) satisfies the conditions of Lemma \ref{subsec::ProofE:Lem::leftmodgen}, so there exists a left-continuous modification of \(\crate{\v}{\t}(\s)\).
\end{proof}

\lin

\begin{proof}[Proof of existence in Theorem \ref{sec::Main:Thm::Local SDE}]

Let \(\{\F\vsi{\tree\sln{1}}\ts{\t}:\t\in [0,\T]\}\) be the natural filtration of \(\X\cind{\tree\sln{1}}\tip{}\). Recall that by Proposition \ref{subsec::Well-:Prop::SDE=IG}, \(\X\cind{}\tip{}\) can be expressed as the unique solution to,

\[\X\cind{\v}\tp{\t} = \X\cind{\v}\tp{0} + \int_\S\int_0^\t \s\,\poiss\vind{\v}\left(d\tt,\left(0,c{\v}(\X\cind{}\tp{\tt-},\s)\right],d\s\right) \te{ for all } \v \in V.\]

Then,

\[\left(\proj\vsi{\tree\sln{1}}\ts{\T}(\X\cind{}\tip{})\right)^\t = \left(\proj\vsi{\tree\sln{1}}\ts{\T}(\X\cind{}\tip{})\right)^0 + \sum_{\v \in \tree\sln{1}}\ev\vind{\v}\int_\S\int_0^\t \s\,\poiss\vind{\v}\left(d\tt,\left(0,\IGr\vind{\v}(\X\cind{}\tp{\tt-},\s)\right],d\s\right).\]

However, this is not \(\F\vsi{\tree\sln{1}}\ts{\t}\)-adapted. Let \(\rp{} = \{(\rt{\it},\mark{\it})\} = \pmap{\tree\sln{1}}(\X\cind{}\tip{}).\) Then,

\[\left(\proj\vsi{\tree\sln{1}}\ts{\T}(\X\cind{}\tip{})\right)^\t = \left(\proj\vsi{\tree\sln{1}}\ts{\T}(\X\cind{}\tip{})\right)^0 + \sum_{0 < \rt{\it} \leq \t}\mark{\it}\]

Therefore it suffices to derive the \(\F\vsi{\tree\sln{1}}\ts{\t}\)-intensity of \(\rp{}\). \(\rp{}\) has \(\F\vsi{V}\ts{\t}\)-intensity \(\rate{\rp{}}(\X\cind{}\tp{\t-},\mark{}) := \sum_{\v \in \tree\sln{1}}\sum_{\s\in \S}\mb{I}_{\mark{} = \s\ev\vind{\v}}\IGr\vind{\v}(\X\cind{}\tp{\t-},\s)\). Each \(\IGr\vind{\v}\) is clearly left-continuous in time, so \(\rate{\rp{}}\) is also left-continuous in time. Recall that \(\m{}{}{}\) is the law of \(\X\cind{}\tip{}\). Then,

\[\exmu{\m{}{}{}}{\rate{\rp{}}(\X\cind{}\tp{\t-},\mark{})|\F\vsi{\tree\sln{1}}\ts{\t-}} = \sum_{\v \in \tree\sln{1}}\sum_{\s\in \S} \mb{I}_{\mark{} = \s\ev\vind{\v}}\exmu{\m{}{}{}}{\IGr\vind{\v}(\X\cind{}\tp{\t-},\s)|\F\vsi{\tree\sln{1}}\ts{\t-}}.\]

Applying Theorem \ref{sec::Main:Thm::CI} and symmetry of \(\m{}{}{}\) yields,

\begin{align*}
\exmu{\m{}{}{}}{\IGr\vind{\v}(\X\cind{}\tp{\t-},\s)|\F\vsi{\tree\sln{1}}\ts{\t-}} &= \exmu{\m{}{}{}}{\IGr\vind{\v}(\X\cind{}\tp{\t-},\s)|\X\cind{\tree\sln{1}}\tip{[0,\t)}}\\
&\os{\te{Thm \ref{sec::Main:Thm::CI}}}{=} \exmu{\m{}{}{}}{\IGrg{}(\X\cind{\cl{\v}}\tp{\t-},\s)|\X\cind{\{\v,\root\}}\tip{[0,\t)}} \\
&\os{\te{Sym}}{=} \exmu{\XX{}{}\sim \m{}{}{}}{\IGrg{}(\XX{\tree\sln{1}}{\t-},\s)|\XX{\{\root,1\}}{[0,\t)} = \X\cind{\{\v,\root\}}\tip{[0,\t)}}\\
&= \exmu{\XX{}{}\sim \proj\vsi{\tree\sln{1}}\ts{\T}(\m{}{}{})}{\IGrg{}(\XX{\tree\sln{1}}{\t-},\s)|\XX{\{\root,1\}}{[0,\t)} = \X\cind{\{\v,\root\}}\tip{[0,\t)}}\\
&= \exmu{\cm{\t}\left(\X\cind{\{\v,\root\}}\tip{[0,\t)},\proj\vsi{\tree\sln{1}}\ts{\T}(\m{}{}{})\right)}{\IGrg{}(\X\cind{\tree\sln{1}}\tp{\t-},\s)}\\
&=\crate{}{}(\X\cind{\{\v,\root\}}\tip{[0,\t)},\s) = \crate{\v}{\t}(\s).
\end{align*}

By Lemma \ref{subsec::ProofE:Lem::leftmod}, \(\crate{\v}{\t}(\s)\) has a left-continuous modification. Then, by Lemma \ref{subsec::ProofE:Lem::filtering}, \(\crate{\v}{\t}(\s)\) is a \(\F\vsi{\tree\sln{1}}\ts{}\)-predictable filtration of \(\XX{}{}\).

\ind By lemma \ref{subsec::Some:Lem::PPtoSDE}, we can characterize the law of \(\proj\vsi{\tree\sln{1}}\ts{\T}(\X\cind{}\tip{})\) as the law of the unique solution (given \(\proj\vsi{\tree\sln{1}}\ts{\T}(\m{}{}{})\)) to the SDE

\begin{align*}
\X\cind{\v}\tp{\t} &= \X\cind{\v}\tp{0} + \int_0^\t\int_\S \s\,\poiss\vind{\v}(d\s,(0,\crate{\v}{\tt}(\s)],d\tt) \te{ for } \v \in \{1,\dots,\degr\},\\
\X\cind{\root}\tp{\t} &= \X\cind{\root}\tp{0} + \int_0^\t\int_\S \s\,\poiss\vind{\root}(d\s,(0,\IGr\vind{\root}(\X\cind{}\tp{\tt-},\s)],d\tt).
\end{align*}
\end{proof}

\subsection{Proof of Uniqueness}
\label{subsec::ProofU:sec::Proof2}\labe{subsec::ProofU:sec::Proof2}

\pfsum We start with an arbitrary measure \(\mmm{}{}{1}\) satisfying the characterization provided in Theorem \ref{sec::Main:Thm::Local SDE}. We characterize the density of this measure with respect to a simple process. Using these densities, we extend the process to an infinite dimensional process whose marginal distribution is \(\mmm{}{}{1}\). We then prove this infinite dimensional process is precisely \(\m{}{}{}\).

\begin{proof}[Proof of Theorem \ref{sec::Main:Thm::Local SDE}]

Assume \(\mmm{}{}{1}\) is a probability measure on \(\sset\vsi{\tree\sln{1}}\ts{\T-}\) and suppose that \(\mmm{}{}{1}\) is a solution to equation \eqref{sec::Main:eqn::Local SDE}.

\ind Let \(\X\cind{}\tip{}{1}\) be a process with law \(\mmm{}{}{1}\) embedded in \(\sset\vsi{V}\ts{\T-}\). That is, \(\X\cind{\v}\tip{}{1} \equiv 0\) for \(\v \notin \tree\sln{1}\). Recall that, for \(\v \in \tree\sln{1}\setminus\{\root\}\),

\[\crate{}{}(\X\cind{\{\v,\root\}}\tip{[0,\t)}{1},\s) = \exmu{\cm{\t}(\X\cind{\{\v,\root\}}\tip{[0,\t)}{1},\mmm{}{}{1})}{\IGrg{}(\X\cind{}\tp{\t-}{1},\s)}.\]

\ind We will prove uniqueness of the local SDE by showing that \(\mmm{}{}{1}\) is the marginal distribution of \(\m{}{}{}\), which is the law of \(\X\cind{}\tip{}\) (as defined in equation \eqref{subsec::Notat:Eqn::IG}). To do that, we will construct a sequence of random variables \(\{\X\cind{}\tip{}{n}:n\in\mb{N}\}\) on \(\sset\vsi{\tree\sln{n}}\ts{\T-}\) converging weakly to \(\X\cind{}\tip{}\). 

\lin

\begin{lem}
The marginal distribution of \(\mmm{}{}{1}\) on \(\sset\vsi{\{\v,\root\}}\ts{\T}\) for \(\v \in \tree\sln{1}\setminus\{\root\}\) is the law of the unique solution to the following SDE:

\begin{align}
\X\cind{\{\v,\root\}}\tp{\t}{1} = \X\cind{\{\v,\root\}}\tp{0}{1} &+ \ev\vind{\v}\int_\S\int{(0,\crate{}{}(\X\cind{\{\v,\root\}}\tip{[0,\tt)}{1},\s)]}\int{(0,\t]}\s\,\poiss\vind{\v}(d\tt,d\r,d\s)\nonumber\\
&+ \ev\vind{\root}\int_\S\int{(0,\crate{}{}(\X\cind{\{\root,\v\}}\tip{[0,\tt)}{1},\s)]}\int{(0,\t]}\s\,\poiss\vind{\root}(d\tt,d\r,d\s)
\label{subsec::ProofU:eqn::Marginal}
\end{align}
\labe{subsec::ProofU:eqn::Marginal}
\label{subsec::ProofU:Lem::Marginal}
\end{lem}
\labe{subsec::ProofU:Lem::Marginal}

\purpose This allows us to derive the marginal density of the double neighborhood of \((\tree\sln{n})^c\) for all \(n\). With this marginal density, we can derive conditional intensities that can be used to extend \(\mmm{}{}{1}\) to more nodes.

\pfsum By Lemma \ref{subsec::ProofE:Lem::leftmod}, \(\crate{}{}\) has a left-continuous modification so we can directly apply Lemma \ref{subsec::ProofE:Lem::filtering}.

\begin{proof}
Let \(\rp{} = \pmap{\tree\sln{1}}(\X\cind{}\tip{}{1})\) be defined as in Definition \ref{subsec::ProofE:Defn::pmap}. Then \(\rp{}\) has \(\F\vsi{\tree\sln{1}}\ts{}\)-predictable intensity,

\[\crate{\rp{}}{\t}(\X\cind{}\tip{[0,\t)}{1},\mark{}) = \sum_{\v\in \tree\sln{1}\setminus\{\root\}}\sum_{\s\in \S} \mb{I}_{\mark{} = \s\ev\vind{\v}}\crate{}{}(\X\cind{\{\v,\root\}}\tip{[0,\t)}{1},\s) + \sum_{\s\in\S}\mb{I}_{\mark{} = \s\ev\vind{\root}}\IGr\vind{\root}(\X\cind{}\tp{\t-}{1},\s).\]

Then \(\proj\vsi{\{\v,\root\}}\ts{\T}(\rp{})\defeq \pmap{\{\v,\root\}}(\X\cind{}\tip{}{1})\) \tr{notation?} has \(\F\vsi{\tree\sln{1}}\ts{}\)-predictable intensity,

\[\rate{\proj\vsi{\{\v,\root\}}\ts{\T}(\rp{})}{\t}(\X\cind{}\tip{[0,\t)}{1},\mark{}) \defeq \sum_{\s\in \S} \left(\mb{I}_{\mark{} = \s\ev\vind{\v}}\crate{}{}(\X\cind{\{\v,\root\}}\tip{[0,\t)}{1},\s) + \mb{I}_{\mark{} = \s\ev\vind{\root}}\IGr\vind{\root}(\X\cind{}\tp{\t-}{1},\s)\right)\te{ for } \kappa \in \S\carp{\{\v,\root\}}.\]

Consider the candidate rate \(\crate{\proj\vsi{\{\v,\root\}}\ts{\T}(\rp{})}{\t}\) defined in the following manner:

\begin{align*}
\crate{\proj\vsi{\{\v,\root\}}\ts{\T}(\rp{})}{\t}(\kappa) &= \exmu{\m{}{}{1}}{\rate{\proj\vsi{\{\v,\root\}}\ts{\T}(\rp{})}^{\t}(\X\cind{}\tip{[0,\t)}{1},\kappa)\middle|\F\vsi{\{\v,\root\}}\ts{\t-}}\\
&=\exmu{\m{}{}{1}}{\sum_{\s\in \S}\left(\mb{I}_{\kappa = \s\ev\vind{\v}} \crate{}{}(\X\cind{\{\v,\root\}}\tip{[0,\t)}{1},\s) + \mb{I}_{\kappa = \s\ev\vind{\root}}\IGr\vind{\root}(\X\cind{}\tp{\t-}{1},\s)\right)\middle|\F\vsi{\{\v,\root\}}\ts{\t-}}\\
&=\sum_{\s\in \S}\mb{I}_{\kappa = \s\ev\vind{\v}} \crate{}{}(\X\cind{\{\v,\root\}}\tip{[0,\t)}{1},\s) + \sum_{\s\in \S}\mb{I}_{\kappa = \s\ev\vind{\root}}\exmu{\m{}{}{1}}{\IGr\vind{\root}(\X\cind{}\tp{\t-}{1},\s)\middle|\F\vsi{\{\v,\root\}}\ts{\t-}}\\
&=\sum_{\s\in \S}\mb{I}_{\kappa = \s\ev\vind{\v}} \crate{}{}(\X\cind{\{\v,\root\}}\tip{[0,\t)}{1},\s) + \sum_{\s\in \S}\mb{I}_{\kappa = \s\ev\vind{\root}}\exmu{\XXX{}{} \sim \m{}{}{1}}{\IGrg{}(\XXX{\tree\sln{1}}{\t-},\s)\middle|\XXX{\{\root,\v\}}{[0,\t)} = \X\cind{\{\root,\v\}}\tip{[0,\t)}{1}}\\
&=\sum_{\s\in \S}\mb{I}_{\kappa = \s\ev\vind{\v}} \crate{}{}(\X\cind{\{\v,\root\}}\tip{[0,\t)}{1},\s) + \sum_{\s\in \S}\mb{I}_{\kappa = \s\ev\vind{\root}}\exmu{\cm{\t}(\X\cind{\{\root,\v\}}\tip{[0,\t)}{1},\m{}{}{1})}{\IGrg{}(\X\cind{\tree\sln{1}}\tp{\t-}{1},\s)}\\
&=\sum_{\s\in \S}\left(\mb{I}_{\kappa = \s\ev\vind{\v}} \crate{}{}(\X\cind{\{\v,\root\}}\tip{[0,\t)}{1},\s) + \mb{I}_{\kappa = \s\ev\vind{\root}}\crate{}{}(\X\cind{\{\root,\v\}}\tip{[0,\t)}{1},\s)\right)\\
\end{align*}

Notice that \(\X\cind{}\tip{}{1}\) and \(\rate{}\) satisfy Assumption \ref{subsec::ProofE:Assu::Eassu}. Thus, \(\crate{}{}(\X\cind{\{\root,\v\}}\tip{[0,\t)}{1},\s)\) has a left-continuous modification by Lemma \ref{subsec::ProofE:Lem::leftmod}. Then \(\crate{\proj\vsi{\{\v,\root\}}\ts{\T}(\rp{})}{\t}(\mark{})\) also has a left-continuous modification. By Lemma \ref{subsec::ProofE:Lem::filtering}, \(\crate{\proj\vsi{\{\v,\root\}}\ts{\T}(\rp{})}{\t}(\kappa)\) is the \(\F\vsi{\{\v,\root\}}\ts{}\)-predictable intensity of \(\rp{}\). By Lemma \ref{subsec::Some:Lem::genfiniteSDE}, equation \eqref{subsec::ProofU:eqn::Marginal} has a unique solution and by Lemma \ref{subsec::Some:Lem::PPtoSDE}, that solution has jump intensity given by the above.

\end{proof}

\lin

\tr{TODO::standardize space, time and mark orderings of Poisson processes.}

\begin{defn}
Suppose \(\{\poiss\vind{}\}\) is Poisson process with intensity \(\leb\otimes \Sm\) on \(\mb{R}^2\times \S\). Define,

\[\XX{}{\t} = \XX{}{0} + \int{(0,\t]}\int{(0,1]}\int_\S\s\,\poiss\vind{}(d\s,d\r,d\tt).\]

Let \(\mm{}{}{} = \law(\XX{}{})\). Suppose \(\mmm{\v}{0,}{1}\ll\mm{}{0}{}\) for all \(\v\in\tree\sln{1}\). Let \(\{\mm{\v}{}{}:\v\in V\}\) be the distributions of a sequence of i.i.d. \(\S\carp{\v}\)-valued c\`adl\`ag processes. For any \(\U\subseteq V\), let 

\[\mm{\U}{}{} = \otimes_{\v\in\U} \mm{\v}{}{}.\]

Finally, for any \(\t\in [0,\T)\), let \(\mm{\U}{\t,}{}\) be the restriction of \(\mm{\U}{}{}\) to \(\pmsr(\sset\vsi{\U}\ts{\t-})\). Use a similar system for all measures.
\label{subsec::ProofU:Defn::nu}
\end{defn}
\labe{subsec::ProofU:Defn::nu}

\lin

\begin{lem}
For any \(\v \in V\setminus\{\root\}\), let \(\p{\v}\) be the parent node of \(\v\) (neighboring node of \(\v\) closest to \(\root\)). Fix \(n \in \mb{N}\). Let \(\mmm{}{}{n} \in \pmsr\left(\sset\vsi{\tree\sln{n}}\ts{\T-}\right)\) be the law of the unique solution to the following SDE:

\begin{equation}
\X\cind{\v}\tp{\t} = \begin{cases}
\X\cind{\v}\tp{0} + \int{(0,\t]}\int_\S\int{\left(0,\crate{}{}(\X\cind{\{\v,\p{\v}\}}\tip{[0,\tt)},\s)\right]}\s\,\poiss\vind{\v}(d\r,d\s,d\tt)\te{ if } \v \in \tree\sln{n}\setminus \tree\sln{n-1}\\
\X\cind{\v}\tp{0} + \int{(0,\t]}\int_\S\int{\left(0,\rate{}(\X\cind{\cl{\v}}\tp{\tt-},\s\right)}\s\,\poiss\vind{\v}(d\r,d\s,d\tt)\te{ if } \v \in \tree\sln{n-1}
\end{cases}
\label{subsec::ProofU:eqn::extendedSDE}
\end{equation}
\labe{subsec::ProofU:eqn::extendedSDE}

Then for any \(\alt{n} < n\), \(\mmm{}{\t}{\alt{n}} = \proj\vsi{\tree\sln{\alt{n}}}\ts{\t}(\mmm{}{\t}{n})\).
\label{subsec::ProofU:Lem::extendedSDE}
\end{lem}
\labe{subsec::ProofU:Lem::extendedSDE}

\purpose By constructing larger processes with the whose marginal distribution is \(\mmm{}{}{1}\), we can, in the limit, construct an interacting particle system on \(V\) that projects down to \(\mmm{}{}{}\). All that will remain will be to prove that this process is equal in distribution to \(\m{}{}{}\).

\pfsum Using Lemmas \ref{subsec::ProofU:Lem::Marginal} and \ref{subsec::Some:Lem::radnik} \tr{rrewrite}, we can construct a conditional density which can be used to extend \(\mu\sln{1}\). We can use simple density arguments to prove the marginal properties we can use Lemma \ref{subsec::Some:Lem::radnik} \tr{rrewrite} to get the SDE formulation.

\begin{proof}
\tr{I'm not being consistent about the intervals I am using. Everything is in half open intervals. I should make the final result the same.}

Let \(\mm{}{}{} \in \pmsr(\sset\vsi{V}\ts{\T-})\) be as defined in Definition \ref{subsec::ProofU:Defn::nu}.

\ind Recall that \(\rp{} \defeq \pmap{}(\X\cind{}\tip{}{1})\) maps \(\X\cind{}\tip{}{1}\) to the point process coinciding with the jumps of \(\X\cind{}\tip{}{1}\). This point process has intensity,

\[\ratee{}(\rp{}[0,\t),\mark{}) = \begin{cases}
\crate{}{}(\X\cind{\{\v,\root\}}\tip{[0,\t)}{1},\s) &\te{ if } \v\in \tree\sln{1}\setminus\{\root\}\te{ and } \mark{} = \s\ev\vind{\v}\\
\IGrg{}(\X\cind{\tree\sln{1}}\tp{\t-}{1},\s) &\te{ if } \mark{} = \s\ev\vind{\root}\\
0 &\te{ otherwise}.
\end{cases}\]

Let \(\mm{}{}{1} \defeq \mm{\tree\sln{1}}{}{}\). Then \(\pmap{}(\mm{}{}{1})\) has constant intensity \(\mb{I}_{\kappa \in\{\s\ev\vind{\v}:\s\in\S\setminus\{0\},\v\in\tree\sln{1}\}}\). 

\ind Define the following mapping,

\begin{align}
\ds{\v}{\t}(\XXX{}{},f) &\defeq \sum_{0 < \rt{\it}_\v \leq \t} \log{f(\XXX{}{[0,\rt{\it}_\v)},\mark{\it}_\v)} - \int{(0,\t]\times \S} [f(\XXX{}{[0,\tt)},\s) - 1]\,ds\,\Sm(d\s) \label{subsec::ProofU:eqn::shortdense}\\
f&\te{ is a }[0,\const{}] \te{-valued mapping and } \pmap{\v}(\XXX{}{}) = \{(\rt{\it}_\v,\mark{\it}_\v):\it\in\mb{N}\}.\nonumber
\end{align} 
\labe{subsec::ProofU:eqn::shortdense}

Let \(\{(\rt{\it},\mark{\it})\}\) be the events of \(\pmap{}(\X\cind{}\tip{}{1})\). By Lemma \ref{subsec::Some:Lem::radnik},

\begin{align}
\dense{1}{\t}(\X\cind{\tree\sln{1}}\tip{})&\defeq \frac{d\mmm{}{\t}{1}}{d\mm{}{\t}{1}}\nonumber\\
&= \frac{d\mmm{}{0}{1}}{d\mm{}{0,}{1}}\exp\left(\sum_{0< \rt{\it} \leq \t} \log{\ratee{}(\X\cind{}\tip{[0,\rt{\it})}{1},\mark{\it})} - \int{(0,\t]\times\S} [\ratee{}(\X\cind{}\tip{[0,\tt)}{1},\s) - 1]\,d\tt\,\Sm(d\s)\right)\nonumber\\
&= \frac{d\mmm{}{0}{1}}{d\mm{}{0,}{1}}\exp\Bigg(\sum_{\v\in\tree\sln{1}\setminus\{\root\}}\left(\sum_{0< \rt{\it}_\v \leq \t} \log{\crate{}{}(\X\cind{\{\v,\root\}}\tip{[0,\rt{\it}_\v)}{1},\mark{\it})} - \int{(0,\t]\times\S} [\crate{}{}(\X\cind{\{\v,\root\}}\tip{[0,\tt)}{1},\s) - 1]\,d\tt\,\Sm(d\s)\right)\nonumber\\
&\hspace{24pt} + \left(\sum_{0 < \rt{\it}_\root \leq \t} \log{\IGrg{}(\X\cind{\tree\sln{1}}\tp{\rt{\it}_\root-}{1},\mark{\it}_\root)} - \int{(0,\t]\times\S} [\IGrg{}(\X\cind{\tree\sln{1}}\tp{\tt-}{1},\s) - 1]\,ds\,\Sm(d\s)\right)\Bigg)\nonumber\\
&= \frac{d\mmm{}{0}{1}}{d\mm{}{0}{1}}\exp\left(\sum_{\v\in\tree\sln{1}\setminus\{\root\}} \ds{\v}{\t}(\X\cind{\{\v,\root\}}\tip{}{1},\crate{}{}) + \ds{\root}{\t}(\X\cind{\tree\sln{1}}\tip{}{1},\IGrg{})\right).
\label{subsec::ProofU:eqn::L1 density}
\end{align}

By a similar calculation, we can apply Lemmas \ref{subsec::Some:Lem::radnik} and \ref{subsec::ProofU:Lem::Marginal} to get,

\begin{equation}
\alt{\dense}{}{\t}(\X\cind{\{\v,\root\}}\tip{}{1}) \defeq \frac{d\mmm{\{\v,\root\}}{\t,}{}}{d\mm{\{\v,\root\}}{\t,}{}} = \frac{d\mmm{\{\v,\root\}}{0,}{}}{d\mm{\{\v,\root\}}{0,}{}}\exp\left(\ds{\v}{\t}(\X\cind{\{\v,\root\}}\tip{}{1},\crate{}{}) + \ds{\root}{\t}(\X\cind{\{\root,\v\}}\tip{}{1},\crate{}{})\right).
\label{subsec::ProofU:eqn::Margdense}
\end{equation}
\labe{subsec::ProofU:eqn::Margdense}

Define,

\begin{align*}
\cdense{}{\t}&(\X\cind{\{\tree\sln{1}\setminus\{\root\}\}}\tip{}{1};\x\cind{\{\root,1\}}\tip{})\\
& \defeq\frac{d\mmm{\tree\sln{1}\setminus\{\root,1\}}{0,}{}}{d\mm{\tree\sln{1}\setminus\{\root,1\}}{0,}{}}\exp\left(\sum_{\v\in \tree\sln{1}\setminus\{\root,1\}} \ds{\v}{\t}([\X\cind{\{v\}}\tip{}{1},\x\cind{\root}\tip{}],\crate{}{}) + \ds{\root}{\t}([\X\cind{\tree\sln{1}\setminus\{\root,1\}}\tip{}{1},\x\cind{\{\root,1\}}\tip{}],\IGrg{}) - \ds{\root}{\t}(\x\cind{\{\root,1\}}\tip{},\crate{}{})\right)\\
\end{align*}

Then,

\[\cdense{}{\t}(\X\cind{\tree\sln{1}\setminus\{\root\}}\tip{}{1};\x\cind{\{\root,1\}}\tip{}) = \frac{\dense{1}{\t}([\X\cind{\tree\sln{1}\setminus\{\root\}}\tip{}{1},\x\cind{\{\root,1\}}\tip{}])}{\alt{\dense{}{\t}}(\x\cind{\{1,\root\}}\tip{})}.\]

By definition,

\[\alt{\dense}{}{\t}(\X\cind{\{1,\root\}}\tip{}{1}) = \exmu{\mm{\tree\sln{1}\setminus\{1,\root\}}{\t,}{}(\X\cind{\tree\sln{1}\setminus\{1,\root\}}\tip{}{1})}{\dense{1}{\t}([\X\cind{\tree\sln{1}\setminus\{\root\}}\tip{}{1},\x\cind{\{\root,1\}}\tip{}])}.\]

So,

\[\exmu{\mm{\tree\sln{1}\setminus\{1,\root\}}{\t,}{}}{\cdense{}{\t}(\X\cind{\tree\sln{1}\setminus\{\root\}}\tip{}{1};\x\cind{\{1,\root\}}\tip{})} = 1.\]

The important thing is that this can be used to extend \(\X\cind{}\tip{}{1}\) to a process with nodes in \(\tree\sln{2}\) whose marginal distribution with respect to the nodes on \(\tree\sln{1}\) is equal to \(\X\cind{}\tip{}{1}\). To do that, consider the following notation:

\ind Let \(\v \in V\setminus\{\root\}\). Let \(\c{}:V\setminus\{\root\} \ra V^{\degr-1}\) be defined such that \(\c{\v} = (\c{1}(\v),\dots,\c{\degr-1}(\v))\) are the children of \(\v\). Let \(\p{}:V\setminus\{\root\}\ra V\) map nodes to their parent.

\ind We can define the sequence of functions \(\dense{n}{\t}: \sset\vsi{\tree\sln{n}}\ts{\t-} \ra [0,\infty)\) by,

\[\dense{n}{\t}(\X\cind{}\tip{}{n}) := \dense{n-1}{\t}(\X\cind{\tree\sln{n-1}}\tip{}{n})\prod_{\v\in \tree\sln{n-1}\setminus\tree\sln{n-2}} \cdense{}{\t}(\X\cind{\c{\v}}\tip{}{n};\X\cind{\{\v,\root\}}\tip{}{n})\]

for \(n > 1\) (\(\tree\sln{0} = \{\root\}\)). 

\ind Let \(\mm{}{}{n}\defeq \mm{\tree\sln{n}}{}{}\) and assume for any \(\U \subseteq V\), \(\mmm{\U}{0,}{} = \otimes_{\v\in\U}\mmm{\v}{0,}{}\) where \(\{\mmm{\v}{0,}{}:\v\in V\}\) describes a sequence of i.i.d. \(\S\)-valued random variables. We can show using induction that,

\begin{equation}
\dense{n}{\t}(\X\cind{}\tip{}{n}) = \frac{d\mmm{}{\t}{n}}{d\mm{}{0}{n}}\exp\left(\sum_{\v\in\tree\sln{n-1}}\ds{\v}{\t}(\X\cind{\cl{\v}}\tip{}{n},\IGrg{}) + \sum_{\v\in\tree\sln{n}\setminus\tree\sln{n-1}} \ds{\v}{\t}(\X\cind{\{v,\p{\v}\}}\tip{}{n},\crate{}{})\right).
\label{subsec::ProofU:eqn::densen}
\end{equation}
\labe{subsec::ProofU:eqn::densen}

Assume equation \eqref{subsec::ProofU:eqn::densen} holds for \(\dense{n-1}{\t}\). Then,

\begin{align*}
\dense{n}{\t}(\X\cind{}\tip{}{n}) &= \dense{n-1}{\t}(\X\cind{\tree\sln{n-1}}\tip{}{n})\prod_{\v\in\tree\sln{n-1}\setminus\tree\sln{n-2}} \cdense{}{\t}(\X\cind{\c{\v}}\tip{}{2};\X\cind{\{\v,\p{\v}\}}\tip{}{2})\\
&=\left(\frac{d\mmm{}{0}{n-1}}{d\mm{}{0}{n-1}}\prod_{\v\in\tree\sln{n-1}\setminus\tree\sln{n-2}}\frac{d\mmm{\c{\v}}{0,}{}}{d\mm{\c{\v}}{0,}{}}\right)\exp\Bigg(\sum_{\v\in\tree\sln{n-2}}\ds{\v}{\t}(\X\cind{\cl{\v}}\tip{}{n},\IGrg{}) + \sum_{\v\in\tree\sln{n-1}\setminus\tree\sln{n-2}} \ds{\v}{\t}(\X\cind{\{\v,\p{\v}\}}\tip{}{n},\crate{}{})\\
&\ind + \sum_{\v\in\tree\sln{n-1}\setminus\tree\sln{n-2}}\left(\sum_{\vv\in \c{\v}} \ds{\vv}{\t}(\X\cind{\{\vv,\v\}}\tip{}{n},\crate{}{}) + \ds{\v}{\t}(\X\cind{\cl{\v}}\tip{}{n},\IGrg{}) - \ds{\v}{\t}(\X\cind{\{\v,\p{\v}\}}\tip{}{n},\crate{}{})\right)\Bigg)\\
&=\frac{d\mmm{}{0}{n}}{d\mm{}{0}{n}}\exp\left(\sum_{\v\in\tree\sln{n-1}}\ds{\v}{\t}(\X\cind{\cl{\v}}\tip{}{n},\IGrg{}) + \sum_{\v\in\tree\sln{n}\setminus\tree\sln{n-1}} \ds{\v}{\t}(\X\cind{\{\v,\p{\v}\}}\tip{}{n},\crate{}{})\right).
\end{align*}

By a simple calculation analogous to what we did earlier to show that \(\dense{1}{\t}\) was a Radon-Nykodim derivative, we can apply Proposition \ref{subsec::Prope:Prop::radnikder} to prove that this is the Radon-Nikodym derivative of a marked point process. 

\ind For each \(n > 1\), define \(\mmm{}{}{n} \in \pmsr(\sset\vsi{\tree\sln{n}}\ts{\T-})\) by,

\[\frac{d\mmm{}{\t}{n}}{d\mm{}{\t}{n}} = \dense{n}{\t}(\X\cind{}\tip{}{n}).\]

Then,

\begin{align*}
\frac{d\proj\vsi{\tree\sln{n-1}}\ts{\t}(\mmm{}{\t}{n})}{d\mm{}{\t}{n-1}} &= \int{\sset\vsi{\tree\sln{n}\setminus\tree\sln{n-1}}\ts{\t-}} \frac{d\mmm{}{\t}{n}}{d\mm{}{\t}{n}}\,\mm{\tree\sln{n}\setminus\tree\sln{n-1}}{\t,}{}(d\X\cind{\tree\sln{n}\setminus\tree\sln{n-1}}\tip{}{n})\\
&=\int{\sset\vsi{\tree\sln{n}\setminus\tree\sln{n-1}}\ts{\t-}} \dense{n}{\t}(\X\cind{}\tip{}{n})\,\mm{\tree\sln{n}\setminus\tree\sln{n-1}}{\t,}{}(d\X\cind{\tree\sln{n}\setminus\tree\sln{n-1}}\tip{}{n})\\
&= \int{\sset\vsi{\tree\sln{n}\setminus\tree\sln{n-1}}\ts{\t-}} \dense{n-1}{\t}(\X\cind{\tree\sln{n-1}}\tip{}{n})\prod_{\v\in \tree\sln{n-1}\setminus\tree\sln{n-2}} \cdense{}{\t}(\X\cind{\c{\v}}\tip{}{n};\X\cind{\{v,\p{\v}\}}\tip{}{n})\,\mm{\tree\sln{n}\setminus\tree\sln{n-1}}{\t,}{}(d\X\cind{\tree\sln{n}\setminus\tree\sln{n-1}}\tip{}{n})\\
&= \dense{n-1}{\t}(\X\cind{\tree\sln{n-1}}\tip{}{n})\prod_{\v\in \tree\sln{n-1}\setminus\tree\sln{n-2}}\int{\sset\vsi{\c{\v}}\ts{\t-}} \cdense{}{\t}(\X\cind{\c{\v}}\tip{}{n};\X\cind{\{v,\p{\v}\}}\tip{}{n})\,\mm{\c{\v}}{\t,}{}(d\X\cind{\c{\v}}\tip{}{n})\\
&= \dense{n-1}{\t}(\X\cind{\tree\sln{n-1}}\tip{}{n})\prod_{\v\in \tree\sln{n-1}\setminus\tree\sln{n-2}}\exmu{\mm{\c{\v}}{\t,}{}}{\cdense{}{\t}(\X\cind{\c{\v}}\tip{}{n};\X\cind{\{v,\p{\v}\}}\tip{}{n})}\\
&= \dense{n-1}{\t}(\X\cind{\tree\sln{n-1}}\tip{}{n}).
\end{align*}

This proves that \(\proj\vsi{\tree\sln{n-1}}\ts{\t}(\mmm{}{\t}{n}) = \mmm{}{\t}{n-1}\). Furthermore, for any \(\alt{n} < n\),

\[\proj\vsi{\tree\sln{\alt{n}}}\ts{\t}(\mmm{}{\t}{n}) = \proj\vsi{\tree\sln{\alt{n}}}\ts{\t}\circ\proj\vsi{\tree\sln{\alt{n} + 1}}\ts{\t} \circ\cdots\circ \proj\vsi{\tree\sln{n-1}}\ts{\t}(\mmm{}{\t}{n}) = \proj\vsi{\tree\sln{\alt{n}}}\ts{\t}\circ\proj\vsi{\tree\sln{\alt{n} + 1}}\ts{\t} \circ\cdots\circ \proj\vsi{\tree\sln{n-2}}\ts{\t}(\mmm{}{\t}{n-1}) = \cdots = \mmm{}{\t}{\alt{n}}.\]

\ind Fix \(n\in\mb{N}\). By Lemma \ref{subsec::Some:Lem::radnik}, \(\mmm{}{}{n}\) can be described as the law of the unique solution to equation \eqref{subsec::ProofU:eqn::extendedSDE}.
\end{proof}

\lin

For any \(\U\subseteq V\), we can consider the embedding \(\pmsr\left(\sset\vsi{\U}\ts{\t-}\right) = \pmsr\left((\sset\vsi{\U}\ts{\t-},\F\vsi{\U}\ts{\t-})\right) \subseteq \pmsr\left((\sset\vsi{V}\ts{\t-},\F\vsi{\U}\ts{\t-})\right)\). That is, a measure \(\mmm{}{}{}\in \pmsr\left(\sset\vsi{\U}\ts{\t-}\right)\) can be considered as a \(\F\vsi{\U}\ts{}\)-adapted measure on \(\sset\vsi{V}\ts{\t-}\).

\ind Let's summarize what we have so far. We have a sequence of measures \(\{\mmm{}{}{n}:n\in\mb{N}\} \subset \pmsr(\sset\vsi{V}\ts{\T-})\) satisfying:

\begin{enumerate}[(a)]
\item \(\mmm{}{}{1}\) solves equation \eqref{sec::Main:eqn::Local SDE}.

\item \(\mmm{}{}{n}(\X\cind{\tree\sln{\alt{n}}}\tip{}{n} \in \cdot) = \mmm{}{}{\alt{n}}(\X\cind{\tree\sln{\alt{n}}}\tip{}{\alt{n}}\in \cdot)\) for all \(n \geq \alt{n}\).

\item \(\frac{d\mmm{}{\t}{n}}{d\mm{}{\t}{n}} = \dense{n}{\t}(\X\cind{}\tip{}{n})\).
\end{enumerate}

Let \(\{\mmm{\U}{\t,}{}:\t \leq \T\}_{\U\subset V,\U\te{ finite}}\) be a collection of measures defined by

\[\mmm{\U}{\t,}{}(\cdot) = \mmm{}{\t}{n}(\X\cind{}\tip{[0,\t)}{n} \in \cdot) \te{ for any }n\te{ \tt.\t. }\U \subseteq \tree\sln{n}.\]

By property (b) above, this is well-defined. Since each \(\mmm{\U}{}{}\) is a probability measure defined on the Borel sets of \(\sset\vsi{\U}\ts{\T-}\), they are all inner regular (\tr{citation?}). Now, fix some finite \(\U\subseteq V\) and let \(\UU \subseteq \U\). Suppose \(n\) is such that \(\U \subseteq \tree\sln{n}\). Then \(\UU\subseteq \tree\sln{n}\), so

\[\proj\vsi{\UU}\ts{\t}(\mmm{\U}{\t,}{})(\cdot) = \mmm{\U}{\t,}{}\left(\proj\vsi{\UU}\ts{\t}(\X\cind{\U}\tip{}{n}) \in \cdot\right) = \mmm{}{\t}{n}\left(\X\cind{\UU}\tip{}{n} \in \cdot\right) = \mmm{\UU}{\t,}{}(\cdot).\]

Therefore the conditions of the Daniell-Kolmogorov extension theorem are satisfied. Therefore, there exists a \(\mmm{}{}{}\in \ms{P}(\sset\vsi{\U}\ts{\T-})\) such that \(\proj\vsi{\U}\ts{\T-}(\mmm{}{}{}) =\mmm{\U}{}{}\) for all finite \(\U\). \tr{citation needed (Reading off of Lecture notes (Theorem 2.4.3) which were used as the basis of Terence Tao's measure theory book)}.

\ind In particular, there exists a probability space with canonical process \(\X\cind{}\tip{}\) such that \(\mmm{}{}{} = \law(\X\cind{}\tip{[0,\T)})\) and \(\mmm{\v}{}{} = \law(\X\cind{\v}\tip{[0,\T)})\) for all \(\v \in V\). In particular, this means that \(\law(\X\cind{\tree\sln{n}}\tip{[0,\T)}) = \mmm{\tree\sln{n}}{}{} = \mmm{}{}{n}\). Since \(\X\cind{\tree\sln{n}}\tip{} \ra \X\cind{}\tip{}\) almost surely (we are in the topology of componentwise convergence), \(\mmm{}{}{n} \Rightarrow \mmm{}{}{}\). In order to characterize \(\X\cind{}\tip{}\) and \(\mmm{}{}{}\), we construct a stochastic differential equation on a probability space on which \(\X\cind{}\tip{}{n} \sim \mmm{}{}{n}\) and \(\X\cind{}\tip{}{n} = \X\cind{\tree\sln{n}}\tip{}\) almost surely. \tr{I don'\t know if it's clear, but we are taking \(\X\cind{}\tip{}{n}\) and \(\X\cind{}\tip{}\) as given in this probability space.}

\ind On this space, we construct a sequence of i.i.d Poisson processes as follows (Construction is based on the proof of \cite[Theorem 14.7.1(b)]{DalVer08}. The result is given in \cite[Exercise 14.7.1]{DalVer08} \tr{TODO: rigorously solve this exercise myself}).

\ind Let \(\alt{\S}^n = \{\s\ev\vind{\v}: \s\in\S,\v \in \tree\sln{n}\}\). For each \(n\), consider \(\alt{\S}^n\) as embedded in \(\S\carp{V}\). Thus, \(\alt{\S}^1 \subset \alt{\S}^2 \subset \cdots\). Let \(\alt{\Sm}\sln{n}\) be the measure on \(\alt{\S}^n\) defined by \(\alt{\Sm}\sln{n}(\{\s\ev\vind{\v}\}) = \mb{I}_{\v \in \tree\sln{n}}\Sm(\s)\). Let \(\{\rt{n,\it}_\v,\mark{n,\it}_{\v}\}\) be the jump sizes and jump times of \(\X\cind{\v}\tip{}{n}\). Let \(\alt{\poiss}{n}\) be a sequence Poisson processes on \(\mb{R}^+\times\alt{\S}^n\times \mb{R}^+\) with intensity measure \(d\t\times\alt{\Sm}^n\times d\r\) and such that if \(\evnt{} \in \ms{B}(\mb{R}^+\times\alt{\S}^{n-1}\times \mb{R}^+)\), then \(\alt{\poiss}{n}(\evnt{}) = \alt{\poiss}{n-1}(\evnt{})\). Assume \(\{\alt{\poiss}{n}:n\in\mb{N}\}\) are independent of \(\{\X\cind{}\tip{},\X\cind{}\tip{}{n}:n\in\mb{N}\}\). Let \(\{\rv_{\v}^{i}\}\) be a sequence of i.i.d. uniform random variables with support on \([0,1]\).

\ind Recall the mapping \(\pmap{}(\cdot)\) from Definition \ref{subsec::ProofE:Defn::pmap}. Define the Marked point process \(\rp{n} = \pmap{}(\X\cind{}\tip{}{n})\). Then the intensity of \(\rp{n}\) is given by,

\[\rate{n}(\t,\sv\cind{}\vsi{\tree\sln{n}}) = \begin{cases}
\rate{}(\X\cind{\cl{\v}}\tp{\t-}{n},\s) &\te{ if } \sv\cind{}\vsi{\tree\sln{n}} = \s\ev\vind{\v},\s \in \S\setminus\{0\},\v\in\tree\sln{n-1}\\
\crate{}{}(\X\cind{\{\v,\p{\v}\}}\tip{[0,\t)}{n},\s) &\te{ if } \sv\cind{}\vsi{\tree\sln{n}} = \s\ev\vind{\v},\s\in\S\setminus\{0\},\v\in\tree\sln{n}\setminus\tree\sln{n-1}\\
0 &\te{ otherwise.}
\end{cases}\]

For any \(\evnt{} \in \ms{B}(\mb{R}^+\times\alt{\S}^n\times\mb{R}^+)\), define

\begin{equation}
\poiss\sln{n}(\evnt{}) = \alt{\poiss}{n}\left(\evnt{}\cap\{(\t,\sv\cind{}\vsi{\tree\sln{n}},\r):\r > \rate{n}(\t,\sv\cind{}\vsi{\tree\sln{n}})\}\right) + \#\{(\rt{n,\it}_\v,\mark{n,\it}_\v,\rv_{\v}^{\it}\rate{n}(\rt{n,\it}_\v,\mark{n,\it}_\v) \in \evnt{}: \v\in \tree\sln{n}\}.
\label{subsec::ProofU:eqn::Poissonexpl}
\end{equation}
\labe{subsec::ProofU:eqn::Poissonexpl}

Then \(\poiss\sln{n}\) is a Poisson random measure on \(\mb{R}^+\times\alt{\S}^n\times \mb{R}^+\) with intensity measure \(d\t\times \alt{\Sm}^n\times d\r\) (see proof of \cite[Theorem 14.7.1(b)]{DalVer08})

\ind Notice that for any \(\evnt{} \in \ms{B}(\mb{R}^+\times \alt{\S}^{n-2}\times \mb{R}^+)\), \(\poiss\sln{n}(\evnt{}) = \poiss\sln{n-1}(\evnt{})\) almost surely. Define the random measure \(\poiss\vind{}\) on \(\ms{B}(\mb{R}^+\times \{\s\ev\vind{\v}:\s\in \S,\v \in V\}\times \mb{R}^+)\) by,

\[\poiss\vind{}(\evnt{}) = \lim_{n \ra\infty}\poiss\sln{n}\left(\proj\vsi{\tree\sln{n-1}}\ts{}(\evnt{})\right).\]

Here \(\proj\vsi{\tree\sln{n}}\ts{}(\evnt{})\) is the restriction of \(\evnt{}\) to \(\mb{R}^+\times \alt{\S}^n\times\mb{R}^+\). 

\ind Notice that this limit exists almost surely, because it is the limit of an almost surely monotonically increasing sequence. Let \(\poiss\vind{\v}\) be random measures on \(\mb{R}^+\times\S\times\mb{R}^+\) with intensity \(d\t\times\Sm(d\s)\times d\r\). Define it by,

\[\poiss\vind{\v}(\evnt{}) = \poiss\vind{}\left(\{(\t,\s\ev\vind{\v},\r):(\t,\s,\r)\in \evnt{}\}\right) \te{ for } \evnt{} \in \ms{B}(\mb{R}^+\times\S\times\mb{R}^+).\]

Similarly define,

\[\alt{\poiss}{\v}(\evnt{}) = \poiss\sln{n}\left(\{(\t,\s\ev\vind{\v},\r):(\t,\s,\r)\in \evnt{}\}\right)\te{ for } \evnt{} \in \ms{B}(\mb{R}^+\times\S\times\mb{R}^+)\te{ and }n\te{ such that } \v\in \tree\sln{n}\setminus\tree\sln{n-1}.\]

Then \(\{\poiss\vind{\v}\}\) and \(\{\alt{\poiss}{\v}\}\) are both sequences of i.i.d. Poisson processes. Furthermore, for any \(n \in \mb{N}\), \(\{\poiss\vind{\vv},\alt{\poiss}{\vvv}:\vv\in \tree\sln{n-1},\vvv\in\tree\sln{n}\setminus\tree\sln{n-1}\}\) are i.i.d.

\lin

\begin{lem}
The claims above are true. Namely, \(\poiss\sln{n}\) are all Poisson processes with intensity measure \(d\t\times\alt{\Sm^{n}}\times d\r\), \(\{\poiss\vind{\v}:\v\in V\}\) is a sequence of i.i.d. Poisson processes with intensity measure \(d\t\times\Sm\times d\r\) and \(\{\poiss\vind{\vv},\alt{\poiss}{\vvv}:\vv\in \tree\sln{n-1},\vvv\in\tree\sln{n}\setminus\tree\sln{n-1}\}\) are i.i.d. for any \(n \in \mb{N}\).

\label{subsec::ProofU:Lem::Poisson}
\end{lem}
\labe{subsec::ProofU:Lem::Poisson}
\begin{proof}

Fix \(n \in \mb{N}\). Notice that most of the assumptions of \cite[Proposition 14.7.I(b)]{DalVer08} are satisfied, except the filtration with respect to which \(\rate{n}\) is predictable is slightly larger (the proposition requires the filtration to only contain the jumps of \(\X\cind{}\tip{}{n}\), but not the initial state). However, the proof of the proposition does not fail when the initial state is included in the filtration (Lemma \ref{sec::TL:Lem::embedding}). Furthermore, \(\poiss\sln{n}\) is the Poisson process constructed in the proof, so it is a Poisson process with intensity \(d\t\times \alt{\Sm^n}\times d\r\).

\ind By construction, \(\poiss\vind{\v}\) is the restriction of \(\poiss\sln{n}\) to \(\mb{R}^+ \times \{\s\ev\vind{\v}: \s\in \S\}\times \mb{R}^+\) for all \(\v\in \tree\sln{n-1}\). Thus, for any finite \(\U \subset V\), there exists a \(n\) such that \(\U \subseteq \tree\sln{n-1}\), so \(\{\poiss\vind{\v}: \v\in \U\}\) are i.i.d. Thus, \(\{\poiss\vind{\v}: \v\in V\}\) are i.i.d.

\ind Similarly, for any \(n \in \mb{N}\), \(\{\poiss\vind{\v},\alt{\poiss}{\vv}: \v \in \tree\sln{n-1},\vv\in\tree\sln{n}\setminus\tree\sln{n-1}\}\) is just the set of restrictions of \(\poiss\sln{n}\) to \(\mb{R}^+\times\{\s\ev\vind{\v}\}\times\mb{R}^+\) for each \(\v\in \tree\sln{n}\), so they are i.i.d. Poisson processes with intensity measure \(d\t\times \Sm\times d\r\) because \(\poiss\sln{n}\) is a Poisson process with intensity measure \(d\t\times\alt{\Sm^n}\times d\r\).
\end{proof}

\lin

Let \(\{\poiss\vind{\v},\alt{\poiss}{\v}:\v\in V\}\) be constructed as above. Then \(\X\cind{}\tip{}{n}\) almost surely solves the equation,

\begin{equation}
\X\cind{\v}\tp{\t}{n} = \begin{cases}
\X\cind{\v}\tp{0}{} + \int{(0,\t]}\int_\S\int{(0,\crate{}{}(\X\cind{\{\v,\p{\v}\}}\tip{[0,\tt)}{n},\s)]}\s\alt{\poiss}{\v}(d\tt,d\s,d\r)\te{ for } \v \in \tree\sln{n}\setminus\tree\sln{n-1}\\
\X\cind{\v}\tp{0}{} + \int{(0,\t]}\int_\S\int{(0,\rate{}(\X\cind{\cl{\v}}\tp{\tt-}{n},\s)]}\s\,\poiss\vind{\v}(d\tt,d\s,d\r)\te{ for } \v \in \tree\sln{n-1}.
\end{cases}
\label{subsec::ProofU:eqn::ExtendedSDE_fixedPoisson}
\end{equation}
\labe{subsec::ProofU:eqn::ExtendedSDE\_fixedPoisson}

By Lemma \ref{subsec::ProofU:Lem::Poisson}, these Poisson processes are i.i.d. By Lemma \ref{subsec::ProofU:Lem::extendedSDE}, \(\te{law}(\X\cind{}\tip{}{n}) = \mmm{}{}{n}\). By construction, \(\proj\vsi{\tree\sln{n}}\ts{\T-}(\X\cind{}\tip{}) = \X\cind{}\tip{}{n}\) for all \(n\in\mb{N}\).

\ind Fix any \(\v\in V\). Let \(n\in \mb{N}\) be any natural number such that \(\v\in \tree\sln{n-1}\). Then for any \(\t \in [0,\T)\),

\begin{align*}
\X\cind{\v}\tp{0} + \int{(0,\t]}\int_\S\int{(0,\rate{}(\X\cind{\cl{\v}}\tp{\tt-},\s)]}\s\poiss\vind{\v}(d\r,d\s,d\tt) &= \X\cind{\v}\tp{0} + \int{(0,\t]}\int_\S\int{(0,\rate{}(\X\cind{\cl{\v}}\tp{\tt-}{n},\s)]}\s\poiss\vind{\v}(d\r,d\s,d\tt)\\
&=\X\cind{\v}\tp{\t}{n} = \X\cind{\v}\tp{\t}.
\end{align*}

Thus, \(\X\cind{}\tip{}\) is a solution to the coupled equation,

\begin{equation}
\X\cind{\v}\tp{\t} = \X\cind{\v}\tp{0} + \int{(0,\t]}\int_\S \int{(0,\rate{}(\X\cind{}\tp{\tt-},\s)]}\s\,\poiss\vind{\v}(d\r,d\s,d\tt).
\label{subsec::ProofU:eqn::XSDE}
\end{equation}
\labe{subsec::ProofU:eqn::XSDE}

However, by Propositions \ref{subsec::Well-:Prop::SDEWP} and \ref{subsec::Well-:Prop::SDE=IG}, equation \eqref{subsec::ProofU:eqn::XSDE} has a unique solution, and that solution has distribution \(\m{}{}{}\). Thus, \(\mmm{}{}{} = \m{}{}{}\). We conclude that \(\mmm{}{}{1} = \proj\vsi{\tree\sln{1}}\ts{\T-}(\m{}{}{})\).

\end{proof}

\section{Analysis of Assumptions}

\begin{description}
\item[Graphs: ] Graph is assumed to be an infinite regular tree

I have a method to expand the class of graphs to which this applies a bit. Unfortunately, there are some problems with the proof of uniqueness once the tree structure disappears. It may also be possible to extend to random graph structure.

\item[Sublimit graphs: ] Sublimit graphs are assumed to be trees which grow in a regular fashion to the entire graph. This is not a good assumption. Try to extend more generally. Use local weak convergence.

\item[Full process: ] The full process is assumed to be Feller with infinitesimal generator of the form,

\[\IG f(\sv\cind{}\vsi{V}) = \sum_{\v \in V}\sum_{\s \in \S} \IGr\vind{\v}(\sv\cind{}\vsi{V},\s)[f(\sv\cind{}\vsi{V} + \s \ev\vind{\v}) - f(\sv\cind{}\vsi{V})].\]

This is somewhat restrictive and fails in certain load balancing schemes where jobs move between queues (so 2 nodes change simultaneously). Consider general jumps. Also, the state-space \(\S\) is assumed to be finite. Consider making it countable (for load balancing). Finally, consider the case when the full process is not Markov or the initial conditions are not i.i.d.

\item[Conditional Independence: ] We assume the graph has bounded degree. We assume the double neighborhood is finite. This works well in trees but may fail in general, especially for other applications which look at the conditional independence of infinite sets.
\end{description}

\newpage
\appendix

\section{Infinitesimal Generators}
\label{sec::Infin}\labe{sec::Infin}

Let \(\spce\) be a compact and countable set. \tr{For most of the paper, \(\spce = \S\carp{V}\) which is compact with respect to the topology of componentwise convergence.}

Let \(\cont(\spce)= \{f:\spce \ra \mb{R} \te{ continuous}\}\).

\lin

\begin{defn}
A Feller process on \(\spce\) is a collection of probability measures \(\{\pr{\x}:\x \in \spce\}\) on \(\cad([0,\infty),\spce)\) with canonical process \(\X\) such that

\begin{enumerate}[(a)]
\item \(\pr{\x}(\X\cind{}\tp{0} = \x) = 1\) for all \(\x \in \spce\).

\item The mapping \(\x \mapsto \pr{\x}(\typset)\) is measurable for every \(\sigma(\X)\)-measurable set \(\typset\).

\item \(\pr{\x}(\X\cind{}\tp{\tt+\cdot} \in \typset|\X\cind{}\tp{\ttt}:\ttt \in [0,\tt]) = \pr{\X\cind{}\tp{\tt}}(\typset)\) for all \(\typset \in \sigma(\X)\) and \(\x \in \spce\).

\item For all \(\f\in \cont(\spce)\), the mapping \(\x\mapsto \exmu{\x}{\f(\X_{\t})}\) is also continuous.
\end{enumerate}
\label{sec::Infin:Def::Feller}
\end{defn}
\labe{sec::Infin:Def::Feller}

\textbf{Source: } This definition is adapted from \cite[Definition 1.1,1.2]{Lig85}.

\textbf{Remark: } We will also refer to a probability measure \(\m \in \mc{P}(\cad([0,\T],\spce))\) as Feller if

\begin{enumerate}[(a)]
\item There exists an measure \(\alt{\m}\in \mc{P}(\cad([0,\infty),\spce))\) such that \(\alt{\m}|_{\cad([0,T],\spce)} = \m\).

\item There exists a probability measure \(\mm\in \mc{P}(\spce)\) and a Feller process \(\{\alt{\m}^\x:\x \in \spce\}\) such that 

\[\alt{\m}(\cdot) = \int{\spce} \alt{\m}^\x(\cdot)\,d\mm(\x).\]
\end{enumerate}

\textbf{Another Remark: } Given a c\`adl\`ag \(\spce\)-valued random process \(\X\cind{}\tip{}\), we say \(\X\cind{}\tip{}\) is Feller if,

\[\left\{\law\left(\X\cind{}\tip{}\middle|\X\cind{}\tp{0} = \x\cind{}\tip{}\right): \x\cind{}\tip{} \in \spce\right\}\]

satisfies Definition \ref{sec::Infin:Def::Feller}.

\purpose As shown later, there is a bijection between Feller processes and Infinitesimal generators. This allows us to express the process \(\mu\) in terms of its infinitesimal generator in equation \eqref{subsec::Notat:Eqn::IG}.

\lin

\begin{defn}
An infinitesimal generator is a (possibly unbounded) linear operator \(\IG{}\) on the space of continuous functions \(\cont(\spce)\) paired with a dense domain \(\core(\IG{}) \subseteq \cont(\spce)\) satisfying the following properties:

\begin{enumerate}
\item If \(f \in \mc{D}(\IG{})\), \(a \geq 0\) and \(g:= f - a\IG{} f\), then 

\[\inf_{\x \in \spce} f(\x) \geq \inf_{\x \in \spce} g(\x)\]

\noindent In particular, this implies that \(\|f\| \leq \|f - a\IG{} f\|\).

\item For all sufficiently small \(a > 0\), \(I - a\IG{}\) is surjective as a mapping from \(\mc{D}(\IG{})\) to \(\cont(\spce)\).

\item \(1 \in \core(\IG{})\) and \(\IG{} 1 = 0\).
\end{enumerate}
\label{sec::Infin:Def::IG}
\end{defn}
\labe{sec::Infin:Def::IG}

\textbf{Source: }\cite[Definitions 2.1,2.7]{Lig85}

\purpose This is an abstract definition of the class of unbounded operators that can be infinitesimal generators. The more well-known definition of infinitesimal generators arises from the bijection between Feller Processes and infinitesimal generators (Proposition \ref{sec::Infin:Thm::Bij}).

\lin

\begin{thms}
There is a bijection between infinitesimal generators and Feller processes. Furthermore, the infinitesimal generator \(\IG{}\) can be obtained from the Feller process \(\m\) by the following relation:

\begin{equation}
\IG f(\x) = \lim_{\t\searrow 0} \frac{1}{\t}\left(\exmu{\m}{f(\X\cind{}\tp{\t})|\X\cind{}\tp{0}=\x} - f(\x)\right)
\label{sec::Infin:eqn::FellerIG}
\end{equation}
\labe{sec::Infin:eqn::FellerIG}
\label{sec::Infin:Thm::Bij}
\end{thms}
\labe{sec::Infin:Thm::Bij}

\purpose This proves that infinitesimal generators characterize Feller processes.

\pfsum Apply \cite[Theorem 1.5,2.9]{Lig85}.

\lin

\begin{defn}
Let \(\IG{}\) be an infinitesimal generator. A dense subset \(\core\subset \core(\IG{})\) is called a core of \(\IG{}\) if \(\IG{}\) is the closure of the operator \(\IG{}|_\core\).
\label{sec::Infin:Def::core}
\end{defn}
\labe{sec::Infin:Def::core}

\textbf{Source: }\cite[Definition 2.11]{Lig85}

\purpose \(\core(\IG{})\) is extremely difficult to characterize in general. However, we can explicitly derive the core of the processes we are interested in.

\lin

\begin{thms}[Trotter-Kurtz]
Suppose \(\IG{n}\) and \(\IG{}\) are generators of Feller processes \(\m{n}\) and \(\m\) respectively. If there is a core \(\core\) for \(\IG{}\) such that \(\core \subset \mc{D}(\IG{n})\) for all \(n\) and \(\IG{n} f \ra \IG{} f\) for all \(f \in \core\), then 

\[\exmu{\m{n}}{f(\XX{}{\t})|\XX{}{0}=\cdot} \ra \exmu{\mu}{f(\XX{}{\t})|\XX{}{0}=\cdot}\]

uniformly in \(\t\) for all \(f \in \cont(\spce)\).
\label{sec::Infin:Thm::TrotterKurtz}
\end{thms}
\labe{sec::Infin:Thm::TrotterKurtz}

\purpose This shows that convergence of infinitesimal generators implies convergence of the process in "a sense." This is used to prove Corollary \ref{sec::Infin:Cor::Convergence}, which tells us when convergence of infinitesimal generators gives us weak convergence of the corresponding Feller processes.

\pfsum Apply \cite[Theorem 2.12]{Lig85}

\lin

\begin{coro}
In addition to the conditions of Theorem \ref{sec::Infin:Thm::TrotterKurtz}, suppose that \(\{\m{n}\}\) are tight and that \((\m{n}){0} \Rightarrow \m{0}\). Then \(\m{n} \Rightarrow \alt{\m}\).
\label{sec::Infin:Cor::Convergence}
\end{coro}
\labe{sec::Infin:Cor::Convergence}

\purpose We use this theorem to prove that our exact local representation on the infinite graph is a good approximation on large finite graphs.

\pfsum Use the same methods as in the proof of \cite[Theorem 4.2]{Kur81} to show weak convergence of the finite dimensional distributions. Apply \cite[Theorem 13.1]{Bil99} to get weak convergence.

\begin{proof}
By \cite[Theorem 13.1]{Bil99} (tightness + weak convergence of the finite dimensional distributions implies weak convergence), it suffices to prove weak convergence of the finite-dimensional distributions of \(\alt{\m}{n}\). Let the initial conditions (i.e. restriction to time 0) of \(\alt{\m}{n}\) be denoted \(\alt{\mm}{n}\) and let \(\alt{\mm}\) denote the initial condition of \(\alt{\m}\). Let \(f\) be any continuous (and therefore bounded function since we are assuming \(\spce\) is compact) function from \(\spce^k\ra\mb{R}\). Since \(\alt{\m}{n}\) are Feller, \(\exmu{\alt{\m}{n}}{f(\XX{}{\t})|\XX{}{0} = \cdot}\) is continuous for all \(\t\). By the monotone class theorem, both the positive and negative parts of \(f\) can be approximated arbitrarily closely from below by functions of the form \(\sum_{i=1}^n f{i}(\xx{1})g{i}(\xx{2},\dots,\xx{\it})\). By monotone convergence, we can assume without loss of generality that \(f(\xx{1},\dots,\xx{\it}) = f{1}(\xx{1})f{2}(\xx{2},\dots,\xx{\it})\).

\ind By Theorem \ref{sec::Infin:Thm::TrotterKurtz}, \(\exmu{\alt{\m}{n}}{f(\XX{}{\t})|\XX{}{0}} \ra \exmu{\alt{\m}}{f(\XX{}{\t})|\XX{}{0}}\). Then, by bounded convergence and convergence of the initial condition,

\[\exmu{\alt{\m}{n}}{f(\XX{}{\t})}  = \exmu{\alt{\mm}{n}}{\exmu{\alt{\m}{n}}{f(\XX{}{\t})|\XX{}{0}}} \ra \exmu{\alt{\mm}{n}}{\exmu{\alt{\m}}{f(\XX{}{\t})|\XX{}{0}}} \ra \exmu{\alt{\mm}}{\exmu{\alt{\m}}{f(\XX{}{\t})|\XX{}{0}}} = \exmu{\alt{\m}}{f(\XX{}{\t})}\]

Thus all of the one-dimensional distributions converge. Assume that,

\[\exmu{\alt{\m}{n}}{g(\XX{}{\t{1}},\dots,\XX{}{\t{k-1}})|\XX{}{0}=\xxx} \ra \exmu{\alt{\m}}{g(\XX{}{\t{1}},\dots,\XX{}{\t{k-1}})|\XX{}{0}=\xxx}\]

\noindent for any continuous function \(g\) and for any \(\{\t{1},\dots,\t{k-1}\} \subset [0,T]\). Fix \(0\leq \t{1} <\t{2} <\cdots < \t{\it}\leq T\). Let \(f\) be from \((S')^k \ra \mb{R}\). We can assume without loss of generality that \(f\) is non-negative (consider negative and positive parts separately).

\begin{align}
\exmu{\alt{\m}{n}}{f(\XX{}{0},\XX{}{\t{2}},\dots,\XX{}{\t{\it}})|\XX{}{0} = \xxx}&= \exmu{\alt{\m}{n}}{f{1}(\XX{}{0})f{2}(\XX{}{\t{2}},\dots,\XX{}{\t{k}})|\XX{}{0}=\xxx}\nonumber\\
&= f{1}(\xxx)\exmu{\alt{\m}{n}}{f{2}(\XX{}{\t{2}},\dots,\XX{}{\t{k}})|\XX{}{0}=\xxx}\nonumber\\
&\os{\te{Induction}}{\ra} f{1}(\xxx)\exmu{\alt{\m}}{f{2}(\XX{}{\t{2}},\dots,\XX{}{\t{k}})|\XX{}{0}=\xxx}\nonumber\\
&= \exmu{\alt{\m}}{f(\XX{}{0},\XX{}{\t{2}},\dots,\XX{}{\t{\it}})|\XX{}{0}=\xxx}
\label{sec::Infin:eqn::zerocase}
\end{align}
\labe{sec::Infin:eqn::zerocase}

So,

\begin{align*}
\exmu{\alt{\m}{n}}{f(\XX{}{0},\XX{}{\t{2}},\dots,\XX{}{\t{\it}})} &= \exmu{\alt{\mm}{n}}{\exmu{\alt{\m}{n}}{f(\XX{}{0},\XX{}{\t{2}},\dots,\XX{}{\t{\it}})|\XX{}{0}}}\\
&\ra \exmu{\alt{\mm}}{\exmu{\alt{\m}}{f(\XX{}{0},\XX{}{\t{2}},\dots,\XX{}{\t{\it}})|\XX{}{0}}}\\
&= \exmu{\alt{\m}}{f(\XX{}{0},\XX{}{\t{2}},\dots,\XX{}{\t{\it}})}
\end{align*}

then,

\begin{align*}
\exmu{\alt{\m}{n}}{f(\XX{}{\t{1}},\dots,\XX{}{\t{\it}})|\XX{}{0}=\xxx}&=\exmu{\XX\sim\alt{\m}{n}}{\exmu{\XX\sim \alt{\m}{n}}{f(\XX{\t{1}},\dots,\XX{\t{\it}})|\XX{\t{1}}=\XX{}{\t{1}},\XX{0}=\xxx}|\XX{}{0}=\xxx}\\
&=\exmu{\XX\sim\alt{\m}{n}}{\exmu{\XX\sim \alt{\m}{n}}{f(\XX{0},\dots,\XX{\t{\it}-\t{1}})|\XX{0}=\XX{}{\t{1}}}|\XX{}{0}=\xxx}\\
&\os{\te{Eqn \eqref{sec::Infin:eqn::zerocase}}}{\ra} \exmu{\XX\sim\alt{\m}{n}}{\exmu{\XX\sim \alt{\m}}{f(\XX{0},\dots,\XX{\t{\it}-\t{1}})|\XX{0}=\XX{}{\t{1}}}|\XX{}{0}=\xxx}\\
&\os{\te{Theorem \ref{sec::Infin:Thm::TrotterKurtz}}}{\ra} \exmu{\XX\sim\alt{\m}}{\exmu{\XX\sim \alt{\m}}{f(\XX{0},\dots,\XX{\t{\it}-\t{1}})|\XX{0}=\XX{}{\t{1}}}|\XX{}{0}=\xxx}\\
&=\exmu{\alt{\m}}{f(\XX{}{\t{1}},\dots,\XX{}{\t{\it}})|\XX{}{0}=\xxx}
\end{align*}

\begin{align*}
\exmu{\alt{\m}{n}}{f(\XX{}{\t{1}},\dots,\XX{}{\t{\it}})}&= \exmu{\XX\sim \XX{}{\t{1}}}{\exmu{\alt{\m}{n}}{f(\XX{}{\t{1}},\dots,\XX{}{\t{\it}})|\XX{}{\t{1}}=\XX}}\\
&=\exmu{\XX\sim \alt{\m}{n}|_{\t{1}}}{\exmu{\alt{\m}{n}}{f(\XX{}{0},\XX{\t{2}-\t{1}},\dots,\XX{\t{\it}-\t{1}})|\XX{}{0}=\XX}}\\
&\os{\te{Eqn \eqref{sec::Infin:eqn::zerocase}}}{\ra} \exmu{\XX\sim \alt{\m}{n}|_{\t{1}}}{\exmu{\m}{f(\XX{}{0},\XX{\t{2}-\t{1}},\dots,\XX{\t{\it}-\t{1}})|\XX{}{0}=\XX}}\\
&\os{\te{Theorem \ref{sec::Infin:Thm::TrotterKurtz}}}{\ra} \exmu{\XX\sim \alt{\m}|_{\t{1}}}{\exmu{\m}{f(\XX{}{0},\XX{\t{2}-\t{1}},\dots,\XX{\t{\it}-\t{1}})|\XX{}{0}=\XX}}\\
&=\exmu{\alt{\m}}{f(\XX{}{\t{1}},\dots,\XX{}{\t{\it}})}
\end{align*}

It follows by induction that the finite-dimensional distributions of \(\alt{\m}{n}\) converge weakly. Note: this proof is similar to the proof of \cite[Theorem 4.2]{Kur81}, but with the details filled in.
\end{proof}

\lin 

\section{Point Processes}
\label{sec::Point}\labe{sec::Point}

\subsection{Properties of Point Processes}
\label{subsec::Prope:sec::Point}\labe{subsec::Prope:sec::Point}

\lin

\begin{defn}
Let \(\spce\) be a Polish space. Let \(\rp\) be a random non-negative integer valued measure on \(\spce\) such that \(\sup_{\x \in \spce} \rp(\{\x\})\leq 1\) almost surely. Then \(\rp\) is called a simple point process on \(\spce\) and the random set \(E = \{\x \in \spce: \rp(\{\x\}) = 1\}\) is the set of events in \(\spce\). In the case where \(\spce \subseteq [0,\infty)\), we use the notation \(\rp{\t} := \rp([0,\t])\). We also use the notation \(\evs = \{\rt{i}\}_{i=1}^{\infty}\) where \(\rt{i} < \rt{i+1}\) almost surely for all \(i\). We will use \(\evs = \{	{i}\}\) to denote a sample from \(\{\rt{i}\}\).
\label{subsec::Prope:Def::SPP}
\end{defn}
\labe{subsec::Prope:Def::SPP}

\textbf{Source: }\cite[Definition 9.1.II]{DalVer08}

\purpose Used to define Marked point processes.

\lin

\begin{defn}
Let \(\mspce\) be a Polish space. Let \(\rp\) be a simple point process on \([0,\infty)\times \mspce\). Define \(\rpg\) by \(\rpg((\typset) = \rp(\typset\times \mspce)\) for all \((\typset \in \ms{B}([0,\infty))\). If \(\rpg\) is a simple point process on \([0,\infty)\), then \(\rp\) is a simple marked point process on \([0,\infty)\times \mspce\). If \((\t,k) \in \evs\), then we call \(\t\) an event of \(\rp\) and \(k\) is the corresponding mark. We will generally write \(\evs = \{(\rt{i},\mark{i})\}_{i=1}^{\infty}\) where \(\rt{i} < \rt{i+1}\) almost surely for all \(i\). Sample events are written as \(\evs = \{(	{i},k{i})\}\). 
\label{subsec::Prope:Def::MPP}
\end{defn}
\labe{subsec::Prope:Def::MPP}

\textbf{Source: }\cite[Definition 6.4.I]{DalVer03}.

\purpose Jump Markov processes can be characterized by marked point processes. This allows us to apply point process theory to processes that satisfy Assumption \ref{subsec::Assum:Assu::Local}.

\lin

\begin{defn}
A marked point process \(\rp\) is called non-explosive if \(\ex{(\rpg)_T} < \infty\). (Based on boundedly finite measures \cite[Definition 9.1.I]{DalVer08}.
\label{subsec::Prope:Def::non-explosive}
\end{defn}
\labe{subsec::Prope:Def::non-explosive}

\textbf{Source: } Called boundedly finite measures in \cite[Definition 9.1.I]{DalVer08}.

\purpose This is an assumption used in several theorems in \cite{DalVer03} and \cite{DalVer08}.

\lin

\begin{defn}
Let \(\rp\) be a non-explosive marked point process on the Polish space \([0,\infty)\times \mspce\) adapted to some filtration \(\F\ts{\t}\). Let \(\ell\) be some fixed non-negative measure on \(\mspce\) which we will call the reference measure on \(\mspce\). Then \(\rp\) is said to have \(\F\ts{\t}\)-predictable intensity \(\rate(\t,k)\) if for all \(K \in \ms{B}(\mspce)\), \(\int_K \rate(\t,k)\ell(dk)\) is the \(\F\ts{\t}\)-predictable intensity of \(\rp([0,\t]\times K)\). 
\label{subsec::Prope:Def::MI defn}
\end{defn}
\labe{subsec::Prope:Def::MI defn}

\textbf{Source: }\cite[Definition 14.3.I]{DalVer08}

\purpose Section \ref{subsec::ProofU:sec::Proof2} makes heavy use of relative likelihoods of Marked point processes which can be written in terms of the intensity of the process.

\lin

\begin{prop}
Suppose \(\rp\) is a \(\F\)-adapted non-explosive marked point process on \([0,\infty)\times \mspce\) with \(\F\)-predictable intensity \(\rate\). Suppose \(\F\ts{\t}\) can be expressed in the form \(\F\ts{\t} = \F\ts{0}\wedge \FH{\t}\) where \(\FH{\t}\) is the natural history of \(\rp\) and \(\F\ts{0} = \sigma(\X\cind{}\tp{0})\) for some random variable \(\X\cind{}\tp{0}\). Let \(E = \{(\rt{n},\mark{n})\}\) be the sequence of events of \(\rp\) increasing in \(\rt\). Then \(\rate\) uniquely characterizes \(\rp\).
\label{subsec::Prope:Prop::intense char}
\end{prop}
\labe{subsec::Prope:Prop::intense char}

\purpose This means that for non-explosive point processes, it is enough to know the intensity. This is why the statement of Proposition \ref{subsec::Prope:Prop::radnikder} is meaningful.

\pfsum Apply \cite[Propositions 14.3.II(b),14.2.IV(c) and 9.2.III]{DalVer08}. There is one extra technical condition that we have to proof holds which we can show using \cite[Proposition A1.5.III]{DalVer03}.

\begin{proof}
Assume that \(\law((\rt{n},\mark{n})|\F\ts{\rt{n-1}})\) is a regular distribution for all \(n\). Then uniqueness of the intensity is given by \cite[Proposition 14.3.II (b)]{DalVer08}. By \cite[Proposition 14.2.IV (c)]{DalVer08}, the compensator of \(\rp\) uniquely defines the finite dimensional distributions of \(\rp\), which uniquely define \(\rp\) in distribution \cite[Proposition 9.2.III]{DalVer08}. However, the intensity of \(\rp\) uniquely defines its compensator, so all that remains is to prove that the regular conditional distribution above exists.

\ind Fix \(n\). Suppose \(\XX\) is a \(\spce\)-valued random variable. Let \(\m\) be the law of \(\rp\). Then \(\left([0,\infty)\times \mspce\right)^{n-1}\times\spce\) and \([0,\infty)\times \mspce\) are both Polish spaces, and \(\alt{\m}\) defined by 

\[\alt{\m}((\t{n},k{n}),(	{i},k{i})_{i=1}^{n-1},\xxx) = \m\left((\rt{i},\mark{i}) = (	{i},k{i})\te{ for } i=1,\dots,n, \XX = \xxx\right)\]

is a Borel measure. Therefore, by \cite[Proposition A1.5.III]{DalVer03}, the regular conditional distribution \(\ms{L}((\rt{n},\mark{n})|\F\ts{\rt{n-1}})\) exists.
\end{proof}


\lin

\begin{lem}
Suppose \(\rp\) is a marked process with \(\F\ts{\t}\)-predictable ground intensity \(\rate{\t}\) bounded by some \(\const < \infty\). Assume \(\rp\) has marks in \(\mspce\) and \(\rate\) is defined with respect to the reference measure \(\Sm\) on \(\mspce\). Then for all \(K \in \ms{B}(\mspce)\), \(\rp([0,\t]\times K) - \int_0^\t\int_K \rate(\tt,\mark)\,\ell(d\mark)\,ds\) is a Martingale.
\label{Subsec::Prope:Lem::easier}
\end{lem}
\labe{Subsec::Prope:Lem::easier}

\begin{proof}
Fix some \(K \in \ms{B}(\mspce)\). Let \(\rate{K}(\t) = \rate(\t,K)\). Let \(\rp{K}(\cdot) = \rp(\cdot\times K)\). Then \(\rate{K}(\t) \leq \rate(\t,\mspce) \leq \const\). Therefore \(\rp{K}\) is a simple point process with bounded intensity. Reduce to the case of a simple point process (\(\mspce = \{0\}, K = \mspce, \rp = \rp{K},\rate(\t) = \rate{K}(\t)\)).

Let \(M(\t) = \rp(\t) - \int_0^\t \rate(\tt)\,ds\). Let \(\rt{n}\) be a localizing sequence of \(M(\t)\). Notice for all \(n\),

\[|M(\t\wedge \rt{n})| \leq \max\{\rp(\t\wedge \rt{n}),\t\const\}\leq \max\{\rp(\t),\t\const\}\]

So \(M(\t\wedge\rt{n})\) is dominated by \(\max\{\rp(\t),\t\const\}\), and \(\ex{\max\{\rp(\t),\t\const\}} \leq \ex{\rp(\t) + \t\const} \leq 2\t\const < \infty\). By dominated convergence,

\[\ex{M(\t)|\F\ts{\tt}} = \ex{\lim_{n\ra\infty} M(\t\wedge \rt{n})\middle|\F\ts{\tt}} = \lim_{n\ra\infty}\ex{M(\t\wedge \rt{n})|\F\ts{\tt}} = \lim_{n\ra\infty} M(\tt\wedge \rt{n}) = M(\tt)\]
\end{proof}

\lin

\begin{lem}
Let \(\rp\) be a marked point process with bounded \(\F\ts{\t}\)-predictable ground intensity \(\rate_g\leq B\). Suppose that for any \(K \subseteq \mspce\), \(\rate(\t,K)\) is almost surely left-continuous. Then for any \(K \subseteq \mspce\),

\[\rate(\t,K) = \lim_{s\searrow 0}\frac{1}{\tt}\ex{\rp((\t,\t+\tt]\times K)|\F\ts{\t-}}\]

\tb{There is a slight subtlety here. We need to know that the intensity exists and that it is left-continuous and uniformly bounded for this lemma to hold. Otherwise, this can fail in a number of ways. Proving existence of the intensity is fine, but left-continuity can be tedious.}

\label{Subsec::Prope:Lem::easy intense calc}
\end{lem}
\labe{Subsec::Prope:Lem::easy intense calc}

\begin{proof}
By Lemma \ref{Subsec::Prope:Lem::easier}, we can use the Martingale definition of intensity.

\begin{align*}
\lim_{\tt\searrow 0}\frac{1}{\tt}\ex{\rp((\t,\t+\tt]\times K)|\F\ts{\t-}}& = \lim_{\tt\searrow 0}\frac{1}{\tt}\ex{\ex{\rp((\t,\t+\tt]\times K)|\F\ts{\t}}\middle|\F\ts{\t-}}\\
&= \lim_{\tt\searrow 0}\frac{1}{\tt}\ex{\ex{\int_\t^{\t+\tt} \rate(r,K)\,dr\middle|\F\ts{\t}}\middle|\F\ts{\t-}}\\
&= \ex{\ex{\lim_{\tt \searrow 0} \frac{1}{\tt}\int_\t^{\t+\tt} \rate(r,K)\,dr\middle|\F\ts{\t}}\middle|\F\ts{\t-}}\\
&=\ex{\ex{\rate(\t+,K)|\F\ts{\t}}\middle|\F\ts{\t-}}\\
&=\rate(\t,K)
\end{align*}

We were able to move the limit inside the expectation by bounded convergence. Then we apply Lebesgue differentiation getting a right-continuous modification by virtue of the integral chosen in the prelimit.
\end{proof}

\lin

\tr{Commented out and unused proposition. Revisit later.}
%\begin{prop}
%Suppose \(\rp{}\) is a \(\F\vsi{}\ts{}\)-adapted point process on \([0,\T)\times \spce\) with \(\F\vsi{}\ts{}\)-predictable intensity \(\ratee{\t}:\spce \ra\mb{R}^+\) with respect to the reference probability measure \(\Sm\) on \(\spce\). Suppose there exists a constant \(\const{} < \infty\) such that \(\rate{}\) is bounded from above by \(\const{}\). Then for any interval \(I \subseteq [0,\T)\) and any measurable \(\typset \subseteq \spce\),
%
%\[\pr(\rp{}(I\times\typset) = 0) = \exp\left(-\ex{\int_I\int_\typset \ratee{\t}(\mark{})\,\Sm(d\mark{})\,d\t}\right).\]
%\label{subsec::Prope:Prop::voidprob}
%\end{prop}
%\labe{subsec::Prope:Prop::voidprob}
%
%\begin{proof}
%The proof is similar to the proof of \cite[Lemma 1]{BreMas96}. By Lemma \ref{Subsec::Prope:Lem::easier}, \(M(\t) = \rp{}([0,\t]\times \typset) - \int_0^\t \int{\typset} \ratee{\tt}(\mark{})\,\Sm{}(d\mark{})\,d\tt\) is a Martingale. Then,
%
%\[\ex{\rp{}(I\times\typset)} = \ex{\int_I\int_\typset \ratee{\t}(\mark{})\,\Sm(d\mark{})\,d\t} \os{\te{Tonelli}}{=} \int_I\int_\typset \ex{\ratee{\t}(\mark{})}\,\Sm(d\mark{})\,d\t.\]
%
%Let \(\rp{\typset}(\t) \defeq \rp{}([0,\t]\times \typset)\). Since \(\ratee{}\) is bounded, we can assume without loss of generality that \(I = (a,b]\) for some \(0 \leq a < b < \T\). Then,
%
%\[\mb{I}_{\rp{}{(a,b]\times \typset} = 0} = 1 - \int{(a,b]} \mb{I}_{\rp{}((a,\t)\times \typset) = 0}\,\rp{\typset}(d\t).\]
%
%
%Taking an expectation,
%
%\[\pr\left(\rp{}(I\times\typset)=0\right) = 1 - \ex{\int{(a,b]}\mb{I}_{\rp{}((a,\t)\times \typset) = 0}\,\rp{\typset}(d\t)}.\]
%
%\tr{for me: Since \(\mb{I}_{\rp{}((a,\t)\times \typset) = 0}\) is \(\F\vsi{}\ts{\t}\)-predictable, we can replace the integral with respect to \(\rp{\typset}\) with an integral with density \(\ratee{}\). To prove this fact, it suffices to show it for elementary predictable functions and then extend to all predictable processes.}
%
%\ind Then,
%
%\begin{align*}
%\pr\left(\rp{}(I\times\typset)=0\right) &= 1 - \ex{\int{(a,b]}\mb{I}_{\rp{}((a,\t)\times \typset) = 0}\int_\typset\ratee{\t}(\mark{})\,\Sm(d\mark{})\,d\t}\\
%& = 1 - \int{I\times \typset} \pr\left(\rp{}((a,\t)\times\typset) = 0\right)\ex{\ratee{\t}(\mark{})|\rp{}((a,\t)\times\typset) = 0}\,\Sm(d\mark{})\,d\t.\\
%& = 1 - \int{I\times \typset} \pr\left(\rp{}((a,\t]\times\typset) = 0\right)\ex{\ratee{\t}(\mark{})|\rp{}((a,\t)\times\typset) = 0}\,\Sm(d\mark{})\,d\t.
%\end{align*}
%
%Letting \(f(\t) = \pr(\rp{}((a,\t]\times \typset) = 0)\) and \(g(\t) = \int_A\ex{\ratee{\t}(\mark{})|\rp{}((a,\t)\times \typset) = 0}\Sm(d\mark{})\), this simplifies to
%
%\[f(\t) = 1 - \int_a^\t f(\tt)g(\tt)\,d\tt.\]
%
%This has the unique solution,
%
%\[f(\t) = \exp\left(-\int_a^\t g(\tt)\,d\tt\right).\]
%
%That is,
%
%\[\pr\left(\rp{}(I\times\typset) = 0\right) = \exp\left(-\int{I\times\typset} \ex{\ratee{\t}(\mark{})|\rp{}((a,\t)\times\typset) = 0}\,\Sm(d\mark{})\,d\t\right).\]
%
%\end{proof}


\lin

\begin{prop}
Let \(\rp\) be a marked process adapted to the filtration \(\F\ts{\t} := \F\ts{0}\wedge \FH{\t}\) where \(\FH\) is its natural filtration. Let the events and marks of \(\rp\) be given by \(\{(\rt{j},\mark{j})\}\) such that \(\{\rt{j}\}\) is an almost surely increasing sequence. For \(i \in \{1,2\}\), let \(\pr{i}\) be probability measures on the probability space such that \(\rp\) is non-explosive and simple with respect to both probability measures. Let \(\pr{i}_\t\) be the restriction of \(\pr{i}\) to \(\F\ts{\t}\). Suppose \(\F\ts{0}\) describes a random variable, \(\X\), with law \(\mm^i\) under \(\pr{i}\). If \(\rp\) has a strictly positive \(\pr{1},\F\)-predictable intensity \(\rate^1\), then \(\pr{2}_\t \ll \pr{1}_\t\) for all \(\t \in [0,T]\) if and only if there exists a non-negative, \(\F\)-predictable process \(\m\) such that \(\rp\) admits the \(\F\)-intensity \(\rate^2 = \m\rate^1\) under \(\pr{2}\) and \(\mm^2 \ll \mm^1\). When this is satisfied, the likelihood ratio is the \(\pr{1}\)-a.t. c\`adl\`ag process defined by 

\begin{equation}
L_\t:= \frac{d\pr{2}_\t}{d\pr{1}_\t}(\rp) = \frac{d\mm^2}{d\mm^1}\left(\prod_{0<\rt^i\leq \t} \m(\rt^i,\mark{i})\right)\exp\left(-\int{(0,\t]\times \mspce}[\m(\t,\mark) - 1]\rate^1(\t,\mark)\,ds\,\ell(d\mark)\right)
\label{subsec::Prope:eqn::Lnat}
\end{equation}
\labe{subsec::Prope:eqn::Lnat}
\label{subsec::Prope:Prop::radnikder}
\end{prop}
\labe{subsec::Prope:Prop::radnikder}

\purpose We can define a standard process by choosing some fixed intensity \(\rate^1\) and use it to completely characterize Markov processes. In fact, a large portion of section \ref{subsec::ProofU:sec::Proof2} involves manipulations of such Radon-Nykodim derivatives to construct various processes.

\pfsum In the case where \(\F\ts{0}\) is trivial, we can directly apply \cite[Theorem 14.4.I]{DalVer08}. To extend, we define \(\pr{i}\) as an integral of a class of regular conditional probabilities and apply \cite[Theorem 14.4.I]{DalVer08} accordingly.

\begin{proof}
Let \(f\) be a bounded, \(\alt{\F}{\t}\) measurable function to the real numbers. Let \(\m(\t,k;\xx,\x)\) be the value \(\m\) takes when \(\rp[0,\t)=\xx[0,\t)\) and \(\{\X=\x\}\). Since \(\m\) is \(\alt{\F}\)-predictable, this is deterministic for any \(\xx,\x\).

\[\mb{E}^2[f(\X,\rp[0,\t])] = \int_\spce \mb{E}^2[f(\x,\rp[0,\t])|\X=\x]\,d\mm^2(\x)\]

Note that for any fixed \(\x \in \te{supp}(\X)\) and any \(i \in \{1,2\}\), there exists a regular conditional distribution \(\pr{i}_\x\) which describes the law of \(\rp\) conditioned on \(\X = \x\).

\[\mb{E}^2[f(\X,\rp[0,\t])] = \int_\spce \mb{E}^2_\x[f(\x,\rp[0,\t])]\,d\mm^2(\x)\]

Note that for any fixed \(\x\), \(\pr{i}_\x\) and \(\rp\) satisfy the conditions of \cite[Theorem 14.4.I]{DalVer08}. So,

\[L_\t(\rp,\x):=\frac{d\pr{2}_{\t,\x}}{d\pr{1}_{\t,\x}}(\rp) = \left(\prod_{0<\rt^i\leq \t} \m(\rt^i,\mark{i};\rp,\x)\right)\exp\left(-\int{(0,\t]\times\mspce} [\m(\tt,k;\rp,\x) - 1]\rate^1(\tt,k;\rp,\x)\,ds\,\ell(dk)\right)\]

Giving us,

\begin{align*}
\mb{E}^2\left[f(\X,\rp[0,\t])\right] &= \int_\spce \mb{E}^2_\x[f(\x,\rp[0,\t])]\,d\mm^2(\x)\\
&=\int{\spce} \mb{E}^1_\x[f(\x,\rp[0,\t])L_\t(\rp,\x)]\,d\mm^2(\x)\\
&= \int{\spce} \frac{d\mm^2}{d\mm^1}(\x) \mb{E}^1_\x[f(\x,\rp[0,\t])L_\t(\rp,\x)]\,d\mm^1(\x)\\
&= \mb{E}^1\left[f(\X,\rp[0,\t])L_\t(\rp,\X)\frac{d\mm^2}{d\mm^1}\right]
\end{align*}
\end{proof}

\lin

\subsection{Some Results on History-Dependent Poisson SDEs}
\label{subsec::Some:sec::Point}\labe{subsec::Some:sec::Point}

\lin

\begin{lem}
Let \(G = (V,E)\) be a finite graph and let \(0 < \const{}< \infty\). Let \(\X\cind{}\tp{0}\) be an \(\S\carp{V}\)-valued random variable. Let \(\Sm\) be a probability measure over \(\S\) with positive weight on all elements in \(\S\setminus\{0\}\) and 0 weight on \(\{0\}\). Let \(\{\ratee{\t,\v}\}_{\v \in V,\t\in [0,\T]}\) be a set of measurable mappings from \(\sset\vsi{V}\ts{\t-} \times \S\) to \([0,\const{}]\) such that if \(h \in \sset\vsi{V}\ts{\t-}\), then \(\t\mapsto \ratee{\t,\v}(h[0,\t),\s)\) is left-continuous for all \(\v \in V\) and \(\s \in \S\). Let \(\{\poiss\vind{\v}\}_{\v \in V}\) be i.i.d. Poisson processes on \(\mb{R}^+\times \S\times\mb{R}^+\) with intensity measure \(\leb\otimes\Sm\otimes\leb\) where \(\leb\) is the Lebesgue measure on \(\mb{R}\).

\ind Then given any \(\S\carp{V}\)-valued random variable, \(\X\cind{}\tp{0}\), the following SDE has a unique strong solution:

\begin{equation}
\X\cind{\v}\tp{\t} = \X\cind{0}\tp{\v} + \int{(0,\t]}\int_\S\int{(0,\ratee{\tt,\v}(\X\cind{}\tip{[0,\tt)},\s)]}  \s\,\poiss\vind{\v}(d\r,d\s,d\tt)
\label{subsec::Some:eqn::genfiniteSDE}
\end{equation}
\labe{subsec::Some:eqn::genfiniteSDE}
\label{subsec::Some:Lem::genfiniteSDE}
\end{lem}
\labe{subsec::Some:Lem::genfiniteSDE}

\purpose The local representation is given by a fixed point SDE of this form. We will create several processes that solve similar equations and we need them to be well-posed.

\pfsum Direct construction.

\begin{proof}
Since \(\ratee{\tt,\v} \leq \const{}\), we can view \(\{\poiss\vind{\v}:\v\in V\}\) as a sequence of Poisson random measures on \([0,\T)\times \S\times [0,\const{}]\). Notice that,

\[\ex{\sum_{\v\in V}\poiss\vind{\v}([0,\T)\times\S\times[0,\const{}])} = \const{}\T|V|.\]

Thus, \(\sum_{\v\in V}\poiss\vind{\v}\) is an almost surely finite measure on \([0,\T)\times \S\times [0,\const{}]\). Let \(\{(\rt{\it},\mark{\it},\r{\it},\v{\it}):\it = 0,\dots,n, n\in \mb{N}\}\) be the set of events of \(\sum_{\v\in V}\) in \([0,\T)\times\S\times [0,\const{})\times V\) ordered so that \(0=\rt{0} < \rt{1} < \cdots < \rt{n} < \T\). In each event, \(\rt{\it} \in [0,\T)\), \(\mark{\it}\in \S\setminus\{0\}, \r{\it} \in [0,\const{}]\) and \(\v{\it} \in V\) denotes which process went off.

\ind Let \(\X\cind{}\tip{}\) be the c\`adl\`ag process constructed below:

\begin{enumerate}
\item \(\X\cind{}\tp{0}\) is given as in the statement of the Lemma.

\item \(\X\cind{}\tp{\t} = \X\cind{}\tp{0}\) on \([0,\rt{1})\).

\item 

\[\X\cind{}\tp{\rt{1}} = \begin{cases}
\X\cind{}\tp{0} + \mark{1}\ev\vind{\v{1}} &\te{ if } \r{1} \leq \ratee{\rt{1},\v{1}}(\X\cind{}\tip{[0,\rt{1})},\mark{1})\\
\X\cind{}\tp{0} &\te{ otherwise.}
\end{cases}
\] 

\item Continue on. In general, \(\X\cind{}\tp{\t} = \X\cind{}\tp{\rt{\it-1}}\) on \(\t \in [\rt{\it-1},\rt{\it})\) for \(\it= 1,\dots,n\).

\item 

\[\X\cind{}\tp{\rt{\it}} = \begin{cases}
\X\cind{}\tp{\rt{\it-1}} + \mark{\it}\ev\vind{\v{\it}} &\te{ if } \r{\it} \leq \ratee{\rt{\it},\v{\it}}(\X\cind{}\tip{[0,\rt{\it})},\mark{\it})\\
\X\cind{}\tp{\rt{\it-1}} &\te{ otherwise.}
\end{cases}\]

\item Then \(\X\cind{}\tp{\t} = \X\cind{}\tp{\rt{n}}\) for \(\t\in [\rt{n},\T)\).
\end{enumerate}

\(\X\cind{}\tip{}\) solves equation \eqref{subsec::Some:eqn::genfiniteSDE} by construction. Furthermore, if \(\XX{}{}\) also solves \eqref{subsec::Some:eqn::genfiniteSDE}, then 

\begin{enumerate}
\item \(\XX{}{0} = \X\cind{}\tp{0}\) by assumption.

\item \(\XX{}{\t} = \XX{}{0} = \X\cind{}\tp{0} = \X\cind{}\tp{\t}\) for all \(\t\in [0,\rt{1})\).

\item 

\begin{align*}
\XX{}{\rt{1}} &= \begin{cases}
\XX{}{0} + \mark{1}\ev\vind{\v{1}} &\te{ if } \r{1} \leq \ratee{\rt{1},\v{1}}(\XX{}{[0,\rt{1})},\mark{1})\\
\XX{}{0} &\te{ otherwise.}
\end{cases}\\
&= \begin{cases}
\X\cind{}\tp{0} + \mark{1}\ev\vind{\v{1}} &\te{ if } \r{1} \leq \ratee{\rt{1},\v{1}}(\X\cind{}\tip{[0,\rt{1})},\mark{1})\\
\X\cind{}\tp{0} &\te{ otherwise.}
\end{cases}\\
&= \X\cind{}\tp{\rt{1}}.
\end{align*}

\item Inductive hypothesis: \(\XX{}{\t} = \X\cind{}\tp{\t}\) for \(\t\in [0,\rt{\it})\). 

\item 

\begin{align*}
\XX{}{\rt{\it}} &= \begin{cases}
\XX{}{\rt{\it-1}} + \mark{\it}\ev\vind{\v{\it}} &\te{ if } \r{\it} \leq \ratee{\rt{\it},\v{\it}}(\XX{}{[0,\rt{\it})},\mark{\it})\\
\XX{}{\rt{\it-1}} &\te{ otherwise.}
\end{cases}\\
&= \begin{cases}
\X\cind{}\tp{\rt{\it-1}} + \mark{\it}\ev\vind{\v{\it}} &\te{ if } \r{\it} \leq \ratee{\rt{\it},\v{\it}}(\X\cind{}\tip{[0,\rt{\it})},\mark{\it})\\
\X\cind{}\tp{\rt{\it-1}} &\te{ otherwise.}
\end{cases}\\
&= \X\cind{}\tp{\rt{\it}}.
\end{align*}

\item Then \(\XX{}{\t} = \XX{}{\rt{\it}} = \X\cind{}\tp{\rt{\it}} = \X\cind{}\tp{\t}\) for \(\t \in [\rt{\it},\rt{\it+1})\). Then, \(\XX{}{\t} = \X\cind{}\tp{\t}\) for \(\t\in [0,\rt{\it+1})\).

\item Finally, \(\XX{}{\t} = \XX{}{\rt{n}} = \X\cind{}\tp{\rt{n}} = \X\cind{}\tp{\t}\) for \(\t\in [\rt{n},\T)\), so \(\XX{}{} = \X\cind{}\tip{}\) almost surely.
\end{enumerate}
\end{proof}

\lin

\begin{lem}
Suppose that \(V\) is finite. Recall that \(\pmap{}\) maps c\`adl\`ag processes to marked point processes (see definition \ref{subsec::ProofE:Defn::pmap}). Suppose \(\rp{} = \pmap{}(\XX{}{})\) for some \(\sset\vsi{V}\ts{\T-}\)-valued stochastic process, \(\XX{}{}\). Suppose also that \(\rp{}\) has \(\XX{}{}\)-predictable, left-continuous \tr{(If we can remove the left-continuous assumption in Lemma \ref{subsec::Some:Lem::genfiniteSDE}, then this becomes unnecessary.)} intensity \(\ratee{\t}(\cdot)\) bounded from above by \(\const{}\). Suppose there exist mappings \(\{\ratee{\t,\v}:\sset\vsi{}\ts{\t-}\times \S \ra [0,\const{}]\}_{\t\in[0,\T),\v\in V}\) such that 

\begin{equation}
\ratee{\t}(\sv\cind{}\vsi{V}) := \begin{cases}
\ratee{\t,\v}(\XX{}{[0,\t)},\s) &\te{ if } \sv\cind{}\vsi{V} = \s\ev\vind{\v}\\
0 &\te{ otherwise,}
\end{cases}
\label{subsec::Some:eqn::intense}
\end{equation}
\labe{subsec::Some:eqn::intense}

and such that \(\t\mapsto \ratee{\t,\v}(\XX{}{[0,\t)},\sv\cind{}\vsi{V})\) is almost-surely left continuous on \([0,\T)\) for all \(\v\in V,\sv\cind{}\vsi{V}\in \S\carp{V}\). Then there is a unique solution, \(\X\cind{}\tip{}\), to equation \eqref{subsec::Some:eqn::genfiniteSDE}, and if \(\X\cind{}\tp{0} \deq \XX{}{0}\), then \(\X\cind{}\tip{} \deq \XX{}{}\).

\label{subsec::Some:Lem::PPtoSDE}
\end{lem}
\labe{subsec::Some:Lem::PPtoSDE}

\begin{proof}

We can assume without loss of generality that \(\ratee{\t,\v}(\xx{}{[0,\t)},\s) = 0\) for all \(\xx{}{[0,\t)}\in \sset\vsi{}\ts{\t-}\) such that \(\pr(\XX{}{[0,\t)} = \xx{}{[0,\t)}) = 0\). Then since \(\ratee{\t}(\cdot)\) is almost surely left-continuous, we can conclude that \(\ratee{\t,\v}(\cdot,\s)\) is left-continuous with respect to \(\t\) given c\`adl\`ag inputs for all \(\v\in V,\s\in\S\). By Lemma \ref{subsec::Some:Lem::genfiniteSDE}, the following equation has a unique solution:

\[\X\cind{\v}\tp{\t} = \X\cind{0}\tp{\v} + \int{(0,\t]}\int_\S\int{(0,\ratee{\tt,\v}(\X\cind{}\tip{[0,\tt)},\s)]}  \s\,\poiss\vind{\v}(d\r,d\s,d\tt).\]

By \cite[Exercise 14.7.1]{DalVer08}, \(\pmap{\v}(\X\cind{}\tip{})\) has \(\X\cind{}\tip{}\)-predictable intensity \(\ratee{\t,\v}(\X\cind{}\tip{[0,\t)},\s)\) for \(\s \in \S\). Then \(\alt{\rp{}} \defeq \pmap{}(\X\cind{}\tip{})\) has \(\X\cind{}\tip{}\)-predictable intensity,

\[\ratee{\t}(\X\cind{}\tip{[0,\t)},\sv\cind{}\vsi{V}) = \begin{cases}
\ratee{\t,\v}(\X\cind{}\tip{[0,\t)},\sv\cind{}\vsi{V}) &\te{ if } \sv\cind{}\vsi{V} = \s\ev\vind{\v}\\
0&\te{ otherwise.}
\end{cases}\]

By assumption, \(\X\cind{}\tp{0} \deq \XX{}{0}\). Thus, \(\rp{}\) and \(\alt{\rp{}}\) have the same intensity. By Proposition \ref{subsec::Prope:Prop::intense char}, \(\rp{} \deq \alt{\rp{}}\).
\end{proof}
\lin

\begin{lem}
Assume the notation and assumptions from Lemmas \ref{subsec::Some:Lem::genfiniteSDE} and \ref{subsec::Some:Lem::PPtoSDE} hold under the probability measure \(\m{}{}{}\). Suppose under \(\mm{}{}{}\), \(\X\cind{}\tip{}\) solves,

\[\X\cind{\v}\tp{\t} = \X\cind{\v}\tp{0} +\int{(0,\t]}\int_\S\int{(0,1]} \s \poiss\vind{\v}(d\r,d\s,d\tt),\]

where \(\{\X\cind{\v}\tp{0}\}_{\v \in V}\) are i.i.d uniformly distributed over \(\S\). Let \(\rp{} \defeq \pmap{}(\X\cind{}\tip{}) = \{(\rt{\it},\mark{\it}):\it\in \mb{N}\}\).

\ind Let \(\ov{\ell}\) be the extension of \(\Sm\) to \(\alt{\S} = \{\s\ev\vind{\v}: \s \in \S, \v \in V\}\) given by \(\alt{\Sm}(\typset\ev\vind{\v}) = \Sm(\typset)\) for any \(\typset \subseteq \S\). Then,

\begin{equation}
\frac{d\m{}{\t}{}}{d\mm{}{\t}{}}= \frac{d\m{}{0}{}}{d\mm{}{0}{}}\left(\prod_{0< \rt{\it}\leq \t} \ratee{\t}(\mark{\it})\right)\exp\left(-\int{(0,\t]\times \S} (\ratee{\tt}(\s) - 1)\,d\tt\alt{\Sm}(d\s)\right)
\label{subsec::Some:eqn::radnik}
\end{equation}
\labe{subsec::Some:eqn::radnik}
\label{subsec::Some:Lem::radnik}
\end{lem}
\labe{subsec::Some:Lem::radnik}

\purpose This lemma combined with Lemma \ref{subsec::Some:Lem::genfiniteSDE} allow us to freely alternate between SDE and density formulations of finite node Markov processes.

\pfsum The key is to express \(\X\) in terms of a Marked point process. Then we can compute the intensities of the point process under \(\m\) and \(\mm\) respectively and apply Proposition \ref{subsec::Prope:Prop::radnikder}.

\begin{proof}
Notice that \(\X\cind{}\tip{} \mapsto (\X\cind{}\tp{0},\pmap{\X\cind{}\tip{}})\) is a one-to-one mapping from c\`adl\`ag processes on \(\S\carp{V}\) to marked point processes with marks in \(\alt{\S}\). Thus, we can consider \(\rp{}\) a marked point process with marks in \(\alt{\S}\). In both cases, \(\rp{}\) is \(\F\vsi{}\ts{\t}\)-adapted, where \(\F\vsi{}\ts{\t} = \F\vsi{}\ts{0}\vee \FH{}{\t}\) and \(\FH{}{\t}\) is the natural filtration of \(\rp{}\).

\ind By Lemma \ref{subsec::Some:Lem::PPtoSDE}, \(\rp{}\) has predictable intensity \(\ratee{\t}(\cdot)\) with respect to \(\F\vsi{}\ts{\t}\) and \(\m{}{}{}\). \(\rp{}\) has predictable intensity 1 with respect to \(\F\vsi{}\ts{\t}\) and \(\mm{}{}{}\). This holds all of the information about the original process \(\X\cind{}\tip{}\), so we can consider \(\frac{d\m{}{\t}{}}{d\mm{}{\t}{}}\) as a change of measure affecting \(\rp{}\) instead of \(\X\cind{}\tip{}\). In Lemma \ref{subsec::Some:Lem::genfiniteSDE}, it was assumed that \(\ratee{\t,\v}\) is bounded. Thus, the result follows directly from Proposition \ref{subsec::Prope:Prop::radnikder}. 
\end{proof}

\lin
\section{Other Technical Lemmas}
\label{sec::TL}\labe{sec::TL}

\begin{lem}
Assume \(\X,\XX\) and \(\XXX\) are random elements such that \(\X\perp \XX|\XXX\). Assume also that \(\pr(\X=0) = \pr(\XX=0) = \pr(\XXX=0) = 0\).

\begin{enumerate}[(a)]
\item If \(\phi,\psi\) are measurable functions and \(\theta\) is a 1-to-1 function, then \(\phi(\X)\perp \psi(\XX)|\theta(\XXX)\).

\item If \(T\perp(\X,\XX,\XXX)\), then \(\X\perp \XX|(\XXX,T)\), \((\X,T)\perp \XX|\XXX\) and \(\X\perp (\XX,T)|\XXX\).

\item If \(T\perp (\X,\XX,\XXX)\) and \(\phi\) is a measurable function, then

\[\X\perp \XX|(\XXX,\phi(\X,\XXX,T))\]

\item If \(\typset\) is \(\sigma(\XXX)\) measurable, then 

\[\X\mb{I}_\typset\perp \XX\mb{I}_\typset|\XXX\mb{I}_\typset\]

\item If \(U\perp V\) and \((U,V)\perp(\X,\XX,\XXX)\), then 

\[(\X,\XXX,U)\perp (\XX,\XXX,V)|\XXX\]

\item Suppose \(\X\mb{I}_{	ypset{i}}\perp \XX\mb{I}_{	ypset{i}}|\XXX\mb{I}_{	ypset{i}}\) for all \(i\in I\) where \(I\) is a finite or countably infinite set and \(\{	ypset{i}\}\) is a family of disjoint sets. Then,

\[\X\mb{I}_{\cup_i 	ypset{i}}\perp \XX\mb{I}_{\cup_i 	ypset{i}}|\XXX\mb{I}_{\cup_i 	ypset{i}}\]

\item Let \(\typset\) be any event such that \(\pr(\typset) > 0\). Suppose \(U\mb{I}_\typset\perp \mb{I}_\typset(\X,\XX,\XXX)|\mb{I}_\typset\). Suppose also that \(\X\mb{I}_\typset\perp \XX\mb{I}_\typset|\mb{I}_\typset(\XXX,U)\), but do not necessarily assume \(\X\perp \XX|\XXX\). Then 

\[\X\mb{I}_\typset\perp \XX\mb{I}_\typset|\XXX\mb{I}_\typset\]

\item If \(\typset\) is an event that happens with probability 1, and \(\X\mb{I}_\typset \perp \XX\mb{I}_\typset |\XXX\mb{I}_\typset\), then 

\[\X\perp \XX |\XXX\]
\end{enumerate}
\label{sec::TL:Lem::Props}
\end{lem}
\labe{sec::TL:Lem::Props}

\begin{proof}
For all parts of this lemma, I use the following two results:

\begin{itemize}
\item \(\X\perp \XX|\XXX\) if and only if

\[\ex{\ex{f(\X)|\XXX}g(\XX)h(\XXX)} = \ex{f(\X)g(\XX)h(\XXX)}\]

for all bounded non-negative measurable functions \(f,g\) and \(h\).

\item Any bounded non-negative measurable function in two variables \(f(\x,\xx)\) can be approximated by a sum of a product of two bounded non-negative measurable functions in one variable:

\[f(\x,\xx) = \sum_{k=1}^\infty f^k{1}(\x)f^k{2}(\xx)\]

Within this lemma, I will assume without loss of generality that all functions of the form \(f(\x,\xx)\) can be written as a product: \(f(\x,\xx) = f{1}(\x)f{2}(\xx)\).
\end{itemize}

\begin{enumerate}[(a)]
\item \(\tilde{f}(\X):=f(\phi(\X))\) and \(\tilde{g}(\XX):=g(\psi(\XX))\) are non-negative, bounded measurable functions, and \(\sigma(\theta(\XXX)) = \sigma(\XXX)\) because \(\theta\) is 1-to-1. Let \(\tilde{h}(\XXX):= h(\theta(\XXX))\). Then,

\begin{align*}
\ex{\ex{f(\phi(\X))|\theta(\XXX)}g(\psi(\XX))h(\theta(\XXX))} &= \ex{\ex{\tilde{f}(\X)|\XXX}\tilde{g}(\XX)\tilde{h}(\XXX)}\\
& = \ex{\tilde{f}(\X)\tilde{g}(\XX)\tilde{h}(\X)}\\
& = \ex{f(\phi(\X))g(\psi(\XX))h(\theta(\XXX))}
\end{align*}

\item Since \(T\perp (\X,\XX,\XXX)\), notice that by the tower property,

\[\ex{\ex{f{1}(\X)f{2}(\XX)|\XXX}g(\XXX)h(T)} = \ex{f{1}(\X)f{2}(\XX)g(\XXX)}\ex{h(T)} = \ex{f{1}(\X)f{2}(\XX)g(\XXX)h(T)}\]

So \((\X,\XX)\perp T|\XXX\). In particular, that means that 

\[\ex{\ex{f(\X)|\XXX,T}g(\XX)h(\XXX,T)} = \ex{\ex{f(\X)|\XXX}g(\XX)h_1(\XXX)}\ex{h_2(T)} = \ex{f(\X)g(\XX)h(\XXX,T)}\]

which proves that \(\X\perp \XX|\XXX,T\).

\[\ex{\ex{f{1}(\X)f{2}(T)|\XXX}g(\XX)h(\XXX)} = \ex{f{2}(T)}\ex{\ex{f{1}(\X)|\XXX}g(\XX)h(\XXX)} = \ex{f(\X,T)g(\XX)h(\XXX)}\]

So \((\X,T)\perp \XX|\XXX\). Then \(\X\perp (\XX,T)|\XXX\) by symmetry.

\item By part (b), 

\[(\X,T)\perp \XX|\XXX.\]

By \cite[Lemma 2.10]{RamCur} \tr{See if this has changed}, 

\[(\X,T)\perp \XX|(\XXX,\phi(\XXX,\X,T)).\]

By part (a),

\[\X\perp \XX|(\XXX,\phi(\XXX,\X,T))\]

\item Notice that the event \(\typset^c\) is an atom in \(\sigma(\XXX\mb{I}_\typset)\). For any \(B \in \sigma(\XXX)\) such that \(B\subset \typset\), \(B \in \sigma(\XXX\mb{I}_\typset)\). Therefore, we can represent all sets \(C \in \sigma(\XXX\mb{I}_\typset)\) by \(C = B\) or \(C = B\sqcup \typset^c\) where \(\{B\subset \typset\}\te{ and } B \in \sigma(\XXX)\). Suppose \(C = B\sqcup \typset^c\). Then,

\begin{align*}
\ex{\ex{f(\X\mb{I}_\typset)|\XXX\mb{I}_\typset}\mb{I}_C} &= \ex{f(\X\mb{I}_\typset)\mb{I}_\typset}+\ex{f(\X\mb{I}_\typset)\mb{I}_B} = \ex{f(0)\mb{I}_\typset} + \ex{\ex{f(\X)|\XXX}\mb{I}_B}\\
\end{align*}

So we can write

\begin{equation}
\ex{f(\X\mb{I}_\typset)|\XXX\mb{I}_\typset}(\omega) = \begin{cases}
\ex{f(\X)|\XXX}(\omega) &\te{ if } \omega \in \typset\\
f(0) &\te{ otherwise}
\end{cases}
\label{sec::TL:eqn::disjoint CE}
\end{equation}
\labe{sec::TL:eqn::disjoint CE}

Then

\begin{align*}
\ex{\ex{f(\X\mb{I}_\typset)|\XXX\mb{I}_\typset}g(\XX\mb{I}_\typset)h(\XXX\mb{I}_\typset)} &= \ex{\mb{I}_\typset\ex{f(\X)|\XXX}g(\XX)h(\XXX)} + \ex{\mb{I}_{\typset^c}f(0)g(0)h(0)}\\
&=\ex{\mb{I}_\typset f(\X)g(\XX)h(\XXX)}+\ex{\mb{I}_{\typset^c}f(0)g(0)h(0)}\\
&= \ex{f(\X\mb{I}_\typset)g(\mb{I}_\typset)h(\mb{I}_\typset)}
\end{align*}

which completes the proof.

\item We can show this directly:

\begin{align*}
\mb{E}\bigg[\ex{f{1}(\X)f{2}(\XXX)f{3}(U)|\XXX}g{1}(\XX)&g{2}(\XXX)g{3}(V)h(\XXX)\bigg]\\
&= \ex{f{3}(U)g{3}(V)}\ex{\ex{f{1}(\X)|\XXX}g{1}(\XX)(f{2}(\XXX)g{2}(\XXX)h(\XXX))}\\
&= \ex{f{3}(U)g{3}(V)}\ex{f{1}(\X)g{1}(\XX)f{2}(\XXX)g{2}(\XXX)h(\XXX)}\\
&= \ex{f(\X,\XXX,U)g(\XX,\XXX,V)h(\XXX)}
\end{align*}

\item First, if \(I\) is finite, then it suffices to prove conditional independence for \(I =\{1,2\}\). Notice that any set \(B \in \sigma(\XXX\mb{I}_{\typset{1}\sqcup \typset{2}})\) can be expressed as \(B = C\sqcup D\sqcup\{(\typset{1}\sqcup \typset{2})^c\}\) or \(B = C\sqcup D\) where \(C\in \sigma(\XXX\mb{I}_{\typset{1}})\), \(D \in \sigma(\XXX\mb{I}_{\typset{2}})\), \(C \subseteq \typset{1}\) and \(D \subseteq \typset{2}\). Notice also that the unions defining \(B\) are disjoint unions. Let \(B = C\sqcup D\sqcup \{(\typset{1}\sqcup \typset{2})^c\}\).

\begin{align*}
\mb{E}\bigg[\ex{f(\X\mb{I}_{\typset{1}\sqcup \typset{2}})|\XXX\mb{I}_{\typset{1}\sqcup \typset{2}}}&\mb{I}_B\bigg]= \ex{f(\X\mb{I}_{\typset{1}\sqcup \typset{2}})\mb{I}_B}\\
&= \ex{\mb{I}_Cf(\X\mb{I}_{\typset{1}\sqcup \typset{2}})} + \ex{\mb{I}_Df(\X\mb{I}_{\typset{1}\sqcup \typset{2}})} + \ex{\mb{I}_{(\typset{1}\sqcup \typset{2})^c}f(\X\mb{I}_{\typset{1}\sqcup \typset{2}})}\\
&= \ex{\mb{I}_C f(\X\mb{I}_{\typset{1}})} + \ex{\mb{I}_D f(\X\mb{I}_{\typset{2}})} + \ex{\mb{I}_{(\typset{1}\sqcup \typset{2})^c}f(0)}\\
&= \ex{\mb{I}_{C}\ex{f(\X\mb{I}_{\typset{1}})|\XXX\mb{I}_{\typset{1}}}} + \ex{\mb{I}_{D}\ex{f(\X\mb{I}_{\typset{2}})|\XXX\mb{I}_{\typset{2}}}} + \ex{\mb{I}_{(\typset{1}\sqcup \typset{2})^c}f(0)}
\end{align*}

In particular, we can write

\begin{equation}
\ex{f(\X\mb{I}_{\typset{1}\sqcup \typset{2}})|\XXX\mb{I}_{\typset{1}\sqcup \typset{2}}} = \mb{I}_{\typset{1}}\ex{f(\X\mb{I}_{\typset{1}})|\XXX\mb{I}_{\typset{1}}} + \mb{I}_{\typset{2}}\ex{f(\X\mb{I}_{\typset{2}})|\XXX\mb{I}_{\typset{2}}} + \mb{I}_{(\typset{1}\sqcup \typset{2})^c}f(0)
\label{sec::TL:eqn::disjoint sum CE}
\end{equation}
\labe{sec::TL:eqn::disjoint sum CE}

Then,

\begin{align*}
\mb{E}\bigg[\ex{f(\X\mb{I}_{\typset{1}\sqcup \typset{2}})|\XXX\mb{I}_{\typset{1}\sqcup \typset{2}}}&g(\XX\mb{I}_{\typset{1}\sqcup \typset{2}})h(\XXX\mb{I}_{\typset{1}\sqcup \typset{2}})\bigg]\\
&= \ex{\mb{I}_{\typset{1}}\ex{f(\X\mb{I}_{\typset{1}})|\XXX\mb{I}_{\typset{1}}}g(\XX\mb{I}_{\typset{1}})h(\XXX\mb{I}_{\typset{1}})} +\\
&\hspace{1 cm} \ex{\mb{I}_{\typset{2}}\ex{f(\X\mb{I}_{\typset{2}})|\XXX\mb{I}_{\typset{2}}}g(\XX\mb{I}_{\typset{2}})h(\XXX\mb{I}_{\typset{2}})} + \\
&\hspace{1 cm} \ex{\mb{I}_{(\typset{1}\sqcup \typset{2})^c}f(0)g(0)h(0)}\\
&= \ex{\mb{I}_{\typset{1}}f(\X\mb{I}_{\typset{1}})g(\XX\mb{I}_{\typset{1}})h(\XXX\mb{I}_{\typset{1}})} + \ex{\mb{I}_{\typset{2}}f(\X\mb{I}_{\typset{2}})g(\XX\mb{I}_{\typset{2}})h(\XXX\mb{I}_{\typset{2}})} +\\
&\hspace{1 cm} \ex{\mb{I}_{(\typset{1}\sqcup \typset{2})^c}f(0)g(0)h(0)}\\
&= \ex{f(\X\mb{I}_{\typset{1}\sqcup \typset{2}})g(\XX\mb{I}_{\typset{1}\sqcup \typset{2}})h(\XXX\mb{I}_{\typset{1}\sqcup \typset{2}})}
\end{align*}

Now suppose \(I\) is countably infinite. Without loss of generality, assume \(I = \mb{N}\). Furthermore, assume \(f(0) = g(0) = h(0) = 0\).

Then for any \(n \in \mb{N}\),

\[\ex{f(\X\mb{I}_{\sqcup_{i=1}^n 	ypset{i}})|\XXX\mb{I}_{\sqcup_{i=1}^n 	ypset{i}}} = \sum_{i=1}^n \mb{I}_{	ypset{i}}\ex{f(\X\mb{I}_{	ypset{i}})|\XXX\mb{I}_{	ypset{i}}} + \mb{I}_{\left(\sqcup_{i=1}^n 	ypset{i}\right)^c} f(0)\]

Therefore,

\[\ex{f(\X\mb{I}_{\sqcup_{i=1}^n 	ypset{i}})|\XXX\mb{I}_{\sqcup_{i=1}^n 	ypset{i}}} \nearrow \ex{f(\X\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}})|\XXX\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}}} \te{ almost surely}\]

furthermore, 

\[(g(\XX\mb{I}_{\sqcup_{i=1}^n 	ypset{i}}),h(\XXX\mb{I}_{\sqcup_{i=1}^n 	ypset{i}})) \nearrow (g(\XX\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}}),h(\XXX\mb{I}_{\sqcup_{i=1}^\infty  	ypset{i}})) \te{ almost surely}\]

By the monotone convergence theorem,

\begin{align*}
\lim_{n\ra\infty} \mb{E}\bigg[\ex{f(\X\mb{I}_{\sqcup_{i=1}^n 	ypset{i}})|\XXX\mb{I}_{\sqcup_{i=1}^n 	ypset{i}}}&g(\XX\mb{I}_{\sqcup_{i=1}^n 	ypset{i}})h(\XXX\mb{I}_{\sqcup_{i=1}^n 	ypset{i}})\bigg]\\
& = \ex{\ex{f(\X\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}})|\XXX\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}}}g(\XX\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}})h(\XXX\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}})}
\end{align*}

Similarly by monotone convergence,

\begin{align*}
\lim_{n\ra\infty} \mb{E}\bigg[f(\X\mb{I}_{\sqcup_{i=1}^n 	ypset{i}})&g(\XX\mb{I}_{\sqcup_{i=1}^n 	ypset{i}})h(\XXX\mb{I}_{\sqcup_{i=1}^n 	ypset{i}})\bigg] = \ex{f(\X\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}})g(\XX\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}})h(\XXX\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}})}
\end{align*}

So,

\begin{align*}
\mb{E}\bigg[\ex{f(\X\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}})|\XXX\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}}}&g(\XX\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}})h(\XXX\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}})\bigg]\\
&= \lim_{n\ra\infty} \ex{\ex{f(\X\mb{I}_{\sqcup_{i=1}^n 	ypset{i}})|\XXX\mb{I}_{\sqcup_{i=1}^n 	ypset{i}}}g(\XX\mb{I}_{\sqcup_{i=1}^n 	ypset{i}})h(\XXX\mb{I}_{\sqcup_{i=1}^n 	ypset{i}})}\\
&= \lim_{n\ra\infty} \ex{f(\X\mb{I}_{\sqcup_{i=1}^n 	ypset{i}})g(\XX\mb{I}_{\sqcup_{i=1}^n 	ypset{i}})h(\XXX\mb{I}_{\sqcup_{i=1}^n 	ypset{i}})}\\
&= \ex{f(\X\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}})g(\XX\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}})h(\XXX\mb{I}_{\sqcup_{i=1}^\infty 	ypset{i}})}
\end{align*}

By linearity, this also holds for all bounded and measurable \(f,g\) and \(h\) with no restrictions on \(f(0),g(0),h(0)\), so the proof is complete.

\item 

\begin{align*}
\mb{E}\bigg[\ex{f(\X\mb{I}_\typset)| \XXX\mb{I}_\typset}g(\mb{I}_\typset\XXX)&h(\mb{I}_\typset U)\bigg] = \ex{\mb{I}_\typset\ex{f(\X\mb{I}_\typset)|\XXX\mb{I}_\typset}g(\XXX\mb{I}_\typset)h(\mb{I}_\typset)} + f(0)g(0)h(0)\pr(\typset^c)\\
&=\frac{\ex{\mb{I}_\typset\ex{f(\X\mb{I}_\typset)|\XXX\mb{I}_\typset}g(\XXX\mb{I}_\typset)}\ex{\mb{I}_\typset h(U\mb{I}_\typset)}}{\pr(\typset)} + f(0)g(0)h(0)\pr(\typset^c)\\
&=\frac{\ex{\mb{I}_\typset f(\X\mb{I}_\typset)g(\XXX\mb{I}_\typset)}\ex{\mb{I}_\typset h(U\mb{I}_\typset)}}{\pr(\typset)} + f(0)g(0)h(0)\pr(\typset^c)\\
&=\ex{\mb{I}_\typset f(\X\mb{I}_\typset)g(\XXX\mb{I}_\typset)h(U\mb{I}_\typset)} + f(0)g(0)h(0)\pr(\typset^c)\\
&= \ex{f(\X\mb{I}_\typset)g(\XXX\mb{I}_\typset)h(U\mb{I}_\typset)}
\end{align*}

So \(\ex{f(\X\mb{I}_\typset|\XXX\mb{I}_\typset} = \ex{f(\X\mb{I}_\typset|\XXX\mb{I}_\typset,U\mb{I}_\typset}\). Then 

\begin{align*}
\ex{\ex{f(\X\mb{I}_\typset)|\XXX\mb{I}_\typset}g(\XX\mb{I}_\typset)h(\XXX\mb{I}_\typset)} &= \ex{\ex{f(\X\mb{I}_\typset)|\mb{I}_\typset(\XXX,U)}g(\XX\mb{I}_\typset)h(\XXX\mb{I}_\typset)}\\
&=\ex{f(\X\mb{I}_\typset)g(\XX\mb{I}_\typset)h(\XXX\mb{I}_\typset)}
\end{align*}

\item 
\begin{align*}
\ex{\ex{f(\X)|\XXX}g(\XX)h(\XXX)} &= \ex{\ex{f(\X\mb{I}_\typset)|\XXX\mb{I}_\typset}g(\XX\mb{I}_\typset)h(\XXX\mb{I}_\typset)}\\
&= \ex{f(\X\mb{I}_\typset)g(\XX\mb{I}_\typset)h(\XXX\mb{I}_\typset)} = \ex{f(\X)g(\XX)h(\XXX)}
\end{align*}
\end{enumerate}
\end{proof}

\lin

\begin{lem}
Let \(\phi: \mb{R}^+ \ra \mb{R}^+\) be a monotonic function such that \(\phi(0+) = 0\). Suppose also that \(\phi \leq C\) for some constant \(C\). Then there exists a continuous monotonic concave function \(\psi:\mb{R}^+\ra \mb{R}^+\) such that \(\psi(0) = 0\) and \(\phi \leq \psi\leq C\).
\label{sec::TL:Lem::concbd}
\end{lem}
\labe{sec::TL:Lem::concbd}

\purpose This is used in Proposition \ref{subsec::Well-:Prop::SDE=IG} for a technical result.

\begin{proof}
Fix \(\ep > 0\). Since \(\phi(0+) = 0\), there exists a \(\delta > 0\) such that \(\phi(\delta) < \ep/2\). Let \(\ov{\phi} = \min\{\phi+\ep/2, C\}\).

\ind Let \(a_\ep = \inf\{a \geq 0: a\x + \ep \geq \phi(\x)\te{ for all } \x\geq 0\}\). Note that \(0\leq a_\ep \leq C/\delta\). 

\ind Define \(\psi_\ep(\x) = \min\{a\x+\ep,C\}\). Then \(\psi_\ep\) is continuous, concave, non-decreasing, \(\psi_\ep(0) = \ep\) and \(\psi_\ep \geq \phi\).

\ind Let \(\psi(\x) = \inf_{\ep > 0} \psi_\ep(\x)\). Then \(\psi\) is trivially concave, bounded and non-decreasing. Furthermore, since it is non-decreasing, it can only have jump discontinuities, and left and right limits exist at each point. Suppose \(\x\) is a discontinuity point of \(\psi\). Let \(\triangle\psi(\x) = \psi(\x+) - \psi(\x-)\).

For any small \(\delta > 0\), notice that

\[\lim_{\delta \ra 0} \frac{\psi(\x-\delta) + \psi(\x+\delta)}{2} = \psi(\x-) + \frac{\triangle\psi(\x)}{2} > \psi(\x-).\]

Thus, there exists some \(\delta\) and some \(1>\rate>1/2\) such that

\[\rate\psi(\x-\delta) + (1 -\rate)\psi(\x+\delta) > \psi(\x-) > \psi(\x + (1 - 2\rate)\delta) = \psi\left(\rate(\x-\delta) + (1 - \rate)(\x+\delta)\right).\]

This contradicts concavity of \(\psi\). Thus, \(\psi\) is continuous.
\end{proof}

\lin

\begin{defn}
Let \(\{	{i}\}\) be denote a finite set of times \(0=	{0} <\t{1} <\cdots < \t{n}=1\). Let \(\X\in \cad([0,T],\spce)\) where \(\spce\) is a separable and complete space with respect to the metric \(d\). Define,

\[\modu{\X}([\t{i-1},	{i})) = \sup_{\tt,\t\in [\t{i-1},	{i})} d(\X\cind{}\tp{\t},\X\cind{}\tp{\tt}).\]

Then for all \(\delta \in (0,T)\),

\[\cmodu{\X}(\delta) = \inf_{\{	{i}\}: \min_i |	{i} - \t{i-1}| > \delta} \max_{i} \modu{\X}([\t{i-1},	{i}))\]

is called the c\`adl\`ag modulus of continuity.
\label{sec::TL:Def::modulus}
\end{defn}
\labe{sec::TL:Def::modulus}

\purpose This modulus of continuity is useful for the c\`adl\`ag version of the Arzela-Ascoli Theorem.

\lin

\begin{thms}
Let \(\{\m^i\}\subseteq \mc{P}\left(\cad([0,T],\spce)\right)\) where \(\spce\) is a separable and complete normed space. Assume \(\X^i\) is a random process with law \(\m^i\) for each \(i\). Then \(\{\m_i\}\) is tight if and only if:

\begin{enumerate}[(1)]
\item 

\[\lim_{a \ra \infty}\limsup_{n \ra\infty} \pr\left(\sup_{\t \in [0,T]} |\X^i_\t| \geq a\right) = 0.\]

\item For all \(\ep > 0\),

\[\lim_{\delta \searrow 0}\limsup_{n\ra\infty} \pr\left(\cmodu{\X^i}(\delta) \geq \ep\right) = 0.\]
\end{enumerate}
\label{sec::TL:Thm::Tight}
\end{thms}
\labe{sec::TL:Thm::Tight}

\begin{proof}
This is simply a restatement of \cite[Theorem 13.2]{Bil99}.
\end{proof}

\lin

\begin{lem}
Let \(\{\X\cind{}\tip{}{n}\}\) be a sequence \(\sset\vsi{V}\ts{\T}\)-valued Feller processes satisfying Assumption \ref{subsec::Assum:Assu::CI}. Let the infinitesimal generators of these processes be given by the equation:

\[\IG\sln{n}f(\sv\cind{}\vsi{V}) = \sum_{\v\in V}\sum_{\s \in \S} \IGr\vindsln{n}{\v}(\sv\cind{}\vsi{V},\s)[f(\sv\cind{}\vsi{V} + \s\ev\vind{\v}) - f(\sv\cind{}\vsi{V})].\]

If there exists some \(\const{} < \infty\) such that

\[\sup_{n}\sup_{\sv\cind{}\vsi{V}\in \S\carp{V}}\sup_{\v\in V}\sup_{\s\in \S} \IGr\vindsln{n}{\v}(\sv\cind{}\vsi{V},\s) \leq \const{},\]

then for all finite \(\U \subseteq V\),

\[\lim_{\delta \searrow 0} \sup_n \pr\left(\cmodu{\proj\vsi{\U}\ts{\T}\left(\X\cind{}\tip{}{n}\right)}(\delta) \geq \ep\right) = 0\]

for all \(\ep > 0\).
\label{sec::TL:Lem::TightSupport}
\end{lem}
\labe{sec::TL:Lem::TightSupport}

\purpose This allows us to obtain the c\`adl\`ag version of the equicontinuity condition necessary for Theorem \ref{sec::TL:Thm::Tight}. Note: The first time this lemma is applied is in the proof of Proposition \ref{subsec::Well-:Prop::IGApprox}. The proof refers to Proposition \ref{subsec::Well-:Prop::SDE=IG}.

\begin{proof}
Fix any \(n \in \mb{N}\). Let \(\cconst = \sup_{\s,\ss \in \S} |\s - \ss|\). Let \(\XX{}{}\) be the \(\cad([0,\T],\mb{R}^\U)\)-valued process defined by the following stochastic integral:

\[\XX{}{\t} = \sum_{\v \in \U}\cconst\ev\vind{\v}\int_0^\t\int_0^{\const{}}\alt{\poiss}{\v}(d\r, d\tt)\]

where \(\{\alt{\poiss}{\v}:\v \in \U\}\) are a sequence of i.i.d. unit rate Poisson processes on \(\mb{R}^2\). 

\ind By Proposition \ref{subsec::Well-:Prop::SDE=IG}, there exists a sequence of i.i.d Poisson processes, \(\{\poiss\vind{\v}:\v\in V\}\), on \(\S\times\mb{R}^2\) with intensity measure \(\Sm\otimes \leb\) such that,

\[\X\cind{\v}\tp{\t}{n} = \X\cind{\v}\tp{0}{n} + \int_\S\int_0^\t \s\,\poiss\vind{\v}(d\tt,(0,\rate{\v}(\X\cind{}\tp{\tt-}{n})],d\s)\]

for all \(\v\in V\). Let

\[\alt{\poiss}{\v}(\cdot) = \int_\S\,\poiss\vind{\v}(\cdot\times \S).\]

Since \(\Sm\) is a probability measure on \(\S\) and \(\{\poiss\vind{\v}:\v\in V\}\) are i.i.d., it follows that \(\{\alt{\poiss}{\v}:\v\in \U\}\) is a sequence of unit rate i.i.d. Poisson processes as desired. Under this coupling, every time \(\proj\vsi{\U}\ts{\T}(\X\cind{}\tip{}{n})\) experiences a jump, \(\XX{}{}\) also experiences a jump. Furthermore, the magnitude of the jump of \(\XX{}{}\) is larger. For any \(\tt<\ttt\in [0,\T]\) and \(\v\in \U\),

\begin{align*}
|\X\cind{\v}\tp{\tt}{n} - \X\cind{\v}\tp{\ttt}{n}|&\leq \cconst\left|\{\#\te{ of jumps in }\X\cind{\v}\tp{(\tt,\ttt]}{n}\}\right| \\
&\leq \cconst\left|\{\#\te{ of jumps in }\XX{\v}{(\tt,\ttt]}\}\right| = \left|\XX{\v}{\tt} - \XX{\v}{\ttt}\right|
\end{align*}

It follows that for any partition \(\{\t{\it}\}\) of \([0,\T]\),

\begin{align*}
\sup_\it\sup_{\tt,\ttt \in [\t{\it-1},\t{\it})} \sum_{\v\in \U} \b\cind{\v}|\X\cind{\v}\tp{\tt}{n} - \X\cind{\v}\tp{\ttt}{n}|\leq \sup_\it\sup_{\tt,\ttt \in [\t{\it-1},\t{\it})} \sum_{\v\in \U} \b\cind{\v}|\XX{\v}{\tt} - \XX{\v}{\ttt}|.
\end{align*}

Fix \(\delta > 0\). Taking the infimum over all partitions with minimum interval length \(\delta\) yields,

\begin{align*}
\omega'_{\proj\vsi{\U}\ts{\T}\left(\X\cind{}\tip{}{n}\right)}(\delta) &= \inf_{\{\t{\it}\}}\sup_\it\sup_{\tt,\ttt \in [\t{\it-1},\t{\it})} \sum_{\v\in \U} \b\cind{\v}|\X\cind{\v}\tp{\tt}{n} - \X\cind{\v}\tp{\ttt}{n}|\\
&\leq \inf_{\{\t{\it}\}}\sup_\it\sup_{\tt,\ttt \in [\t{\it-1},\t{\it})} \sum_{\v\in \U} \b\cind{\v}|\XX{\v}{\tt} - \XX{\v}{\ttt}|\\
&= \omega'_{\XX{}{}}(\delta).
\end{align*}

Thus,

\[\pr\left(\omega'_{\proj\vsi{\U}\ts{\T}\left(\X\cind{}\tip{}{n}\right)}(\delta) \geq \ep\right) \leq \pr\left(\omega'_{\XX{}{}}(\delta) \geq \ep\right).\]

By applying this same argument to arbitrary \(n\in \mb{N}\) and noticing that the distribution of \(\XX{}{}\) does not vary with respect to our choice of coupling, we get,

\[\sup_{n}\pr\left(\omega'_{\proj\vsi{\U}\ts{\T}\left(\X\cind{}\tip{}{n}\right)}(\delta)\geq \ep\right) \leq \pr\left(\omega'_{\XX{}{}}(\delta) \geq \ep\right).\]

However, \(\XX{}{}\) is just a homogeneous Poisson point process, so the c\`adl\`ag modulus of continuity of \(\XX{}{}\) converges to 0 in probability as \(\delta \ra 0\). Thus,

\[\lim_{\delta \searrow 0}\sup_{n}\pr\left(\omega'_{\proj\vsi{\U}\ts{\T}\left(\X\cind{}\tip{}{n}\right)}(\delta) \geq \ep\right) \leq \lim_{\delta\searrow 0}\pr\left(\omega'_{\XX{}{}}(\delta)\geq \ep\right) = 0.\]


\end{proof}

\lin

\begin{lem}
We can apply \cite[Proposition 14.7.I(b)]{DalVer08} to the proof of Lemma \ref{subsec::ProofU:Lem::Poisson} even though it does not satisfy all of the assumptions.
\label{sec::TL:Lem::embedding}
\end{lem}
\begin{proof}
I use the notation of section \ref{subsec::ProofU:sec::Proof2}. The assumptions of \cite[Proposition 14.7.I(b)]{DalVer08} are as follows:

\begin{itemize}
\item \(\poiss\vind{}(\cdot,\cdot)\) is a marked point process with internal history \(\FH\).

\item \(\poiss\vind{}(\cdot,\cdot)\) has \(\FH\)-predictable intensity \(\rate{}(\t,\mark)\).
\end{itemize}

If we let \(\poiss\vind{}(\cdot,\cdot) = \pmap{}(\X\cind{}\tip{}{n})\) (see Definition \ref{subsec::ProofE:Defn::pmap}), then the proof of \cite[Proposition 14.7.I(b)]{DalVer08} shows that the point process defined in equation \eqref{subsec::ProofU:eqn::Poissonexpl} is a Poisson point process with intensity \(d\t\times \alt{\Sm^n}\times d\r\) and adapted to a larger filtration.

\ind However, our intensity is actually only predictable with respect to \(\F \supseteq \FH\) which includes the value of \(\X\cind{}\tp{0}{n}\). This can be fixed simply. Let \(\rate{\v}^{\sv\cind{}\vsi{\tree\sln{n}}}(\cdot,\cdot) \sim \law(\rate{\v}(\cdot,\cdot)|\X\cind{}\tp{0}{n} = \sv\cind{}\vsi{\tree\sln{n}})\). Then \(\rate{\v}^{\sv\cind{}\vsi{\tree\sln{n}}}(\t,\mark)\) satisfies the conditions above. Then,

\[\poiss\sln{n}{\sv\cind{}\vsi{\tree\sln{n}}}(\evnt{}) = \alt{\poiss}{n}\left(\evnt{}\cap\{(\t,\sv\cind{}\vsi{\tree\sln{n}},\r):\r > \rate{n}^{\sv\cind{}\vsi{\tree\sln{n}}}(\t,\sv\cind{}\vsi{\tree\sln{n}})\}\right) + \#\{(\rt{n,\it}_\v,\mark{n,\it}_\v,\rv_{\v}^{\it}\rate{n}^{\sv\cind{}\vsi{\tree\sln{n}}}(\rt{n,\it}_\v,\mark{n,\it}_\v) \in \evnt{}: \v\in \tree\sln{n}\}\]

is a Poisson process with intensity \(d\t\times \alt{\Sm^n}\times d\r\). Let \(R \subseteq \alt{\S\carp{n}}\), and let \(\inte\) and \(\alt{\inte}\) be intervals in \(\mb{R}^+\). Then,

\begin{align*}
\pr\left(\poiss\sln{n}\left(\inte\times R\times \alt{\inte}\right) = 0\right) &= \sum_{\sv\cind{}\vsi{\tree\sln{n}} \in \alt{\S}^n} \pr\left(\poiss\sln{n}{\sv\cind{}\vsi{\tree\sln{n}}}\left(\inte\times R\times \alt{\inte}\right) = 0\right)\pr(\X\cind{}\tp{0}{n} = \sv\cind{}\vsi{\tree\sln{n}})\\
&= \exp\left(-|R| |\inte||\alt{\inte}|\right)\sum_{\sv\cind{}\vsi{\tree\sln{n}} \in \alt{\S\carp{n}}} \pr(\X\cind{}\tp{0}{n} = \sv\cind{}\vsi{\tree\sln{n}})\\
&=\exp\left(-|R| |\inte||\alt{\inte}|\right)
\end{align*}

Since this holds for every rectangle, \(\poiss\sln{n}\) is a Poisson process on \([0,T]\times \alt{\S\carp{n}}\times [0,\const{}]\) by R\'enyi, M\"onch \cite[Theorem 9.2.XII]{DalVer08}.



\end{proof}
\newpage
\bibliographystyle{plain}
\bibliography{weekly_refs}
\end{document}
