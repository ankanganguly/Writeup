\documentclass[12pt]{article}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{color}
\usepackage{mathrsfs}
\usepackage{fullpage}
\usepackage{commath}
\usepackage{graphicx}
\usepackage{pdfcomment}
%\usepackage{coffee4}
\usepackage{lipsum}
\usepackage{showkeys}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{verbatim}
\usepackage{longtable}
\usepackage{xr}
\externaldocument[F-]{treere}

%General Shorthand Macros
\newcommand{\skipLine}{\vspace{12pt}}
\newcommand{\mb}{\mathbb}
\newcommand{\mc}{\mathcal}
\newcommand{\ms}{\mathscr}
\newcommand{\ra}{\rightarrow}
\newcommand{\ov}{\overline}
\newcommand{\os}{\overset}
\newcommand{\un}{\underline}
\newcommand{\te}{\text}
\newcommand{\ep}{\epsilon}
\newcommand{\tr}{\textcolor{red}}
\newcommand{\tb}{\textcolor{blue}}
\newcommand{\tg}{\textcolor{green}}
\newcommand{\labe}[1]{\tr{\texttt{Label: #1}}}
\newcommand{\tbs}{\textbackslash}
\newcommand{\purpose}{\textbf{Purpose: }}
\newcommand{\pfsum}{\textbf{Proof Summary: }}
\newcommand{\usein}{\textbf{Used in: }}
\newcommand{\app}{\textbf{Applies: }}
\newcommand{\ind}{\hspace{24pt}}
\newcommand{\lin}{\rule{\linewidth}{0.4 pt}}
\newcommand{\pr}{\mb{P}}							%probability
\newcommand{\ex}[1]{\mb{E}\left[#1\right]}			%expectation
\newcommand{\exmu}[2]{\mb{E}^{#1}\left[#2\right]}	%exp wrt a measure
\newcommand{\deq}{\overset{\text{(d)}}{=}}			%equal in dist
\newcommand{\defeq}{:=}								%definition equal
\newcommand{\msr}{\mc{M}}							%space of measures
\newcommand{\pmsr}{\mc{P}}							%space of pmsrs
\newcommand{\cad}{\mc{D}}							%Cadlag space
\newcommand{\argmin}{\te{arg}\min}

%TODO
\newcommand{\valid}{\mc{V}}							%valid histories

%Notation and Basic Assumptions
%Graph Notation
%Base Commands
\newcommand{\sta}{\mc{X}}							%state space
\newcommand{\neigh}[1]{\mc{N}_{#1}}				%neighborhood
\newcommand{\dneigh}[1]{\mc{N}^2_{#1}}			%double neigh
\newcommand{\tneigh}[1]{\mc{N}^3_{#1}}			%double neigh
\newcommand{\gneigh}[2]{\mc{N}^{#1}_{#2}}			%neighborhood w G
\newcommand{\dgneigh}[2]{\mc{N}^{2,#1}_{#2}}		%double neigh w G
\newcommand{\tgneigh}[2]{\mc{N}^{3,#1}_{#2}}		%double neigh w G
\newcommand{\cl}[1]{\ov{#1}}						%graph closure
\newcommand{\bdry}[1]{\partial_{#1}}				%bdry
\newcommand{\gbdry}[2]{\partial^{#1}_{#2}}			%G bdry
\renewcommand{\root}{\mathbf{0}}					%root

%Modifiers
\newcommand{\stb}[1]{_{#1}}							%add base of \st
\newcommand{\indx}[1]{^{#1}}						%sublimit index
\newcommand{\subg}[1]{_{#1}}						%subgraph

%Process Notation
%Base Commands
\newcommand{\Xf}{X}									%Full process
\newcommand{\poiss}{N}								%Poisson process
\newcommand{\leb}{\lambda}							%Lebesgue msr
\newcommand{\Sm}{\ell}								%ctng msr on sta
\newcommand{\rate}{r}								%jump rate
\newcommand{\F}{\mc{F}}								%filtrations
\newcommand{\m}{\mu}								%law of \Xf
\newcommand{\proj}{\pi}								%projection
\newcommand{\utmet}[1]{
\ifstrempty{#1}{
	d_{\te{U}}}{
	d_{\te{U},#1}}}									%uniform metric
\newcommand{\stmet}[1]{
\ifstrempty{#1}{
	d_{\te{S}}}{
	d_{\te{S},#1}}}									%skorokhod metric
\newcommand{\xf}{x}									%x input
\newcommand{\xg}{y}									%y input
\newcommand{\xh}{z}									%z input
\newcommand{\xj}{t}									%t input
\newcommand{\met}[2]{
\ifstrempty{#2}{
	d_{#1}}{
	d_{#1,#2}}}										%gen metric
\newcommand{\bor}{\mc{B}}							%borel
\newcommand{\poisses}{\mathbf{N}}					%poisson family
\newcommand{\delt}{\triangle}						%jump size
\newcommand{\dpoiss}{\omega}						%nonrandom pt pro

%Modifiers
\newcommand{\poissv}[1]{_{#1}}						%v comp of Poisson
\newcommand{\poisso}[1]{^{#1}}						%Other P modifier
\newcommand{\vind}[1]{_{#1}}						%v component
\newcommand{\tme}[1]{(#1)}							%time
\newcommand{\tmi}[1]{#1}							%time interval
\newcommand{\gind}[1]{^{#1}}						%interaction net
\newcommand{\vpara}[1]{^{#1}}						%vertex param
\newcommand{\stpara}[1]{_{#1}}						%state parameter	
\newcommand{\tpara}[1]{_{#1}}						%time parameter
\newcommand{\gvpara}[2]{^{#1,#2}}					%G and v params
\newcommand{\psf}{_*}								%push forward
\newcommand{\tparapsf}[1]{_{#1,*}}					%psf t param
\newcommand{\vpropara}[2]{^{#1,#2}}					%v and process

%Simultaneous Jumps
\newcommand{\Jmps}{\mc{J}}							%set of jumps

%Assumptions
%Base Commands
\newcommand{\psize}{\ell}							%Branching size
\newcommand{\rateset}{\mathbf{\rate}}				%set of rates
\newcommand{\jumpbd}[1]{C_{#1}}						%jump bound
\newcommand{\jumpibd}[2]{C_{#1,#2}}					%jump bds fix i
\newcommand{\Gs}{\mc{G}_\ast}						%graphs
%Modifiers
\newcommand{\tmepro}[3]{
\ifstrempty{#3}{
	\left(#1,#2\right)}{
	\left(#1,#2,#3\right)}}							%time, process
	
%Examples
%Base Commands
\renewcommand{\d}{d}								%degree
\newcommand{\eneigh}[1]{\mc{N}^E_{#1}}				%eff neighborhood
\newcommand{\deneigh}[1]{\mc{N}^{2,E}_{#1}}			%eff double neigh
\newcommand{\ecl}[1]{\ov{#1}^E}						%eff graph closure
\newcommand{\ebdry}[1]{\partial^E_{#1}}				%eff bdry
\newcommand{\einte}[1]{{#1}^{\mathrm{o},E}}			%interior
\newcommand{\tree}[1]{\mc{T}_{#1}}					%subtree	
\newcommand{\desc}{d}								%descendants				

%Well-Posedness
%Base Commands
\newcommand{\compen}{a}								%compensator
\newcommand{\compenbd}{\ov{a}}						%comp max
\newcommand{\Xfjmp}{\ov{\poiss}}					%X-jump process
\newcommand{\apppoiss}{\ov{\ov{\poiss}}}			%append poisson
\newcommand{\tmepoiss}{\alt{\poiss}}				%timechange poiss

%Modifiers
\newcommand{\poissst}[1]{_{#1}}						%poisson state
\newcommand{\poissvst}[2]{_{#1,#2}}					%poisson v,state
\newcommand{\binver}[1]{(#1)^{-1}}					%inverse

%Local Weak Convergence
%Base Commands
\newcommand{\iso}{I}								%isomorphism set
\newcommand{\trnc}[1]{B_{#1}}						%Truncated graph
\newcommand{\spce}{\mc{Y}}							%space
\newcommand{\unifvar}{U}							%uniform rv
\newcommand{\cumrate}{\ov{r}}						%cumul rate over i
\newcommand{\ptsnum}{n}								%num Pssn pts

%Modifiers
\renewcommand{\sp}[1]{[#1]}							%include space
\newcommand{\dit}[2]{_{#1,#2}}						%double iter
\newcommand{\vindit}[2]{_{#1,#2}}					%\vind + \it


%Conditional Independence
\newcommand{\seto}{U}								%1st set in CI
\newcommand{\sett}{W}								%2nd set in CI
\newcommand{\setc}{R}								%set condition CI

%Proof
\newcommand{\mutex}{\|}								%mutually exclsve
\newcommand{\rtt}{\theta}							%2nd stopping time
\newcommand{\apath}{\Gamma}						%path for CI proof
\newcommand{\pathset}[2]{\Lambda_{#1,#2}}		%A space of paths
\newcommand{\evnt}{\mc{E}}						%Typical event
\newcommand{\rv}{A}								%Typical rand elt
\newcommand{\indo}{n}							%index of \rt
\newcommand{\indt}{m}							%index of \rtt


%Statement
%Base Commands
\newcommand{\Xg}{Y}									%Alt proc rep
\newcommand{\brate}{\alt{\rate}}					%local rt at bdry

%Modifications
\newcommand{\inte}[1]{{#1}^\mathrm{o}}				%interior
\newcommand{\alt}[1]{\tilde{#1}}					%alternate

%Existence
%Base commands
\newcommand{\pmap}{\Lambda}							%Mk chain to PP
\newcommand{\rt}{\tau}								%PP time
\renewcommand{\mark}{\kappa}						%PP mark
\newcommand{\ratee}{\Gamma}							%generic rate
\newcommand{\cratee}{\alt{\ratee}}					%gen cdtl rate
\newcommand{\grate}{\ov{\ratee}}					%2nd generic rate
\newcommand{\rp}{P}									%generic PP
\newcommand{\mm}{\nu}								%gen msr
\newcommand{\law}{\te{Law}}							%law
\newcommand{\ev}[1]{\ep^{#1}}						%std basis
\newcommand{\const}{M}								%constant

%Modifications
\newcommand{\sttpara}[2]{_{#1,#2}}					%state and time
\newcommand{\mpara}[1]{^{#1}}						%measure param
\newcommand{\tspara}[2]{_{#1,#2}}					%2 times para
\newcommand{\tmestpro}[3]{\left(#1,#2,#3\right)}	%time,state,pro

%Uniqueness
%Base Commands
\newcommand{\Xh}{Z}									%2nd alt proc
\newcommand{\crate}{\hat{\rate}}					%dneigh bdry rate
\newcommand{\bgrate}{\ov{\rate}}					%gen bdry rate
\newcommand{\bcrate}{\hat{\brate}}					%neigh bdry rate
\newcommand{\mmm}{\eta}								%std msr
\newcommand{\ds}{\Upsilon}							%Radon mapping
\newcommand{\dense}{L}								%density
\newcommand{\densen}{N}								%density of dneigh
\newcommand{\denseph}{\alt{N}}						%density of CUdneigh
\newcommand{\mdense}{M}								%marge density

%Modifications
\newcommand{\gvjpara}[3]{^{#1,#2,#3}}				%include branch
\newcommand{\prc}[1]{_{#1}}							%wrt a msr
\renewcommand{\it}[1]{_{#1}}						%iterator
\newcommand{\jpara}[1]{^{#1}}						%B_j dependence
\newcommand{\vjpara}[2]{^{#1,#2}}					%v, B_j depend.

%Appendix
\newcommand{\Xj}{T}								%4th variable
\newcommand{\typset}{A}							%typical set
\newcommand{\topo}{\mc{T}}						%Topology

\newcommand{\indxset}[1]{_{#1}}					%indexed by set


\newtheorem{thms}{Theorem}[section]
\newtheorem{conj}[thms]{Conjecture}
\newtheorem{prop}[thms]{Proposition}
\newtheorem{coro}[thms]{Corollary}
\newtheorem{lem}[thms]{Lemma}
%\newtheorem{sublem}{Sublemma}[lem]
\newtheorem{defn}[thms]{Definition}
\newtheorem{assu}{Assumption}
\newtheorem{nassu}{New Assumption}
\renewcommand{\theassu}{\Alph{assu}}
\newtheorem{example}[thms]{Example}

\setlength{\parindent}{0pt}

\begin{document}

\title{General Graph Topology Results (Working Title)}
\author{Ankan Ganguly}

\maketitle

Remark: This document uses the results from the derivation of the local approximation on trees. I will refer to this derivation as the main paper for now.

\skipLine

Remark: In this paper I mostly work with locally finite graphs. However, I proved all my results in the main paper for bounded degree graphs. I may need to strengthen the assumptions of this paper to bounded degree. However, since we are working with local convergence, all results that hold for locally finite graphs should extend to bounded degree graphs (the one possible exception would be well-posedness results).

\tableofcontents

\section{TODO}

\begin{itemize}
\item \tg{Bad notation! I use \(i\) to indicate elements of \(\sta\) and to enumerate branches of \(A\).} Now I mostly use \(j\), but there may be a few stray \(i\)'s hanging around.

\item Let \(U,U'\subseteq V\) such that \(|U| = |U'|\). I'll often say things like \(\Xf\vind{U} = \Xf\vind{U'}\). This makes sense if there is an implied bijection \(\phi:U \ra U'\). Make sure that the implied bijection is clear wherever I make such statements.

\item In lemma 4.3, I state that the lemma holds if the conditional expectation is well-defined. This is not precise language. Modify it to state that the regular conditional probability is almost surely well-defined at \(\Xh\vind{W'}\tmi{[0,t)} = \Xg\vind{W}\tmi{[0,t)}\).

\item I'm a little inconsistent in the interval bounds I use. Make sure I use open/closed/half-open intervals with some purpose.

\item I've been forgetting to put \(i\) in the integral for the SDEs. Tried to fix it, make sure I got them all.

\item Replace references to \cite[exercise 14.7.I]{DalVer08} with references to lemma \ref{ref::propoi}.

\item Describe all notation from the foundations paper here as well.
\end{itemize}

\subsection{New Assumptions}
\label{na}

Note: This section uses all notation defined in the foundations paper and through section 2.1 of this paper. I will let \(\sta\) be a finite or countable group, and let \(\Sm\) be a probability measure over \(\sta\).

\begin{defn}
\label{na::valid}
Given a rate function, \(\{\rate\gvpara{G}{v}\stpara{i}\tmepro{\cdot}{\cdot}{}:G \in \Gs,v \in V\gind{G}, i \in \sta\}\),

\[\valid \subset \Gs\sp{\cad} = \{(G,\xf)\in \Gs\sp{\cad}: \te{ for all }t>0,v\in V\te{ s.t. } \Delta \xf\vind{v}\tme{t} \neq 0,\quad \rate\gvpara{G}{v}\stpara{\Delta\xf\vind{v}\tme{t}}\tmepro{t}{\xf\vind{\cl{v}}}{} > 0.\},\]

is the set of \emph{valid histories}.
\end{defn}

We also redefine \((G,\Xf\gind{G})\) and the jump rate:

\[\rate\gvpara{G}{v}\stpara{i}\tmepro{\cdot}{\xf}{}: \mb{R}^+\times \cad^{V\gind{G}} \ra \mb{R}^+.\]

I will often write \(\rate\gvpara{G}{v}\stpara{i}\tmepro{\cdot}{\xf\vind{\cl{v}}}{}\) to emphasize the dependence of the rate on a subset of the components of \(\xf\).

\[\Xf\gind{G}\vind{v}\tme{t} = \Xf\gind{G}\vind{v}\tme{0} + \int_{\sta\times (0,\infty)\times (0,t]} i\mb{I}_{r \leq \rate\gvpara{G}{v}\stpara{i}\tmepro{s}{\Xf\gind{G}\vind{v}}{}}\,\poiss\poissv{v}(ds,dr,di).\]

First, assumptions on initial histories. 

\begin{nassu}
\label{na::start}

The initial distribution is independently distributed \tr{(or second-order Gibbs)} and,

\[\sup_{G,v} \ex{\Xf\gind{G}\vind{v}\tme{0}} < \infty.\]
\end{nassu}

We need jump rates to be consistent:

\begin{nassu}
\label{na::consist}

Suppose there exists a rooted isomorphism \(\phi\) such that \(\phi((G,\xf)) = (H,\xg)\). Then,

\[\rate\gvpara{G}{v}\stpara{i}\tmepro{t}{\xf\vind{\cl{v}}}{} = \rate\gvpara{\phi(G)}{\phi(v)}\stpara{i}\tmepro{t}{\xg\vind{\phi(\cl{v})}}{}.\]
\end{nassu}

\begin{nassu}
\label{na::bddr}

For each \(t>0\), there exist constants \(\jumpibd{i}{t}\) and \(\jumpbd{t}\) such that,

\[\sup_{G,v,\xf\in\valid} \|\rate\gvpara{G}{v}\stpara{i}\tmepro{\cdot}{\xf}{}\|_t \leq \jumpibd{i}{t}\te{ and } \sum_{i\in\sta} i\Sm(\{i\})\jumpibd{i}{t} = \jumpbd{t} < \infty.\]
\end{nassu}

The Lipschitz dependence on history is the only assumption that should have changed significantly.

\begin{nassu}
\label{na::liprx}

Using the same constants as in assumption \ref{na::bddr},

\[\sup_{G,\xf,\xg\in \valid} \sum_{i\in\sta}i\Sm(\{i\})|\rate\gvpara{G}{v}\stpara{i}\tmepro{t}{\xf}{} - \rate\gvpara{G}{v}\stpara{i}\tmepro{t}{\xg}{}| \leq \jumpbd{t}\stmet{t-}(\xf\vind{\cl{v}},\xg\vind{\cl{v}})\te{ for all } v\in V.\]

\tr{Here, \(\stmet{t}\) is the Skorohod metric on \(\cad^{\cl{v}}\). Furthermore, for \(i,j\in\sta^{\cl{v}}\), I assume \(d(i,j) = \sup_{u\in\cl{v}} d(i_u,j_u)\).}
\end{nassu}

The continuous part of the jump rate should still be locally-Lipschitz in \(t\):

\begin{nassu}
\label{na::liprt}

The continuous part of the jump rate is locally Lipschitz in \(t\). For any \(T < \infty\) and \(0 \leq t_1 < t_2 < T\),

\[\sup_{G,v,\xf\in\valid} \sum_{i\in\sta}|i|\Sm(\{i\})\left|\rate\gvpara{G}{v}\stpara{i}\tmepro{t_2}{\xf}{} - \rate\gvpara{G}{v}\stpara{i}\tmepro{t_1}{\xf}{} - \sum_{t_1\leq s < t_2} \Delta\rate\gvpara{G}{v}\stpara{i}\tmepro{s}{\xf}{}\right| \leq \jumpbd{T}|t-s|.\] 
\end{nassu}

Before continuing, we need to update the definition of a symmetry of \(\Xf\).

\begin{defn}
\label{na::Xsim}

Let \((G,\Xf\gind{G})\) be well-defined. \(\phi:V \ra V\) is said to be a symmetry of \(\Xf\gind{G}\) if,

\begin{enumerate}
\item \(\phi\) is an automorphism of \(G\).

\item 

\[\rate\gvpara{G}{v}\stpara{i}\tmepro{t}{\xf\vind{\cl{v}}}{} = \rate\gvpara{G}{\phi(v)}\stpara{i}\tmepro{t}{\xg\vind{\phi(\cl{v})}}{} \te{ for all } G\in \Gs, v \in V,i\in \sta, t \in \mb{R}^+, \xf,\xg \in \valid\te{ such that } \xf\vind{\cl{v}} = \xg\vind{\phi(\cl{v})}.\]
\end{enumerate}
\end{defn}
\section{Notation and basic assumptions}
\label{not}

This paper is an extension of another paper where well-posedness, local weak convergence and the conditional independence property are established. That paper will be cited using \cite{F}. This paper uses the same notation and assumptions as that paper.

\subsection{More on graph symmetries}

\begin{defn}
For any graph \(G\), an automorphism \(\phi: V \ra V\) is an isomorphism from \(G\) to itself. Note: if \(G\) is a rooted graph, it is possible that \(\phi(\root) \neq \root\).
\label{a:siso}
\end{defn}

Of course, the most important point is that the symmetry extend to \(\Xf\).

\begin{defn}
Let \((G,\Xf\gind{G})\) be well-defined. \(\phi: V \ra V\) is said to be a symmetry of \(\Xf\gind{G}\) if,

\begin{enumerate}
\item \(\phi\) is an automorphism of \(G\).

\item  \tr{This is no longer necessary unless I decide to make \(\rate\) depend explicitly on \(v\) again.}

\begin{equation}
\rate\stpara{i}\left(\xf\gind{G}\vind{\phi(\cl{v})}\tmi{[0,t)}\right) = \rate\stpara{i}\left(\xf\gind{G}\vind{\cl{v}}\tmi{[0,t)}\right) \te{ for all } v \in V,i \in \sta, t \in \mb{R}^+, \xf\in \Omega\vpara{V}\tpara{t}.
\label{a::ratesym}
\end{equation}

\item \(\Xf\gind{G}\vind{\phi(V)}\tme{0} \deq \Xf\gind{G}\vind{V}\tme{0}\).
\end{enumerate}
\label{a:Xsim}
\end{defn}

This is called a symmetry of \(\Xf\) for a simple reason:

\begin{prop}
Let \((G,\Xf\gind{G})\) be well-defined, and suppose \(\phi\) is a symmetry of \(\Xf\gind{G}\). Then,

\[\Xf\gind{G}\vind{V} \deq \Xf\gind{G}\vind{\phi(V)},\]

where \(\phi(V)\) is treated as a permutation of \(V\).
\label{a::simprop}
\end{prop}
\begin{proof}
By definition, \(\Xf\gind{G}\) is the unique strong solution to the equation,
\[\Xf\gind{G}\vind{v}\tme{t} = \Xf\gind{G}\vind{v}\tme{0} + \int_\sta\int_{(0,t]\times(0,\infty)} i\mb{I}_{r \leq \rate\stpara{i}\tmepro{s}{\Xf\gind{G}\vind{\cl{v}}}{}}\,\poiss\poissv{v}(dr,ds,di) \te{ for } v \in V, t \geq 0.\]

By \cite[Proposition 2.10]{Kur07}, \((\{\poiss\poissv{v}:v\in V\},\Xf\gind{G})\) is also the unique-in-law weak solution to the equation above.

\ind Let \(\Xg\vind{v} = \Xf\vind{\phi(v)}\). Then for all \(v\in V,t\geq 0\),

\begin{align*}
\Xg\gind{G}\vind{v}\tme{t} &= \Xf\gind{G}\vind{\phi(v)}\tme{t} = \int_\sta\int_{(0,t]\times(0,\infty)} i\mb{I}_{r \leq \rate\stpara{i}\tmepro{s}{\Xf\gind{G}\vind{\cl{\phi(v)}}}{}}\,\poiss\poissv{\phi(v)}(dr,ds,di)\\
&= \Xg\gind{G}\vind{v}\tme{t} = \int_\sta\int_{(0,t]\times(0,\infty)} i\mb{I}_{r \leq \rate\stpara{i}\tmepro{s}{\Xg\gind{G}\vind{\cl{v}}}{}}\,\poiss\poissv{\phi(v)}(dr,ds,di)\\
\end{align*}

Then \(\{\poiss\poissv{\phi(v)}:v \in V\} \deq \{\poiss\poissv{v}:v\in V\}\) and \((\{\poiss\poissv{\phi(v)}:v \in V\},\Xg\gind{G}) \deq (\{\poiss\poissv{v}:v \in V\},\Xf\gind{G})\), so \(\Xg\gind{G}\vind{V} = \Xf\gind{G}\vind{\phi(V)} \deq \Xf\gind{G}\vind{V}\).
\end{proof}



\subsection{New Assumptions}
\label{a::not}

\tr{Assumptions can be simplified by assuming the initial distribution is i.i.d.} The local equations require a few more regularization assumptions to hold. This includes,

\begin{assu}
The continuous part of \(\rateset\) is locally Lipschitz in \(t\): for any \(T < \infty\) and \(0\leq s < t < T\),

\begin{equation}
\sup_{\xf \in \cad, \xf'\in \cad^\sqcup} \sum_{i\in \sta}|i|\left|\rate\stpara{i}\tmepro{t}{\xf}{\xf'} - \rate\stpara{i}\tmepro{s}{\xf}{\xf'} - \sum_{s\leq u < t} \delt \rate\stpara{i}\tmepro{u}{\xf}{\xf'}\right| \leq \jumpbd{T}\left|t - s\right|.
\label{a::tLipschitz}
\end{equation}

\tr{Note: since \(\rate\stpara{i}\) is c\`agl\`ad wrt \(t\), \(\delt\rate\stpara{i}\tmepro{t}{\xf}{\xf'} = \rate\stpara{i}\tmepro{t+}{\xf}{\xf'} - \rate\stpara{i}\tmepro{t}{\xf}{\xf'}\).}
\label{a::liprt}
\end{assu}

\begin{assu}
\(t\mapsto \rate\stpara{i}\tmepro{t}{\xf}{\xf'}\) is left-continuous for all \(i\in \sta,\xf\in \cad\) and \(\xf'\in \cad^\sqcup\). Furthermore, it is continuous at all \(t\) such that \(\xf\vind{\cl{v}}\tme{t}\) is continuous. 

\tr{This assumption is only used to prove existence of the local equations.}
\label{a::lctr}
\end{assu}

Now we can characterize the types of symmetries necessary for the local equations to be asymptotically exact.

\begin{assu}
Suppose \(G \in \Gs\). \(G\) is said to be admissible if there exists a finite set \(A \subset V\) such that,

\begin{enumerate}[(a)]
\item There exists a finite partition \(\{B_i\}_{i=1}^\psize\) of \(A^c\).

\item \(\dneigh{B_i} \subseteq A\) for all \(i\).

\item Let \(C_i = B_i\cap\neigh{A}\). For each \(i\), there exists a automorphism, \(\phi_i\), such that \(\phi_i(C_i\cup \dneigh{B_i}) \subset A\), and \(\phi_i(B_i\setminus C_i)\cap A = \emptyset\). \tr{The last one may be unnecessary, but it greatly simplifies the casework.}

\item For any \(j,j' \in \{1,\dots,\psize\}\), \(\dgneigh{G}{B_{j'}}\cap\phi_j(C_j\cup\dgneigh{G}{B_j}) \in \{\dgneigh{G}{B_{j'}},\emptyset\}\). 

\item \tr{I may be able to weaken (d) to \(\dgneigh{G}{B_{j'}}\cap\phi_j(C_j\cup\dgneigh{G}{B_j}) = \dgneigh{G}{B_{j'}}\) whenever \(\gneigh{G}{B_{j'}}\cap\phi_j(C_j)\) is non-empty. Without this, the admissible set needs to be very large.}

\item For every \(v \in \phi_j(C_j)\), suppose \(v \in \gneigh{G}{B_{j'}}\). Then \(\dgneigh{G}{B_{j'}}\subseteq \phi_j(C_j\cup\gneigh{G}{B_j})\). \tr{This implies (e)}

\item If \(\phi_j(C_j) \cap \gneigh{G}{B_{j'}}\) is nonempty, then \(\dgneigh{G}{B_{j'}} \subseteq \phi_j(C_j\cup\dgneigh{G}{B_j})\). In fact, \(\phi_j^{-1}(\dgneigh{G}{B_{j'}}) = \dgneigh{G}{B_{j''}\indx{1}}\) for some \(j''\). Furthermore, \(C_j\cap\phi_j^{-1}(\gneigh{G}{B_{j'}}) = \gneigh{G}{B_{j''}\indx{1}}\). \tr{Stronger version of the statement above. Experiment to see what's necessary.}

\item If \(\phi_j(\dgneigh{G}{B_j}\setminus\gneigh{G}{B_j})\cap\gneigh{G}{B_{j'}}\) is nonempty, then \(\phi_j(C_j)\cap\dgneigh{G}{B_{j'}} = \emptyset\). \tr{I suspect this can be proven using the points above. Try to do so or find a simpler set of assumptions that satisfy this.}

\item If we let \(A\indx{1} = A\cup \left(\bigcup_{i=1}^\psize C_i\right)\). Then \(A\indx{1}\) is also admissible with partition \(\{B\indx{1}_i\}_{i=1}^{\psize\indx{1}}\) and boundary nodes \(C\indx{1}_i = B\indx{1}_i\cap \neigh{A\indx{1}}\).

\item If \(C\indx{1}_{i'} \subseteq B_i\), then there exists a \(j\) so that \(\phi_i(C\indx{1}_{i'}) = C_j\). \tr{I think this is implied by the other conditions if \(A\) has a unique corresponding set of branches and boundary nodes. Check if this is sufficient.}
\end{enumerate}

The set \(A\) is called an admissible set. \(\{B_i\}_{i=1}^\psize\) will be referred to as the set of branches of \(A\). \(\psize\) is the branching number of \(A\). \(\{C_i\}_{i=1}^\psize\) will be called the boundary nodes of \(A\).

\ind \tr{Right now I'm just adding assumptions whenever I need them (after making sure load-balancing satisfies them).}
\label{a::admissible}
\end{assu}

\begin{assu}
Let \((G,\Xf\gind{G}) \in \Gs\sp{\cad}\) be well-defined. Then all automorphisms of assumption \ref{a::admissible} are symmetries of \((G,\Xf\gind{G})\).
\label{a::padmin}
\end{assu}

The definition of an admissible set is designed ensure a high enough level of symmetry for the arguments in the main paper to hold in this case as well. \tr{Interestingly enough, if this assumption suffices to prove the local approximation, then we will be able to understand the dynamics of a typical class of particles even when such particles are split into heterogeneous classes so long as they are distributed with a high level of symmetry. This will be especially useful if we consider random graphs later.}

\subsection{Examples}
\label{not::ex}

%\begin{example}[Contact Process on the \(\d\)-Cayley Tree]
%\label{ex::cp}
%
%The contact process can be used to model the spread of disease through a population. Each particle represents a member of the population, and edges represent interactions between particles which can spread disease. Each node is assumed to become ill at a rate proportional to the fraction of its neighbors that are ill. Let \(\lambda\) be the proportionality constant. Each node recovers at unit rate. (\cite[Chapter VI]{Lig85}).
%
%\ind Let \(G \in \Gs\). Assume \(\Xf\gind{G}\tme{0} \sim \te{Binom}(p)\) for some \(p \in [0,1]\). Then assumption \ref{a::bddinit} is trivially satisfied.
%
%\begin{align*}
%\rate\stpara{1}(t,\xf\vind{v}\tmi{[0,t)},\xf\vind{\neigh{v}}\tmi{[0,t)} &:=
%\frac{\lambda}{|\neigh{v}|}\sum_{u \in \neigh{v}}\xf\vind{u}\tme{t-}\mb{I}_{\xf\vind{v}\tme{t-} = 0}\\
%\rate\stpara{-1}(t,\xf\vind{v}\tmi{[0,t)},\xf\vind{\neigh{v}}\tmi{[0,t)} &:=
%\mb{I}_{\xf\vind{v}\tme{t-} = 1}
%\end{align*}
%
%Let \(\ell(\{i\}) = \frac{\mb{I}_{i=\pm 1}}{2}\). Then,
%
%\[\sum_{i \in \pm 1}|i|\ell(\{i\})\sup_{\substack{t\in [0,T]\\\xf\in\cad,\xf'\in\cad^\sqcup}} \rate\stpara{i}\tmepro{t}{\xf}{\xf'} \leq \frac{\max\{\lambda,1\}}{2} < \infty.\]
%
%Thus \cite[assumption \ref{F-a::bddr}]{F} is satisfied. Finally, note that,
%
%\begin{align*}
%\sup_{\substack{k \in \mb{N}_0\\\xf,\xg \in \cad,\xf',\xg'\in \cad^k}} &\frac{\sum_{i \in \sta}|i|\Sm(\{i\})\left|\rate\stpara{i}\tmepro{t}{\xf}{\xf'} - \rate\stpara{i}\tmepro{t}{\xg}{\xg'}\right|}{\left|\stmet{t-}(\xf,\xg) + \frac{1}{k}\sum_{j=1}^k \stmet{t-}(\xf'\vind{j},\xg'\vind{j})\right|}\\
%& \leq \sup_{\substack{k \in \mb{N}_0\\\xf,\xg \in \cad,\xf',\xg'\in \cad^k}} \frac{\sum_{i \in \sta}|i|\Sm(\{i\})\left|\rate\stpara{i}\tmepro{t}{\xf}{\xf'} - \rate\stpara{i}\tmepro{t}{\xg}{\xg'}\right|}{\left||\xf(t-) - \xg(t-)| + \frac{1}{k}\sum_{j=1}^k |\xf\vind{j}(t-) - \xg\vind{j}(t-)|\right|}\\
%&\leq \frac{\frac{\max{\lambda,1}}{2}}{2} = \frac{\max{\lambda,1}}{4} < \infty
%\end{align*}
%
%So \cite[assumption \ref{F-a::liprx}]{F} is satisfied.
%\end{example}

\begin{example}[Potts Model, Glauber dynamics]
\label{ex::Potts}
We consider the Potts model with Glauber dynamics \cite{Gla63}, \tr{(citation needed)}. \tr{Include brief description of model and applications.} This model is parameterized by some \(\beta\in\mb{R}\).

\ind Let \(\sta = \{1,\dots,q\}\) for some \(q \in \mb{N}\). Then for \(\xf \in \cad\), \(\xf' \in \cad^\sqcup\), \(0 < t < \infty\) and \(j \in \sta\), 

\[\rate\stpara{j-\xf\tme{t-}}\tmepro{t}{\xf}{\xf'} = \begin{cases}
\frac{e^{-\beta\sum_{u} \delta_{j,\xf'_u\tme{t-}}}}{\sum_{k \in \sta} e^{-\beta\sum_{u} \delta_{k,\xf'_u\tme{t-}}}} &\te{ if } j \in \sta\\
0 &\te{ otherwise.}
\end{cases}\]

Where \(\delta_{j,k} = \mb{I}_{j=k}\). Assume \(\{\Xf\vind{v}\tme{0}: v \in V\}\) are i.i.d. uniformly distributed over \(\sta\) and let \(\Sm\) be the uniform probability measure over \(\{-q+1,\dots,q-1\}\). \tr{TODO:: make accommodations for finite state spaces. Maybe state that \(\sta = \mathbb{Z}\) or \(\mathbb{Z}/m\mathbb{Z}\).}

\ind As for the graph topology, let \(G = (V,E, \root)\) be an undirected, \(d\)-Cayley graph (infinite tree with uniform degree \(d\)) and root \(\root\).

Then we can verify all of the assumptions:

\begin{description}
\item[] \cite[Assumption \ref{F-a::bddinit}]{F}: \textbf{Initial conditions are bounded in expectation:} \(\Xf\vind{v}\tme{0} \leq q < \infty\) almost surely, so the assumption is met.

\item[] \cite[Assumption \ref{F-a::bddr}]{F}: \textbf{Jump rates are bounded. Jump rates of the ground jump point process are bounded:} For any \(i\in \mb{Z},t >0, \xf \in \cad\) and \(\xf'\in\cad^\sqcup\),

\[\rate\stpara{i}\tmepro{t}{\xf}{\xf'} \leq \frac{e^{-\beta\sum_{u} \delta_{j,\xf'_u\tme{t-}}}}{\sum_{k \in \sta} e^{-\beta\sum_{u} \delta_{k,\xf'_u\tme{t-}}}} \leq 1.\]

Then, 

\[\sum_{j \in \mb{Z}}|j|\Sm(\{j\})\sup_{j,t,x,x'} \rate\stpara{j}\tmepro{t}{\xf}{\xf'} \leq \sum_{j \in \mb{Z}}|j|\Sm(\{j\}) = \frac{1}{2q-1}\sum_{j = -q+1}^{q-1} |j| < \infty.\]

\item[] \cite[Assumption \ref{F-a::liprx}]{F}: \textbf{Jump rates are Lipschitz with respect to history:} \tr{This assumption may be modified.}

Note that for \(d < q\),

\begin{align*}
\sup_{\xf,\xg\in \cad,\xf',\xg' \in \cad^d, (\xf,\xf')\neq(\xg,\xg')} \frac{\sum_{j \in \mb{Z}}|j|\Sm(\{j\})|\rate\stpara{j}(t,\xf,\xf') - \rate\stpara{j}(t,\xg,\xg')|}{\left|\stmet{t-}(\xf,\xg) + \frac{1}{d}\sum_{k=1}^d \stmet{t-}(\xf',\xg')\right|} \leq \frac{d}{2q-1}\sum_{j=-q+1}^{q-1} |j|
\end{align*}

This is because the denominator is bounded from below by \(\frac{1}{d}\). When \(d > q\), notice that \(\sum_{k\in\sta}e^{-\beta\sum_u \delta_{k,\xf'\vind{u}\tme{t-}}} \geq d-q\) (pigeonhole principle), and \(\sup_{d\in \mb{N},d > q} \frac{d}{d-q} = q+1 < \infty\). Then,

\[\sum_{j \in \mb{Z}}|j|\Sm(\{j\})|\rate\stpara{j}(t,\xf,\xf') - \rate\stpara{j}(t,\xg,\xg')|\leq \sum_{j \in \mb{Z}}|j|\Sm(\{j\})\frac{1}{d-q} = \frac{1}{(2q-1)(d-q)}\sum_{j=-q+1}^{q-1}|j| < \infty.\]

Then,

\begin{align*}
\sup_{\substack{d \in\mb{N},\xf,\xg\in \cad\\ \xf',\xg' \in \cad^d, (\xf,\xf')\neq(\xg,\xg')}} \frac{\sum_{j \in \mb{Z}}|j|\Sm(\{j\})|\rate\stpara{j}(t,\xf,\xf') - \rate\stpara{j}(t,\xg,\xg')|}{\left|\stmet{t-}(\xf,\xg) + \frac{1}{d}\sum_{k=1}^d \stmet{t-}(\xf',\xg')\right|} &\leq \sup_d \frac{d}{(2q-1)[(d-q)\vee 1]}\sum_{j=-q+1}^{q-1}|j|\\
& \leq \frac{q+1}{2q-1}\sum_{j=-q+1}^{q-1}|j|\\
& < \infty
\end{align*}

\item[] \cite[Assumption \ref{F-CI::indinit}]{F}: \textbf{Initial distributions are independent:} We assumed the initial condition is i.i.d.

\item[] Assumption \ref{a::liprt}: \textbf{Jump rates are locally Lipschitz in time if they are continuous:} \(\rate\stpara{j}\tmepro{t}{\xf}{\xf'}\) is constant when \((\xf,\xf')\) is continuous at \(t\).

\item[] Assumption \ref{a::lctr}: \textbf{Jump rates are left-continuous in time and discontinuities match history:} This is trivially true because \(\rate\stpara{j}\tmepro{t}{\xf}{\xf'}\) depends only on \((\xf,\xf')\tme{t-}\).

\item[] Assumption \ref{a::admissible}: \textbf{Graph geometry is symmetric enough:} Let \(A\indx{k} = \{v \in V: d_G(v,\root) \leq k+1\}\). Let \(A \defeq A\indx{0}\). To satisfy assumption \ref{a::admissible}(i), we must prove that \(A\) and \(A\indx{k}\) satisfy all the conditions below for all \(k\in\mb{N}\). All illustrations cover the \(d=3\) case.

\ind For clarity, we name the vertices in the following manner. The root is \(\root\). Its children are labeled \(1,2,\dots,d\). The following children are numbered similarly. Thus \(1123\) is the 3rd child of the 2nd child of the first child of the first child of the root. It is a leaf of \(A\indx{3}\).

\includegraphics[scale=0.1]{treevert.jpg}

\begin{enumerate}[(a)]
\item {\bfseries\boldmath Definition of \(\{B_j\}\):} For each \(j\), \(B_j\) and \(B\indx{k}_j\) are the set of descendants of a single leaf of \(A\) and \(A\indx{k}\) respectively. The descendants of all leaves of \(A\) and \(A\indx{k}\) form a partition of \(A^c\) and \((A\indx{k})^c\). For simplicity we will index the branches by the leaf they descend from. For example, since \(1121\) is a leaf of \(A\indx{3}\), \(B\indx{3}_{1121}\) is the set of descendants of \(1121\). \tr{I did not use this naming convention in figure 2 below.}

\includegraphics[scale=0.1]{pottstree1.jpg}

\item {\bfseries\boldmath\(\dneigh{B_j} \subseteq A\):} See (a) and figure 3 for an example. For \(v \in A\setminus\{\root\}\), \(\dneigh{B_v} = \{v,\root\} \subset A\). If \(v\) is a leaf of \(A\indx{k}\), then \(\dneigh{B\indx{k}_v} = \{v,p(v)\}\subset A\indx{k}\) where \(p(v)\) is the parent of \(v\).

\item {\bfseries\boldmath\(\phi_j(C_j\cup\dneigh{B_j}) \subset A\) and \(\phi_j(B_j\setminus C_j) \cap A = \emptyset\):} See figure 3. For any \(v \in A\setminus \{\root\}\), let \(\phi_v\) be any automorphism of \(G\) such that \(\phi_v(v) = \root\) and \(\phi_v(\root) = v\). See figure 3 for one such example of \(\phi_1\). By definition, \(\phi_v(\{v1,v2,\dots,v(d-1)\}) = \{1,\dots,d\}\setminus \{v\}\), so

\[\phi_v(C_v\cup\dneigh{B_v}) = \{v,\root\}\cup(\{1,\dots,d\}\setminus \{v\}) = A.\]

Furthermore, since \(\phi_v\) is an automorphism and \(\phi_v(C_v\cup\dneigh{B_v}) = A\), it follows that \(\phi_v(B_v\setminus C_v)\cap A = \emptyset\).

\includegraphics[scale=0.1]{phismall.jpg}

For \(v \in A\indx{k}\setminus A\indx{k-1}\), we use a slightly different automorphism (see figure 4 for an example of \(\phi\indx{2}_{111}\)). \(\phi\indx{k}_v(v) = p(v)\) and \(\phi\indx{k}_v(p(v)) = p(p(v))\). This isn't possible in the \(k=0\) case because \(\root\) does not have any parents, but it is possible in general. Then \(\phi\indx{k}_v(C\indx{k}_v) = \phi\indx{k}_v(\{v1,\dots,v(d-1)\}) = \{p(v)1,\dots,p(v)(d-1)\} = C\indx{k-1}_{p(v)}\). Thus,

\[\phi\indx{k}_v(C\indx{k}_v\cup\dneigh{B\indx{k}_v}) = C\indx{k-1}_{p(v)}\cup \{p(v),p(p(v))\} \subset A.\]

Notice that \(\phi\indx{k}_v\) preserves the parent/descendant structure of all descendants of \(v\). Since each \(u\in B_v\setminus C_v\) is a descendant of some \(u' \in C\indx{k}_v\), \(\phi\indx{k}_v(u)\) is a descendant of \(\phi\indx{k}_v(u')\), but \(\phi\indx{k}_v(u')\) is a leaf of \(A\indx{k}\), so \(\phi\indx{k}_v(u) \notin A\indx{k}\). It follows that \(\phi\indx{k}_v(B\indx{k}_v\setminus C\indx{k}_v)\cap A\indx{k} = \emptyset\).

\includegraphics[scale=0.1]{phibig.jpg}

\item {\bfseries\boldmath\(\dneigh{B_{j'}}\cap\phi_j(C_j\cup\dneigh{B_j}) \in \{\dneigh{B_{j'}},\emptyset\}\):} In part (c) we showed that for any \(v \in A\setminus\{\root\}\), \(\phi_v(C_v\cup\dneigh{B_v}) = A\). By (b), \(\dneigh{B_{j'}} \subseteq A\). Thus Thus, \(\dneigh{B_{j'}} \subseteq\phi_j(C_j\cup\dneigh{B_j})\).

\ind Notice that for all \(k\) and \(v \in A\indx{k}\setminus A\indx{k-1}\), \(\dneigh{B\indx{k}_v} = \{v,p(v)\}\). Suppose for some \(u \in A\indx{k}\setminus A\indx{k-1}\), \(v \in \phi\indx{k}_u(C\indx{k}_u\cup\dneigh{B\indx{k}_u})\). By definition of \(\phi\indx{k}\), \(\phi\indx{k}(\dneigh{B\indx{k}_u})\) is contained in the interior of \(A\indx{k}\). Thus, \(v \in \phi\indx{k}_u(C\indx{k}_u)\), so \(p(u) = p(v)\). In this case, \(\phi\indx{k}(u) = p(v)\) and \(\dneigh{B\indx{k}_v} = \{v,p(v)\}\subset \phi\indx{k}_u(C\indx{k}_u\cup\dneigh{B\indx{k}_u})\). Now suppose \(p(v) \in \phi\indx{k}_u(C\indx{k}_u\cup\dneigh{B_u})\). Then \(p(v) = \phi\indx{k}(u)\) and \(p(v) = p(u)\). In this case, \(\phi\indx{k}(C\indx{k}_u) = C\indx{k-1}_{p(u)} = C\indx{k-1}_{p(v)} \ni v\).

\ind \tr{This is kind of complicated. I would recommend walking through the argument while looking at figures 3 and 4}

\ind Thus, \(\dneigh{B\indx{k}_v}\cap\phi\indx{k}_u(C\indx{k}_u\cup\dneigh{B\indx{k}_u}) \in \{\emptyset, \dneigh{B\indx{k}_v}\}\).

\item {\bfseries\boldmath\(\dneigh{B_{j'}}\subseteq\phi_j(C_j\cup\dneigh{B_j})\) whenever \(\neigh{B_{j'}}\cap\phi_j(C_j)\) is nonempty:} (d) implies (e).

\item {\bfseries\boldmath If \(v\in \phi_j(C_j)\cap\neigh{B_{j'}}\) then \(\dneigh{B_{j'}}\subseteq \phi_j(C_j\cup\neigh{B_j})\):} Suppose \(v \in A\setminus \{\root\}\) is in \(\phi_u(C_u)\) for some \(u\). Then \(v \neq u\) (\(\phi_u(\root) = u\)). \(\phi_u(C_u\cup\neigh{B_u}) = A\setminus \{u\}\) and \(v \in \neigh{B_v}\), so \(\dneigh{B_v} = \{v,\root\} \subseteq A\setminus \{u\} = \phi_u(C_u\cup\neigh{B_u})\).

\ind Fix any \(k \geq 1\). Let \(v \in A\indx{k}\setminus A\indx{k-1}\), so \(v = \neigh{B\indx{k}_v}\). If \(v \in \phi\indx{k}_u(C\indx{k}_u)\), then \(p(v) = p(u) = \phi\indx{k}_u(u) = \phi\indx{k}_u(\neigh{B\indx{k}_u})\). Thus, \(\dneigh{B\indx{k}_v} = \{v,p(v)\} \subseteq \phi\indx{k}(C\indx{k}_u\cup\neigh{B\indx{k}_u})\).

\item {\bfseries\boldmath If \(\phi_j(C_j)\cap\neigh{B_{j'}}\) is non-empty, then \(\dneigh{B_{j'}} \subseteq \phi_j(C_j\cup\dneigh{B_j})\). In fact, \(\phi_j^{-1}(\dneigh{B_{j'}}) = \dneigh{B\indx{1}_{j''}}\) for some \(j''\) and \(C_j\cap\phi_j^{-1}(\neigh{B_{j'}}) = \neigh{B\indx{1}_{j''}}\):}

The first statement is implied by (d). Recall that \(\dneigh{B_v} = \{v,\root\}\). Suppose \(v \in \phi_u(C_u)\). Then \(\phi_u(u) = \root\). This means that \(\phi^{-1}_u(\dneigh{B_v}) = \{u',u\}\) for some \(u' \in C_u = \neigh{B\indx{1}_{u'}}\). But then, by definition, \(\dneigh{B\indx{1}_{u'}} = \{u',u\} = \phi^{-1}_u(\dneigh{B_v})\). Finally, \(C_u \cap \phi^{-1}(v) = u' = \neigh{B\indx{1}_{u'}}\).

\ind Suppose \(v \in A\indx{k}\setminus A\indx{k-1}\) and \(v \in \phi\indx{k}_u(C\indx{k}_u)\) for some \(u \in A\indx{k}\setminus A\indx{k-1}\). Suppose \((\phi\indx{k})^{-1}_u(v) = u' \in C\indx{k}_u\). Then,

\[(\phi\indx{k})^{-1}_u(\dneigh{B\indx{k}_v}) = (\phi\indx{k})^{-1}_u(\{v,p(v)\}) = \{u',u\} = \dneigh{B\indx{k+1}_{u'}}.\]

Finally,

\[C\indx{k}_u\cap(\phi\indx{k})^{-1}_u(\neigh{B_u}) = C\indx{k}_u\cap u' = u' = \neigh{B\indx{k+1}_{u'}}.\]

\item {\bfseries\boldmath \(\phi_j(\dneigh{B_j}\setminus \neigh{B_j})\cap \neigh{B_{j'}}\) nonempty implies \(\phi_j(C_j)\cap\dneigh{B_{j'}} = \emptyset\):}

For any \(v \in A\setminus\{\root\}\), \(\phi_v(\dneigh{B_v}\setminus\neigh{B_v}) = \phi_v(\root) = v\). Then \(\phi_v(C_v)\cap\dneigh{B_v} = (\{1,\dots,d\}\setminus\{v\})\cap \{v,\root\} = \emptyset\).

\ind This is trivially true. For any \(v \in A\indx{k}\setminus A\indx{k-1}\), \(\phi\indx{k}_v(\dneigh{B\indx{k}_v}\setminus\neigh{B\indx{k}_v}) = \phi\indx{k}_v(p(v)) = p(p(v)) \in A\indx{k-1}\). Thus, the intersection is always empty.

\item {\bfseries\boldmath \(\ov{A}\) is admissible:} This is true as long as \(A\indx{k}\) satisfies all of the other conditions.

\item {\bfseries\boldmath \(C\indx{1}_{j'} \subseteq B_j\) implies that there exists a \(j''\) such that \(\phi_j(C\indx{1}_{j'}) = C_{j''}\):} 

Suppose \(C\indx{1}_u \subseteq B_v\) for some \(u,v\). Then \(\phi_v(u) \in A\setminus\{\root,v\}\) and \(\phi_v(v) = \root\). Because \(\phi_v\) is an automorphism, the descendants of \(u\) are mapped to the descendants of \(\phi_v(u)\). That is,

\[\phi_v(C\indx{1}_u) = C_{\phi_v(u)}.\]

Now suppose \(C\indx{k+1}_u \subseteq B\indx{k}_v\) for some appropriate \(u,v\). Then \(u \in C\indx{k}_v\), so \(p(\phi\indx{k}_v(u)) = p(v)\). Since \(\phi\indx{k}\) preserves the descendants of all descendants of \(v\), it follows that \(\phi\indx{k}_v(C\indx{k+1}_u) = C\indx{k}_{\phi\indx{k}_v(u)}\).
\end{enumerate}

\item[] Assumption \ref{a::padmin}: \textbf{All automorphisms of assumption \ref{a::admissible} are symmetries of \((G,\Xf\gind{G})\):} This follows because \(\{\Xf\gind{G}\vind{v}\tme{0}:v \in V\}\) are i.i.d.
\end{description}
\end{example}

The work of \tr{(Cite other local equation papers)} cover the tree topology of example \ref{ex::Potts}. However, this paper extends the local equation to other useful deterministic graph topologies.

\begin{example}[Load Balancing]
\label{ex::lb}
\tr{For simplicity I'm only introducing the nearest neighbor load-balancing. This requires asymmetric inputs. I will just assume for now that \(\rate\) is equipped to handle asymmetric inputs.} This model is parameterized by some \(\lambda > 0\).

\ind We introduce a model similar to that of \cite{BudMukWu17}. Consider a network of servers. Jobs arrive at each server at a constant rate of \(\lambda\). Upon arrival, the jobs investigate the size of the server's queue as well as \(\d\) neighboring queues within the network (chosen uniformly at random). The job chooses uniformly at random from the local servers with the shortest queue lengths. Each queue processes jobs at unit rate.

\ind Let \(\sta = \mb{N}_0\), and let \(\Sm\) be the uniform probability measure on \(\{\pm 1\}\). Let \(G = (V,E)\) represent the network topology. Notice that the evolution of any server \(v \in V\) depends not only on its neighbors \(\neigh{v}\), but also on the neighbors of its neighbors (if \((u,v) \in E\) and a job arrives at \(u\), \(u\) may choose to send the job to \(v\) or to one of the neighbors of \(u\) depending on the queue sizes of its neighbors). Thus we work in two graph topologies. The first is \(G\), which is assumed to be a \(\d\)-Cayley tree. This is the topology describing how servers are connected. The second is \(G^E = (V,E^E)\). This is the effective graph topology. Here \(E^E = \{(u,v) \in V^2: d_G(u,v) \in \{1,2\}\}\). Any graph operation (such as \(v\mapsto \neigh{v}\)) done with respect to \(G^E\) will have a superscript \(E\). So, the neighbors of \(v\) with respect to \(G\) are \(\neigh{v}\), but \(\eneigh{v}\) denotes the neighbors of \(v\) with respect to \(G^E\).

\ind To account for the asymmetry of \(\rate\), I'm changing the notation here slightly. We let \(\rate\) depend on \(G^E\) and \(v\). Rewrite condition 2 of definition \ref{a:Xsim} as follows:

\lin

Let \(G = (V,E,\root), G' = (V',E',\root') \in \Gs\) and \(v \in V, u\in V'\). If \(G\vpara{\cl{v}} \cong (G')\vpara{\cl{u}}\), then there exists an isomorphism from \(G\vpara{\cl{v}}\) to \((G')\vpara{\cl{u}}\) (not necessarily preserving the root) such that \(\phi(v) = u\), and 

\[\rate\gvpara{G}{v}\stpara{i}\tmepro{t}{\xf\vind{v}}{\xf\vind{\gneigh{G}{v}}} = \rate\gvpara{G'}{\phi(v)}\stpara{i}\tmepro{t}{\xg\vind{\phi(v)}}{\xg\vind{\phi(\gneigh{G'}{u})}}, \te{ whenever } \xf\vind{\cl{v}} = \xg\vind{\phi(\cl{u})}.\]

\lin

For \(v \in V\), \(\xf \in \cad\vpara{\ecl{v}}:=\cad\vpara{\cl{\cl{v}}}\), \(0 < t < \infty\) and \(i \in \sta\),

\begin{align*}
\rate\stpara{1}\gvpara{G^E}{v}\tmepro{t}{\xf}{} &= \sum_{u \in \cl{v}} \left(\frac{\d}{|\neigh{v}|}\wedge 1\right)\frac{\lambda\mb{I}_{\xf\vind{v}\tme{t-} = \min_{w\in\neigh{u}} \xf\vind{w}\tme{t-}}}{|\te{argmin}_{w\in\neigh{u}} \xf\vind{w}\tme{t-}|}\\
\rate\stpara{-1}\gvpara{G^E}{v}\tmepro{t}{\xf}{} &= \mb{I}_{\xf\vind{v}\tme{t-} > 0}\\
\rate\stpara{i}\gvpara{G^E}{v}\tmepro{t}{\xf}{} &= 0 \te{ when } i \neq \pm 1.
\end{align*}

Note that for our choice of \(G\), each server checks all of its neighbors at any given time. However, for graphs with higher degree vertices, each server only checks \(\d\) random neighbors. Finally, assume \(\{\Xf\vind{v}\gind{G^E}\tme{0}: v \in V\}\) is i.i.d. Poisson unit rate.

We can now verify the assumptions.

\begin{description}
\item[] \cite[Assumption \ref{F-a::bddinit}]{F}: \textbf{Initial distribution is bounded in expectation:}

\[\sup_{G,v} \ex{|\Xf\vind{v}\gind{G}\tme{0}|} = 1 < \infty.\]

\item[] \cite[Assumption \ref{F-a::bddr}]{F}: \textbf{Jump rates are bounded. Jump rates of the ground jump point process are bounded:} The jump rate is maximized when \(\xf\vind{v}\tme{t-}\) is strictly smaller than all of its neighbors and their neighbors.

\[\sup_{G,v,t,\xf,i} \rate\stpara{i}\gvpara{G^E}{v}\tmepro{t}{\xf}{} \leq \sup_{G,v}\left(\frac{d}{|\neigh{v}|}\wedge 1\right)(|\neigh{v}|+1)\lambda \vee 1\leq (d+1)\lambda\vee 1 < \infty.\]

\item[] \cite[Assumption \ref{F-a::liprx}]{F}: \textbf{Jump rates are Lipschitz with respect to history:} As written, load-balancing doesn't satisfy this. However, it turns out for Markov processes this assumption is not necessary \tr{Make the changes}. I hypothesize that we can replace this Lipschitz assumption with a supremum type assumption for non-Markov processes. However, I'll have to see if the Hawkes process satisfies this first.

\item[] \cite[Assumption \ref{F-CI::indinit}]{F}: \textbf{Initial distributions are independent:} We assumed the initial distribution was i.i.d.

\item[] Assumption \ref{a::liprt}: \textbf{The continuous part of jump rates are locally Lipschitz in time:} This is trivially true because the jump rate depends only on \(\Xf\vind{\ecl{v}}\tme{t-}\).

\item[] Assumption \ref{a::lctr}: \textbf{Jump rates are left-continuous in time and discontinuities match history:} Again, trivially true because \(\Xf\) is Markov.

\item[] Assumption \ref{a::admissible}: \textbf{Graph geometry is sufficiently symmetric:} Let \(\tree{k}\) indicate the subtree of \(G\) with \(k\) generations of descendants. Thus, \(\tree{0} = \{\root\}\), \(\tree{1} = \{\root,1,\dots,d\}\) and so on. That is, \(\tree{k} = \{v \in V: d_G(\root,v) \leq k\}\). We use the following notation for graph operations:

\tr{Move this to the beginning of the example.}

\begin{itemize}
\item \(\neigh{v}\) is the neighborhood of \(v\) wrt \(G\). \(\eneigh{v}\) is the neighborhood of \(v\) wrt \(G^E\).

\item \(\dneigh{v}\) is the double neighborhood of \(v\) wrt \(G\). \(\deneigh{v}\) is the double neighborhood of \(v\) wrt \(G^E\).

\item \(\cl{v} = v\cup \neigh{v}\). \(\ecl{v} = v\cup\eneigh{v}\).

\item For \(U \subset V\), \(\inte{U} = \{v \in U: \neigh{v}\subseteq U\}\). \(\einte{U} = \{v \in U: \eneigh{v}\subseteq U\}\).
\end{itemize}

Let \(A = \tree{5}\). In general, define \(A\indx{k} = \tree{5+2k}\). Then \(A\indx{1} = \ecl{A}\) and \(A\indx{k+1} = \ecl{A\indx{k}}\). We are now ready to start verifying conditions. All illustrations will cover the \(\d = 3\) case. All edges on drawn graphs will be with respect to \(G\), not \(G^E\). All arguments will be made for \(A\indx{k}\) for all \(k \in \mb{N}_0\).

\ind Note: I say a vertex \(v\in V\) is in the \(k\)th generation if \(d_G(v,\root) = k\). This stratification makes it much easier to talk about graph topology. Symbolically this will be written \(g(v) = k\) or \(v \in \bdry{\tree{k}}\). \tr{I made a mistake in the illustrations. Due to assumption \ref{a::admissible}(d), \(A\) must be 5 generations, not 4, but all the illustrations have \(A\) as 4 generations. I'll fix this later.}

\begin{enumerate}[(a)]
\item {\bfseries\boldmath Definition of \(\{B_j\}\):} Fix \(k\). We name the branches of \(A\indx{k}\) after vertices \(v\) in the \(2k + 3\)rd generation. For \(v \in \bdry{\tree{2k+3}}\), \(B\indx{k}_v\) is the maximal subset of descendants of \(v\) such that \(B\indx{k}_v\cap A\indx{k} = \emptyset\). For every vertex \(u \in (A\indx{k})^c\), there exists a unique \(v \in \bdry{\tree{2k+3}}\) such that \(v\) is the ancestor of \(u\) (with respect to \(G\)!). Thus, \(\{B\indx{k}_v:v \in \bdry{\tree{k}}\}\) is a partition of \((A\indx{k})^c\). (See figure 5 for a partial illustration of \(A,B_{111}\) and \(C_{111}\) \tr{fix illustration}).

\includegraphics[scale=0.1]{fattreeABC.jpg}

\item {\bfseries\boldmath \(\deneigh{B_j} \subseteq A\):} See figure 3 for an example of \(\deneigh{B_{111}}\) \tr{fix illustration}.

\ind Fix \(k\). For \(v \in A\indx{k}\), 

\[\deneigh{B\indx{k}_v} = \left(\desc(v)\cap A\indx{k}\right)\cup\{v,p(v)\},\]

where \(\desc(v) = \{u\in V: p^m(u) = v\te{ for some }m\}\) is the set of descendants of \(v\). This is clearly a subset of \(A\indx{k}\) since \(\{v,p(v)\} \subset \bdry{\tree{2k+3}}\cup\bdry{\tree{2k+2}}\).

\ind\tr{This works because \(A\indx{k} = \bigcup_{m=0}^{2k+5} \bdry{\tree{m}}\).}

\item {\bfseries\boldmath \(\phi_j(C_j\cup\deneigh{B_j}) \subset A\) and \(\phi_j(B_j\setminus C_j) \cap A = \emptyset\):}

See figure 3 for an illustration of \(\phi_{111}(C_{111}\cap \deneigh{B_{111}})\) \tr{fix}.

\ind We can explicitly describe \(\phi\). First, \(\phi\indx{k}_v(p(v)) = p^3(v)\) (in the \(k=0\) case, this is just the root). Suppose \(u\) is a descendant of \(p(v)\). Using our naming convention, \(u = p(v)w\) where \(w\) is another string of numbers indicating the path from \(p(v)\) to \(u\). Then \(\phi\indx{k}_v(u) = \phi\indx{k}_v(p(v))w\). (we treat \(\root w\) as \(w\)).

\ind For example, let \(u = 21324221\), and suppose \(v = 21323\). Then \(k = 1\) because \(v \in \bdry{\tree{5}} = \bdry{\tree{2*1+3}}\). \(p(v) = 2132\) and \(w = 4221\). Then \(\phi\indx{1}_v(p(v)) = 21\), so \(\phi\indx{1}_v(u) = \phi\indx{1}_v(p(v))w = 214221\). Furthermore, \(\phi\indx{1}_v(v) = 213\). \tr{Explain this in terms of paths. That's a more intuitive way of understanding these automorphisms. It's also a good way to rigorously prove that these are automorphisms.}

\ind Notice that this does not uniquely define \(\phi\indx{k}_v\), but it does define \(\phi\indx{k}_v\) on all vertices we are interested in. In particular, if \(u\) is \(p(v)\) or a descendant of \(p(v)\) and \(u \in \bdry{\tree{m}}\), then \(\phi\indx{k}_v(u) \in \bdry{\tree{m-2}}\).

\ind Now we can address the problem. Fix \(k\) and \(v \in \bdry{\tree{2k+3}}\). Notice that \(C\indx{k}_v\cup\deneigh{B\indx{k}_v} \subset \cup_{m=2k+2}^{2k+7} \bdry{\tree{m}}\). Furthermore, all elements of \(C\indx{k}_v\cup\deneigh{B\indx{k}_v}\) except \(p(v)\) are descendants of \(p(v)\). Thus,

\[\phi\indx{k}_v(C\indx{k}_v\cup\deneigh{B\indx{k}_v}) \subset \cup_{m=2k}^{2k+5} \bdry{\tree{m}} \subseteq A\indx{k}.\]

Furthermore, if \(u \in B\indx{k}_v \setminus C\indx{k}_v\), then \(g(u) > 2k+7\), so \(\phi\indx{k}_v(u) \in \bdry{\tree{m}}\) for some \(m > 2k+5\). But then \(\bdry{\tree{m}}\cap A\indx{k} = \emptyset\), so \(\phi\indx{k}_v(u) \notin A\indx{k}\).

\item {\bfseries\boldmath \(\deneigh{B_{j'}}\cap\phi_j(C_j\cup\deneigh{B_j}) \in \{\deneigh{B_{j'}},\emptyset\}\):}

We can argue using the definition of \(\phi\indx{k}_v\) defined above. 

\[C\indx{k}_v\cup\deneigh{B\indx{k}_v} = \left(\desc(v)\cap A\indx{k+1}\right)\cup\{v,p(v)\}.\]

Thus,

\[\phi\indx{k}_v(C\indx{k}_v\cup\deneigh{B\indx{k}_v}) = \left(\desc(\phi\indx{k}_v(v))\cap A\indx{k}\right)\cup\{\phi\indx{k}_v(v),p^3(v)\}.\]

\ind It's easier to think in terms of generations:

\[\bdry{\tree{m}}\cap \phi\indx{k}_v(C\indx{k}_v\cup\deneigh{B\indx{k}_v}) = \begin{cases}
\{w: p^{m-2k-1}(w) = \phi\indx{k}_v(v)\} &\te{ if } 2k+5\geq m > 2k+1\\
\{\phi\indx{k}_v(v)\} &\te{ if } m = 2k+1\\
\{p^3(v)\} &\te{ if } m = 2k\\
\emptyset &\te{ otherwise}
\end{cases}.\]

\ind Suppose there exist a \(w \in \deneigh{B\indx{k}_u}\cap \phi\indx{k}_v(C\indx{k}_v\cup\deneigh{B\indx{k}_v})\) for some \(u\). 

\begin{description}
\item[Case 1: ] If \(2k+4\leq g(w) \leq 2k+5\), then \(w\) must be a descendant of \(u\) and a descendant of \(\phi\indx{k}_v(v)\). It follows that \(p^2(u) = \phi\indx{k}_v(v)\), so \(\deneigh{B\indx{k}_u}\) is contained in \(\phi\indx{k}_v(v)\) and its descendants. Thus \(\deneigh{B\indx{k}_u} \subset \phi\indx{k}_v(C\indx{k}_v\cup\deneigh{B\indx{k}_v})\).

\item[Case 2: ] If \(g(w) = 2k+3\), \(p(w) = u\). Furthermore, \(p^3(w) = \phi\indx{k}_v(v)\). It follows that \(p^2(u) = \phi\indx{k}_v(v)\). Conclude as in case 1.

\item[Case 3: ] If \(g(w) = 2k+2\), then \(w = p(u)\) and \(p(w) = \phi\indx{k}_v(v)\). Again, it follows that \(p^2(u) = \phi\indx{k}_v(v)\) and we can conclude as in case 1.
\end{description}

Thus, if \(\deneigh{B\indx{k}_u}\cap \phi\indx{k}_v(C\indx{k}_v\cup\deneigh{B\indx{k}_v})\) is non-empty, then it is \(\deneigh{B\indx{k}_u}\).

\item {\bfseries\boldmath\(\dneigh{B_{j'}}\subseteq\phi_j(C_j\cup\dneigh{B_j})\) whenever \(\neigh{B_{j'}}\cap\phi_j(C_j)\) is nonempty:} (d) implies (e).

\item {\bfseries\boldmath If \(v\in \phi_j(C_j)\cap\eneigh{B_{j'}}\) then \(\deneigh{B_{j'}}\subseteq \phi_j(C_j\cup\eneigh{B_j})\):}

Suppose \(u \in \eneigh{B\indx{k}_{v'}}\) and \(u \in \phi\indx{k}_v(C\indx{k}_v)\). Then \(u\) is a descendant of \(v'\), and \(u\) is a descendant of \(\phi\indx{k}_v(v)\). Thus, \(p^2(v') = \phi\indx{k}_v(v)\).

\ind Note that \(\eneigh{B\indx{k}_v} = \desc(v)\cap A\indx{k}\), so \(\phi\indx{k}_v(C\indx{k}_v\cup\eneigh{B\indx{k}_v}) = \desc(\phi\indx{k}_v(v))\cap A\indx{k}\). However, \(\eneigh{B\indx{k}_{v'}} = \desc(v')\cap A\indx{k} \subset \desc(\phi\indx{k}_v(v))\cap A\indx{k}\), so we're done.

\item {\bfseries\boldmath If \(\phi_j(C_j)\cap\eneigh{B_{j'}}\) is non-empty, then \(\deneigh{B_{j'}} \subseteq \phi_j(C_j\cup\deneigh{B_j})\). In fact, \(\phi_j^{-1}(\deneigh{B_{j'}}) = \deneigh{B\indx{1}_{j''}}\) for some \(j''\) and \(C_j\cap\phi_j^{-1}(\eneigh{B_{j'}}) = \eneigh{B\indx{1}_{j''}}\):}

The first part is implied by (d). Recall that \(\deneigh{B\indx{k}_v} = \left(\desc(v)\cap A\indx{k}\right)\cup\{v,p(v)\}\). Now suppose \(\phi\indx{k}_{v'}(C\indx{k}_{v'}) \cap \eneigh{B\indx{k}_v}\) is nonempty. What are these sets?

\[\phi\indx{k}_{v'}(C\indx{k}_{v'}) = \left(\bigcup_{m=2k+4}^{2k+5}\bdry{\tree{m}}\right)\cap \desc(\phi\indx{k}_{v'}(v')).\]

\[\eneigh{B\indx{k}_v} = \left(\bigcup_{m=2k+4}^{2k+5}\bdry{\tree{m}}\right)\cap \desc(v) \subseteq \phi\indx{k}_{v'}(C\indx{k}_{v'}).\]

So it should be clear that if \(\deneigh{B\indx{k}_v} = \left(\desc(v)\cap A\indx{k}\right)\cup\{v,p(v)\}\) is non-empty, then \(p^2(v) = \phi\indx{k}_{v'}(v')\). Since descendants of \(p(v')\) are preserved under \(\phi\indx{k}_{v'}\), it follows that descendants of \(p^3(v')\) are preserved under the inverse \tr{(be a little more clear what this means)}. Thus,

\[C\indx{k}_{v'}\supseteq (\phi\indx{k}_{v'})^{-1}(\eneigh{B\indx{k}_v}) = \left(\bigcup_{m=2k+6}^{2k+7}\bdry{\tree{m}}\right)\cap \desc((\phi\indx{k}_{v'})^{-1}(v)) = \eneigh{B\indx{k+1}_{(\phi\indx{k}_{v'})^{-1}(v)}}\]

Furthermore,

\[\deneigh{B\indx{k}_v} = \eneigh{B\indx{k}_v}\cup\{v,p(v)\},\]

so

\[(\phi\indx{k}_{v'})^{-1}(\deneigh{B\indx{k}_v}) = \eneigh{B\indx{k+1}_{(\phi\indx{k}_{v'})^{-1}(v)}} \cup \{(\phi\indx{k}_{v'})^{-1}(v),p((\phi\indx{k}_{v'})^{-1}(v))\} = \deneigh{B\indx{k+1}_{(\phi\indx{k}_{v'})^{-1}(v)}}.\]

\item {\bfseries\boldmath \(\phi_j(\deneigh{B_j}\setminus \eneigh{B_j})\cap \eneigh{B_{j'}}\) nonempty implies \(\phi_j(C_j)\cap\deneigh{B_{j'}} = \emptyset\):}

\[\deneigh{B\indx{k}_v}\setminus \eneigh{B\indx{k}_v} = \{v,p(v)\} \in \cup_{m=2k+2}^{2k+3}\bdry{\tree{m}}.\]

Then,

\[\phi\indx{k}_v(\{v,p(v)\}) \in \cup_{m=2k}^{2k+1}\bdry{\tree{m}}.\]

However, for any \(u\in \bdry{\tree{2k+3}}\), 

\[\eneigh{B\indx{k}_u} \in \cup_{m=2k+4}^{2k+5}.\]

Thus, \(\phi\indx{k}_v(\deneigh{B\indx{k}_v}\setminus \eneigh{B\indx{k}_v}) \cap \eneigh{B\indx{k}_u} = \emptyset\).

\item {\bfseries\boldmath \(\ov{A}\) is admissible:} This is true as long as \(A\indx{k}\) satisfies all of the other conditions.

\item {\bfseries\boldmath \(C\indx{1}_{j'} \subseteq B_j\) implies that there exists a \(j''\) such that \(\phi_j(C\indx{1}_{j'}) = C_{j''}\):} 

If \(C\indx{k+1}_{v'} \subseteq B\indx{k}_v\), it follows that \(p^2(v') = v\). \(v'\) is a descendant of \(p(v)\), so it's descendants are preserved under \(\phi\indx{k}_v\).

\[C\indx{k+1}_{v'} = \desc(v')\cap \left(\cup_{m=2k+8}^{2k+9}\bdry{\tree{m}}\right).\]

Thus,

\[\phi\indx{k}_v(C\indx{k+1}_{v'}) = \desc(\phi\indx{k}_v(v'))\cap \left(\cup_{m=2k+6}^{2k+7}\bdry{\tree{m}}\right) = C\indx{k}_{\phi\indx{k}_v(v')}.\]
\end{enumerate}

\item[] Assumption \ref{a::padmin}: \textbf{The starting distribution is independent:} \tr{This is going to change soon. Rate needs to be consistent across \(G\).} \(\{\Xf\vind{v}\tme{0}:v \in V\}\) is assumed to be i.i.d. 
\end{description}

\end{example}

\begin{example}[Hawkes Process]
\label{ex::Hawkes}

In general, the non-linear Hawkes process is used to describe point processes with clustering behavior. We are particularly interested in applications to neuronal modeling. The jump rates of the Hawkes process can be described in the following manner \cite{BreMas96}:

\[\rate\stpara{1}\gvpara{G}{v}\tmepro{t}{\xf\vind{\cl{v}}}{} = \psi_v\left(\frac{1}{|\neigh{u}|}\sum_{u \in \cl{v}}\int_{(0,t)}  h_{uv}(t-s)\,d\xf\vind{u}(s)\right).\]

\(\rate\stpara{i} \equiv 0\) for any \(i \neq 1\). \tr{The scaling factor and finite history are our additions}. Within the neuroscience community there is a lot of interest in what functions \(\{\psi_v,h_{uv}\}\) and graph topologies can produce stable stationary processes \tr{choose citations}. \cite{GerDegTru17} introduce a specific nonlinear model for the single neuron model, derive an approximation and investigate stability conditions. Their model is given by,

\[\psi(x) = ce^x\te{ and } h(s) = J_r\theta(s)e^{-s/\tau_r} + J_a\theta(s)e^{-s/\tau_a} + J_{ref}\theta(s)\theta(\tau_{ref}-s).\]

Here \(\theta\) is the Heaviside function, \(J_r\) and \(J_a\) are parameters used to model the behavior of the neuron (refractory or burst tendencies, adaptation vs inhibition, etc). \(\tau_r,\tau_s\) are time constants. \(J_{ref} = -\infty\) and \(\tau_{ref}\) are used to enforce an absolute refractory period (time when the neuron cannot fire).

\ind We extend this model to multiple neurons using the simplest approach:

\[\psi_v(x) = \psi(x),\quad h_{vv}(s) = h(s) \te{ and } h_{uv}(s) = J_{uv}e^{-s/\tau_{uv}}.\]

We make the following assumptions:

\begin{enumerate}
\item \(J_re^{-\tau_{ref}/\tau_r} + J_ae^{-\tau_{ref}/\tau_a} = 0\) with \(J_r < 0\). This ensures the continuity of \(h\). 

\item \(\tau_{\cdot},c > 0\).

\item \(J_{uv} := J_u\) does not depend on \(v\).

\item \(J_u \in \{\pm J\}\) for some fixed \(J > 0\). If \(J_u < 0\), then \(u\) is called inhibitory. Otherwise it is called excitatory.

\item \(\Xf\vind{v}\tme{0} = 0\) a.s. for all \(v\). \tr{Consider including history.}

\item \(\tau_{uv} = \tau_{in}\) if \(u\) is inhibitory. \(\tau_{uv} = \tau_{ex}\) if \(u\) is excitatory.
\end{enumerate}

\tr{I introduce a heterogenous network here. An alternative approach would be to set \(\sta = \mb{N}_0^2\) to represent a excitatory, inhibitory pair.} Notice this introduces a heterogeneous network with two types of neurons. Excitatory and inhibitory. Let \(G^{\pm} = (V^\pm,E^\pm,\root^\pm)\) be two \(\d\)-Cayley graphs representing networks of excitatory and inhibitory neurons. Let \(\phi^{-\ra+}: V^- \ra V^+\) be an isomorphism \tr{(assume \(\phi^{-\ra+}(\root-) = \root+\))}. Let \(G = (V,E)\) be the graph defined by,

\[V = V^+\cup V^- \te{ and } E = E^+\cup E^-\cup \{(\phi^{-\ra+}(v),v): v \in V^-\}.\]

Thus we have an excitatory and inhibitory network, and each neuron is connected to precisely one neuron in the other network. We can now start verifying assumptions:

\begin{description}
\item[] \item[] \cite[Assumption \ref{F-a::bddinit}]{F}: \textbf{Initial distribution is bounded in expectation:}

Better yet, they are constant and almost surely 0.

\item[] \cite[Assumption \ref{F-a::bddr}]{F}: \textbf{Jump rates are bounded. Jump rates of the ground jump point process are bounded:}

Recall that \(\xf_v\) cannot jump more than once in an interval of size \(\tau_{ref}\). Thus,

\begin{align*}
\rate\gvpara{G}{v}\stpara{i}\tmepro{t}{\xf\vind{v}}{} &\leq c\vee c\exp\left(\frac{1}{|\neigh{v}|}\left(\sum_{m=0}^\infty J_re^{-m\tau_{ref}/\tau_r} + J_ae^{-m\tau_{ref}/\tau_a}+\sum_{u \in \cl{v}} J_ue^{-m\tau_{ref}/\tau_{u}}\right)\right)\\
&= c\vee c\exp\left(\frac{1}{|\neigh{v}|}\left(\frac{J_r}{1 - e^{-\tau_{ref}/\tau_r}} + \frac{J_a}{1 - e^{-\tau_{ref}/\tau_a}} + \sum_{u\in \cl{v}} \frac{J_u}{1 - e^{-\tau_{ref}/\tau_u}}\right)\right)\\
&\leq c\vee c\exp\left(\frac{1}{|\neigh{v}|}\left(\frac{J_a}{1 - e^{-\tau_{ref}/\tau_a}} + (|\neigh{v}|+1)\frac{J}{1 - e^{-\tau_{ref}/\tau_{ex}}}\right)\right)\\
&\leq c\exp\left(\frac{J_a + 2J}{1 - e^{-\tau_{ref}/\max\{\tau_a,\tau_{ex}\}}}\right) < \infty.
\end{align*}

\item[] \cite[Assumption \ref{F-a::liprx}]{F}: \textbf{Jump rates are Lipschitz with respect to history:}

Now our process is no longer Markov, and timing makes a difference. Since the jump rate is bounded, we can ignore the case where \(\stmet{t-}(\xf,\xg) \geq 1\) (so ignore the case in which \(\xf\) and \(\xg\) jumped a different number of times in the past). Instead, fix \(G,v,\xf,\xg,t\) and suppose \(\sup_{u \in \cl{v}}\stmet{t-}(\xf\vind{u},\xg\vind{u}) = \epsilon < 1\). What does this mean? This means that on the interval \([0,t)\), \(\xf\) and \(\xg\) had the same number of jumps, and the timing of respective jumps varied by at most \(\epsilon\).

\ind Now, notice that \(x \mapsto \exp(x)\) is Lipschitz on the interval \(\left(-\infty,\frac{J_a + 2J}{1 - e^{-\tau_{ref}/\max\{\tau_a,\tau_{ex}\}}}\right]\) with coefficient \(L_1 < \infty\). Therefore, it suffices to prove that

\[\frac{1}{|\neigh{v}|}\sum_{u \in \cl{v}}\int_0^t h_{uv}(t-s)\,d\xf_u(s),\]

is Lipschitz. Notice that \(h_{uv}\) is Lipschitz for all \(u,v\) (it's a sum of negative exponentials, and there are finitely many combinations of constants that define all of the \(u,v \in V\) \tr{rewrite}) with maximal Lipschitz coefficient \(L_2 <\infty\). Furthermore, the integral decomposes into a sum of at most \((|\neigh{v}|+1)\left\lceil\frac{t}{\tau_{ref}}\right\rceil\) elements. \tr{rewrite this coherently when I am less tired}. Thus, \(\rate\) is Lipschitz with coefficient bounded by,

\[\jumpbd{T}  = L_1L_2\left\lceil\frac{T}{\tau_{ref}}\right\rceil.\]

\tr{Rewrite this whole assumption!}

\item[] \cite[Assumption \ref{F-CI::indinit}]{F}: \textbf{Initial distributions are independent:}

The initial distributions are deterministic and therefore independent \tr{Consider allowing history.}

\item[] Assumption \ref{a::liprt}: \textbf{The continuous part of jump rates are locally Lipschitz in time:}

Suppose \(t\) is a point of continuity for \(\xf\vind{\cl{v}}\). Let \(t^v_i\) be the jump times of \(\xf\vind{v}\). Suppose also that \(t - t^v_i > \tau_{ref}\) for all \(t^v_i < t\).

\begin{align*}
\frac{d}{dt}\rate\stpara{1}\gvpara{G}{v}\tmepro{t}{\xf}{} &= c\exp\left(\frac{1}{|\neigh{v}|}\sum_{u\in\cl{v}}\int_{(0,t)} h_{uv}(t-s)\,d\xf\vind{u}(s)\right)\frac{d}{dt}\left(\frac{1}{|\neigh{v}|}\sum_{u\in\cl{v}}\int_{(0,t)} h_{uv}(t-s)\,d\xf\vind{u}(s)\right)\\
&\leq \frac{c\exp\left(\frac{J_a + 2J}{1 - e^{-\tau_{ref}/\max\{\tau_a,\tau_{ex}\}}}\right)}{|\neigh{v}|}\frac{d}{dt}\left(\sum_{t^v_i < t} J_re^{-(t-t^v_i)/\tau_r} + J_ae^{-(t-t^v_i)/\tau_a} + \sum_{u\in\neigh{v}}\sum_{t^u_i < t} J_ue^{-(t-t^u_i)/\tau_u}\right)\\
&\leq 2c\exp\left(\frac{J_a + 2J}{1 - e^{-\tau_{ref}/\max\{\tau_a,\tau_{ex}\}}}\right)\frac{J_r + J_a + J}{\min\{\tau_r,\tau_a,\tau_{ex},\tau_{in}\}}\left\lceil\frac{t}{\tau_{ref}}\right\rceil < \infty
\end{align*}

\item[] Assumption \ref{a::lctr}: \textbf{Jump rates are left-continuous in time and discontinuities match history:}

This is a direct artifact of the integral defining the jump rate.

\item[] Assumptions \ref{a::admissible} and \ref{a::padmin} \textbf{Graph geometry is sufficiently symmetric with respect to symmetries of \(\Xf\):}

I combine the last two assumptions because unlike in examples \ref{ex::Potts} and \ref{ex::lb}, not all automorphisms of \(G\) are symmetries of \(\Xf\).

\ind Let \(\phi^+\) be an automorphism of \(G^+\). Define,

\[\phi^- = (\phi^{-\ra+})^{-1}\phi^+\phi^{-\ra+}.\]

Then,

\[\phi(v) = \begin{cases}
\phi^+(v) &\te{ if } v \in V^+\\
\phi^-(v) &\te{ if } v \in V^-
\end{cases},\]

is an automorphism of \(G\) and a symmetry of \(\Xf\). This gives us a injection from any admissible set and its symmetries on the \(\d\)-Cayley tree to the admissible sets of \(G\) and their symmetries.
\end{description}

\end{example}

\begin{example}[TASEP with delay]

This model is based off of TASEP with movement rate \(\alpha\). However, particle transfer from one vertex is not instantaneous, and instead happens at rate \(\beta\). This produces an example of a process which is distinctly asymmetric and non-Markovian.

\ind These dynamics can be described in the following manner. Let \(\sta = \{0,1\}\). Let \(G = (V,E,\root)\), where \(V = \mb{Z}\), \(E = \{(v,v+1): v \in V\}\) and \(\root = 0\). For \((G,\xf)\in \Gs\sp{\sta}\), let \(\{\tau^v_m(t,\xf)\}\) be the transition times of \(\xf\vind{v}\) in decreasing order. Thus, \(t \geq \tau^v_1(t,\xf) \geq \tau^v_2(t,\xf) \geq\cdots\). If \(\xf\vind{v}\) has had fewer than \(m\) transitions, \(\tau^v_m(t,\xf) = 0\).

\begin{align*}
\rate\gvpara{G}{v}\stpara{1}\tmepro{t}{\xf_{\cl{v}}}{} &=  \begin{cases}
\beta &\te{ if } \xf\vind{v}\tme{t-} = \xf\vind{v-1}\tme{t-} = 0\te{ and } \tau^{v-1}_1(t,\xf) > \tau^v_1(t,\xf)\\
\beta &\te{ if } \xf\vind{v}\tme{t-} = 0,\xf\vind{v-1}\tme{t-} = 1\te{ and } \tau^{v-1}_2(t,\xf) > \tau^v_1(t,\xf)\\
0&\te{ otherwise}
\end{cases}\\
\rate\gvpara{G}{v}\stpara{-1}\tmepro{t}{\xf_{\cl{v}}}{} &=  \begin{cases}
\alpha &\te{ if } \xf\vind{v}\tme{t-} = 1, \xf\vind{v+1}\tme{t-} = 0\te{ and } \tau^{v}_2(t,\xf) \leq \tau^{v+1}_1(t,\xf)\\
0&\te{ otherwise}
\end{cases}\\
\rate\gvpara{G}{v}\stpara{i}\tmepro{\cdot}{\cdot}{} &\equiv 0\te{ for all } i \neq \pm 1.
\end{align*}

Finally, we assume for any \(\tilde{G} \in \Gs\), and \(v \in V\gind{\tilde{G}}\) such that \(|\neigh{v}| \neq 2\), \(\rate\gvpara{\tilde{G}}{v}\stpara{i}\tmepro{t}{\cdot}{} \equiv 0\). We can tailor the density of traffic through the initial distribution. \(\{\Xf\vind{v}\tme{0}:v \in V\}\) are assumed to be i.i.d. Bernoulli random variables with parameter \(p \in (0,1)\).

\ind We can now verify assumptions:

\begin{description}
\item[] \cite[Assumption \ref{F-a::bddinit}]{F}: \textbf{Initial distribution is bounded in expectation:}

The state space is bounded by 1, so this is trivially true.

\item[] \cite[Assumption \ref{F-a::bddr}]{F}: \textbf{Jump rates are bounded. Jump rates of the ground jump point process are bounded:}

Jump rates are bounded from above by \(\max\{\alpha,\beta\}\).

\item[] \cite[Assumption \ref{F-a::liprx}]{F}: \textbf{Jump rates are Lipschitz with respect to history:}

\tr{Restrict suprema to valid paths.} Notice that if \(\xf\vind{v}\tme{t-} \neq \xg\vind{v}\tme{t-}\), then \(|\rate\gvpara{G}{v}\stpara{i}\tmepro{t}{\xf\vind{v}}{} - \rate\gvpara{G}{v}\stpara{i}\tmepro{t}{\xf\vind{v}}{}| \geq \min\{\alpha,\beta,|\alpha-\beta|\}\). Now suppose \(\sup_{u\in\cl{v}} \stmet{t-}(\xf\vind{u},\xg\vind{u}) = \ep < 1\).

\tr{Modify lipschitz condition to \(|r(x_{\cl{v}}) - r(y_{\cl{v}})|\leq C\inf_{\lambda}\sup_{u\in\cl{v}}\|x_u - y_u\|_t\).}

Any small change in time does not change the value of the jump rate as all that matters is the order of events.

\item[] \cite[Assumption \ref{F-CI::indinit}]{F}: \textbf{Initial distributions are independent:}

Yup.

\item[] Assumption \ref{a::liprt}: \textbf{The continuous part of jump rates are locally Lipschitz in time:}

In fact, they are constant.

\item[] Assumption \ref{a::lctr}: \textbf{Jump rates are left-continuous in time and discontinuities match history:}

Yup.

\item[] Assumptions \ref{a::admissible} and \ref{a::padmin} \textbf{Graph geometry is sufficiently symmetric with respect to symmetries of \(\Xf\):}

The symmetries of \(\Xf\) consist of all mappings of the form \(\phi(v) = v + m\) for some \(m \in \mb{Z}\). Note that automorphisms of \(G\) also include mappings of the form \(\phi(v) = -v+m\), but these are not symmetries of \(\Xf\). This is why we cannot use the symmetries introduced in the first example. Before we verify this, note the following:

\begin{enumerate}
\item \(A\indx{k} = \{-k-1,\dots,0,\dots,k+1\}\), and \(A = A\indx{0}\).

\item The branches are given by \(B\indx{k}_1 = \{k+2,k+3,\dots\}\) and \(B\indx{k}_{-1} = \{-k-2,-k-3,\dots\}\).

\item For \(j\in \pm 1\), \(\neigh{B\indx{k}_j} = \{j(k+1)\}\) and \(\dneigh{B\indx{k}_j} = \{j(k+1),jk\}\).

\item For \(j \in \pm 1\), \(\phi\indx{k}_j(v) = v - j\).
\end{enumerate}

Then,

\begin{enumerate}[(a)]
\item {\bfseries\boldmath Definition of \(\{B_j\}:\)} See item 2 above.

\item {\bfseries\boldmath\(\dneigh{B_j}\subseteq A\):}

\[\dneigh{B\indx{k}_j} = \{j(k+1),jk\} \subset \{-k-1,\dots,0,\dots,k+1\} = A\indx{k}.\]

\item {\bfseries\boldmath \(\phi_j(C_j\cup\dneigh{B_j}) \subset A\) and \(\phi_j(B_j\setminus C_j) \cap A = \emptyset\):}

\begin{align*}
\phi\indx{k}_j(C\indx{k}_j\cup\dneigh{B\indx{k}_j}) &= \phi\indx{k}_j(\{j(k+2),j(k+1),jk\}) = \{j(k+2) - j,j(k+1)-j,jk-j\}\\
&= \{j(k+1),jk,j(k-1)\} \subseteq \{-k-1,\dots,k+1\} = A\indx{k}.
\end{align*}

\item {\bfseries\boldmath \(\dneigh{B_{j'}}\cap\phi_j(C_j\cup\dneigh{B_j}) \in \{\dneigh{B_{j'}},\emptyset\}\):}

When \(k = 0\), \(\phi_j(B_j) = A\), so this is trivially true. When \(k > 0\),

\begin{align*}
\dneigh{B\indx{k}_{j'}}\cap\phi\indx{k}_j(C\indx{k}_j\cup\dneigh{B\indx{k}_j}) &= \{j'(k+1),j'k\}\cap\{j(k+1),jk,j(k-1)\} \\
&= \begin{cases}
\{j'(k+1),j'k\} = \dneigh{B\indx{k}_{j'}}&\te{ if }j = j'\\
\emptyset &\te{ if } j \neq j'
\end{cases}.
\end{align*}

\item {\bfseries\boldmath\(\dneigh{B_{j'}}\subseteq\phi_j(C_j\cup\dneigh{B_j})\) whenever \(\neigh{B_{j'}}\cap\phi_j(C_j)\) is nonempty:} (d) implies (e).

\item {\bfseries\boldmath If \(v\in \phi_j(C_j)\cap\neigh{B_{j'}}\) then \(\dneigh{B_{j'}}\subseteq \phi_j(C_j\cup\neigh{B_j})\):}

\[\phi\indx{k}_j(C\indx{k}_j)\cap\neigh{B\indx{k}_{j'}} = \{j(k+1)\}\cap\{j'(k+1)\}.\]

So it's non-empty if and only if \(j = j'\). But then,

\[\phi\indx{k}_j(\neigh{B\indx{k}_j}\cup C\indx{k}_j) = \{j(k+1),jk\} = \dneigh{B\indx{k}_j}.\]


\item {\bfseries\boldmath If \(\phi_j(C_j)\cap\neigh{B_{j'}}\) is non-empty, then \(\dneigh{B_{j'}} \subseteq \phi_j(C_j\cup\dneigh{B_j})\). In fact, \(\phi_j^{-1}(\dneigh{B_{j'}}) = \dneigh{B\indx{1}_{j''}}\) for some \(j''\) and \(C_j\cap\phi_j^{-1}(\neigh{B_{j'}}) = \neigh{B\indx{1}_{j''}}\):}

The first part is implied by part (d). By part (f), we know that if the intersection is non-empty, then \(j = j'\). Thus,

\[(\phi\indx{k}_j)^{-1}(\dneigh{B\indx{k}_j}) = \{j(k+1)+j,jk+j\} = \{j(k+2),j(k+1)\} = \dneigh{B\indx{k+1}_j},\]

and

\[C\indx{k}_j\cap(\phi\indx{k}_j)^{-1}(\neigh{B\indx{k}_j}) = \{j(k+2)\}\cap\{j(k+2)\} = \{j(k+2)\} = \neigh{B\indx{k+1}_j}.\]

\item {\bfseries\boldmath \(\phi_j(\dneigh{B_j}\setminus \neigh{B_j})\cap \neigh{B_{j'}}\) nonempty implies \(\phi_j(C_j)\cap\dneigh{B_{j'}} = \emptyset\):}

\[\phi\indx{k}_j(\dneigh{B\indx{k}_j}\setminus\neigh{B\indx{k}_j})\cap\neigh{B\indx{k}_{j'}} = \{j(k-1)\}\cap \{j'(k+1)\}.\]

This is non-empty if and only if \(j = -j'\) and \(k = 0\). In this case,

\[\phi_j(C_j) \cap \dneigh{B_{j'}} = \{j\}\cap\{j',0\} = \{j\}\cap\{-j,0\} = \emptyset.\]

\item {\bfseries\boldmath \(\ov{A}\) is admissible:} This is true as long as \(A\indx{k}\) satisfies all of the other conditions.

\item {\bfseries\boldmath \(C\indx{1}_{j'} \subseteq B_j\) implies that there exists a \(j''\) such that \(\phi_j(C\indx{1}_{j'}) = C_{j''}\):} 

If \(C\indx{k+1}_{j'} \subseteq B\indx{k}_j\), then \(j = j'\). In this case,

\[\phi\indx{k}_j(C\indx{k+1}_j) = \{j(k+3) - j\} = \{j(k+2)\} = C\indx{k}_j.\]

\end{enumerate}
\end{description}
\end{example}


\section{Statement of the Local Approximation}
\label{Main}


\begin{thms}
Let \((G,\Xf) \in \Gs\sp{\cad}\) satisfy \cite[assumptions \ref{F-a::bddinit},\ref{F-a::bddr}, \ref{F-a::liprx}, \ref{F-CI::indinit}]{F} as well as assumptions \ref{a::liprt},\ref{a::lctr},\ref{a::admissible} and \ref{a::padmin}. Let \(A\) be the admissible set and \(\{B_i\}\) the branches of \(A\). Let \(\inte{A} = \{v \in A: \neigh{v} \subseteq A\}\). Consider the following equations:

\begin{align}
\Xg\vind{v}\tme{t} &= 
\begin{cases}
\Xg\vind{v}\tme{0} + \int_{\sta} \int_{[0,t)\times (0,\infty)} i\mb{I}_{r\leq \rate\stpara{i}\tmepro{s}{\Xg\vind{\cl{v}}}{}}\,\poiss\poissv{v}(dr,ds,di) & \te{ if } v \in \inte{A}\\
\Xg\vind{v}\tme{0} + \int_{\sta} \int_{[0,t)\times (0,\infty)} i\mb{I}_{r\leq \brate\vjpara{v}{B_j}\stpara{i}\tmepro{s}{\Xg\vind{\dneigh{B_j}}}{}}\,\poiss\poissv{v}(dr,ds,di) &\te{ if } v \in \neigh{B_j}
\end{cases}\label{Main::local}\\
\brate\vjpara{v}{B_j}\stpara{i}\tmepro{t}{\xf}{} &= \exmu{\Xg \sim \mu}{\rate\stpara{i}\tmepro{t}{\Xg\vind{\cl{\phi_j(v)}}}{}\middle|\Xg\vind{\phi_j(\dneigh{B_j})}\tmi{[0,t)} = x\vind{\dneigh{B_j}}\tmi{[0,t)}} \te{ if } v \in \neigh{B_j}\label{Main::CI}\\
\mu &= \law(\Xg).\label{Main::fixed}
\end{align}

\tr{\(\brate\) depends on the vertex \(v\), the admissible set \(A\), the branch set \(B_j\) and the symmetry \(\phi_j\). Figure out what parameters are useful to include and what are not in defining \(\brate\).}

\ind Equations \eqref{Main::local}, \eqref{Main::CI} and \eqref{Main::fixed} have a unique weak solution in law satisfying the results of \cite[theorem \ref{F-CI::CI}]{F}, and \(\mu = \law(\Xf\vind{A})\). (We don't yet have a general proof of uniqueness, just that only one of the solutions satisfies the conditional independence property outlined in \cite[section \ref{F-CI}]{F}).
\label{Main::Main}
\end{thms}

\section{Proof of Existence}
\label{Ex}

In this section, we prove that \(\law(\Xf\vind{A})\) is a weak solution to equations \eqref{Main::local}-\eqref{Main::fixed} in Theorem \ref{Main::Main}.

\ind Just like in the regular tree case, the idea of the proof is to convert \(\Xf\) into a point process and use a well-known filtration result for point processes.

\ind In this section, we assume \((G,\Xf)\) satisfy assumptions \ref{a::admissible} and \ref{a::padmin}. Recall that \(\proj\vpara{\cdot}\tpara{\cdot}(\cdot)\) is the projection mapping (see \cite[section \ref{F-not::p}]{F}). All graph operations (unless otherwise stated) are assumed to be in terms of \(G\). So if \(v \in A\setminus\inte{A}\), then \(\neigh{v}\) contains elements outside of \(A\).

\begin{defn}
Let \(U\subseteq V\) and suppose \(\Xg\) is a \(\sta^U\)-valued c\`adl\`ag stochastic process adapted to its own natural filtration. Define the marked point process \(\pmap(\Xg)\) as a random measure on \((0,\infty) \times \sta^U\) defined by,

\[\pmap(\Xg)(\{(\rt,\mark)\}) = \begin{cases}
1 &\te{ if } \Xg\tme{\rt} - \Xg\tme{\rt-} = \mark\\
0 &\te{ otherwise}
\end{cases}.\]

Similarly, for \(W \subseteq U\), \(\pmap\vpara{W}(\Xg) = \pmap\left(\proj\vpara{W}(\Xg)\right)\). For any \(v\in U\), \(\pmap\vpara{v}(\Xg)\) is a random measure on \((0,\infty) \times \sta\) given by,

\[\pmap\vpara{v}(\Xg)(\{(\rt,\mark)\}) = \begin{cases}
1 &\te{ if } \Xg\vind{v}\tme{\rt} - \Xg\vind{v}\tme{\rt-} = \mark\\
0 &\te{ otherwise}
\end{cases},\]

and

\[\pmap\vpara{v}(\Xg)(\{(\rt,\mark): \Xg\vind{v}\tme{\rt} - \Xg\vind{v}\tme{\rt-} \neq \mark\}) = 0.\]

Finally, for any \(T\in (0,\infty)\), \(\pmap\tpara{T}(\Xg) = \pmap(\Xg)|_{\ms{B}\left((0,T]\times\sta^U\right)}\). \(\pmap\vpara{W}\tpara{T}(\Xg)\) and \(\pmap\vpara{v}\tpara{T}(\Xg)\) are defined in a similar fashion.
\label{Ex::pmap}
\end{defn}

\ind \tr{revise assumption \ref{Ex::Eassu}. Make it as simple as possible for lemma \ref{Ex::leftmod} to hold. I only use this assumption for lemma \ref{Ex::leftmod}}

\begin{assu}
Define the following variables and assume the following:

\begin{enumerate}[(a)]
\item Define \(G = (V,E,\root) \in \Gs\).

\item Define \(A \subseteq U\subseteq V\) and \(A\) is finite.

\item Define \(\Xg \in \cad\vpara{U}\).

\item Assume \(\pmap\vpara{v}(\Xg)\) has a \(\Xg\)-predictable intensity \(\ratee\vpara{v}\) for all \(v \in U\).

\item Assume \(\ratee\vpara{v}\tmestpro{t}{i}{\Xg} \leq \jumpibd{i}{t}\).

\item Define the sequence of measurable mappings \(\{f_t: \cad\vpara{A}\tpara{t-}\times \sta \ra\mb{R}^+:t \in \mb{R}^+\}\).

\item Assume \(t \mapsto f_t(\xf,i)\) is left continuous for all \(\xf \in \cad\vpara{A}\) and continuous at all continuity points of \(\xf\).

\item Define a family of finite constants \(\{\const\sttpara{i,t}: i \in \sta,t\in \mb{R}^+\}\). Define \(\const\tpara{t} \defeq \sum_{i\in\sta}\Sm(\{i\})\const\sttpara{i}{t} < \infty\).

\item Assume \(f_t(\cdot,i) \leq \const\sttpara{i}{t}\).

\item Assume the continuous part of \(t \mapsto f_t(\cdot,i)\) is uniformly \(\const\tpara{T}\)-Lipschitz on \([0,T)\) for all \(T < \infty\).
\end{enumerate}
%Suppose \(G \in \Gs\). Let \(A \subseteq U \subseteq V\), and assume \(A\) is finite. Let \(\Xg \in \cad\vpara{U}\), and for all \(v \in U\), \(\pmap\vpara{v}(\Xg)\) has a \(\Xg\)-predictable intensity \(\ratee\vpara{v}\) such that \(\ratee\vpara{v}\tmepro{t}{\Xg}{} \leq \jumpibd{i}{t}\). Define the mapping \(f_t: \cad\vpara{A}\tpara{t-}\times\sta \ra \mb{R}^+\). There exists a sequence of constants \(\{\const\sttpara{i}{t}:i \in \sta,t \in \mb{R}^+\}\) that are non-decreasing in \(t\) and satisfy
%
%\[\sum_{i \in \sta}\Sm(\{i\})\const\sttpara{i}{t} \defeq \const\tpara{t} < \infty\]
%
%such that \(f_t(\cdot,i)\) is bounded from above by \(\const\sttpara{i}{t}\) and the continuous part of \(t \mapsto f_t(\Xg\vind{A},i)\) is uniformly \(\const\tpara{T}\)-Lipschitz on \([0,T)\) for all \(T < \infty\). \tr{I hope it's clear. By uniformly locally Lipschitz, I mean that it's locally-Lipschitz with respect to \(t\), and the Lipschitz coefficient has a non-random upper bound.} Finally, \(t \mapsto f_t(\Xg\vind{A},i)\) is left-continuous and continuous at all continuity points of \(\Xg\vind{A}\).
\label{Ex::Eassu}
\end{assu}


\begin{lem}
Let \(\rp\) be an \(\F\)-adapted marked point process with \(\F\)-predictable intensity \(\ratee\) with respect to the reference measure \(\Sm\) on its mark space. For all \(t \in [0,\infty)\), let \(\sigma(\rp_{t}) \subseteq \alt{\F}_{t}\subset \F_{t}\) define a subfiltration of \(\F\) containing the history of \(\rp\). If there exists an \(\ell\times \pr\)-almost sure left-continuous modification of \(\cratee(t,\mark) := \ex{\ratee(t,\mark)|\alt{\F}_{t-}}\) with respect to \(t\), then \(\cratee\) is the \(\alt{\F}\)-predictable intensity of \(\rp\). 
\label{Ex::filtering}
\end{lem}

\begin{proof}
This is a restatement of \cite[theorem 14.3.III]{DalVer08}.
\end{proof}

Now we need a simple method to know when the conditional expectation has a left-continuous modification. The following lemma, although a technical lemma, may be more broadly useful. It is also later applied in the proof of uniqueness.

\ind \tr{Revise and simplify the statement lemma \ref{Ex::leftmod} as much as possible.}
\begin{lem}
Suppose Assumption \ref{Ex::Eassu} holds. Let \(\mm = \law(\Xg)\) and \(W\subseteq A \subseteq U\subseteq V\). Let \(W'\subseteq A\) be such that there exists a bijection \(\phi:W' \ra W\). For any \(i \in \sta\), let

\[\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{} \defeq \exmu{\Xh\sim \mm\vpara{A}}{f_t(\Xh\tmi{[0,t)},i)|\Xh\vind{W'}\tmi{[0,t)} = \Xg\vind{\phi(W')}\tmi{[0,t)} = \Xg\vind{W}\tmi{[0,t)}}.\]

\tr{Assume the regular conditional probability of \(\mm\vpara{A}\) with respect to \(\Xh\vind{W'}\tmi{[0,t)} = \Xg\vind{W}\tmi{[0,t)}\) is almost surely well-defined.} Then \(\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{}\) has an almost surely left-continuous modification on \(\mb{R}^+\) with respect to \(t\) for every \(\ell\)-almost every \(i \in \sta\), where \(\ell\) is the reference measure on \(\sta\) (see \cite[section \ref{F-not::p}]{F}). Furthermore, \(\|\grate\stpara{i}\tmepro{\cdot}{\cdot}{}\|\tpara{T-} \leq \const\sttpara{i}{T}\), \(t\mapsto\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{}\) is a.s. continuous at all continuity points of \(\Xg\vind{W}\), and the continuous part of \(t\mapsto\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{}\) is locally Lipschitz with Lipschitz coefficient \(\const\sttpara{i}{T}\left(1 + 2|A|\jumpbd{T}e^{T|A|\jumpbd{T}}\right)\) on \([0,T]\).
\label{Ex::leftmod}
\end{lem}

\tr{This lemma is applied in the proof of existence. It is also applied in lemmas \ref{Uq::marg} and \ref{Uq::marg2}.}

\ind The proof is shown after the proof of lemma \ref{Ex::bddvar}. To prove this, we use a result from a website (see \cite[section \ref{F-not::p}]{F}) which can be used to prove the existence of a left-continuous modification of \(\ratee\vpara{v}\tpara{t}(i)\) in lemma \ref{Ex::leftmod}.

\begin{defn}
A set \(\evnt\) is called elementary with respect to a filtration \(\{\F\tpara{t}\}\) if it is a finite union of sets of the form \((s,t]\times \alt{\evnt}\) where \(\alt{\evnt} \in \F\tpara{s}\).
\label{Ex::elementary}
\end{defn}

The notion of an elementary set gives us a useful set of test sets to prove the existence of a left-continuous modification. 

\begin{lem}
Let \(\Xf\tme{t}\) be a stochastic process that is left continuous in probability and such that \(\sup_{\evnt\te{ elementary}}\ex{\int_0^T \mb{I}_\evnt\,d\Xf} < \infty\) for all \(T < \infty\). Then there exists a left-continuous modification of \(\Xf\).
\label{Ex::leftmodgen}
\end{lem}
\begin{proof}
The website Almost Sure (url: https://almostsure.wordpress.com/2009/12/18/cadlag-modifications/) has a statement of a similar result along with a partial proof. Completing the proof and adapting it to left-continuous modifications instead of c\`adl\`ag functions is simple. I have a full proof written up elsewhere, but I haven't included it here because it is virtually identical to the original proof provided in the link above.
\end{proof}

So, to prove lemma \ref{Ex::leftmod}, it suffices to prove that \(\grate\stpara{i}\) is left-continuous in probability and has bounded variance in expectation. We start with proving that it is left-continuous in probability.

\begin{lem}
Let \(\Xg,\mm,\ratee\) and \(f_t\) satisfy the conditions of Assumption \ref{Ex::Eassu}. Let \(\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{}\) be defined as in Lemma \ref{Ex::leftmod}. Then \(\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{}\) is left-continuous in probability for \(i \in \sta\setminus\{0\}\). That is, for every \(t \in (0,T]\), \(i \in \sta\) and \(\ep > 0\),

\[\lim_{s \searrow 0}\pr\mpara{\mm}\left(|\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{}- \grate\stpara{i}\tmepro{t-s}{\Xg\vind{W}}{}| > \ep\right) = 0.\]

Furthermore, suppose \(0 < s < t < T < \infty\). Then there exists a non-random constant \(\alt{\const}\sttpara{i}{T}\) such that,

\begin{equation}
\mb{I}_{\Xg\vind{W}\tmi{[t-s,t)} \equiv \Xg\vind{W}\tme{(t-s)-}}\left|\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{}- \grate\stpara{i}\tmepro{t-s}{\Xg\vind{W}}{}\right| < s\alt{\const}\sttpara{i}{T} \te{ almost surely}.
\label{Ex::ptwslip}
\end{equation}

\label{Ex::pleft}
\end{lem}
\begin{proof}
Fix \(T < \infty\), \(t \in (0,T)\) and \(0 < s < t\). Let \(x \in \cad\vpara{W}\). Suppose that \(s\) is sufficiently small so that \(\xf\tmi{[t-s,t)} \equiv \xf\tme{(t-s)-}\). Because \(\xf\) is a c\`adl\`ag mapping taking values in a countable space equipped with the discrete topology, there always exist \(s\) small enough for this to be true.

\ind Define,

\[\evnt\tspara{s}{t} \defeq \{\xg \in \cad\vpara{A}: \xg\tmi{[t-s,t)} \equiv \xg\tme{(t-s)-}\}.\]

For \(Z \sim \mm\vpara{A}\), I will write \(\evnt\tspara{s}{t}\) as a shorthand for the event that \(Z \in \evnt\tspara{s}{t}\). Before starting the proof, we begin by establishing some inequalities.

\begin{itemize}
\item We can bound the probability of \(\evnt\tspara{s}{t}\):

\begin{equation}
\pr\mpara{\mm\vpara{A}}(\evnt\tspara{s}{t}) \geq \exp\left(-s|A|\jumpbd{T}\right)
\label{Ex::evntbd}
\end{equation}

Justification: by \cite[Exercise 14.7.I]{DalVer08}, there exists a Poisson process of rate \(|A|\jumpbd{T}\) such that all discontinuities of \(\Xg\vind{A}\tmi{[0,T)}\) coincide with events of the Poisson process (although the reverse is generally false). Use that coupling to get this estimate.

\item 

\begin{align}
\big|\exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t}(\Xh,i)\middle|\evnt\tspara{s}{t},\Xh\vind{W'}\tmi{[0,t)} = \xf\tmi{[0,t)}}& - \exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t-s}(\Xh,i)\middle|\evnt\tspara{s}{t},\Xh\vind{W'}\tmi{[0,t)} = \xf\tmi{[0,t)}}\big|\nonumber \\
&= \left|\exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t}(\Xh,i) - f\tpara{t-s}(\Xh,i)\middle|\evnt\tspara{s}{t},\Xh\vind{W'}\tmi{[0,t)} = \xf\tmi{[0,t)}}\right|\nonumber\\
& \leq \exmu{\Xh \sim\mm\vpara{A}}{|f\tpara{t}(\Xh,i) - f\tpara{t-s}(\Xh,i)|\middle|\evnt\tspara{s}{t},\Xh\vind{W'}\tmi{[0,t)} = \xf\tmi{[0,t)}}\nonumber\\
&\os{\te{assumption} \ref{Ex::Eassu}}{\leq} \const\sttpara{i}{T}s.
\label{Ex::lipft}
\end{align}

\item Notice that \(\{\evnt\tspara{s}{t},\Xh\vind{W'}\tmi{[0,t)} = \xf\tmi{[0,t)}\} = \{\evnt\tspara{s}{t},\Xh\vind{W'}\tmi{[0,t-s)} = \xf\tmi{[0,t-s)}\}\).

\begin{align*}
\exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t-s}(\Xh,i)\middle|\evnt\tspara{s}{t},\Xh\vind{W'}\tmi{[0,t)} = \xf\tmi{[0,t)}} &= \exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t-s}(\Xh,i)\middle|\evnt\tspara{s}{t},\Xh\vind{W'}\tmi{[0,t-s)} = \xf\tmi{[0,t-s)}}\\
&\os{\te{ineq. }\eqref{Ex::evntbd}}{=}\frac{\exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t-s}(\Xh,i)\mb{I}_{\evnt\tspara{s}{t}}\middle|\Xh\vind{W'}\tmi{[0,t-s)} = \xf\tmi{[0,t-s)}}}{\pr\mpara{\mm\vpara{A}}\left(\evnt\tspara{s}{t}\right)}
\end{align*}

Let \(\poiss\) be the Poisson process used in the coupling described in the justification of equation \eqref{Ex::evntbd}. Then \(\poiss\tmi{[t-s,t)}\) is independent of \(\Xh\vind{W'}\tmi{[0,t-s)}\), so

\begin{align*}
\frac{\exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t-s}(\Xh,i)\mb{I}_{\evnt\tspara{s}{t}}\middle|\Xh\vind{W'}\tmi{[0,t-s)} = \xf\tmi{[0,t-s)}}}{\pr\mpara{\mm\vpara{A}}\left(\evnt\tspara{s}{t}\right)} &\leq \frac{\exmu{\Xh\sim\mm\vpara{A}}{f\tpara{t-s}(\Xh,i)\middle|\Xh\vind{W'}\tmi{[0,t-s)} = \xf\tmi{[0,t-s)}}}{\exp\left(-s|A|\jumpbd{T}\right)}\\
&= \frac{\grate\stpara{i}\tmepro{t-s}{\xf}{}}{\exp\left(-s|A|\jumpbd{T}\right)}.
\end{align*}

and,

\begin{align*}
&\frac{\exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t-s}(\Xh,i)\mb{I}_{\evnt\tspara{s}{t}}\middle|\Xh\vind{W'}\tmi{[0,t-s)} = \xf\tmi{[0,t-s)}}}{\pr\mpara{\mm\vpara{A}}\left(\evnt\tspara{s}{t}\right)} \\
&\hspace{48 pt}\geq \frac{\pr(\poiss\tmi{[t-s,t)} = 0)\exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t-s}(\Xh,i)\middle|\Xh\vind{W'}\tmi{[0,t-s)} = \xf\tmi{[0,t-s)}}}{\pr\mpara{\mm\vpara{A}}\left(\evnt\tspara{s}{t}\right)}\\
&\hspace{48 pt} \geq \exp\left(-s|A|\jumpbd{T}\right)\grate\stpara{i}\tmepro{t-s}{\xf}{}.
\end{align*}

Thus,

\begin{equation}
e^{-s|A|\jumpbd{T}}\grate\stpara{i}\tmepro{t-s}{\xf}{} \leq \exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t-s}(\Xh,i)\middle|\evnt\tspara{s}{t},\Xh\vind{W'}\tmi{[0,t)} = \xf\tmi{[0,t)}} \leq \frac{\grate\stpara{i}\tmepro{t-s}{\xf}{}}{e^{-s|A|\jumpbd{T}}}.
\label{Ex::cdbd}
\end{equation}
\end{itemize}

First, we compute \(\grate\stpara{i}\tmepro{t}{\xf}{}\):

\begin{align*}
\grate\stpara{i}\tmepro{t}{\xf}{} &= \exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t}(\Xh,i)\middle|\evnt\tspara{s}{t},\Xh\vind{W'}\tmi{[0,t)} = \xf\tmi{[0,t)}}\pr(\evnt\tspara{s}{t})\\
&\hspace{24 pt} + \exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t}(\Xh,i)\middle|\evnt\tspara{s}{t}^c,\Xh\vind{W'}\tmi{[0,t)} = \xf\tmi{[0,t)}}\pr(\evnt\tspara{s}{t}^c).
\end{align*}

Then by equation \eqref{Ex::evntbd} and assumption \ref{Ex::Eassu},

\[e^{-s|A|\jumpbd{T}}\exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t}(\Xh,i)\middle|\evnt\tspara{s}{t},\Xh\vind{W'}\tmi{[0,t)} = \xf\tmi{[0,t)}} \leq \grate\stpara{i}\tmepro{t}{\xf}{}\]
\[\leq \exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t}(\Xh,i)\middle|\evnt\tspara{s}{t},\Xh\vind{W'}\tmi{[0,t)} = \xf\tmi{[0,t)}} + \const\sttpara{i}{T}(1 - e^{-s|A|\jumpbd{T}}).\]

By equation \eqref{Ex::lipft},

\[e^{-s|A|\jumpbd{T}}\exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t-s}(\Xh,i)\middle|\evnt\tspara{s}{t},\Xh\vind{W'}\tmi{[0,t)} = \xf\tmi{[0,t)}} - \const\sttpara{i}{T}se^{-s|A|\jumpbd{T}} \leq \grate\stpara{i}\tmepro{t}{\xf}{}\]
\[\leq \exmu{\Xh \sim\mm\vpara{A}}{f\tpara{t-s}(\Xh,i)\middle|\evnt\tspara{s}{t},\Xh\vind{W'}\tmi{[0,t)} = \xf\tmi{[0,t)}} + \const\sttpara{i}{T}(1 + s - e^{-s|A|\jumpbd{T}}).\]

By equation \eqref{Ex::cdbd},

\[e^{-2s|A|\jumpbd{T}}\grate\stpara{i}\tmepro{t-s}{\xf}{} - \const\sttpara{i}{T}se^{-s|A|\jumpbd{T}} \leq \grate\stpara{i}\tmepro{t}{\xf}{}\]
\[\leq e^{s|A|\jumpbd{T}}\grate\stpara{i}\tmepro{t-s}{\xf}{}+ \const\sttpara{i}{T}(1 + s - e^{-s|A|\jumpbd{T}}).\]

This simplifies to,

\[(e^{-2s|A|\jumpbd{T}}-1)\grate\stpara{i}\tmepro{t-s}{\xf}{} - \const\sttpara{i}{T}se^{-s|A|\jumpbd{T}} \leq \grate\stpara{i}\tmepro{t}{\xf}{} - \grate\stpara{i}\tmepro{t-s}{\xf}{}\]
\[\leq (e^{s|A|\jumpbd{T}}-1)\grate\stpara{i}\tmepro{t-s}{\xf}{}+ \const\sttpara{i}{T}(1 + s - e^{-s|A|\jumpbd{T}}).\]


Since \(f\tpara{t-s}(\xf,i) \leq \const\sttpara{i}{T}\), it follows that \(\grate\stpara{i}\tmepro{t-s}{\xf}{}\leq \const\sttpara{i}{T}\). This implies,

\begin{equation}
\const\sttpara{i}{T}(1 - se^{-s|A|\jumpbd{T}}-e^{-2s|A|\jumpbd{T}}) \leq \grate\stpara{i}\tmepro{t}{\xf}{} - \grate\stpara{i}\tmepro{t-s}{\xf}{} \leq \const\sttpara{i}{T}(e^{s|A|\jumpbd{T}} + s - e^{-s|A|\jumpbd{T}})
\label{Ex::lipbd}
\end{equation}

Now, notice that for \(s \in (0,T)\),

\begin{align*}
\frac{|1 - se^{-s|A|\jumpbd{T}}-e^{-2s|A|\jumpbd{T}}|}{s} & \leq e^{-s|A|\jumpbd{T}} + \frac{1 - e^{-2s|A|\jumpbd{T}}}{s}\\
&\leq e^{-s|A|\jumpbd{T}} + \frac{2s|A|\jumpbd{T}}{s}\\
&\leq 1 + 2|A|\jumpbd{T}.
\end{align*}

Similarly,

\begin{align*}
\frac{|e^{s|A|\jumpbd{T}} + s - e^{-s|A|\jumpbd{T}}|}{s} &\leq 1 + e^{s|A|\jumpbd{T}}\frac{1 - e^{-2s|A|\jumpbd{T}}}{s}\\
&\leq 1 + 2|A|\jumpbd{T}e^{T|A|\jumpbd{T}}.
\end{align*}

Thus, equation \eqref{Ex::ptwslip} holds for,

\begin{equation}
\alt{\const}\sttpara{i}{T} = \const\sttpara{i}{T}\left(1 + 2|A|\jumpbd{T}e^{T|A|\jumpbd{T}}\right).
\label{Ex::altconst}
\end{equation}


\ind To prove that \(\grate\stpara{i}\) is left-continuous in probability, we must also consider jumps. 

\begin{align}
\ex{|\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{} - \grate\stpara{i}\tmepro{t-s}{\Xg\vind{W}}{}|}&\leq \alt{\const}\sttpara{i}{T}|s| + \ex{\mb{I}_{\Xg\vind{W}\tmi{[t-s,t)} \not\equiv \Xg\vind{W}\tme{(t-s)-}}|\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{} - \grate\stpara{i}\tmepro{t-s}{\Xg\vind{W}}{}|}\nonumber\\
&\leq \alt{\const}\sttpara{i}{T}|s| + 2\const\sttpara{i}{T}\pr\left(\Xg\vind{W}\tmi{[t-s,t)} \equiv \Xg\vind{W}\tme{(t-s)-}\right)\nonumber\\
&\leq \alt{\const}\sttpara{i}{T}|s| + 2\const\sttpara{i}{T}\left(1 - e^{-s|W|\jumpbd{T}}\right)\nonumber\\
&\leq s\left(\alt{\const}\sttpara{i}{T} + 2\const\sttpara{i}{T}|W|\jumpbd{T}\right)
\label{Ex::expectbd}
\end{align}

By the Chebyshev inequality, \(t \mapsto \grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{}\) is left-continuous in probability.
\end{proof}

Now we prove that in expectation, \(\grate\stpara{i}\) is a bounded variation process.

\begin{lem}
Suppose Assumption \ref{Ex::Eassu} holds. Let \(\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{}\) be defined as in Lemma \ref{Ex::leftmod}. Then, 

\[\sup_{\typset\te{ elementary}} \ex{\int_0^T \mb{I}_\typset\,d\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{}} < \infty.\]
\label{Ex::bddvar}
\end{lem}

\begin{proof}
Any elementary set can be expressed in the form

\[\typset = \bigcup_{k = 1}^n [s\indx{k},t\indx{k})\times \typset\indx{k},\]

where \(\{[s\indx{k},t\indx{k}):k=1,\dots,n\}\) are disjoint. If \(s\indx{k} = t\indx{k} = 0\), then \([s\indx{k},t\indx{k}) = \{0\}\) and \(\typset\indx{k}\) are all \(\sigma\left(\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{}:t\in [0,s\indx{k}]\right)\)-measurable. By lemma \ref{Ex::pleft}, for any \(T < \infty\), there exists a \(\ov{\const}\sttpara{i}{T}\) such that for any \(0 < s < t < T\),

\[\ex{|\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{} - \grate\stpara{i}\tmepro{s}{\Xg\vind{W}}{}|} \leq \ov{\const}\sttpara{i}{T}|t-s|.\]

Let \(\typset = \bigcup_{k = 1}^n [s\indx{k},t\indx{k})\times \typset\indx{k}\) be an arbitrary elementary set. Assume without loss of generality that \(\{[s\indx{k},t\indx{k}):k = 1,\dots,n\}\) are disjoint. Then,

\begin{align*}
\ex{\int_0^T \mb{I}_A\,d\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{}} &\leq \sum_{k=1}^n \ex{|\grate\stpara{i}\tmepro{t\indx{k}}{\Xg\vind{W}}{} - \grate\stpara{i}\tmepro{s\indx{k}}{\Xg\vind{W}}{}|}\\
&\leq \ov{\const}\sttpara{i}{T}\sum_{k=1}^n |t\indx{k} - s\indx{k}| \leq \ov{\const}\sttpara{i}{T}|T| < \infty.
\end{align*} 
\end{proof}

We can now prove the lemma \ref{Ex::leftmod}.

\begin{proof}[Proof of lemma \ref{Ex::leftmod}]
By lemmas \ref{Ex::pleft} and \ref{Ex::bddvar}, \(\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{}\) satisfies the conditions of lemma \ref{Ex::leftmodgen}. Thus a left-continuous modification of \(\grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{}\) exists.

\ind \(\grate\stpara{i}\) is bounded from above by \(\const\sttpara{i}{T}\) on \([0,T]\) because it is the conditional expectation of a mapping \(f_\cdot\) which is also bounded from above by \(\const\sttpara{i}{T}\).

\ind Let \(\xf\in \cad\vpara{W}\) be continuous on \([t,t+s)\). Again, notice that if \(t\) is a point of continuity for \(\xf\), then there exists an \(s\) sufficiently small such that this is true. Then by lemma \ref{Ex::pleft},

\[\left|\grate\stpara{i}\tmepro{t+s}{\xf}{} - \grate\stpara{i}\tmepro{t}{\xf}{}\right| < s\alt{\const}\sttpara{i}{T}\]

Because \(\grate\stpara{i}\) is left-continuous, we can take a liminf over a small, dense set and apply continuity to get, \tr{either remove this sentence or write out the liminf explicitly}

\[\pr\left(\left|\grate\stpara{i}\tmepro{t+s}{\Xg\vind{W}}{} - \grate\stpara{i}\tmepro{t}{\Xg\vind{W}}{}\right| < s\alt{\const}\sttpara{i}{T} \te{ for all } s > 0\te{ suff. small}\right) = 1.\]

Thus, \(\grate\stpara{i}\) is almost surely continuous at \(t\). Furthermore, for any \(0 < s < t < T\) and for \(\mm\vpara{W}-a.s.\) \(\xf\), let \(s= s\it{0} < s\it{1} < s\it{2} < \cdots < s\it{N(\xf)} < s\it{N(\xf)+1} = t\) enumerate the bounds of \([s,t]\) and the discontinuities of \(\xf\). Then, 

\begin{align*}
\left|\grate\stpara{i}\tmepro{t+s}{\xf}{} - \grate\stpara{i}\tmepro{t}{\xf}{} - \sum_{u \in [s,t)} \delt\grate\stpara{i}\tmepro{u}{\xf}{} \right| & \leq \sum_{k=0}^{N(\xf)} \left|\grate\stpara{i}\tmepro{s\it{k+1}}{\xf}{} - \grate\stpara{i}\tmepro{s\it{k}}{\xf}{}\right| \leq \alt{\const}\sttpara{i}{T}|t - s|.
\end{align*}

Thus the continuous part of \(\grate\stpara{i}\) is almost surely uniformly locally Lipschitz.
\end{proof}


\begin{proof}[Proof of Theorem \ref{Main::Main} Existence]

Let \((G,\Xf) \in \Gs\sp{\cad}\) satisfy assumptions \ref{a::admissible} and \ref{a::padmin}. Let \(\ev{v} \in \sta^V\) denote the standard basis vector of \(\sta^V\). That is, \(\ev{v}\vind{u} = \mb{I}_{u=v}\). By \cite[theorem \ref{F-wp::wp}]{F} \tr{(could just assume there exists a weak solution) (no need. I use \cite[assumptions \ref{F-a::bddinit} and \ref{F-a::bddr}]{F} elsewhere, so the theorem would apply anyway)}, \(\Xf\) is the unique solution to,

\[\Xf\tme{t} = \Xf\tme{0} + \sum_{v \in V}\ev{v}\int_\sta\int_{(0,t]\times (0,\infty)} i\mb{I}_{r \leq \rate\stpara{i}\tmepro{s}{\Xf\vind{\cl{v}}}{}}\,\poiss\poissv{v}(dr,ds,di).\]

Then,

\[\left(\proj\vpara{A}(\Xf)\right)\tme{t} = \left(\proj\vpara{A}(\Xf)\right)\tme{0} + \sum_{v\in A}\ev{v}\int_\sta\int_{(0,t]\times (0,\infty)} i\mb{I}_{r \leq \rate\stpara{i}\tmepro{s}{\Xf\vind{\cl{v}}}{}}\,\poiss\poissv{v}(dr,ds,di).\]

By definition, \(\pmap\left(\proj\vpara{A}(\Xf)\right) = \pmap\vpara{A}(\Xf)\). Let \(\rp = \pmap\vpara{A}(\Xf)\). By \cite[Exercise 14.7.1]{DalVer08}, \(\rp\) has \(\Xf\)-predictable intensity \(\ratee\) given by,

\[\ratee(\rt,\mark) = \sum_{v \in A} \sum_{i \in \sta} \mb{I}_{\mark = i\ev{v}} \rate\stpara{i}\tmepro{\rt}{\Xf\vind{v}}{\Xf\vind{\neigh{v}}}.\]

However, for \(v \in A\setminus \inte{A}\), \(\rate\stpara{i}\tmepro{\rt}{\Xf\vind{v}}{\Xf\vind{\neigh{v}}}\) is not \(\Xf\vind{A}\)-measurable. Let's propose an alternate rate given by,

\begin{equation}
\cratee(\rt,\mark) = \sum_{v \in \inte{A}}\sum_{i\in \sta} \mb{I}_{\mark = i\ev{v}}\rate\stpara{i}\tmepro{\rt}{\Xf\vind{v}}{\Xf\vind{\gneigh{G}{v}}} + \sum_{v \in A\setminus \inte{A}}\sum_{i \in \sta} \mb{I}_{\mark = i\ev{v}}\ex{\rate\stpara{i}\tmepro{\rt}{\Xf\vind{v}}{\Xf\vind{\gneigh{G}{v}}}\middle|\F\vpara{A}\tpara{\rt-}}.
\label{Ex::tempfiltrate}
\end{equation}

Notice that by lemma \ref{Ex::filtering}, if \(\alt{\ratee}\) has a \(\Sm\times \pr\)-a.s. left-continuous modification with respect to time, then it is the \(\F\vpara{A}\)-predictable rate of \(\rp\). For all \(i\in\sta\), \(\rate\stpara{i}\tme{\cdot}\) is almost surely left-continuous and bounded (assumptions \ref{a::lctr}, \cite[\ref{F-a::bddr}]{F}). Thus, it suffices to prove that \(\ex{\rate\stpara{i}\tmepro{\rt}{\Xf\vind{\cl{v}}}{}\middle|\F\vpara{A}\tpara{\rt-}}\) also has a left continuous modification for all \(i\in \sta\) and \(v \in A\setminus\inte{A}\).

\ind Fix some \(v \in A\setminus \inte{A}\). By assumption \ref{a::admissible}, there exists a unique \(j\) such that \(v \in \neigh{B_j}\). Recall that \(C_j = \neigh{A}\cap B_j\), and there exists a symmetry of \(\Xf\), \(\phi_j\) such that \(\phi_j(C_j\cup\dneigh{B_j}) \subseteq A\). By proposition \ref{a::simprop}, \(\Xf\vind{V} \deq \Xf\vind{\phi_j(V)}\). It should be clear that \(\cl{v} \subseteq C_j\cup\dneigh{B_j}\).

\ind Recalling that \(\m = \law(\Xf)\) and applying \cite[theorem \ref{F-CI::CI}]{F} (we may consider \(\rate\stpara{i}\tmepro{\rt}{\Xf\vind{\cl{v}}}{}\) as a \(\F\vpara{C_j\cup\dneigh{B_j}}\tpara{\rt-}\)-measurable random variable and apply \cite[lemma \ref{F-TL::Props}(e)]{F} from the main paper),

\begin{align*}
\exmu{\m}{\rate\stpara{i}\tmepro{\rt}{\Xf\vind{\cl{v}}}{}\middle|\F\vpara{A}\tpara{\rt-}} &=\exmu{\m}{\rate\stpara{i}\tmepro{\rt}{\Xf\vind{\cl{v}}}{}\middle|\F\vpara{A}\tpara{\rt-}}\\
&\os{\te{\cite[thm \ref{F-CI::CI}]{F}}}{=} \exmu{\m}{\rate\stpara{i}\tmepro{\rt}{\Xf\vind{\cl{v}}}{}\middle|\F\vpara{\dneigh{B_j}}\tpara{\rt-}}\\
&=\exmu{\Xg\sim \m}{\rate\stpara{i}\tmepro{\rt}{\Xg\vind{\cl{v}}}{}\middle|\Xg\vind{\dneigh{B_j}}\tmi{[0,\rt)} = \Xf\vind{\dneigh{B_j}}\tmi{[0,\rt)}}\\
&\os{\te{prop \ref{a::simprop}}}{=} \exmu{\Xg\sim \m}{\rate\stpara{i}\tmepro{\rt}{\Xg\vind{\phi_j(\cl{v})}}{}\middle|\Xg\vind{\phi_j(\dneigh{B_j})}\tmi{[0,\rt)} = \Xf\vind{\dneigh{B_j}}\tmi{[0,\rt)}}\\
&\os{\phi_j(v) \in \inte{A}}{=} \exmu{\Xg\sim \m}{\rate\stpara{i}\tmepro{\rt}{\Xg\vind{\phi_j(\cl{v})}}{}\middle|\Xg\vind{\phi_j(\dneigh{B_j})}\tmi{[0,\rt)} = \Xf\vind{\dneigh{B_j}}\tmi{[0,\rt)}}\\
\end{align*}

Notice that assumption \ref{Ex::Eassu} is satisfied:

\ind \tb{Full verification just to be careful. Notation from assumption is in green to avoid confusion.}

\begin{enumerate}[(a)]
\item \(\tg{G} = G\).

\item \(\tg{A} = A\), \(\tg{U} = V\).

\item \(\tg{Y} = \Xf\).

\item \(\tg{\ratee\vpara{v}(t,i,\Xg)} = \rate\stpara{i}\tmepro{t}{\Xf\vind{\cl{v}}}{}\).

\item See \cite[assumption \ref{F-a::bddr}]{F}.

\item \(\tg{f_t(\xf,i)} = \rate\stpara{i}\tmepro{t}{\xf\vind{\phi_j(\cl{v})}}{}\).

\item \(\tg{\const\sttpara{i}{t}} \defeq \jumpibd{i}{t}\).

\item See \cite[assumption \ref{F-a::bddr}]{F}.

\item See assumptions \ref{a::lctr} and \ref{a::liprt}.
\end{enumerate}

\tb{End verification.}

\ind Here \(W = \dneigh{B_j}\) and \(W' = \phi_j(\dneigh{B_j})\). The regular conditional distribution is almost surely well-defined because \(\phi_j\) is a symmetry of \(\Xf\), so the condition is almost surely a history that could occur with positive probability \tr{(clarify)}. Thus, by lemma \ref{Ex::leftmod}, \(\exmu{\m}{\rate\stpara{i}\tmepro{\rt}{\Xf\vind{\cl{v}}}{}\middle|\F\vpara{A}\tpara{\rt-}}\) has a left-continuous modification. Then \(\cratee\) must also have a left-continuous modification, and 

\[\cratee(\rt,\mark) = \sum_{v \in \inte{A}}\sum_{i\in \sta} \mb{I}_{\mark = i\ev{v}}\rate\stpara{i}\tmepro{\rt}{\Xf\vind{\cl{v}}}{} + \sum_j\sum_{v \in B_j}\sum_{i \in \sta} \mb{I}_{\mark = i\ev{v}}\exmu{\Xg\sim \m}{\rate\stpara{i}\tmepro{\rt}{\Xg\vind{\phi_j(\cl{v})}}{}\middle|\Xg\vind{\phi_j(\dneigh{B_j})}\tmi{[0,\rt)} = \Xf\vind{\dneigh{B_j}}\tmi{[0,\rt)}}.\]

Once again, by \cite[Exercise 14.7.1]{DalVer08}, the process \(\pmap^{-1}(\rp) \deq \proj\vpara{A}(\Xf)\), and can be written as a solution to the equations,

\[\Xg\vind{v}\tme{t} = \Xg\vind{v}\tme{0} + \begin{cases}
\int_\sta\int_{(0,t]\times (0,\infty)} i\mb{I}_{r \leq \rate\stpara{i}\tmepro{s}{\Xg\vind{\cl{v}}}{}}\,\poiss\poissv{v}(dr,ds,di) &\te{ if } v \in \inte{A}\\
\int_\sta\int_{(0,t]\times (0,\infty)} i\mb{I}_{r \leq \brate\vjpara{v}{B_j}\stpara{i}\tmepro{s}{\Xg}{}}\,\poiss\poissv{v}(dr,ds,di) &\te{ if } v \in \neigh{B_j}
\end{cases},\]

where

\[\brate\vjpara{v}{B_j}\stpara{i}\tmepro{t}{\xg}{} = \exmu{\Xg\sim \m}{\rate\stpara{i}\tmepro{t}{\Xg\vind{\phi_j(\cl{v})}}{}\middle|\Xg\vind{\phi_j(\dneigh{B_j})}\tmi{[0,t)} = \xg\vind{\dneigh{B_j}}\tmi{[0,t)}}\te{ if } v \in \neigh{B_j}.\]

\end{proof}

\section{Proof of Uniqueness}
\label{Uq}

Let \((G,\Xf\gind{G}) \in \Gs\sp{\cad}\) satisfy assumptions \ref{a::admissible} and \ref{a::padmin}. Assume \(G\) is non-random. Let \(\rate\) be defined by assumptions \cite[\ref{F-a::bddr},\ref{F-a::liprx}]{F}, \ref{a::liprt} and \ref{a::lctr}. Let \(\m = \law(\Xf\gind{G})\).

\ind Let \((\mm,\Xg)\) be a solution to the local equations (\eqref{Main::local}-\eqref{Main::fixed}). Assume that for every \(U,U' \subseteq A\) such that \(\{U,U',\dgneigh{G\vpara{A}}{U}\}\) is a partition of \(A\) and \(t \in [0,\infty)\),

\[\Xg\vind{U}\tmi{[0,t)} \perp \Xg\vind{U'}\tmi{[0,t)} |\Xg\vind{\dgneigh{G\vpara{A}}{U}}\tmi{[0,t)}.\]

Our approach to this proof will be to construct a measure \(\mm\vpara{V} \in \pmsr(\Gs\sp{\cad})\) such that \(\proj\psf\vpara{A}(\mm\vpara{V}) = \mm\). Then we will show that \(\mm\vpara{V} = \m\). 

\ind \tr{Insert explanation here. The gist is we need to understand the conditional distribution of each boundary set of \(A\) given it's double neighborhood inside \(A\). We can do this by studying the same conditional distribution in a symmetry that takes the set inside \(A\). To do that, we start by computing the marginals of the double neighborhood, and the whole set under the application of symmetry.}

\begin{lem}
For all \(j \in \{1,\dots,\psize\}\), \(\proj\psf\vpara{\phi_j(\dgneigh{G}{B_j})}(\mm)\) is equal in distribution to the unique strong solution to the following equation:

\begin{equation}
\Xh\vind{v}\tme{t} = \Xh\vind{v}\tme{0} + \begin{cases}
\int_\sta\int_{(0,t]\times (0,\infty)} i\mb{I}_{r \leq \bgrate\vjpara{v}{B_j}\stpara{i}\tmepro{s}{\Xh}{}}\,\poiss\poissv{v}(dr,ds,di)&\te{ if } v \in \phi_j(\dgneigh{G}{B_j})\cap \inte{A}\\
\int_\sta\int_{(0,t]\times (0,\infty)} i\mb{I}_{r \leq \bcrate\vjpara{v}{B_j}\stpara{i}\tmepro{s}{\Xh}{}}\,\poiss\poissv{v}(dr,ds,di)&\te{ if } v \in \phi_j(\dgneigh{G}{B_j})\cap\gneigh{G}{B_{j'}}
\end{cases}
\label{Uq::marg1eqn}
\end{equation}

where \(j' \in \{1,\dots,\psize\}\) is not necessarily distinct from \(j\), and

\begin{align}
\bgrate\vjpara{v}{B_j}\stpara{i}\tmepro{t}{\Xh}{} &\defeq \ex{\rate\stpara{i}\tmepro{t}{\Xh\vind{\cl{v}}}{}\middle|\Xh\vind{\phi_j(\dgneigh{G}{B_j})}\tmi{[0,t)}} \te{ if } v \in  \phi_j(\dgneigh{G}{B_j})\cap \inte{A} \label{Uq::brrt}\\
\bcrate\vjpara{v}{B_j}\stpara{i}\tmepro{t}{\Xh}{} &\defeq \ex{\brate\vjpara{v}{B_{j'}}\stpara{i}\tmepro{t}{\Xh}{}\middle| \Xh\vind{\phi_j(\dgneigh{G}{B_j})}\tmi{[0,t)}} \te{ if } v \in \phi_j(\dgneigh{G}{B_j})\cap\gneigh{G}{B_{j'}}\label{Uq::brcdrt}
\end{align}
\label{Uq::marg}
\end{lem}
\begin{proof}

Let \(\rp = \pmap(\Xg)\) where \(\Xg \sim \mm\). By a direct application of \cite[Exercise 14.7.1]{DalVer08}, \(\rp\vind{\phi_j(\dgneigh{G}{B_j})}\) has \(\Xg\)-intensity \(\ratee\) given by,

\begin{equation}
\ratee(\rt,\mark) = \sum_{v \in\phi_j(\dgneigh{G}{B_j})\cap\inte{A}} \sum_{i \in \sta} \mb{I}_{\mark = i\ev{v}} \rate\stpara{i}\tmepro{\rt}{\Xg\vind{\cl{v}}}{} + \sum_{j' = 1}^\psize\sum_{v \in \phi_j(\dgneigh{G}{B_j})\cap\gneigh{G}{B_j'}}\sum_{i\in \sta} \mb{I}_{\mark = i\ev{v}} \brate\vjpara{v}{B_{j'}}\stpara{i}\tmepro{\rt}{\Xg}{}.
\label{Uq::Xg-int}
\end{equation}

Consider the following candidate for the \(\Xg\vind{\phi_j(\dgneigh{G}{B_j})}\)-intensity of \(\rp\), 

\[\cratee(\rt,\mark) \defeq \exmu{\Xg \sim \mm}{\ratee(\rt,\mark)\middle|\Xg\vind{\phi_j(\dgneigh{G}{B_j})}\tmi{[0,\rt)}}.\]

By lemma \ref{Ex::filtering}, it \(\cratee\) is the intensity if it has a \(\pr\times\Sm\)-a.s. left-continuous modification with respect to \(\rt\). Since \(\ratee\) is a countable sum of elements of which finitely many (one) are nonzero for any given argument \((\rt,\mark)\), it suffices to prove that the conditional expectation of each element of equation \eqref{Uq::Xg-int} is also left continuous. Fix \(\mark \in \sta^A\).

\skipLine

\tb{Begin verification of lemma \ref{Ex::leftmod}:}

\skipLine

\begin{enumerate}[(a)]
\item \(\tg{G} = G\vpara{A}\).

\item \(\tg{A} = A = \tg{U} \subsetneq V\).

\item \(\tg{\Xg} = \Xg\).

\item \(\tg{\ratee\vpara{v}(t,i,\Xg)} = \ratee(t,i\ev{v})\).

\item \(\rate\stpara{i} \leq \jumpibd{i}{t}\) by \cite[assumption \ref{F-a::bddr}]{F}, and \(\brate\vjpara{v}{B_{j'}}\stpara{i}\) is a conditional expectation of \(\rate\stpara{i}\) so it is bounded by the same constant. Thus, if \(v \in \gbdry{G}{A}\), then \(\ratee\vpara{v}(t,i,\cdot) = \brate\vjpara{v}{B_{j'}}\stpara{i}(t,\cdot) \leq \jumpibd{i}{t}\). Similarly if \(v \in \inte{A}\), \(\ratee\vpara{v}(t,i,\cdot) = \rate\stpara{i}(t,\cdot) \leq \jumpibd{i}{t}\).

\item \(f_t = \ratee(t,\mark)\).

\item Set \(\const\sttpara{i}{t} \defeq \jumpibd{i}{t}(1 + 2|A|\jumpibd{i}{t}e^{t|A|\jumpibd{i}{t}})\).

\item See (e).

\item If \(u \in \inte{A}\), then this is true by assumptions \ref{a::lctr} and \ref{a::liprt}. If \(u \in \gbdry{G}{A}\), then this is true by lemma \ref{Ex::leftmod} and equation \eqref{Ex::altconst}.
\end{enumerate}

Lastly, the conditional expectation is well-defined by a well known result in probability theory.

\skipLine

\tb{End verification of lemma \ref{Ex::leftmod}:}

\skipLine

This leaves us with two cases.

\begin{description}
\item[Case 1: ] \(v \in \phi_j(\dgneigh{G}{B_j})\cap\inte{A}\).

In this case, fix \(i,v\) and \(\mark = i\ev{v}\).

\begin{align*}
\cratee(\rt,\mark) &= \exmu{\Xg\sim\mm}{\ratee(\rt,\mark)\middle|\Xg\vind{\phi_j(\dgneigh{G}{B_j})}\tmi{[0,\rt)}} = \exmu{\Xg\sim\mm}{\rate\stpara{i}\tmepro{\rt}{\Xg\vind{\cl{v}}}{}\middle|\Xg\vind{\phi_j(\dgneigh{G}{B_j})}\tmi{[0,\rt)}} = \bgrate\vjpara{v}{B_j}\tmepro{t}{\Xg}{}.
\end{align*}

\skipLine

\item[Case 2: ] \(v \in \phi_j(\dgneigh{G}{B_j})\cap\gneigh{G}{B_{j'}}\) where \(j,j'\) are not necessarily distinct.

In this case, fix \(i,v\) and \(\mark = i\ev{v}\).

\begin{align*}
\cratee(\rt,\mark) &= \exmu{\Xg\sim\mm}{\ratee(\rt,\mark)\middle|\Xg\vind{\phi_j(\dgneigh{G}{B_j})}\tmi{[0,\rt)}} = \exmu{\Xg\sim\mm}{\brate\vjpara{v}{B_{j'}}\stpara{i}\tmepro{\rt}{\Xg}{}\middle|\Xg\vind{\phi_j(\dgneigh{G}{B_j})}\tmi{[0,\rt)}} = \bcrate\vjpara{v}{B_j}\stpara{i}\tmepro{\rt}{\Xg}{}.
\end{align*}


\end{description}
\end{proof}

Now we compute the marginal distribution of \(C_j\cap\dgneigh{G}{B_j}\) under symmetry. 
%However, before doing that, we need a graph theoretic result:
%
%\begin{lem}
%For all \(j \in \{1,\dots,\psize\}\), \(\phi_j(C_j)\cap \inte{A} = \emptyset\).
%\label{Uq::symbdry}
%\end{lem}
%\begin{proof}
%Fix \(j\). By assumption \ref{a::admissible}, there exists a \(j'\) such that \(\phi_j(C_{j'}\indx{1}) = C_j\) for some \(C_{j'}\indx{1}\) such that \(C_{j'}\indx{1} \subseteq B_j\). In fact, \(C_{j'}\indx{1} \subseteq \gneigh{C_j}\).
%
%\ind Then, since \(\phi_j(C_{j'}\indx{1}) = C_j\), we can conclude that \(\gneigh{G}{\phi_j(C_j)} \supseteq \phi_j 
%\end{proof}

\begin{lem}
For all \(j \in \{1,\dots,\psize\}\), \(\proj\psf\vpara{\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)}(\mm)\) is equal in distribution to the unique strong solution to the following equation:

\begin{equation}
\Xh\vind{v}\tme{t} = \Xh\vind{v}\tme{0} + \begin{cases}
\int_\sta\int_{(0,t]\times(0,\infty)} i\mb{I}_{r \leq \brate\vjpara{v}{B_{j'}}\stpara{i}\tmepro{s}{\Xh}{}}\,\poiss\poissv{v}(dr,ds,di).\te{ if } v \in \phi_j(C_j)\cap \gneigh{G}{B_{j'}}\\
\int_\sta\int_{(0,t]\times(0,\infty)} i\mb{I}_{r \leq \rate\stpara{i}\tmepro{s}{\Xh\vind{\cl{v}}}{}}\,\poiss\poissv{v}(dr,ds,di).\te{ if } v \in \phi_j(\gneigh{G}{B_j})\\
\int_\sta\int_{(0,t]\times(0,\infty)} i\mb{I}_{r \leq \bgrate\vjpara{v}{B_j}\stpara{i}\tmepro{s}{\Xh}{}}\,\poiss\poissv{v}(dr,ds,di).\te{ if } v \in \phi_j(\dgneigh{G}{B_j}\setminus\gneigh{G}{B_j})\cap\inte{A}\\
\int_\sta\int_{(0,t]\times(0,\infty)} i\mb{I}_{r \leq \bcrate\vjpara{v}{B_j}\stpara{i}\tmepro{s}{\Xh}{}}\,\poiss\poissv{v}(dr,ds,di).\te{ if } v \in \phi_j(\dgneigh{G}{B_j}\setminus\gneigh{G}{B_j})\cap\gneigh{G}{B_{j'}}\\
\end{cases}
\label{Uq::marg2eqn}
\end{equation}

where \(\rate,\brate,\bgrate\) and \(\bcrate\) are as defined in lemma \ref{Uq::marg}, theorem \ref{Main::Main} and \cite[assumption \ref{F-a::bddr}]{F}.
\label{Uq::marg2}
\end{lem}
\begin{proof}
The proof is similar to the proof of lemma \ref{Uq::marg}. Only there are more cases. Once again, let \(\Xg \sim \mm\), \(\rp = \pmap(\Xg)\). Then by \cite[Exercise 14.7.1]{DalVer08}, \(\rp\vind{\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)}\) has \(\Xg\)-intensity \(\ratee\) given by,

\begin{equation}
\ratee(\rt,\mark) = \sum_{v \in\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)\cap\inte{A}} \sum_{i \in \sta} \mb{I}_{\mark = i\ev{v}} \rate\stpara{i}\tmepro{\rt}{\Xg\vind{\cl{v}}}{} + \sum_{j' = 1}^\psize\sum_{v \in \phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)\cap\gneigh{G}{B_{j'}}}\sum_{i\in \sta} \mb{I}_{\mark = i\ev{v}} \brate\vjpara{v}{B_{j'}}\stpara{i}\tmepro{\rt}{\Xg}{}.
\label{Uq::Xg-int2}
\end{equation}

Consider the following candidate for the \(\Xg\vind{\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)}\)-intensity of \(\rp\), 

\[\cratee(\rt,\mark) \defeq \exmu{\Xg \sim \mm}{\ratee(\rt,\mark)\middle|\Xg\vind{\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)}\tmi{[0,\rt)}}.\]

By lemma \ref{Ex::filtering}, \(\cratee\) is the intensity if it has a \(\pr\times\Sm\)-a.s. left-continuous modification with respect to \(\rt\). Since \(\ratee\) is a countable sum of elements of which finitely many (one) are nonzero for any given argument \((\rt,\mark)\), it suffices to prove that the conditional expectation of each element of equation \eqref{Uq::Xg-int} is also left continuous. Fix some \(\mark \in \sta^A\).

\skipLine

\tb{Begin verification of lemma \ref{Ex::leftmod}:}

\skipLine

This is exactly the same as the verification in the proof lemma \ref{Uq::marg} with only the values of \(\tg{W}\) and \(\tg{W'}\) changing.

\skipLine

\tb{End verification of lemma \ref{Ex::leftmod}:}

\skipLine

\ind Now we evaluate \(\cratee\) for different \(\kappa\). Suppose \(\kappa = i\ev{v}\), where \(i \in \sta\) and \(v\in A\) are fixed.

\begin{description}
\item[Case 1: ] \(v \in \phi_j(C_j)\).

By assumption \ref{a::admissible}\tb{(f), there exists a \(j'\) such that \(\dgneigh{G}{B_{j'}} \subseteq \phi_j(C_j\cup \gneigh{G}{B_j})\), and \(v \in \gneigh{G}{B_{j'}}\)}. Thus, \(\cratee(\rt,\mark) = \brate\vjpara{v}{B_{j'}}\stpara{i}\tmepro{\rt}{\Xg}{}\).

\item[Case 2: ] \(v\in \phi_j(\gneigh{G}{B_j})\). 

Because \(\phi_j\) is an automorphism, \(\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right) \subseteq A\) and \(\cl{v} \subseteq C_j\cup\dgneigh{G}{B_j}\), we can conclude that \(v \in \inte{A}\). Since \(\rate\stpara{i}\tmepro{\rt}{\Xg\vind{\cl{v}}}{}\) is \(\F\vpara{\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)}\tpara{\rt-}\)-measurable, we can conclude that \(\cratee(\rt,\mark) = \rate\stpara{i}\tmepro{\rt}{\Xg\vind{\cl{v}}}{}\).

\item[Case 3: ] \(v \in \phi_j(\dgneigh{G}{B_j}\setminus\gneigh{G}{B_j})\cap\inte{A}\).

Because \(\Xg\sim\mm\), \(\ratee(\rt,\mark) = \rate\stpara{i}\tmepro{\rt}{\Xg\vind{\cl{v}}}{}\) which is \(\F\vpara{\cl{v}}\tpara{\rt-}\)-measurable. We can consider this to be a measurable function of \(\Xg\vind{A\setminus\phi_j(C_j)}\tmi{[0,\rt)}\). By applying \cite[lemma \ref{F-TL::Props}(e)]{F}, we get

\begin{align*}
\cratee(\rt,\mark) &= \ex{\rate\stpara{i}\tmepro{\rt}{\Xg\vind{\cl{v}}}{}\middle|\Xg\vind{\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)}\tmi{[0,\rt)}}\\
&= \ex{\rate\stpara{i}\tmepro{\rt}{\Xg\vind{\cl{v}}}{}\middle|\Xg\vind{\phi_j\left(\dgneigh{G}{B_j}\right)}\tmi{[0,\rt)}}\\
&= \bgrate\vjpara{v}{B_j}\stpara{i}\tmepro{\rt}{\Xg}{}.
\end{align*}

\item[Case 4: ] \(v \in \phi_j(\dgneigh{G}{B_j}\setminus\gneigh{G}{B_j})\cap \gneigh{G}{B_{j'}}\) for some \(j'\) not necessarily distinct from \(j\).

First, by assumption \ref{a::admissible}\tb{(h), \(\phi_j(C_j)\cap\dgneigh{G}{B_{j'}}= \emptyset\)}. Because \(\Xg\sim\mm\), \(\ratee(\rt,\mark) = \brate\vjpara{v}{B_{j'}}\stpara{i}\tmepro{\rt}{\Xg}{}\) which is \(\F\vpara{\dgneigh{G}{B_{j'}}}\tpara{\rt-}\)-measurable. We can consider this to be a measurable function of \(\Xg\vind{A\setminus\phi_j(C_j)}\tmi{[0,\rt)}\). By applying \cite[lemma \ref{F-TL::Props}(e)]{F}, we get

\begin{align*}
\cratee(\rt,\mark) &= \ex{\brate\vjpara{v}{B_{j'}}\stpara{i}\tmepro{\rt}{\Xg}{}\middle|\Xg\vind{\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)}\tmi{[0,\rt)}}\\
&= \ex{\brate\vjpara{v}{B_{j'}}\stpara{i}\tmepro{\rt}{\Xg}{}\middle|\Xg\vind{\phi_j\left(\dgneigh{G}{B_j}\right)}\tmi{[0,\rt)}}\\
&= \bcrate\vjpara{v}{B_j}\stpara{i}\tmepro{\rt}{\Xg}{}.
\end{align*}
\end{description}

The lemma follows by direct application of \cite[Exercise 14.7.1]{DalVer08}.
\end{proof}

As we extend \(\mm\) to larger processes, it's easiest to look at these larger processes in terms of their density with respect to a standard process.

\begin{defn}
Let \(\poiss\) be a Poisson random measure on \(\sta\times\mb{R}^2\) with intensity \(\Sm\times\leb\). Define \(\Xh\) by,

\[\Xh\vind{v}\tme{t} = \Xh\vind{v}\tme{0} + \int_{\sta}\int_{(0,t]\times (0,1]}i\,\poiss(dr,ds,di).\]

\ind Let \(\mmm = \law(\Xh)\). Suppose \(\mm\vpara{v}\tpara{0}\ll\mmm\tpara{0}\) for all \(v\in A\). Let \(\{\mmm\vind{v}:v\in V\}\) be the distributions of a sequence of i.i.d. copies of the measure \(\mmm\). For any \(U\subseteq V\), let 

\[\mmm\vpara{U} = \otimes_{v\in U} \mm\vpara{v}.\]

Finally, for any \(T < \infty\) and \(t\in [0,T)\), let \(\mm\vpara{U}\tpara{t}\) be the restriction of \(\mm\vpara{U}\) to c\`adl\`ag processes defined on \([0,T)\) (see \cite[section \ref{F-not::p}]{F}).
\label{Uq::eta}
\end{defn}

We now have to describe how to extend the graph \(G\vind{A}\).

\begin{defn}
As in assumption \ref{a::admissible}, let \(A\indx{1} = A\cup\left(\bigcup_{i=1}^\Sm C_i\right)\). By assumption \ref{a::admissible}, we can find branches of \(A\indx{1}\), \(\{B_i\indx{1}\}_{i=1}^{\Sm\indx{1}}\). Let \(C_i\indx{1} = B_i\indx{1}\cap\gneigh{G}{A\indx{1}}\). Finally, for all \(i = 1,\dots,\Sm\indx{1}\), let \(\phi_i\indx{1}\) be a symmetry of \(\Xf\) mapping \(C_i\indx{1}\cup \dgneigh{G}{B\indx{1}_i}\) to a subset of \(A\). We can assume without loss of generality that \(\phi_i\indx{1}(C_i\indx{1}\cup \dgneigh{G}{B\indx{1}_i}) = \phi_{j\indx{1}_i}(C_{j\indx{1}_i}\cup\dgneigh{G}{B_{j\indx{1}_i}})\) for some \(j\indx{1}_i \in \{1,\dots,\Sm\}\).

\ind In general, let \(A\indx{k} = A\indx{k-1} \cup \left(\bigcup_{i=1}^{\Sm\indx{k}} C_i\indx{k-1}\right)\). Again, by assumption \ref{a::admissible}, there exist branches of \(A\indx{k}\), \(\{B_i\indx{k}\}_{i=1}^{\Sm\indx{k}}\). Let \(C_i\indx{k} = B_i\indx{k}\cap \gneigh{G}{A\indx{k}}\). Finally, for all \(i=1,\dots,\Sm\indx{k}\), \(\phi_i\indx{k}\) is the symmetry of \(\Xf\) mapping \(C_i\indx{k}\cup\dgneigh{G}{B_i\indx{k}}\) to \(\phi_{j\indx{k}_i}(C_{j\indx{k}_i}\cup\dgneigh{G}{B_{j\indx{k}_i}})\) for some \(j\indx{k}_i \in \{1,\dots,\Sm\}\).
\label{Uq::Extnot}
\end{defn}

And now we begin the core argument. Here we construct a sequence of processes on a sequence of increasing spaces whose marginal distributions are consistent with each other and \(\mm\).

\begin{lem}
Fix \(k \in \mb{N}\). Let \(\mm\indx{k} = \law(\Xg\indx{k})\) where \(\Xg\indx{k}\) is the unique strong solution to the following SDE:

\begin{equation}
\Xg\indx{k}\vind{v}\tme{t} = \Xg\indx{k}\vind{v}\tme{0} + 
\begin{cases}
\int_\sta\int_{(0,t]\times(0,\infty)} i\mb{I}_{r \leq \brate\vjpara{v}{B\indx{k}_j}\stpara{i}\tmepro{s}{\Xg}{}}\,\poiss\poissv{v}(dr,ds,di) &\te{ if } v \in \gneigh{G}{B\indx{k}_j}\\
\int_\sta\int_{(0,t]\times(0,\infty)} i\mb{I}_{r \leq \rate\stpara{i}\tmepro{s}{\Xg\vind{\cl{v}}}{}}\,\poiss\poissv{v}(dr,ds,di) &\te{ if } v \in A\indx{k-1}
\end{cases}.
\label{Uq::exteqn}
\end{equation}

Here \(\brate\) is defined by,

\[\brate\vjpara{v}{B\indx{k}_j}\stpara{i}\tmepro{t}{\xg}{} \defeq \exmu{\Xh\sim \mm}{\rate\stpara{i}\tmepro{t}{\Xh\vind{\cl{\phi_j\indx{k}(v)}}}{}\middle|\Xh\vind{\phi_j\indx{k}\left(\dgneigh{G}{B\indx{k}_j}\right)}\tmi{[0,t)} = \xg\indx{k}\vind{\dgneigh{G}{B\indx{k}_j}}\tmi{[0,t)}} \te{ for } A\indx{k}\te{ admissible, and } v \in \gneigh{G}{B\indx{k}_j}.\]

Then for any \(k' \leq k\), \(\proj\psf\vpara{A\indx{k'}}(\mm\indx{k}) = \mm\indx{k'}\) and \(\proj\psf\vpara{A}(\mm\indx{k}) = \mm\).
\label{Uq::ext}
\end{lem}

\begin{proof}
Let \(\mmm\vpara{V}\) be as defined in definition \ref{Uq::eta}. Recall that \(\rp\defeq \pmap(\Xg)\) maps \(\Xg\) (the solution to equations \eqref{Main::local}-\eqref{Main::fixed}) to a point process coinciding with the jumps of \(\Xg\). This point process has intensity,

\[\ratee\prc{\mm}(\rt,\mark) = \begin{cases}
\brate\vjpara{v}{B_j}\stpara{i}\tmepro{\rt}{\Xg}{} &\te{ if } v \in \gneigh{G}{B_j}\te{ and } \mark = i\ev{v}\\
\rate\stpara{i}\tmepro{\rt}{\Xg\vind{\cl{v}}}{} &\te{ if } v \in \inte{A}\te{ and } \mark = i\ev{v}\\
0 &\te{ otherwise}
\end{cases}.\]

Let \(\mmm\indx{0} \defeq \mmm\vpara{A}\). Then \(\pmap\psf(\mmm\indx{0})\) has intensity,

\[\ratee\prc{\mmm\indx{0}}(\rt,\mark) = 
\begin{cases}
1 &\te{ if } \mark\in  \{i\ev{v}: i \in \sta,v \in A\}\\
0 &\te{ otherwise}
\end{cases}.\]

\tr{Later be more precise with definitions. For now, this should be clear enough as I'm using \(\ds\) as a shorthand rather than a mapping.} Define the following mapping where \(f\) is a function and \(\Xh \in \cad\vpara{U}\) for some finite \(U \subseteq V\). Suppose the \(k\)th jump of the \(v\)th component of \(\Xh\) happens at time \(\rt\vpara{v}\it{k}\), and \(\Xh\tme{\rt\vpara{v}\it{k}} - \Xh\tme{\rt\vpara{v}\it{k}-} = \mark\vpara{v}\it{k}\). 

\begin{equation}
\ds\vpara{v}\tpara{t}(\Xh,f): = \sum_{0 < \rt\vpara{v}\it{k}\leq t} \log f(\Xh\tmi{[0,\rt\vpara{v}\it{k})},\mark\vpara{v}\it{k}) - \int_{\sta\times[0,t)} [f(\Xh\tmi{[0,s)},i) - 1]\,\Sm(di)\,ds.
\label{Uq::ds}
\end{equation}

Now, let \(\{(\rt\it{k},\mark\it{k}):k\in\mb{N}\}\) be the events of \(\pmap(\Xg)\). Let \(\mark\it{k} = i\it{k}\ev{v\it{k}}\). Let \(\{(\rt\it{k}\vpara{v},\mark\it{k}\vpara{v}):k\in\mb{N}\}\) be the events of \(\pmap\vpara{v}(\Xg)\). Note that \(\mark\it{k}\vpara{v} \in \sta\). Then by lemma \ref{ref::Lnat},

\begin{align*}
\dense\tpara{t}(\Xg)&\defeq \frac{d\mm\tpara{t}}{d\mmm\tpara{t}\indx{0}}\\
&= \frac{d\mm\tpara{0}}{d\mmm\tpara{0}\indx{0}}\exp\left(\sum_{0< \rt\it{k}\leq t} \log\left(\ratee\prc{\mm}(\rt\it{k},\mark\it{k})\right) - \sum_{v \in A}\int_{\sta\times (0,t]} [\ratee\prc{\mm}(s,i) - 1]\,\Sm(di)\,ds\right)\\
&= \frac{d\mm\tpara{0}}{d\mmm\tpara{0}\indx{0}}\exp\Bigg(\sum_{j=1}^\psize \sum_{v \in \gneigh{G}{B_j}}\left(\sum_{0 < \rt\it{k}\vpara{v}\leq t} \log\left(\brate\vjpara{v}{B_j}\stpara{\mark\it{k}\vpara{v}}\tmepro{\rt\it{k}\vpara{v}}{\Xg}{}\right) - \int_{\sta\times (0,t]} [\brate\vjpara{v}{B_j}\stpara{i}\tmepro{s}{\Xg}{} - 1]\,\Sm(di)\,ds\right) \\
&\hspace{24 pt} + \sum_{v \in \inte{A}}\left(\sum_{0 < \rt\it{k}\vpara{v}\leq t} \log\left(\rate\stpara{\mark\it{k}\vpara{v}}\tmepro{\rt\it{k}\vpara{v}}{\Xg\vind{\cl{v}}}{}\right) - \int_{\sta\times (0,t]} [\rate\stpara{i}\tmepro{s}{\Xg\vind{\cl{v}}}{} - 1]\,\Sm(di)\,ds\right)\Bigg)\\
&= \frac{d\mm\tpara{0}}{d\mmm\tpara{0}\indx{0}}\exp\left(\sum_{j=1}^{\psize}\sum_{v\in \gneigh{G}{B_j}} \ds\vpara{v}\tpara{t}(\Xg\vind{\dgneigh{G}{B_j}},\brate\vjpara{v}{B_j}\stpara{\cdot}) + \sum_{v\in\inte{A}}\ds\vpara{v}\tpara{t}(\Xg\vind{\cl{v}},\rate\stpara{\cdot})\right).
\end{align*}

By a similar computation, apply lemma \ref{Uq::marg} to get,

\begin{align*}
\densen\jpara{j}\tpara{t}(\Xg\vind{\phi_j(\dgneigh{G}{B_j})}) &\defeq \frac{d\mm\vpara{\phi_j(\dgneigh{G}{B_j})}\tpara{t}}{d\mmm\vpara{\phi_j(\dgneigh{G}{B_j})}\tpara{t}}\\
&= \frac{d\mm\vpara{\phi_j(\dgneigh{G}{B_j})}\tpara{0}}{d\mmm\vpara{\phi_j(\dgneigh{G}{B_j})}\tpara{0}}\exp\Bigg(\sum_{j'=1}^\psize \sum_{v \in \phi_j(\dgneigh{G}{B_j})\cap \gneigh{G}{B_{j'}}} \ds\vpara{v}\tpara{t}\left(\Xg\vind{\phi_j(\dgneigh{G}{B_j})},\bcrate\vjpara{v}{B_j}\stpara{\cdot}\right)\\
&\hspace{24 pt} + \sum_{v \in \phi_j(\dgneigh{G}{B_j})\cap\inte{A}} \ds\vpara{v}\tpara{t}\left(\Xg\vind{\phi_j(\dgneigh{G}{B_j})},\bgrate\vjpara{v}{B_j}\stpara{\cdot}\right)\Bigg)
\end{align*}

Apply lemma \ref{Uq::marg2} and another similar computation to get,

\begin{align*}
\denseph\jpara{j}\tpara{t}(\Xg\vind{\phi_j(C_j\cup \dgneigh{G}{B_j})}) &\defeq \frac{d\mm\vpara{\phi_j(C_j\cup \dgneigh{G}{B_j})}\tpara{t}}{d\mmm\vpara{\phi_j(C_j\cup \dgneigh{G}{B_j})}\tpara{t}}\\
&= \frac{d\mm\vpara{\phi_j(C_j\cup \dgneigh{G}{B_j})}\tpara{0}}{d\mmm\vpara{\phi_j(C_j\cup \dgneigh{G}{B_j})}\tpara{0}}\exp\Bigg(\sum_{j' = 1}^{\psize}\sum_{v \in \phi_j(C_j)\cap\gneigh{G}{B_{j'}}} \ds\vpara{v}\tpara{t}\left(\Xg\vind{\dgneigh{G}{B_{j'}}},\brate\vjpara{v}{B_{j'}}\stpara{\cdot}\right) + \sum_{v \in \phi_j(\gneigh{G}{B_j})} \ds\vpara{v}\tpara{t}\left(\Xg\vind{\cl{v}},\rate\stpara{\cdot}\right)\\
&\hspace{24pt} + \sum_{j'=1}^\psize \sum_{v \in \phi_j(\dgneigh{G}{B_j}\setminus\gneigh{G}{B_j})\cap \gneigh{G}{B_{j'}}} \ds\vpara{v}\tpara{t}\left(\Xg\vind{\phi_j(\dgneigh{G}{B_j})},\bcrate\vjpara{v}{B_j}\stpara{\cdot}\right)\\
&\hspace{24 pt} + \sum_{v \in \phi_j(\dgneigh{G}{B_j}\setminus\gneigh{G}{B_j})\cap\inte{A}} \ds\vpara{v}\tpara{t}\left(\Xg\vind{\phi_j(\dgneigh{G}{B_j})},\bgrate\vjpara{v}{B_j}\stpara{\cdot}\right)\Bigg)
\end{align*}

Applying the fact that \(\mm\tpara{0}\) is assumed to be a product measure,

\begin{align}
\mdense\jpara{j}\tpara{t}(\Xg\vind{\phi_j(C_j)};\xg\vind{\phi_j(\dgneigh{G}{B_j})}) &\defeq \frac{\denseph\jpara{j}\tpara{t}(\Xg\vind{\phi_j(C_j)};\xg\vind{\phi_j(\dgneigh{G}{B_j})})}{\densen\jpara{j}\tpara{t}(\xg\vind{\phi_j(\dgneigh{G}{B_j})})}\nonumber\\
&= \frac{\frac{d\mm\vpara{\phi_j(C_j\cup \dgneigh{G}{B_j})}\tpara{0}}{d\mmm\vpara{\phi_j(C_j\cup \dgneigh{G}{B_j})}\tpara{0}}}{\frac{d\mm\vpara{\phi_j(\dgneigh{G}{B_j})}\tpara{0}}{d\mmm\vpara{\phi_j(\dgneigh{G}{B_j})}\tpara{0}}}\exp\Bigg(\sum_{j' = 1}^{\psize}\sum_{v \in \phi_j(C_j)\cap\gneigh{G}{B_{j'}}} \ds\vpara{v}\tpara{t}\left(\Xg\vind{\dgneigh{G}{B_{j'}}\cap\phi_j(C_j)};\xg\vind{\dgneigh{G}{B_{j'}}\cap\phi_j(\dgneigh{G}{B_j})},\brate\vjpara{v}{B_{j'}}\stpara{\cdot}\right)\nonumber\\
&\hspace{24pt} + \sum_{v \in \phi_j(\gneigh{G}{B_j})} \left(\ds\vpara{v}\tpara{t}\left(\Xg\vind{\cl{v}\cap\phi_j(C_j)};\xg\vind{\cl{v}\cap\phi_j(\dgneigh{G}{B_j})},\rate\stpara{\cdot}\right) - \ds\vpara{v}\tpara{t}\left(\xg\vind{\phi_j(\dgneigh{G}{B_j})},\bgrate\vjpara{v}{B_j}\stpara{\cdot}\right)\right)\nonumber\\
&\hspace{24pt} +  \sum_{j'=1}^\psize \sum_{v \in \phi_j(\dgneigh{G}{B_j}\setminus\gneigh{G}{B_j})\cap \gneigh{G}{B_{j'}}} \left(\ds\vpara{v}\tpara{t}\left(\xg\vind{\phi_j(\dgneigh{G}{B_j})},\bcrate\vjpara{v}{B_j}\stpara{\cdot}\right) - \ds\vpara{v}\tpara{t}\left(\xg\vind{\phi_j(\dgneigh{G}{B_j})},\bcrate\vjpara{v}{B_j}\stpara{\cdot}\right)\right)\nonumber\\
&\hspace{24pt} +  \sum_{v \in \phi_j(\dgneigh{G}{B_j}\setminus\gneigh{G}{B_j})\cap\inte{A}} \left(\ds\vpara{v}\tpara{t}\left(\xg\vind{\phi_j(\dgneigh{G}{B_j})},\bgrate\vjpara{v}{B_j}\stpara{\cdot}\right) - \ds\vpara{v}\tpara{t}\left(\xg\vind{\phi_j(\dgneigh{G}{B_j})},\bgrate\vjpara{v}{B_j}\stpara{\cdot}\right)\right)\Bigg)\nonumber\\
&= \frac{d\mm\vpara{\phi_j(C_j)}\tpara{0}}{d\mmm\vpara{\phi_j(C_j)}\tpara{0}}\exp\Bigg(\sum_{j' = 1}^{\psize}\sum_{v \in \phi_j(C_j)\cap\gneigh{G}{B_{j'}}} \ds\vpara{v}\tpara{t}\left(\Xg\vind{\dgneigh{G}{B_{j'}}\cap\phi_j(C_j)};\xg\vind{\dgneigh{G}{B_{j'}}\cap\phi_j(\dgneigh{G}{B_j})},\brate\vjpara{v}{B_{j'}}\stpara{\cdot}\right)\nonumber\\
&\hspace{24pt} + \sum_{v \in \phi_j(\gneigh{G}{B_j})} \left(\ds\vpara{v}\tpara{t}\left(\Xg\vind{\cl{v}\cap\phi_j(C_j)};\xg\vind{\cl{v}\cap\phi_j(\dgneigh{G}{B_j})},\rate\stpara{\cdot}\right) - \ds\vpara{v}\tpara{t}\left(\xg\vind{\phi_j(\dgneigh{G}{B_j})},\bgrate\vjpara{v}{B_j}\stpara{\cdot}\right)\right)\Bigg)
\label{Uq::M}
\end{align}

By definition, 

\[\densen\jpara{j}\tpara{t}(\xg\vind{\phi_j(\dgneigh{G}{B_j})}) = \exmu{\mmm\vpara{\phi_j(C_j)}\tpara{t}}{\denseph\jpara{j}\tpara{t}(\Xg\vind{\phi_j(C_j)};\xg\vind{\phi_j(\dgneigh{G}{B_j})})}.\]

Thus,

\[\exmu{\mmm\vpara{\phi_j(C_j)}\tpara{t}}{\mdense\jpara{j}\tpara{t}(\Xg\vind{\phi_j(C_j)};\xg\vind{\phi_j(\dgneigh{G}{B_j})})} = \frac{\densen\jpara{j}\tpara{t}(\xg\vind{\phi_j(\dgneigh{G}{B_j})})}{\densen\jpara{j}\tpara{t}(\xg\vind{\phi_j(\dgneigh{G}{B_j})})} = 1.\]

Thus, \(\mdense\jpara{j}\tpara{t}\) is the density of the distribution of \(\Xg\vind{\phi_j(C_j)}\) conditioned on \(\Xg\vind{\phi_j(\dgneigh{G}{B_j})}\) with respect to \(\mmm\vpara{\phi_j(C_j)}\tpara{t}\). This can be used to extend \(\mm\) to larger domains. To do this, consider the following mappings \(\dense\indx{k}\tpara{t}: \cad\vpara{A\indx{k}}\tpara{t} \ra \mb{R}^+\):

\[\dense\indx{0}\tpara{t}(\xg\indx{0}) = \dense\tpara{t}(\xg\indx{0}).\]

\[\dense\indx{k+1}\tpara{t}(\xg\indx{k+1}) = \dense\indx{k}\tpara{t}(\xg\indx{k+1}\vind{A\indx{k}})\prod_{j=1}^{\psize\indx{k}}\mdense\jpara{j\indx{k}_j}\tpara{t}\left(\xg\indx{k+1}\vind{C_j\indx{k}};\xg\indx{k+1}\vind{\dgneigh{G}{B\indx{k}_j}}\right).\]

Let \(\mmm\indx{k} \defeq \mmm\vpara{A\indx{k}}\) for all \(k\in \mb{N}\). I claim that,

\[\dense\indx{k}\tpara{t}(\xg\indx{k}) = \frac{d\mm\indx{k}\tpara{0}}{d\mmm\indx{k}\tpara{0}}\exp\left(\sum_{j=1}^{\psize\indx{k}}\sum_{v\in \gneigh{G}{B_j\indx{k}}} \ds\vpara{v}\tpara{t}\left(\xg\indx{k}\vind{\dgneigh{G}{B_j\indx{k}}},\brate\vjpara{v}{B\indx{k}_{j}}\stpara{\cdot}\right) + \sum_{v \in A\indx{k-1}} \ds\vpara{v}\tpara{t}\left(\xg\indx{k}\vind{\cl{v}},\rate\stpara{\cdot}\right)\right),\]

where \(\brate\) is defined as in the statement of lemma \ref{Uq::ext}. To prove this, we first need to understand some properties of \(\mdense\). Fix some \(j \in \{1,\dots,\psize\indx{k}\}\). Let \(j' = j\indx{k}_j\) (as defined in definition \ref{Uq::Extnot}). Let \(\phi = \phi\indx{k}_j\). Apply equation \eqref{Uq::M}, and let \(\xg\vind{v} = \xg\indx{k+1}\vind{\phi^{-1}(v)}\) for all \(v \in A\). First, notice that for any \(j'' \in \{1,\dots,\psize\}\) and \(v \in \gneigh{G}{B_{j''}}\cap\phi(C\indx{k}_j\cup\dgneigh{G}{B\indx{k}_{j}})\), \tb{(assumption \ref{a::admissible}(g)(j)?) there exists a \(j'''(v) \in \{1,\dots,\psize\indx{k+1}\}\) such that \(\phi^{-1}(\dgneigh{G}{B_{j''}}) = \dgneigh{G}{B\indx{k+1}_{j'''(v)}}\) for some \(j'''(v)\) such that \(\phi^{-1}(v) \in \dgneigh{G}{B\indx{k+1}_{j'''(v)}}\). }

\begin{align}
\brate\vjpara{v}{B_{j''}}\stpara{i}\tmepro{t}{\xg\vind{\dgneigh{G}{B_{j''}}}}{} &= \exmu{\Xg\sim \mm}{\rate\stpara{i}\tmepro{t}{\Xg\vind{\cl{\phi_{j''}(v)}}}{}\middle|\Xg\vind{\phi_{j''}(\dgneigh{G}{B_{j''}})}\tmi{[0,t)} = \xg\vind{\dgneigh{G}{B_{j''}}}\tmi{[0,t)}}\nonumber\\
&=\exmu{\Xg\sim \mm}{\rate\stpara{i}\tmepro{t}{\Xg\vind{\cl{\phi_{j''}(v)}}}{}\middle|\Xg\vind{\phi_{j''}(\dgneigh{G}{B_{j''}})}\tmi{[0,t)} = \xg\indx{k+1}\vind{\dgneigh{G}{B\indx{k+1}_{j'''(v)}}}\tmi{[0,t)}}\nonumber\\
&= \brate\vjpara{\phi^{-1}(v)}{B\indx{k+1}_{j'''(v)}}\stpara{i}\tmepro{t}{\xg\indx{k+1}\vind{\dgneigh{G}{B\indx{k+1}_{j'''(v)}}}}{}
\label{Uq::brateup}
\end{align}

Next,

\begin{align}
\rate\stpara{i}\tmepro{t}{\xg\vind{\cl{v}}}{} &=\rate\stpara{i}\tmepro{t}{\xg\indx{k+1}\vind{\cl{\phi^{-1}(v)}}}{}.
\label{Uq::rateup}
\end{align}

Finally, for \(v \in \phi_{j'}(\gneigh{G}{B_{j'}})\), \(v \in \inte{A}\), so 

\begin{align}
\bgrate\vjpara{v}{B_{j'}}\stpara{i}\tmepro{t}{\xg\vind{\phi_{j'}(\dgneigh{G}{B_{j'}})}}{} &= \exmu{\Xg\sim\mm}{\rate\stpara{i}\tmepro{t}{\Xg\vind{\cl{v}}}{}\middle|\Xg\vind{\phi_{j'}(\dgneigh{G}{B_{j'}})}\tmi{[0,t)} = \xg\vind{\phi_{j'}(\dgneigh{G}{B_{j'}})}\tmi{[0,t)}}\nonumber\\
&= \exmu{\Xg\sim\mm}{\rate\stpara{i}\tmepro{t}{\Xg\vind{\cl{v}}}{}\middle|\Xg\vind{\phi(\dgneigh{G}{B\indx{k}_{j'}})}\tmi{[0,t)} = \xg\indx{k+1}\vind{\dgneigh{G}{B\indx{k}_{j}}}\tmi{[0,t)}}\nonumber\\
&= \brate\vjpara{\phi^{-1}(v)}{B\indx{k}_j}\stpara{i}\tmepro{t}{\xg\indx{k+1}\vind{\dgneigh{G}{B\indx{k}_j}}}{}.
\label{Uq::bgrateup}
\end{align}

Now, notice that \tb{\(\dgneigh{G}{B_{j''}} \cap \phi_{j'}\left(C_{j'}\cup\dgneigh{G}{B_{j'}}\right) \in \{\dgneigh{G}{B_{j''}},\emptyset\}\) for all \(j',j'' \in \{1,\dots,\psize\}\).} Then,

\begin{align}
\mdense\jpara{j'}\tpara{t}&\left(\xg\indx{k+1}\vind{C_j\indx{k}};\xg\indx{k+1}\vind{\dgneigh{G}{B\indx{k}_j}}\right) = \mdense\jpara{j'}\tpara{t}\left(\xg\vind{\phi_{j'}(C_{j'})};\xg\vind{\phi_{j'}(\dgneigh{G}{B_{j'}})}\right)\nonumber\\
&= \frac{d\mm\vpara{\phi_{j'}(C_{j'})}\tpara{0}}{d\mmm\vpara{\phi_{j'}(C_{j'})}\tpara{0}}\left(\xg\vind{\phi_{j'}(C_{j'})}\right)\exp\Bigg(\sum_{j'' = 1}^\psize \sum_{v \in \phi_{j'}(C_{j'})\cap\gneigh{G}{B_{j''}}} \ds\vpara{v}\tpara{t}\left(\xg\vind{\dgneigh{G}{B_{j''}}\cap\phi_{j'}(C_{j'})};\xg\vind{\dgneigh{G}{B_{j''}}\cap\phi_{j'}(\dgneigh{G}{B_{j'}})},\brate\vjpara{v}{B_{j''}}\right)\nonumber\\
&\hspace{24 pt} + \sum_{v \in \phi_{j'}(\gneigh{G}{B_{j'}})}\left(\ds\vpara{v}\tpara{t}\left(\xg\vind{\cl{v}\cap\phi_{j'}(C_{j'})};\xg\vind{\cl{v}\cap\phi_{j'}(\dgneigh{G}{B_{j'}})},\rate\stpara{\cdot}\right) - \ds\vpara{v}\tpara{t}\left(\xg\vind{\phi_{j'}(\dgneigh{G}{B_{j'}})},\bgrate\vjpara{v}{B_{j'}}\right)\right)\nonumber\\
&\os{\te{assum. }\ref{a::padmin}}{=} \frac{d\mm\vpara{C\indx{k}_j}\tpara{0}}{d\mmm\vpara{C\indx{k}_j}\tpara{0}}\left(\xg\indx{k+1}\vind{C\indx{k}_{j}}\right)\exp\Bigg(\sum_{j'' = 1}^\psize \sum_{v \in \phi_{j'}(C_{j'})\cap\gneigh{G}{B_{j''}}} \ds\vpara{v}\tpara{t}\left(\xg\vind{\dgneigh{G}{B_{j''}}},\brate\vjpara{v}{B_{j''}}\right)\nonumber\\
&\hspace{24 pt} + \sum_{v \in \phi_{j'}(\gneigh{G}{B_{j'}})}\left(\ds\vpara{v}\tpara{t}\left(\xg\vind{\cl{v}},\rate\stpara{\cdot}\right) - \ds\vpara{v}\tpara{t}\left(\xg\vind{\phi_{j'}(\dgneigh{G}{B_{j'}})},\bgrate\vjpara{v}{B_{j'}}\right)\right)\nonumber\\
&\os{\te{eqns. }\ref{Uq::brateup}-\ref{Uq::bgrateup}}{=} \frac{d\mm\vpara{C\indx{k}_j}\tpara{0}}{d\mmm\vpara{C\indx{k}_j}\tpara{0}}\left(\xg\indx{k+1}\vind{C\indx{k}_{j}}\right)\exp\Bigg(\sum_{j'' = 1}^\psize \sum_{v \in \phi_{j'}(C_{j'})\cap\gneigh{G}{B_{j''}}} \ds\vpara{\phi^{-1}(v)}\tpara{t}\left(\xg\indx{k+1}\vind{\dgneigh{G}{B\indx{k+1}_{j'''(v)}}},\brate\vjpara{\phi^{-1}(v)}{B\indx{k+1}_{j'''(v)}}\right)\nonumber\\
&\hspace{24 pt} + \sum_{v \in \phi_{j'}(\gneigh{G}{B_{j'}})}\left(\ds\vpara{\phi^{-1}(v)}\tpara{t}\left(\xg\indx{k+1}\vind{\cl{\phi^{-1}(v)}},\rate\stpara{\cdot}\right) - \ds\vpara{\phi^{-1}(v)}\tpara{t}\left(\xg\indx{k+1}\vind{\dgneigh{G}{B\indx{k}_{j}}},\brate\vjpara{\phi^{-1}(v)}{B\indx{k}_{j}}\right)\right)\nonumber\\
&= \frac{d\mm\vpara{C\indx{k}_j}\tpara{0}}{d\mmm\vpara{C\indx{k}_j}\tpara{0}}\exp\Bigg(\sum_{j''' = 1}^{\psize\indx{k+1}} \sum_{v \in C\indx{k}_{j}\cap\gneigh{G}{B\indx{k+1}_{j'''}}} \ds\vpara{v}\tpara{t}\left(\xg\indx{k+1}\vind{\dgneigh{G}{B\indx{k+1}_{j'''}}},\brate\vjpara{v}{B\indx{k+1}_{j'''}}\right)\nonumber\\
&\hspace{24 pt} + \sum_{v \in \gneigh{G}{B\indx{k}_{j}}}\left(\ds\vpara{v}\tpara{t}\left(\xg\indx{k+1}\vind{\cl{v}},\rate\stpara{\cdot}\right) - \ds\vpara{v}\tpara{t}\left(\xg\indx{k+1}\vind{\dgneigh{G}{B\indx{k}_{j}}},\brate\vjpara{v}{B\indx{k}_{j}}\right)\right)
\label{Uq::Mk}
\end{align}

\tb{I assumed that \(C_j\indx{k}\cap\phi^{-1}(\gneigh{G}{B_{j''}}) = \gneigh{G}{B_{j'''}\indx{k+1}}\) for some \(j'''\). }Now we are ready to evaluate \(\dense\indx{k}\). First, notice that the inductive hypothesis holds for \(k=0\). Suppose it also holds for \(k\). Applying equation \eqref{Uq::Mk},

\begin{align*}
\dense\indx{k+1}\tpara{t}(\xg\indx{k+1}) &= \dense\indx{k}\tpara{t}(\xg\indx{k+1}\vind{A\indx{k}})\prod_{j=1}^{\psize\indx{k}}\mdense\jpara{j\indx{k}_j}\tpara{t}\left(\xg\indx{k+1}\vind{C_j\indx{k}};\xg\indx{k+1}\vind{\dgneigh{G}{B\indx{k}_j}}\right)\\
&= \frac{d\mm\indx{k}\tpara{0}}{d\mmm\indx{k}\tpara{0}}\left(\prod_{j=1}^{\psize\indx{k}}\frac{d\mm\vpara{C_j\indx{k}}}{d\mmm\vpara{C_j\indx{k}}}\right)\exp\Bigg(\sum_{j=1}^{\psize\indx{k}}\sum_{v\in \gneigh{G}{B_j\indx{k}}} \ds\vpara{v}\tpara{t}\left(\xg\indx{k+1}\vind{\dgneigh{G}{B\indx{k}_j}},\brate\vjpara{v}{B\indx{k}_j}\stpara{\cdot}\right) + \sum_{v \in A\indx{k-1}} \ds\vpara{v}\tpara{t}\left(\xg\indx{k+1}\vind{\cl{v}},\rate\stpara{\cdot}\right)\\
&\hspace{24 pt} + \sum_{j=1}^{\psize\indx{k}}\sum_{j'''=1}^{\psize\indx{k+1}}\sum_{v \in C_j\indx{k}\cap\gneigh{G}{B_{j'''}\indx{k+1}}}\ds\vpara{v}\tpara{t}\left(\xg\indx{k+1}\vind{\dgneigh{G}{B_{j'''}\indx{k+1}}},\brate\vjpara{v}{B\indx{k+1}_{j'''}}\stpara{\cdot}\right)\\
&\hspace{24pt} + \sum_{j=1}^{\psize\indx{k}}\sum_{v \in \gneigh{G}{B_j\indx{k}}}\left(\ds\vpara{v}\tpara{t}\left(\xg\indx{k+1}\vind{\cl{v}},\rate\stpara{\cdot}\right) - \ds\vpara{v}\tpara{t}\left(\xg\indx{k+1}\vind{\dgneigh{G}{B_j\indx{k}}},\brate\vjpara{v}{B\indx{k}_j}\stpara{\cdot}\right)\right)\Bigg)\\
&= \frac{d\mm\indx{k+1}\tpara{0}}{d\mmm\indx{k+1}\tpara{0}}\exp\left(\sum_{j=1}^{\psize\indx{k+1}}\sum_{v\in \dgneigh{G}{B_j\indx{k+1}}} \ds\vpara{v}\tpara{t}\left(\xg\indx{k+1}\vind{\dgneigh{G}{B\indx{k+1}_j}},\brate\vjpara{v}{B\indx{k+1}_j}\stpara{\cdot}\right) + \sum_{v \in A\indx{k}}\ds\vpara{v}\tpara{t}\left(\xg\vind{\cl{v}}\indx{k+1},\rate\stpara{\cdot}\right)\right)
\end{align*}

Notice that, by lemma \ref{ref::denpro}, \(\dense\indx{k} = \frac{d\mm\indx{k}\tpara{t}}{d\mmm\indx{k}\tpara{t}}\), where \(\mm\indx{k}\) is the law of the unique weak solution to equation \eqref{Uq::exteqn}. Fix some \(k \geq 1\). Then,

\begin{align*}
\frac{d\proj\tparapsf{t}\indx{k-1}(\mm\indx{k})}{d\mmm\indx{k-1}\tpara{t}} &= \int_{\cad\vpara{A\indx{k}\setminus A\indx{k-1}}\tpara{t}} \frac{d\mm\indx{k}\tpara{t}}{d\mmm\indx{k}\tpara{t}}\mmm\vpara{A\indx{k}\setminus A\indx{k-1}}\tpara{t}(d\Xg\indx{k}\vind{A\indx{k}\setminus A\indx{k-1}})\\
&=\int_{\cad\vpara{A\indx{k}\setminus A\indx{k-1}}\tpara{t}} \dense\indx{k}(\Xg\indx{k}\vind{A\indx{k}})\mmm\vpara{A\indx{k}\setminus A\indx{k-1}}\tpara{t}(d\Xg\indx{k}\vind{A\indx{k}\setminus A\indx{k-1}})\\
&=\int_{\cad\vpara{A\indx{k}\setminus A\indx{k-1}}\tpara{t}} \dense\indx{k-1}(\Xg\indx{k}\vind{A\indx{k-1}})\prod_{j=1}^{\psize\indx{k-1}}\mdense\jpara{j_j\indx{k-1}}\tpara{t}\left(\Xg\indx{k}\vind{C_j\indx{k-1}};\Xg\indx{k}\vind{\dgneigh{G}{B_j\indx{k-1}}}\right)\mmm\vpara{A\indx{k}\setminus A\indx{k-1}}\tpara{t}(d\Xg\indx{k}\vind{A\indx{k}\setminus A\indx{k-1}})\\
&=\dense\indx{k-1}(\Xg\indx{k}\vind{A\indx{k-1}})\prod_{j=1}^{\psize\indx{k-1}} \int_{\cad\vpara{C_j\indx{k-1}}\tpara{t}}\mdense\jpara{j_j\indx{k-1}}\tpara{t}\left(\Xg\indx{k}\vind{C_j\indx{k-1}};\Xg\indx{k}\vind{\dgneigh{G}{B_j\indx{k-1}}}\right)\mmm\vpara{C_j\indx{k-1}}\tpara{t}(d\Xg\indx{k}\vind{C_j\indx{k-1}})\\
&=\dense\indx{k-1}(\Xg\indx{k}\vind{A\indx{k-1}})\prod_{j=1}^{\psize\indx{k-1}} \exmu{\mmm\vpara{C_j\indx{k-1}}\tpara{t}}{\mdense\jpara{j_j\indx{k-1}}\tpara{t}\left(\Xg\indx{k}\vind{C_j\indx{k-1}};\Xg\indx{k}\vind{\dgneigh{G}{B_j\indx{k-1}}}\right)}\\
&=\dense\indx{k-1}(\Xg\indx{k}\vind{A\indx{k-1}})
\end{align*}

This proves that \(\proj\tparapsf{t}\vpara{A\indx{k-1}}(\mm\indx{k}\tpara{t}) = \mm\indx{k-1}\tpara{t}\). For any \(k' < k\),

\begin{align*}
\proj\tparapsf{t}\vpara{A\indx{k'}}(\mm\indx{k}\tpara{t}) &= \proj\tparapsf{t}\vpara{A\indx{k'}}\circ\cdots\circ\proj\tparapsf{t}\vpara{A\indx{k-1}}(\mm\indx{k}\tpara{t})\\
&=\proj\tparapsf{t}\vpara{A\indx{k'}}\circ\cdots\circ\proj\tparapsf{t}\vpara{A\indx{k-2}}(\mm\indx{k-1}\tpara{t})\\
&= \mm\indx{k'}\tpara{t}
\end{align*}

That concludes the proof.
\end{proof}

For any finite \(U \subset V\), there exists a \(k\) such that \(U \subseteq A\indx{k}\). We can define \(\mm\vpara{U} \defeq \proj\tparapsf{t}\vpara{U}(\mm\indx{k}\tpara{t})\). By lemma \ref{Uq::ext}, this definition is well-defined and independent of our choice of \(k\). By the Danielle-Kolmogorov Extension theorem \tr{(lemma C.11 of the main paper)}, there exists a unique measure \(\mm\vpara{V} \in \pmsr(\Omega\vpara{V})\) such that \(\proj\psf\vpara{U}(\mm\vpara{V}) = \mm\vpara{U}\) for all finite sets \(U\subseteq V\).

\ind Consider a probability space with canonical process \(\Xg\) such that \(\pr(\Xg \in \cdot) = \mm\vpara{V}(\cdot)\). By lemma \ref{Uq::ext}, we know that \(\Xg\vind{A\indx{k}} \sim \mm\indx{k}\) for all \(k\). Using a method analogous to the one used to prove \cite[Proposition 14.7.1]{DalVer08} (see appendix \ref{con}), we can construct two sequences of i.i.d. poisson processes, \(\{\poiss\poissv{v}:v \in V\}\) and \(\{\alt{\poiss}\poissv{v}:v \in V\}\) such that 

\begin{enumerate}
\item They each have intensity measure \(\leb\times\Sm\).

\item For any \(k \in \mb{N}\), \(\{\poiss\poissv{v},\alt{\poiss}\poissv{u}: v \in A\indx{k-1},u\in A\indx{k}\setminus A\indx{k-1}\}\) is also an i.i.d. sequence.

\item For every \(k\), \(\Xg\vind{A\indx{k}}\) is the almost surely unique solution to 

\begin{equation}
\Xg\vind{v}\tme{t} = \Xg\vind{v}\tme{0} + 
\begin{cases}
\int_\sta\int_{(0,t]\times(0,\infty)} \mb{I}_{r \leq \brate\vjpara{v}{B\indx{k}_j}\stpara{i}\tmepro{s}{\Xg}{}}\,\alt{\poiss}\poissv{v}(dr,ds,di)& \te{ if } v \in \gneigh{G}{B\indx{k}_j}, j \in \{1,\dots,\psize\indx{k}\}\\
\int_\sta\int_{(0,t]\times(0,\infty)} \mb{I}_{r \leq \rate\stpara{i}\tmepro{s}{\Xg\vind{\cl{v}}}{}}\,\poiss\poissv{v}(dr,ds,di)&\te{ if } v \in A\indx{k-1}
\end{cases}.
\label{Uq::extcomb}
\end{equation}

For any \(v \in V\), there exists a \(k\) such that \(\cl{v}\subseteq A\indx{k}\). 
\end{enumerate}

Then,

\begin{align*}
\Xg\vind{v}\tme{t} &= \Xg\vind{v}\tme{0} + \int_\sta\int_{(0,t]\times(0,\infty)} \mb{I}_{r \leq \rate\stpara{i}\tmepro{s}{\Xg\vind{\cl{v}}}{}}\,\poiss\poissv{v}(dr,ds,di)
\end{align*}

Since this holds for all \(v \in V\), we can conclude that \((\Xg,\{\poiss\poissv{v}:v \in V\})\) is a weak solution to \cite[equation \eqref{F-p::Xf}]{F}. However, by \cite[theorem \ref{F-wp::wp}]{F}, there is a unique strong solution to this equation. By \cite[proposition 2.10]{Kur07}, the weak solution to the equation is unique in law. Thus, \(\Xg \deq \Xf\gind{G} \sim \m\). But, by assumption, \(\Xg\sim \mm\vpara{V}\). Thus, \(\mm\vpara{V} = \m\), and \(\mm = \m\vpara{A}\).


\newpage

\appendix
\section{Representations on finite graphs}
\label{ref}

While proving the local approximation, we use three equivalent representations of a stochastic process on finite graphs. The first is the unique weak solution to an SDE driven by i.i.d. Poisson processes. The second is a marked point processes. The last is a density with respect to a reference process. We begin with the equivalence of a

\begin{lem}
Fix any \(T < \infty\). Let \(G  = (V,E) \in \Gs\) be a finite deterministic graph. Let \(\rate\vpara{v}\stpara{i}: [0,T] \times \cad\vpara{\cl{v}} \ra [0,\jumpibd{i}{T}]\) be a predictable \tr{left-continuous?} mapping. Let \(\{\poiss\poissv{v}:v \in V\}\) be a family of i.i.d. Poisson processes on \(\sta\times \mb{R}^2\) with intensity measure \(\Sm\times\leb\). Let \(\Xf\) be the unique weak solution to,

\begin{equation}
\Xf\vind{v}\tme{t} = \Xf\vind{v}\tme{0} + \int_\sta\int_{(0,t]\times (0,\infty)} i\mb{I}_{r \leq \rate\vpara{v}\stpara{i}\tmepro{s}{\Xf}{}}\,\poiss\poissv{v}(dr,ds,di)\te{ for } v \in V, t \in [0,T].
\label{ref::pro}
\end{equation}

Then \(\pmap(\Xf)\) is a marked point process with \(\Xf\)-predictable rate given by,

\begin{equation}
\ratee(\rt,\mark) = \sum_{v \in V} \sum_{i \in \sta} \mb{I}_{\mark = i\ev{v}} \rate\vpara{v}\stpara{i}\tmepro{\rt}{\Xf}{} \te{ for } \rt < T.
\label{ref::poi}
\end{equation}

\label{ref::propoi}
\end{lem}
\begin{proof}
The existence of a unique weak solution is obvious in the finite graph case, and for any realization of the Poisson processes, the solution can be constructed explicitly. The equivalent point process formulation is a restatement of the first part of \cite[exercise 14.7.I]{DalVer08} with slightly different notation.
\end{proof}

Any random element can be described in terms of a density with respect to another random element assuming absolute continuity. Before that, we begin with a lemma that slightly extends a result of Daley and Vere-Jones \cite{DalVer08}.

\tr{Fix notation here to match rest of the paper.}

\begin{prop}
Let \(\rp\) be a marked process adapted to the filtration \(\F\tpara{t} := \F\tpara{0}\wedge \mc{H}\tpara{t}\) where \(\mc{H}\) is its natural filtration of \(\rp\). Let the events and marks of \(\rp\) be given by \(\{(\rt\indx{j},\mark\indx{j})\}\) such that \(\{\rt\indx{j}\}\) is an almost surely increasing sequence. For \(i \in \{1,2\}\), let \(\pr\indx{i}\) be probability measures on the probability space such that \(\rp\) is non-explosive and simple with respect to both probability measures. Let \(\pr\indx{i}\tpara{t}\) be the restriction of \(\pr\indx{i}\) to \(\F\tpara{t}\). Suppose \(\F\tpara{0}\) describes a random variable, \(\Xf\), with law \(\mm\indx{i}\) under \(\pr\indx{i}\). If \(\rp\) has a strictly positive \(\pr\indx{1},\F\)-predictable intensity \(\rate\indx{1}\), then \(\pr\indx{2}\tpara{t} \ll \pr\indx{1}\tpara{t}\) for all \(t \in [0,\infty)\) if and only if there exists a non-negative, \(\F\)-predictable process \(\m\) such that \(\rp\) admits the \(\F\)-intensity \(\rate^2 = \m\rate^1\) under \(\pr\indx{2}\) and \(\mm^2 \ll \mm^1\). When this is satisfied, the likelihood ratio is the \(\pr\indx{1}\)-a.s. c\`adl\`ag process defined by 

\begin{equation}
L_t:= \frac{d\pr\indx{2}\tpara{t}}{d\pr\indx{1}\tpara{t}}(\rp) = \frac{d\mm^2}{d\mm^1}\left(\prod_{0<\rt^i\leq t} \m(\rt^i,\mark^i)\right)\exp\left(-\int_{(0,t]\times \spce}[\m(t,\mark) - 1]\rate^1(t,\mark)\,ds\,\Sm(d\mark)\right)
\label{ref::Lnat}
\end{equation}
\label{ref::radnikder}
\end{prop}

\begin{proof}
Let \(f\) be a bounded, \(\alt{\F}\tpara{t}\) measurable function to the real numbers. Let \(\m(t,k;\xg,\xf)\) be the value \(\m\) takes when \(\rp[0,t)=\xg[0,t)\) and \(\{\Xf=\xf\}\). Since \(\m\) is \(\alt{\F}\)-predictable, this is deterministic for any \(\xg,\xf\).

\[\mb{E}^2[f(\Xf,\rp[0,t])] = \int \mb{E}^2[f(\Xf,\rp[0,t])|\Xf=\xf]\,d\mm^2(\xf)\]

Note that for any fixed \(\xf \in \te{supp}(\Xf)\) and any \(i \in \{1,2\}\), there exists a regular conditional distribution \(\pr^{i,\xf}\) which describes the law of \(\rp\) conditioned on \(\Xf = \xf\).

\[\mb{E}^2[f(\Xf,\rp[0,t])] = \int \mb{E}^2_\xf[f(\xf,\rp[0,t])]\,d\mm^2(\xf)\]

Note that for any fixed \(\xf\), \(\pr^{i,\xf}\) and \(\rp\) satisfy the conditions of \cite[Theorem 14.4.I]{DalVer08}. So,

\[L_t(\rp,\xf):=\frac{d\pr^{2,\xf}\tpara{t}}{d\pr^{1,\xf}\tpara{t}}(\rp) = \left(\prod_{0<\rt^i\leq t} \m(\rt^i,\mark\indx{i};\rp,\xf)\right)\exp\left(-\int_{(0,t]\times\spce} [\m(s,k;\rp,\xf) - 1]\rate^1(s,k;\rp,\xf)\,ds\,\Sm(dk)\right)\]

Giving us,

\begin{align*}
\mb{E}^2\left[f(\Xf,\rp[0,t])\right] &= \int \mb{E}^2_\xf[f(\xf,\rp[0,t])]\,d\mm^2(\xf)\\
&=\int_{\spce} \mb{E}^1_\xf[f(\xf,\rp[0,t])L_t(\rp,\xf)]\,d\mm^2(\xf)\\
&= \int_{\spce} \frac{d\mm^2}{d\mm^1}(\xf) \mb{E}^1_\xf[f(\xf,\rp[0,t])L_t(\rp,\xf)]\,d\mm^1(\xf)\\
&= \mb{E}^1\left[f(\Xf,\rp[0,t])L_t(\rp,\Xf)\frac{d\mm^2}{d\mm^1}\right]
\end{align*}
\end{proof}

Now,

\begin{lem}
Define \((G,\Xf)\) as in lemma \ref{ref::propoi}. Let \(\m = \law(\Xf)\) and let \(\mmm \defeq \mmm\vpara{V}\) be defined as in definition \ref{Uq::eta}. Suppose \(\m\tpara{0} \ll \mmm\tpara{0}\) and for any \(t < \infty\). Then \(\m\tpara{t}\ll \mmm\tpara{t}\) and,

\begin{equation}
\frac{d\m\tpara{t}}{d\mmm\tpara{t}}(\xf) = \frac{d\m\tpara{0}}{d\mmm\tpara{0}}\exp\left(\sum_{v\in V} \ds\vpara{v}\tpara{t}(\xf,\rate\vpara{v}\stpara{\cdot})\right).
\label{ref::den}
\end{equation}
\label{ref::proden}
\end{lem}
\begin{proof}
Let \(\Xh \sim \mmm\). Then \(\pmap(\Xh)\) has rate 1. Furthermore, \(\xf \mapsto (\xf\tme{0},\pmap(\xf))\) marks a bijection. Therefore, it suffices to find the Radon-Nikodym derivative of \(\law(\Xf\tme{0},\pmap(\Xf))\) with respect to \(\law(\Xh\tme{0},\pmap(\Xh))\). We can apply lemma \ref{ref::radnikder} with \(\pr^1 = \mmm\tpara{t}\), \(\pr^2 = \m\tpara{t}\), \(\rate^1 \equiv 1\) and \(\rate^2 = \sum_{v \in V}\sum_{i\in\sta}\rate\vpara{v}\stpara{i}\tmepro{t}{\xf}{}\) and \(\m = \rate^2\).

\begin{align*}
\frac{d\m\tpara{t}}{d\mmm\tpara{t}}(\xf) &= \frac{d\m\tpara{0}}{d\mmm\tpara{0}}\left(\prod_{0 < \rt^j \leq t} \rate\vpara{v^j}\stpara{i^j}\tmepro{\rt^j}{\xf}{}\right)\exp\left(-\sum_{v \in V}\int_{(0,t]\times\sta}[\rate\vpara{v}\stpara{i}\tmepro{s}{\xf}{}\,ds\,\Sm(di)] \right)\\
&=\frac{d\m\tpara{0}}{d\mmm\tpara{0}}\exp\left(\sum_{v \in V}\ds\vpara{v}\tpara{t}(\xf,\rate\vpara{v}\stpara{\cdot}) \right).
\end{align*}
\end{proof}

Lastly, we do the reverse.

\begin{lem}
The converse of lemma \ref{ref::proden} holds.
\label{ref::denpro}
\end{lem}
\begin{proof}
By uniqueness of the Radon-Nikodym derivative, we can immediately extract the point process defined in equation \eqref{ref::poi} and the initial condition from the density given in equation \eqref{ref::den}. By applying the second part of \cite[exercise 14.7.I]{DalVer08}, we get equation \eqref{ref::pro}.
\end{proof}

\section{Construction of jointly embedded Poisson processes}
\label{con}

Use all notation and assumptions from section \ref{Uq}. By lemma \ref{Uq::ext} and the Danielle-Kolmogorov theorem \tr{citation needed}, there exists a \(\mm \in \pmsr(\cad\vpara{V})\) such that \(\mm\vpara{A\indx{k}}\) is the law of the unique weak solution to equation \eqref{Uq::exteqn} for all \(k\).

\ind Let \((\Omega,\F,\{\F\tpara{t}\},\pr)\) be a filtration space containing the sequence \(\{\ov{\poiss}\poissv{v}\}\) of i.i.d. Poisson processes on \(\sta\times(\mb{R}^+)^2\) with intensity measure \(\Sm\times\leb\). Suppose it also contains an \(\Xf \sim \mm\) independent of the Poisson processes. Finally include the independent family of uniform \([0,1]\) random variables \(\{\rv\vpara{v,m}\}\). 

\ind Fix some \(k \in \mb{N}\). Let \(\{(\rt\indx{m},\mark\indx{m},v\indx{m})\}\) be defined by,

\[\rt\indx{m} = \inf\{t > \rt\indx{m-1}: \delt\Xf\vind{A\indx{k}}\tme{t} \neq 0\} \te{ and } \delt\Xf\vind{A\indx{k}}\tme{\rt\indx{m}} = \mark\indx{m}\ev{v\indx{m}}.\]

Define the family \(\{\poiss\poissv{k,v}\}\) of Poisson processes by,

\begin{equation}
\poiss\poissv{k,v}(A) = \ov{\poiss}\poissv{v}\left(A \cap \{(r,t,i): r > \rate\stpara{i}\tmepro{t}{\Xf\vind{\cl{v}}}{}\}\right) + \left|\{(\rt\indx{m},\mark\indx{m},\rv\vpara{v,m}\rate\stpara{\mark\indx{m}}\tmepro{\rt\indx{m}}{\Xf\vind{\cl{v\indx{m}}}}{}) \in A:v\indx{m} = v\}\right|
\end{equation}

By the same argument as presented in the proof of \cite[proposition 14.7.I]{DalVer08}, \(\{\poiss\poissv{k,v}:v \in A\indx{k}\}\) is a sequence of i.i.d. Poisson processes with intensity measure \(\Sm\times\leb\). Furthermore, \((\Xf\vind{A\indx{k}},\{\poiss\poissv{k,v}:v \in A\indx{k}\})\) is a weak solution to equation \eqref{Uq::exteqn}. Finally, it's simple to show that for any \(v \in V\) and \(k,k'\) such that \(v \in A\indx{k-1}\cap A\indx{k'-1}\), \(\poiss\poissv{k,v} = \poiss\poissv{k',v}\) almost surely.

\ind Define \(\poiss\poissv{v} \defeq \poiss\poissv{k,v}\) for \(k\) such that \(v \in A\indx{k-1}\). Define \(\alt{\poiss}\poissv{v} = \poiss\poissv{k,v}\) where \(k\) is such that \(v \in \bdry{A\indx{k}}\). Then they satisfy the statements made at the end of section \ref{Uq}.

\section{Other Technical Lemmas}
\label{TL}
\tr{Double check notation. Make sure it matches the rest of the paper.}

\begin{thms}[Danielle-Kolmogorov Extension Theorem]
Let \(((\spce\indx{\alpha},\F\indx{\alpha}),\topo\indx{\alpha})\indxset{A}\) be a family of measurable spaces \((\spce\indx{\alpha},\F\indx{\alpha})\) equipped with a topology \(\topo\indx{\alpha}\). For each finite \(B \subset A\), let \(\m\indxset{B}\) be an inner regular probability measure on \(\F\indxset{B} \defeq \prod_{\alpha\in B} \F\indx{\alpha}\), obeying the following compatibility condition for all finite \(B\) and \(C\) such that \(C \subset B\subset A\):

\begin{itemize}
\item \(\proj\indxset{B}: \spce\indxset{A} \ra \spce\indxset{A}\) is defined by \(\proj\indxset{B}\left((\xf\indx{\alpha})\indxset{\alpha\in A}\right) = (\xf\indx{\alpha})\indxset{\alpha\in B}\).

\item \(\proj\indxset{C\leftarrow B}\left((\xf\indx{\alpha})\indxset{\alpha \in B}\right) = (\xf\indx{\alpha})\indxset{\alpha \in C}\).

\item For all events \(\evnt\indxset{C} \in \F\indxset{C}\),

\[\m\indxset{C}(\evnt\indxset{C}) = \m\indxset{B}\left(\proj\indxset{C\leftarrow B}^{-1}(\evnt\indxset{C})\right).\]
\end{itemize}

Then there exists a unique probability measure \(\m\indxset{A}\) on \(\F\indxset{A}\) such that \(\m\indxset{B}(\cdot) = \m\indxset{A}\left(\proj\indxset{B}^{-1}(\cdot)\right)\) for all finite \(B \subset A\).
\label{TL::DanKolExt}
\end{thms}

\begin{proof}
This is a restatement of Theorem 62 from \url{https://terrytao.wordpress.com/2010/10/30/245a-notes-6-outer-measures-pre-measures-and-product-measures/#more-4371}. \tr{TODO:: find a better source.}
\end{proof}

\newpage
\bibliographystyle{plain}
\bibliography{weekly_refs}
\end{document}
